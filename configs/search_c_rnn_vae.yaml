global:
  logging_params:
    log_dir: "logs"
    name: "search_c_rnn_vae"

  schedules_path: "tmp/nts_home_schedules.csv"
  loader_params:
    train_batch_size: 1024
    val_batch_size:  1024
    num_workers: 8

  trainer_params:
    min_epochs: 40
    max_epochs: 200
    patience: 20

  seed: 1234

  encoder_params:
    name: "sequence"
    duration: 1440
    jitter: 0.1

# base:
#   experiment_params:
#     LR: 0.01
#     weight_decay: 0.0
#     scheduler_gamma: 0.95
#     kld_weight: 0.001
    # model_params:
    #   name: "VAESeqLSTM"
    #   latent_dim: 6
    #   hidden_layers: 4
    #   hidden_size: 128
    #   dropout: 0.1

# 5x128:
#   experiment_params:
#     LR: 0.01
#     weight_decay: 0.0
#     scheduler_gamma: 0.95
#     kld_weight: 0.001
#   model_params:
#     name: "VAESeqLSTM"
#     latent_dim: 6
#     hidden_layers: 5
#     hidden_size: 128
#     dropout: 0.1

# 6x128:
#   experiment_params:
#     LR: 0.01
#     weight_decay: 0.0
#     scheduler_gamma: 0.95
#     kld_weight: 0.001
#   model_params:
#     name: "VAESeqLSTM"
#     latent_dim: 6
#     hidden_layers: 6
#     hidden_size: 128
#     dropout: 0.1

# 5x256:
#   experiment_params:
#     LR: 0.01
#     weight_decay: 0.0
#     scheduler_gamma: 0.95
#     kld_weight: 0.001
#   model_params:
#     name: "VAESeqLSTM"
#     latent_dim: 6
#     hidden_layers: 5
#     hidden_size: 256
#     dropout: 0.1

6x512:
  experiment_params:
    LR: 0.001
    weight_decay: 0.0
    scheduler_gamma: 0.95
    kld_weight: 0.001
  model_params:
    name: "VAESeqLSTM"
    latent_dim: 6
    hidden_layers: 6
    hidden_size: 512
    dropout: 0.1

