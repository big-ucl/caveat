seed: 12345

logging_params:
  log_dir: logs/sequence_models
  name: rnn_tune

tune:
  trials: 400
  prune: True
  timeout:  72000 # seconds

schedules_path: tmp/nts_schedules_2023.csv

loader_params:
  train_batch_size: 1024
  val_batch_size:  1024
  num_workers: 8

trainer_params:
  min_epochs: 100
  max_epochs: 200
  patience: 50

encoder_params:
  name: "continuous"
  max_length: 16
  norm_duration: 1440
  jitter: trial.suggest_float("jitter", 0, 0.3)
  fix_durations: True
  trim_eos: trial.suggest_categorical("trim_eos", [True, False])
  weighting: unit
  joint_weighting: unit

experiment_params:
  LR: trial.suggest_float("LR", 1e-4, 0.01, log=True)
  weight_decay: 0.02
  scheduler_gamma: 0.975
  kld_weight: 0.005
  duration_loss_weight: 200

model_params:
  name: "VAEContLSTM"
  hidden_n: trial.suggest_int("hidden_n", 2, 6)
  hidden_size: trial.suggest_categorical("hidden_size", [64, 128, 256, 512])
  latent_dim: 6
  dropout: trial.suggest_float("dropout", 0, 0.3)
  teacher_forcing_ratio: 0.5