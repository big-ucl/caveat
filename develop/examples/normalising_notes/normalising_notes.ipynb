{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalising for NLLLoss\n",
    "Divide NLL by log(N), where N is the size of the choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(nan)\n",
      "tensor(0.5516) tensor(0.7958)\n",
      "tensor(0.8900) tensor(0.8101)\n",
      "tensor(1.1101) tensor(0.8008)\n",
      "tensor(1.2883) tensor(0.8004)\n",
      "tensor(1.4584) tensor(0.8140)\n",
      "tensor(1.6098) tensor(0.8273)\n",
      "tensor(1.7186) tensor(0.8265)\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, 9):\n",
    "    o = torch.rand(128, n)\n",
    "    p = nn.Softmax(-1)(o)\n",
    "    lp = nn.LogSoftmax(-1)(o)\n",
    "    norm = np.log(n)\n",
    "    labels = torch.argmax(p, -1)\n",
    "\n",
    "    loss = nn.NLLLoss()(lp, labels)\n",
    "    nloss = loss / norm\n",
    "    print(loss, nloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalising for KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kld(mu: Tensor, log_var: Tensor) -> Tensor:\n",
    "    return torch.mean(\n",
    "        -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9069) tensor(0.9069)\n",
      "tensor(1.8243) tensor(0.9121)\n",
      "tensor(2.7375) tensor(0.9125)\n",
      "tensor(3.6475) tensor(0.9119)\n",
      "tensor(4.5428) tensor(0.9086)\n",
      "tensor(5.4654) tensor(0.9109)\n",
      "tensor(6.3581) tensor(0.9083)\n",
      "tensor(7.3023) tensor(0.9128)\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, 9):\n",
    "    fake = torch.rand(128, 128, n)\n",
    "    mu = fake.mean(dim=0)\n",
    "    log_var = torch.log(fake.var(dim=0))\n",
    "    loss = kld(mu, log_var)\n",
    "    nloss = loss / n\n",
    "    print(loss, nloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caveat",
   "language": "python",
   "name": "caveat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
