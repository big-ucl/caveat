{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#caveat","title":"CAVEAT","text":"<p>Deep generative models for human activity sequences.</p> <p> </p> <p>Work in progress</p> <p>Generate a synthetic data set or load your own using a data loader.</p> <p>Train a generative model.</p> <p>Test and compare your experiments using metrics.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>caveat is an actively maintained and utilised project.</p>"},{"location":"contributing/#how-to-contribute","title":"How to contribute","text":"<p>to report issues, request features, or exchange with our community, just follow the links below.</p> <p>Is something not working?</p> <p> Report a bug</p> <p>Missing information in our docs?</p> <p> Report a docs issue</p> <p>Want to submit an idea?</p> <p> Request a change</p> <p>Have a question or need help?</p> <p> Ask a question</p>"},{"location":"contributing/#developing-caveat","title":"Developing caveat","text":"<p>To find beginner-friendly existing bugs and feature requests you may like to start out with, take a look at our good first issues.</p>"},{"location":"contributing/#setting-up-a-development-environment","title":"Setting up a development environment","text":"<p>To create a development environment for caveat, with all libraries required for development and quality assurance installed, it is easiest to install caveat using the mamba package manager, as follows:</p> <ol> <li>Install mamba with the Mambaforge executable for your operating system.</li> <li>Open the command line (or the \"miniforge prompt\" in Windows).</li> <li>Download (a.k.a., clone) the caveat repository: <code>git clone git@github.com:fredshone/caveat.git</code></li> <li>Change into the <code>caveat</code> directory: <code>cd caveat</code></li> <li>Create the caveat mamba environment: <code>mamba create -n caveat -c conda-forge --file requirements/base.txt --file requirements/dev.txt</code></li> <li>Activate the caveat mamba environment: <code>mamba activate caveat</code></li> <li>Install the caveat package into the environment, in editable mode and ignoring dependencies (we have dealt with those when creating the mamba environment): <code>pip install --no-deps -e .</code></li> </ol> <p>All together:</p> <pre><code>git clone git@github.com:fredshone/caveat.git\ncd caveat\nmamba create -n caveat -c conda-forge -c city-modelling-lab --file requirements/base.txt --file requirements/dev.txt\nmamba activate caveat\npip install --no-deps -e .\n</code></pre> <p>If installing directly with pip, you can install these libraries using the <code>dev</code> option, i.e., <code>pip install -e '.[dev]'</code> Either way, you should add your environment as a jupyter kernel, so the example notebooks can run in the tests: <code>ipython kernel install --user --name=caveat</code> If you plan to make changes to the code then please make regular use of the following tools to verify the codebase while you work:</p> <ul> <li><code>pre-commit</code>: run <code>pre-commit install</code> in your command line to load inbuilt checks that will run every time you commit your changes. The checks are: 1. check no large files have been staged, 2. lint python files for major errors, 3. format python files to conform with the PEP8 standard. You can also run these checks yourself at any time to ensure staged changes are clean by calling <code>pre-commit</code>.</li> <li><code>pytest</code> - run the unit test suite and check test coverage.</li> </ul> <p>Note</p> <p>If you already have an environment called <code>caveat</code> on your system (e.g., for a stable installation of the package), you will need to chose a different environment name. You will then need to add this as a pytest argument when running the tests: <code>pytest --nbmake-kernel=[my-env-name]</code>.</p>"},{"location":"contributing/#rapid-fire-testing","title":"Rapid-fire testing","text":"<p>The following options allow you to strip down the test suite to the bare essentials: 1. The test suite includes unit tests and integration tests (in the form of jupyter notebooks found in the <code>examples</code> directory). The integration tests can be slow, so if you want to avoid them during development, you should run <code>pytest tests/</code>. 2. You can avoid generating coverage reports, by adding the <code>--no-cov</code> argument: <code>pytest --no-cov</code>. 3. By default, the tests run with up to two parallel threads, to increase this to e.g. 4 threads: <code>pytest -n4</code>.</p> <p>All together:</p> <pre><code>pytest tests/ --no-cov -n4\n</code></pre> <p>Note</p> <p>You cannot debug failing tests and have your tests run in parallel, you will need to set <code>-n0</code> if using the <code>--pdb</code> flag</p>"},{"location":"contributing/#memory-profiling","title":"Memory profiling","text":"<p>Note</p> <p>When you open a pull request (PR), one of the GitHub actions will run memory profiling for you. This means you don't have to do any profiling locally. However, if you can, it is still good practice to do so as you will catch issues earlier.</p> <p>caveat can be memory intensive; we like to ensure that any development to the core code does not exacerbate this. If you are running on a UNIX device (i.e., not on Windows), you can test whether any changes you have made adversely impact memory and time performance as follows:</p> <ol> <li>Install memray in your <code>caveat</code> mamba environment: <code>mamba install memray pytest-memray</code>.</li> <li>Run the memory profiling integration test: <code>pytest -p memray -m \"high_mem\" --no-cov</code>.</li> <li>Optionally, to visualise the memory allocation, run <code>pytest -p memray -m \"high_mem\" --no-cov --memray-bin-path=[my_path] --memray-bin-prefix=[my_prefix]</code> - where you must define <code>[my_path]</code> and <code>[my_prefix]</code> - followed by <code>memray flamegraph [my_path]/[my_prefix]-tests-test_100_memory_profiling.py-test_mem.bin</code>. You will then find the HTML report at <code>[my_path]/memray-flamegraph-[my_prefix]-tests-test_100_memory_profiling.py-test_mem.html</code>.</li> </ol> <p>All together:</p> <pre><code>mamba install memray pytest-memray\npytest -p memray -m \"high_mem\" --no-cov --memray-bin-path=[my_path] --memray-bin-prefix=[my_prefix]\nmemray flamegraph [my_path]/[my_prefix]-tests-test_100_memory_profiling.py-test_mem.bin\n</code></pre> <p>For more information on using memray, refer to their documentation.</p>"},{"location":"contributing/#submitting-changes","title":"Submitting changes","text":"<p>To contribute changes:</p> <ol> <li>Fork the project on GitHub.</li> <li>Create a feature branch to work on in your fork (<code>git checkout -b new-fix-or-feature</code>).</li> <li>Test your changes using <code>pytest</code>.</li> <li>Commit your changes to the feature branch (you should have <code>pre-commit</code> installed to ensure your code is correctly formatted when you commit changes).</li> <li>Push the branch to GitHub (<code>git push origin new-fix-or-feature</code>).</li> <li>On GitHub, create a new pull request from the feature branch.</li> </ol>"},{"location":"contributing/#pull-requests","title":"Pull requests","text":"<p>Before submitting a pull request, check whether you have:</p> <ul> <li>Added your changes to <code>CHANGELOG.md</code>.</li> <li>Added or updated documentation for your changes.</li> <li>Added tests if you implemented new functionality.</li> </ul> <p>When opening a pull request, please provide a clear summary of your changes!</p>"},{"location":"contributing/#commit-messages","title":"Commit messages","text":"<p>Please try to write clear commit messages. One-line messages are fine for small changes, but bigger changes should look like this:</p> <pre><code>A brief summary of the commit (max 50 characters)\n\nA paragraph or bullet-point list describing what changed and its impact,\ncovering as many lines as needed.\n</code></pre>"},{"location":"contributing/#code-conventions","title":"Code conventions","text":"<p>Start reading our code and you'll get the hang of it.</p> <p>We mostly follow the official Style Guide for Python Code (PEP8).</p> <p>We have chosen to use the uncompromising code formatter <code>black</code> and the linter <code>ruff</code>. When run from the root directory of this repo, <code>pyproject.toml</code> should ensure that formatting and linting fixes are in line with our custom preferences (e.g., 100 character maximum line length). The philosophy behind using <code>black</code> is to have uniform style throughout the project dictated by code. Since <code>black</code> is designed to minimise diffs, and make patches more human readable, this also makes code reviews more efficient. To make this a smooth experience, you should run <code>pre-commit install</code> after setting up your development environment, so that <code>black</code> makes all the necessary fixes to your code each time you commit, and so that <code>ruff</code> will highlight any errors in your code. If you prefer, you can also set up your IDE to run these two tools whenever you save your files, and to have <code>ruff</code> highlight erroneous code directly as you type. Take a look at their documentation for more information on configuring this.</p> <p>We require all new contributions to have docstrings for all modules, classes and methods. When adding docstrings, we request you use the Google docstring style.</p>"},{"location":"contributing/#release-checklist","title":"Release checklist","text":""},{"location":"contributing/#pre-release","title":"Pre-release","text":"<ul> <li> Make sure all unit and integration tests pass (This is best done by creating a pre-release pull request).</li> <li> Re-run tutorial Jupyter notebooks (<code>pytest examples/ --overwrite</code>).</li> <li> Make sure documentation builds without errors (<code>mike deploy [version]</code>, where <code>[version]</code> is the current minor release of the form <code>X.Y</code>).</li> <li> Make sure the changelog is up-to-date, especially that new features and backward incompatible changes are clearly marked.</li> </ul>"},{"location":"contributing/#create-release","title":"Create release","text":"<ul> <li> Bump the version number in <code>caveat/__init__.py</code></li> <li> Update the changelog with final version number of the form <code>vX.Y.Z</code>, release date, and github <code>compare</code> link (at the bottom of the page).</li> <li> Commit with message <code>Release vX.Y.Z</code>, then add a <code>vX.Y.Z</code> tag.</li> <li> Create a release pull request to verify that the conda package builds successfully.</li> <li> Once the PR is approved and merged, create a release through the GitHub web interface, using the same tag, titling it <code>Release vX.Y.Z</code> and include all the changelog elements that are not flagged as internal.</li> </ul>"},{"location":"contributing/#post-release","title":"Post-release","text":"<ul> <li> Update the changelog, adding a new <code>[Unreleased]</code> heading.</li> <li> Update <code>caveat/__init__.py</code> to the next version appended with <code>.dev0</code>, in preparation for the next main commit.</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#setting-up-a-user-environment","title":"Setting up a user environment","text":"<p>As a <code>caveat</code> user, it is easiest to install using the mamba package manager, as follows:</p> <ol> <li>Install mamba with the Mambaforge executable for your operating system.</li> <li> <p>Open the command line (or the \"miniforge prompt\" in Windows).</p> </li> <li> <p>Create the caveat mamba environment: <code>mamba create -n caveat -c conda-forge -c city-modelling-lab caveat</code></p> </li> <li>Activate the caveat mamba environment: <code>mamba activate caveat</code></li> </ol> <p>All together:</p> <pre><code>mamba create -n caveat -c conda-forge -c city-modelling-lab caveat\n</code></pre>"},{"location":"installation/#running-the-example-notebooks","title":"Running the example notebooks","text":"<p>If you have followed the non-developer installation instructions above, you will need to install <code>jupyter</code> into your <code>caveat</code> environment to run the example notebooks:</p> <pre><code>mamba install -n caveat jupyter\n</code></pre> <p>With Jupyter installed, it's easiest to then add the environment as a jupyter kernel:</p> <pre><code>mamba activate caveat\nipython kernel install --user --name=caveat\njupyter notebook\n</code></pre>"},{"location":"installation/#choosing-a-different-environment-name","title":"Choosing a different environment name","text":"<p>If you would like to use a different name to <code>caveat</code> for your mamba environment, the installation becomes (where <code>[my-env-name]</code> is your preferred name for the environment):</p> <pre><code>mamba create -n [my-env-name] -c conda-forge --file requirements/base.txt\nmamba activate [my-env-name]\nipython kernel install --user --name=[my-env-name]\n</code></pre>"},{"location":"installation/#setting-up-a-development-environment","title":"Setting up a development environment","text":"<p>The install instructions are slightly different to create a development environment compared to a user environment:</p> <pre><code>git clone git@github.com:fredshone/caveat.git\ncd caveat\nmamba create -n caveat -c conda-forge -c city-modelling-lab --file requirements/base.txt --file requirements/dev.txt\nmamba activate caveat\npip install --no-deps -e .\n</code></pre> <p>For more detailed installation instructions specific to developing the caveat codebase, see our development documentation.</p>"},{"location":"api/cli/","title":"CLI Reference","text":"<p>This page provides documentation for our command line tools.</p>"},{"location":"api/cli/#caveat","title":"caveat","text":"<p>Console script for caveat.</p> <p>Usage:</p> <pre><code>caveat [OPTIONS]\n</code></pre> <p>Options:</p> Name Type Description Default <code>--version</code> boolean Show the version and exit. <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"examples/1_synthetic_population_generation/","title":"Introduction to Synthetic Population Generation","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom caveat.data.utils import trace_to_pam, generate_population\nfrom caveat.data.synth import ActivityGen\n</pre> import pandas as pd import matplotlib.pyplot as plt from caveat.data.utils import trace_to_pam, generate_population from caveat.data.synth import ActivityGen In\u00a0[2]: Copied! <pre>generator = ActivityGen()\ngenerator.build()\n\ntrace = generator.run()\nplan = trace_to_pam(trace, generator.map)\nplan.plot()\n</pre>  generator = ActivityGen() generator.build()  trace = generator.run() plan = trace_to_pam(trace, generator.map) plan.plot() In\u00a0[3]: Copied! <pre>population = generate_population(gen=generator, size=10000)\npopulation.act = population.act.map(generator.map)\npopulation\n</pre> population = generate_population(gen=generator, size=10000) population.act = population.act.map(generator.map) population Out[3]: act start end duration pid 0 home 0 390 390 0 1 shop 390 450 60 0 2 work 450 915 465 0 3 leisure 915 990 75 0 4 home 990 1440 450 0 ... ... ... ... ... ... 50340 home 0 375 375 9999 50341 shop 375 390 15 9999 50342 work 390 930 540 9999 50343 leisure 930 1005 75 9999 50344 home 1005 1440 435 9999 <p>50345 rows \u00d7 5 columns</p> In\u00a0[4]: Copied! <pre>population.to_csv(\"example_population.csv\")\n</pre> population.to_csv(\"example_population.csv\") In\u00a0[5]: Copied! <pre>def describe_col(population, col: str) -&gt; pd.DataFrame:\n    description = population.groupby(\"act\")[col].describe()[[\"count\", \"mean\", \"std\", \"min\", \"max\"]]\n    description[\"attribute\"] = col\n    return description\n\ndef describe_cols(population, cols: list[str]) -&gt; pd.DataFrame:\n    description = pd.concat([describe_col(population, c) for c in cols], ignore_index=False)\n    description = description.reset_index().set_index([\"attribute\", \"act\"])\n    # description.set_index((\"attribute\", \"act\"))\n    return description\n\ndescribe_cols(population, [\"start\", \"end\", \"duration\"]).round()\n</pre> def describe_col(population, col: str) -&gt; pd.DataFrame:     description = population.groupby(\"act\")[col].describe()[[\"count\", \"mean\", \"std\", \"min\", \"max\"]]     description[\"attribute\"] = col     return description  def describe_cols(population, cols: list[str]) -&gt; pd.DataFrame:     description = pd.concat([describe_col(population, c) for c in cols], ignore_index=False)     description = description.reset_index().set_index([\"attribute\", \"act\"])     # description.set_index((\"attribute\", \"act\"))     return description  describe_cols(population, [\"start\", \"end\", \"duration\"]).round() Out[5]: count mean std min max attribute act start education 4536.0 867.0 178.0 390.0 1185.0 home 21453.0 554.0 522.0 0.0 1380.0 leisure 6113.0 826.0 287.0 375.0 1305.0 shop 8202.0 631.0 291.0 375.0 1335.0 work 10041.0 419.0 51.0 375.0 1260.0 end education 4536.0 983.0 166.0 405.0 1200.0 home 21453.0 929.0 512.0 375.0 1440.0 leisure 6113.0 889.0 301.0 390.0 1380.0 shop 8202.0 667.0 287.0 390.0 1350.0 work 10041.0 932.0 74.0 735.0 1275.0 duration education 4536.0 115.0 51.0 15.0 285.0 home 21453.0 375.0 75.0 15.0 600.0 leisure 6113.0 62.0 27.0 15.0 210.0 shop 8202.0 36.0 24.0 15.0 180.0 work 10041.0 513.0 66.0 15.0 690.0 In\u00a0[6]: Copied! <pre>def time_distributions(population: pd.DataFrame, mapping: dict):\n    starts = {k: [] for k in mapping.values()}\n    ends = {k: [] for k in mapping.values()}\n    durations = {k: [] for k in mapping.values()}\n    for act, acts in population.groupby('act'):\n        starts[act] = list(acts.start)\n        ends[act] = list(acts.end)\n        durations[act] = list(acts.duration)\n    return starts, ends, durations\n</pre> def time_distributions(population: pd.DataFrame, mapping: dict):     starts = {k: [] for k in mapping.values()}     ends = {k: [] for k in mapping.values()}     durations = {k: [] for k in mapping.values()}     for act, acts in population.groupby('act'):         starts[act] = list(acts.start)         ends[act] = list(acts.end)         durations[act] = list(acts.duration)     return starts, ends, durations In\u00a0[7]: Copied! <pre>starts, ends, durations = time_distributions(population, generator.map)\n</pre> starts, ends, durations = time_distributions(population, generator.map) In\u00a0[8]: Copied! <pre>step = 30\nmini = 0\nmaxi = 1441\nind = 1000\nbw_method = .2\n\nbins = list(range(mini, maxi, step))\nfig, axs = plt.subplots(\n    3,\n    len(starts),\n    figsize=(12, 5),\n    sharex=True,\n    sharey=False,\n    tight_layout=True,\n)\nfor i, act in enumerate(starts.keys()):\n    axs[0][i].set_title(act.title(), fontstyle='italic')\n    axs[0][i].hist(starts[act], bins=bins, density=True)\n    pd.Series(starts[act]).plot.kde(ind=ind, bw_method=bw_method, ax=axs[0][i])\n    axs[0][i].set_xlim(mini, maxi)\n    axs[0][i].set_yticklabels([])\n    axs[0][i].set(ylabel=None)\n    axs[0][0].set(ylabel=\"Start times\")\n\n    axs[1][i].hist(ends[act], bins=bins, density=True)\n    pd.Series(ends[act]).plot.kde(ind=ind, bw_method=bw_method, ax=axs[1][i])\n    axs[1][i].set_xlim(mini, maxi)\n    axs[1][i].set_yticklabels([])\n    axs[1][i].set(ylabel=None)\n    axs[1][0].set(ylabel=\"End times\")\n\n    axs[2][i].hist(durations[act], bins=bins, density=True)\n    pd.Series(durations[act]).plot.kde(ind=ind, bw_method=bw_method, ax=axs[2][i])\n    axs[2][i].set_xlim(mini, maxi)\n    axs[2][i].set_yticklabels([])\n    axs[2][i].set(ylabel=None)\n    axs[2][0].set(ylabel=\"Durations\")\n    axs[2][i].set(xlabel=\"Time of day (minutes)\")\n</pre> step = 30 mini = 0 maxi = 1441 ind = 1000 bw_method = .2  bins = list(range(mini, maxi, step)) fig, axs = plt.subplots(     3,     len(starts),     figsize=(12, 5),     sharex=True,     sharey=False,     tight_layout=True, ) for i, act in enumerate(starts.keys()):     axs[0][i].set_title(act.title(), fontstyle='italic')     axs[0][i].hist(starts[act], bins=bins, density=True)     pd.Series(starts[act]).plot.kde(ind=ind, bw_method=bw_method, ax=axs[0][i])     axs[0][i].set_xlim(mini, maxi)     axs[0][i].set_yticklabels([])     axs[0][i].set(ylabel=None)     axs[0][0].set(ylabel=\"Start times\")      axs[1][i].hist(ends[act], bins=bins, density=True)     pd.Series(ends[act]).plot.kde(ind=ind, bw_method=bw_method, ax=axs[1][i])     axs[1][i].set_xlim(mini, maxi)     axs[1][i].set_yticklabels([])     axs[1][i].set(ylabel=None)     axs[1][0].set(ylabel=\"End times\")      axs[2][i].hist(durations[act], bins=bins, density=True)     pd.Series(durations[act]).plot.kde(ind=ind, bw_method=bw_method, ax=axs[2][i])     axs[2][i].set_xlim(mini, maxi)     axs[2][i].set_yticklabels([])     axs[2][i].set(ylabel=None)     axs[2][0].set(ylabel=\"Durations\")     axs[2][i].set(xlabel=\"Time of day (minutes)\")  In\u00a0[9]: Copied! <pre>step = 30\nmini = 0\nmaxi = 1441\n\nbins = list(range(mini, maxi, step))\nduration_bins = list(range(mini, 800, step))\n\nfig, axs = plt.subplots(\n    1,\n    len(starts),\n    figsize=(15, 4),\n    sharex=True,\n    sharey=True,\n    tight_layout=True\n    )\nfor i, (act, act_starts) in enumerate(starts.items()):\n    act_durations = durations[act]\n\n    axs[i].set_title(act.title(), fontstyle='italic')\n    # axs[i].set_xlim(0, 1440)\n    # axs[i].set_ylim(0, 1440)\n    axs[i].hist2d(act_starts, act_durations, bins=(bins,duration_bins))\n</pre>   step = 30 mini = 0 maxi = 1441  bins = list(range(mini, maxi, step)) duration_bins = list(range(mini, 800, step))  fig, axs = plt.subplots(     1,     len(starts),     figsize=(15, 4),     sharex=True,     sharey=True,     tight_layout=True     ) for i, (act, act_starts) in enumerate(starts.items()):     act_durations = durations[act]      axs[i].set_title(act.title(), fontstyle='italic')     # axs[i].set_xlim(0, 1440)     # axs[i].set_ylim(0, 1440)     axs[i].hist2d(act_starts, act_durations, bins=(bins,duration_bins))  In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/1_synthetic_population_generation/#introduction-to-synthetic-population-generation","title":"Introduction to Synthetic Population Generation\u00b6","text":""},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#unreleased","title":"Unreleased","text":""},{"location":"CHANGELOG/#fixed","title":"Fixed","text":""},{"location":"CHANGELOG/#added","title":"Added","text":""},{"location":"CHANGELOG/#changed","title":"Changed","text":""},{"location":"CHANGELOG/#removed","title":"Removed","text":""},{"location":"CHANGELOG/#v010-2023-10-04","title":"[v0.1.0] - 2023-10-04","text":"<p>Initial release.</p>"},{"location":"reference/caveat/core/","title":"caveat.core","text":"<p>Main module.</p>"},{"location":"reference/caveat/data/loader/","title":"caveat.data.loader","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.DescreteSequenceDataset","title":"<code>DescreteSequenceDataset(path, length, step)</code>","text":"<p>             Bases: <code>Dataset</code></p> <p>Torch Dataset for descretised sequence data.</p> PARAMETER  DESCRIPTION <code>path</code> <p>Path to population sequences.</p> <p> TYPE: <code>str</code> </p> <code>length</code> <p>Length of desired sequences in minutes.</p> <p> TYPE: <code>int</code> </p> <code>step</code> <p>Step size of descretisation in minutes.</p> <p> TYPE: <code>int</code> </p> Source code in <code>caveat/data/loader.py</code> <pre><code>def __init__(self, path: str, length: int, step: int):\n    \"\"\"Torch Dataset for descretised sequence data.\n\n    Args:\n        path (str): Path to population sequences.\n        length (int): Length of desired sequences in minutes.\n        step (int): Step size of descretisation in minutes.\n    \"\"\"\n    df = pd.read_csv(path)\n    self.size = df.pid.nunique()\n    self.index_to_acts = {i: a for i, a in enumerate(df.act.unique())}\n    self.acts_to_index = {a: i for i, a in self.index_to_acts.items()}\n    self.encoded = descretise_population(\n        df,\n        samples=self.size,\n        length=length,\n        step=step,\n        class_map=self.acts_to_index,\n    )\n</code></pre>"},{"location":"reference/caveat/data/loader/#caveat.data.loader.DescreteSequenceDataset.acts_to_index","title":"<code>acts_to_index = {a: ifor (i, a) in self.index_to_acts.items()}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.DescreteSequenceDataset.encoded","title":"<code>encoded = descretise_population(df, samples=self.size, length=length, step=step, class_map=self.acts_to_index)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.DescreteSequenceDataset.index_to_acts","title":"<code>index_to_acts = {i: afor (i, a) in enumerate(df.act.unique())}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.DescreteSequenceDataset.size","title":"<code>size = df.pid.nunique()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset","title":"<code>VAEDataset(path, length=1440, step=10, val_split=0.1, seed=1234, train_batch_size=128, val_batch_size=128, test_batch_size=128, num_workers=0, pin_memory=False, **kwargs)</code>","text":"<p>             Bases: <code>LightningDataModule</code></p> <p>Torch Dataset.</p> PARAMETER  DESCRIPTION <code>path</code> <p>description</p> <p> TYPE: <code>str</code> </p> <code>length</code> <p>description. Defaults to 1440.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1440</code> </p> <code>step</code> <p>description. Defaults to 10.</p> <p> TYPE: <code>int</code> DEFAULT: <code>10</code> </p> <code>val_split</code> <p>description. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> <code>seed</code> <p>description. Defaults to 1234.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1234</code> </p> <code>train_batch_size</code> <p>description. Defaults to 128.</p> <p> TYPE: <code>int</code> DEFAULT: <code>128</code> </p> <code>val_batch_size</code> <p>description. Defaults to 128.</p> <p> TYPE: <code>int</code> DEFAULT: <code>128</code> </p> <code>test_batch_size</code> <p>description. Defaults to 128.</p> <p> TYPE: <code>int</code> DEFAULT: <code>128</code> </p> <code>num_workers</code> <p>description. Defaults to 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>pin_memory</code> <p>description. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>caveat/data/loader.py</code> <pre><code>def __init__(\n    self,\n    path: str,\n    length: int = 1440,\n    step: int = 10,\n    val_split: float = 0.1,\n    seed: int = 1234,\n    train_batch_size: int = 128,\n    val_batch_size: int = 128,\n    test_batch_size: int = 128,\n    num_workers: int = 0,\n    pin_memory: bool = False,\n    **kwargs,\n):\n    \"\"\"Torch Dataset.\n\n    Args:\n        path (str): _description_\n        length (int, optional): _description_. Defaults to 1440.\n        step (int, optional): _description_. Defaults to 10.\n        val_split (float, optional): _description_. Defaults to 0.1.\n        seed (int, optional): _description_. Defaults to 1234.\n        train_batch_size (int, optional): _description_. Defaults to 128.\n        val_batch_size (int, optional): _description_. Defaults to 128.\n        test_batch_size (int, optional): _description_. Defaults to 128.\n        num_workers (int, optional): _description_. Defaults to 0.\n        pin_memory (bool, optional): _description_. Defaults to False.\n    \"\"\"\n    super().__init__()\n\n    self.path = path\n    self.length = length\n    self.step = step\n    self.steps = length // step\n    self.val_split = val_split\n    self.generator = torch.manual_seed(seed)\n    self.train_batch_size = train_batch_size\n    self.val_batch_size = val_batch_size\n    self.test_batch_size = test_batch_size\n    self.num_workers = num_workers\n    self.pin_memory = pin_memory\n    self.mapping = None\n</code></pre>"},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.generator","title":"<code>generator = torch.manual_seed(seed)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.length","title":"<code>length = length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.mapping","title":"<code>mapping = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.num_workers","title":"<code>num_workers = num_workers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.path","title":"<code>path = path</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.pin_memory","title":"<code>pin_memory = pin_memory</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.step","title":"<code>step = step</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.steps","title":"<code>steps = length // step</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.test_batch_size","title":"<code>test_batch_size = test_batch_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.train_batch_size","title":"<code>train_batch_size = train_batch_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.val_batch_size","title":"<code>val_batch_size = val_batch_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.val_split","title":"<code>val_split = val_split</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.setup","title":"<code>setup(stage=None)</code>","text":"Source code in <code>caveat/data/loader.py</code> <pre><code>def setup(self, stage: Optional[str] = None) -&gt; None:\n    data = DescreteSequenceDataset(self.path, self.length, self.step)\n    self.mapping = data.index_to_acts\n    self.train_dataset, self.val_dataset = torch.utils.data.random_split(\n        data, [1 - self.val_split, self.val_split], generator=self.generator\n    )\n</code></pre>"},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.test_dataloader","title":"<code>test_dataloader()</code>","text":"Source code in <code>caveat/data/loader.py</code> <pre><code>def test_dataloader(self) -&gt; Union[DataLoader, list[DataLoader]]:\n    return DataLoader(\n        self.val_dataset,\n        batch_size=self.test_batch_size,\n        num_workers=self.num_workers,\n        shuffle=True,\n        pin_memory=self.pin_memory,\n    )\n</code></pre>"},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.train_dataloader","title":"<code>train_dataloader()</code>","text":"Source code in <code>caveat/data/loader.py</code> <pre><code>def train_dataloader(self) -&gt; DataLoader:\n    return DataLoader(\n        self.train_dataset,\n        batch_size=self.train_batch_size,\n        num_workers=self.num_workers,\n        shuffle=True,\n        pin_memory=self.pin_memory,\n    )\n</code></pre>"},{"location":"reference/caveat/data/loader/#caveat.data.loader.VAEDataset.val_dataloader","title":"<code>val_dataloader()</code>","text":"Source code in <code>caveat/data/loader.py</code> <pre><code>def val_dataloader(self) -&gt; Union[DataLoader, list[DataLoader]]:\n    return DataLoader(\n        self.val_dataset,\n        batch_size=self.val_batch_size,\n        num_workers=self.num_workers,\n        shuffle=False,\n        pin_memory=self.pin_memory,\n    )\n</code></pre>"},{"location":"reference/caveat/data/loader/#caveat.data.loader.descretise_population","title":"<code>descretise_population(data, samples, length, step, class_map)</code>","text":"<p>Convert given population of activity traces into vector [P, C, H, W]. P is the population size. C (channel) is length 1. H is a one-hot encoding of activity type. W is time steps.</p> PARAMETER  DESCRIPTION <code>data</code> <p>description</p> <p> TYPE: <code>DataFrame</code> </p> <code>samples</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>length</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>step</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>class_map</code> <p>description</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>torch.tensor: [P, C, H, W]</p> Source code in <code>caveat/data/loader.py</code> <pre><code>def descretise_population(\n    data: pd.DataFrame, samples: int, length: int, step: int, class_map: dict\n) -&gt; torch.tensor:\n    \"\"\"Convert given population of activity traces into vector [P, C, H, W].\n    P is the population size.\n    C (channel) is length 1.\n    H is a one-hot encoding of activity type.\n    W is time steps.\n\n    Args:\n        data (pd.DataFrame): _description_\n        samples (int): _description_\n        length (int): _description_\n        step (int): _description_\n        class_map (dict): _description_\n\n    Returns:\n        torch.tensor: [P, C, H, W]\n    \"\"\"\n    num_classes = len(class_map)  # bit dodgy\n    steps = length // step\n    encoded = np.zeros((samples, steps, num_classes, 1), dtype=np.float32)\n    # todo: we keep the last dimension so we look like an image, remove?\n\n    for pid, trace in data.groupby(\"pid\"):\n        trace_encoding = descretise_trace(\n            acts=trace.act,\n            starts=trace.start,\n            ends=trace.end,\n            length=length,\n            class_map=class_map,\n        )\n        trace_encoding = down_sample(trace_encoding, step)\n        assert len(trace_encoding) == steps\n        trace_encoding = one_hot(trace_encoding, num_classes)\n        trace_encoding = trace_encoding.reshape(steps, num_classes, 1)  # todo\n        encoded[pid] = trace_encoding\n    encoded = encoded.transpose(0, 3, 2, 1)  # [B, C, H, W]\n    return torch.from_numpy(encoded)\n</code></pre>"},{"location":"reference/caveat/data/loader/#caveat.data.loader.descretise_trace","title":"<code>descretise_trace(acts, starts, ends, length, class_map)</code>","text":"<p>Create categorical encoding from ranges with step of 1.</p> PARAMETER  DESCRIPTION <code>acts</code> <p>description</p> <p> TYPE: <code>Iterable[str]</code> </p> <code>starts</code> <p>description</p> <p> TYPE: <code>Iterable[int]</code> </p> <code>ends</code> <p>description</p> <p> TYPE: <code>Iterable[int]</code> </p> <code>length</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>class_map</code> <p>description</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: description</p> Source code in <code>caveat/data/loader.py</code> <pre><code>def descretise_trace(\n    acts: Iterable[str],\n    starts: Iterable[int],\n    ends: Iterable[int],\n    length: int,\n    class_map: dict,\n) -&gt; np.array:\n    \"\"\"Create categorical encoding from ranges with step of 1.\n\n    Args:\n        acts (Iterable[str]): _description_\n        starts (Iterable[int]): _description_\n        ends (Iterable[int]): _description_\n        length (int): _description_\n        class_map (dict): _description_\n\n    Returns:\n        np.array: _description_\n    \"\"\"\n    encoding = np.zeros((length), dtype=np.int8)\n    for act, start, end in zip(acts, starts, ends):\n        encoding[start:end] = class_map[act]\n    return encoding\n</code></pre>"},{"location":"reference/caveat/data/loader/#caveat.data.loader.down_sample","title":"<code>down_sample(array, step)</code>","text":"<p>Down-sample by steppiong through given array. todo: Methodology will down sample based on first classification. If we are down sampling a lot (for example from minutes to hours), we would be better of, samplig based on majority class.</p> PARAMETER  DESCRIPTION <code>array</code> <p>description</p> <p> TYPE: <code>array</code> </p> <code>step</code> <p>description</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: description</p> Source code in <code>caveat/data/loader.py</code> <pre><code>def down_sample(array: np.array, step: int) -&gt; np.array:\n    \"\"\"Down-sample by steppiong through given array.\n    todo:\n    Methodology will down sample based on first classification.\n    If we are down sampling a lot (for example from minutes to hours),\n    we would be better of, samplig based on majority class.\n\n    Args:\n        array (np.array): _description_\n        step (int): _description_\n\n    Returns:\n        np.array: _description_\n    \"\"\"\n    return array[::step]\n</code></pre>"},{"location":"reference/caveat/data/loader/#caveat.data.loader.one_hot","title":"<code>one_hot(target, num_classes)</code>","text":"<p>One hot encoding of given categorical array.</p> PARAMETER  DESCRIPTION <code>target</code> <p>description</p> <p> TYPE: <code>array</code> </p> <code>num_classes</code> <p>description</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: description</p> Source code in <code>caveat/data/loader.py</code> <pre><code>def one_hot(target: np.array, num_classes: int) -&gt; np.array:\n    \"\"\"One hot encoding of given categorical array.\n\n    Args:\n        target (np.array): _description_\n        num_classes (int): _description_\n\n    Returns:\n        np.array: _description_\n    \"\"\"\n    return np.eye(num_classes)[target]\n</code></pre>"},{"location":"reference/caveat/data/synth/","title":"caveat.data.synth","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen","title":"<code>ActivityGen()</code>","text":"Source code in <code>caveat/data/synth.py</code> <pre><code>def __init__(self):\n    self.map = {i: s for i, s in enumerate(self.possible_states)}\n    self.steps = self.duration // self.step_size\n    self.transition_weights = None\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.duration","title":"<code>duration = 24 * 60</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.initial_state","title":"<code>initial_state = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.map","title":"<code>map = {i: sfor (i, s) in enumerate(self.possible_states)}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.max_duration_sensitivity","title":"<code>max_duration_sensitivity = np.array([0.1, 0.1, 0.1, 0.1, 0.1])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.max_duration_tollerance","title":"<code>max_duration_tollerance = np.array([12 * 60, 6 * 60, 60, 360, 120])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.min_duration_sensitivity","title":"<code>min_duration_sensitivity = np.array([1, 1.2, 1, 1.2, 1])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.min_duration_tollerance","title":"<code>min_duration_tollerance = np.array([180, 420, 60, 120, 60])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.pivot_adjustment","title":"<code>pivot_adjustment = 60</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.possible_states","title":"<code>possible_states = ['home', 'work', 'shop', 'education', 'leisure']</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.repetition_sensitivity","title":"<code>repetition_sensitivity = np.array([1, 2, 1, 2, 1])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.repetition_tollerance","title":"<code>repetition_tollerance = np.array([10, 1, 1, 1, 2])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.step_size","title":"<code>step_size = 15</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.steps","title":"<code>steps = self.duration // self.step_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.transition_config","title":"<code>transition_config = {'home': {'home': [(0, 100), (5, 100), (11, 0.1), (23, 100), (24, 100)], 'work': [(0, 0), (6, 0), (9, 0.2), (11, 0.1), (17, 0), (24, 0)], 'shop': [(0, 0), (6, 0), (7, 2), (11, 1), (20, 0), (24, 0)], 'education': [(0, 0), (7.5, 0), (8.5, 5), (11, 0.01), (17, 0.01), (20, 0), (24, 0)], 'leisure': [(0, 0), (6, 0), (9, 2), (16, 0.1), (22, 0), (24, 0)]}, 'work': {'home': [(0, 0), (12, 0), (13, 0.2), (16, 0.5), (17, 1), (24, 100)], 'work': [(0, 100), (12, 100), (20, 0), (24, 0)], 'shop': [(0, 0), (12, 0), (13, 0.1), (14, 0), (18, 0.1), (19, 0), (24, 0)], 'education': [(0, 0), (12, 0), (13, 0.1), (14, 0), (16, 0), (17, 0.1), (19, 0), (24, 0)], 'leisure': [(0, 0), (15, 0), (16, 0.1), (17, 0.2), (24, 0)]}, 'shop': {'home': [(0, 0.3), (23, 1), (24, 1)], 'work': [(0, 0.1), (14, 0.1), (15, 0), (24, 0)], 'shop': [(0, 10), (15, 10), (16, 0), (24, 0)], 'education': [(0, 0.1), (15, 0), (24, 0)], 'leisure': [(0, 0.2), (15, 0), (24, 0)]}, 'education': {'home': [(0, 0), (12, 0), (13, 0.2), (16, 0.1), (17, 100), (24, 100)], 'work': [(0, 0), (12, 1), (15, 0), (24, 0)], 'shop': [(0, 0), (6, 0), (7, 0.1), (11, 0.3), (23, 0), (24, 0)], 'education': [(0, 100), (12, 100), (17, 100), (18, 0), (24, 0)], 'leisure': [(0, 0), (6, 0), (9, 0.1), (16, 0.1), (17, 0), (24, 0)]}, 'leisure': {'home': [(0, 0), (12, 0), (13, 0.2), (16, 0.1), (17, 100), (24, 100)], 'work': [(0, 1), (12, 1), (23, 0), (24, 0)], 'shop': [(0, 0), (6, 0), (7, 0.1), (11, 0.3), (23, 0), (24, 0)], 'education': [(0, 0), (24, 0)], 'leisure': [(0, 100), (19, 100), (23, 0), (24, 0)]}}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.transition_weights","title":"<code>transition_weights = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.build","title":"<code>build()</code>","text":"Source code in <code>caveat/data/synth.py</code> <pre><code>def build(self):\n    num_states = len(self.possible_states)\n    self.transition_weights = np.zeros((num_states, num_states, self.steps))\n    for i in range(num_states):\n        in_state = self.possible_states[i]\n        state_transitions = self.transition_config[in_state]\n        for j in range(num_states):\n            out_state = self.possible_states[j]\n            pivots = state_transitions[out_state]\n            self.transition_weights[i][j] = interpolate_from_pivots(\n                pivots, self.steps, self.pivot_adjustment, self.step_size\n            )\n\n    self.transition_weights = np.transpose(\n        self.transition_weights, (0, 2, 1)\n    )  # ie [in_state, minute, out_state]\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.max_duration_adjustment","title":"<code>max_duration_adjustment(activity_durations)</code>","text":"<p>Penalise current activity based on duration.</p> PARAMETER  DESCRIPTION <code>activity_durations</code> <p>activity durations</p> <p> TYPE: <code>array</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: transition factor adjustments</p> Source code in <code>caveat/data/synth.py</code> <pre><code>def max_duration_adjustment(self, activity_durations: np.array) -&gt; np.array:\n    \"\"\"Penalise current activity based on duration.\n\n    Args:\n        activity_durations (np.array): activity durations\n\n    Returns:\n        np.array: transition factor adjustments\n    \"\"\"\n    return 1 / (\n        np.clip((activity_durations - self.max_duration_tollerance), 1, None)\n        ** self.max_duration_sensitivity\n    )\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.min_duration_adjustment","title":"<code>min_duration_adjustment(activity_durations)</code>","text":"<p>Penalise current activity based on duration.</p> PARAMETER  DESCRIPTION <code>activity_durations</code> <p>activity durations</p> <p> TYPE: <code>array</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: transition factor adjustments</p> Source code in <code>caveat/data/synth.py</code> <pre><code>def min_duration_adjustment(self, activity_durations: np.array) -&gt; np.array:\n    \"\"\"Penalise current activity based on duration.\n\n    Args:\n        activity_durations (np.array): activity durations\n\n    Returns:\n        np.array: transition factor adjustments\n    \"\"\"\n    return (\n        np.clip(((self.min_duration_tollerance - activity_durations)), 1, None)\n        ** self.min_duration_sensitivity\n    )\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.repeat_adjustment","title":"<code>repeat_adjustment(activity_counts)</code>","text":"<p>Penalise activities based on how often they have been done.</p> PARAMETER  DESCRIPTION <code>activity_counts</code> <p>counts of activity repetitions</p> <p> TYPE: <code>array</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: transition factor adjustments</p> Source code in <code>caveat/data/synth.py</code> <pre><code>def repeat_adjustment(self, activity_counts: np.array) -&gt; np.array:\n    \"\"\"Penalise activities based on how often they have been done.\n\n    Args:\n        activity_counts (np.array): counts of activity repetitions\n\n    Returns:\n        np.array: transition factor adjustments\n    \"\"\"\n    return 1 / (\n        np.clip((activity_counts - self.repetition_tollerance), 1, None)\n        ** self.repetition_sensitivity\n    )\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.run","title":"<code>run()</code>","text":"<p>summary</p> Source code in <code>caveat/data/synth.py</code> <pre><code>def run(self):\n    \"\"\"_summary_\"\"\"\n    trace = []  # [(act, start, end, dur), (act, start, end, dur), ...]\n    state = self.initial_state\n    activity_counts = np.zeros((len(self.possible_states)))\n    activity_counts[state] += 1\n    activity_durations = np.zeros((len(self.possible_states)))\n    activity_durations[state] += self.step_size\n\n    for step in range(1, self.steps):\n        new_state = np.random.choice(\n            len(self.possible_states),\n            p=self.transition_probabilities(state, step, activity_counts, activity_durations),\n        )\n        if new_state != state:\n            time = step * self.step_size\n            if not trace:  # first transition\n                prev_end = 0\n            else:\n                prev_end = trace[-1][2]\n            trace.append((state, prev_end, time, time - prev_end))\n\n            # update state\n            state = new_state\n            activity_counts[state] += 1\n            activity_durations[state] = 0  # reset\n\n        activity_durations[state] += self.step_size\n\n    # close\n    prev_end = trace[-1][2]\n    trace.append((state, prev_end, self.duration, self.duration - prev_end))\n    return trace\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.transition_probabilities","title":"<code>transition_probabilities(state, step, activity_counts, activity_durations)</code>","text":"Source code in <code>caveat/data/synth.py</code> <pre><code>def transition_probabilities(\n    self, state, step, activity_counts: np.array, activity_durations: np.array\n):\n    p = self.transition_weights[state][step]\n    p = (\n        p\n        * self.repeat_adjustment(activity_counts)\n        * self.min_duration_adjustment(activity_durations)\n        * self.max_duration_adjustment(activity_durations)\n    )\n    return p / sum(p)\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.interpolate_from_pivots","title":"<code>interpolate_from_pivots(pivots, size=1440, pivot_adjustment=60, step_size=1)</code>","text":"<p>Create a descretised array of shape 'size' based on given 'pivots'.</p> PARAMETER  DESCRIPTION <code>pivots</code> <p>description</p> <p> TYPE: <code>list[tuple[float, float]]</code> </p> <code>size</code> <p>description. Defaults to 1440</p> <p> TYPE: <code>int</code> DEFAULT: <code>1440</code> </p> <code>pivot_adjustment</code> <p>description. Defaults to 60</p> <p> TYPE: <code>int</code> DEFAULT: <code>60</code> </p> <code>step_size</code> <p>Defaults to 1</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: bins</p> Source code in <code>caveat/data/synth.py</code> <pre><code>def interpolate_from_pivots(\n    pivots: list[tuple[float, float]],\n    size: int = 1440,\n    pivot_adjustment: int = 60,\n    step_size: int = 1,\n) -&gt; np.array:\n    \"\"\"Create a descretised array of shape 'size' based on given 'pivots'.\n\n    Args:\n        pivots (list[tuple[float, float]]): _description_\n        size (int, optional): _description_. Defaults to 1440\n        pivot_adjustment (int, optional): _description_. Defaults to 60\n        step_size (int, optional): Defaults to 1\n\n    Returns:\n        np.array: bins\n    \"\"\"\n    bins = np.zeros((size), dtype=np.float64)\n    for k in range(len(pivots) - 1):\n        a_pivot, a_value = pivots[k]\n        b_pivot, b_value = pivots[k + 1]\n        a_pivot = int(a_pivot * pivot_adjustment / step_size)\n        b_pivot = int(b_pivot * pivot_adjustment / step_size)\n        a = (a_pivot, a_value)\n        b = (b_pivot, b_value)\n        bins[slice(a_pivot, b_pivot)] = interpolate_pivot(a, b)\n    return bins\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.interpolate_pivot","title":"<code>interpolate_pivot(a, b)</code>","text":"Source code in <code>caveat/data/synth.py</code> <pre><code>def interpolate_pivot(a: tuple[int, float], b: tuple[int, float]) -&gt; np.array:\n    a_pivot, a_value = a\n    b_pivot, b_value = b\n    return np.linspace(a_value, b_value, abs(b_pivot - a_pivot), endpoint=False)\n</code></pre>"},{"location":"reference/caveat/data/utils/","title":"caveat.data.utils","text":""},{"location":"reference/caveat/data/utils/#caveat.data.utils.gen_person","title":"<code>gen_person(gen, pid)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def gen_person(gen, pid) -&gt; pd.DataFrame:\n    trace = gen.run()\n    return trace_to_df(trace, pid=pid)\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.gen_persons","title":"<code>gen_persons(gen, pids)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def gen_persons(gen, pids) -&gt; pd.DataFrame:\n    return pd.concat([gen_person(gen, pid) for pid in pids], ignore_index=True)\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.generate_population","title":"<code>generate_population(gen, size, cores=None)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def generate_population(gen, size: int, cores: int = None):\n    if cores is None:\n        cores = mp.cpu_count()\n\n    batches = list(split(range(size), cores))\n\n    pools = mp.Pool(cores)\n    results = [pools.apply_async(gen_persons, args=(gen, pids)) for pids in batches]\n    pools.close()\n    pools.join()\n    results = [r.get() for r in results]\n    pop = pd.concat(results, ignore_index=True)\n    return pop\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.split","title":"<code>split(a, n)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def split(a, n):\n    k, m = divmod(len(a), n)\n    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.trace_to_df","title":"<code>trace_to_df(trace, **kwargs)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def trace_to_df(trace: list[tuple], **kwargs) -&gt; pd.DataFrame:\n    df = pd.DataFrame(trace, columns=[\"act\", \"start\", \"end\", \"duration\"])\n    for k, v in kwargs.items():\n        df[k] = v\n    return df\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.trace_to_pam","title":"<code>trace_to_pam(trace, mapping)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def trace_to_pam(trace: list[tuple], mapping: dict):\n    plan = Plan()\n    for act, start, end, duration in trace:\n        name = mapping[act]\n        plan.add(Activity(act=name, start_time=mtdt(start), end_time=mtdt(end)))\n        plan.add(Trip(mode=\"car\", start_time=mtdt(end), end_time=mtdt(end)))\n    return plan\n</code></pre>"},{"location":"reference/caveat/experiment/","title":"caveat.experiment","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.default_params","title":"<code>default_params = {'kld_weight': 0.00025, 'LR': 0.005, 'weight_decay': 0.0}</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment","title":"<code>Experiment(model)</code>","text":"<p>             Bases: <code>LightningModule</code></p> Source code in <code>caveat/experiment.py</code> <pre><code>def __init__(self, model: BaseVAE) -&gt; None:\n    super(Experiment, self).__init__()\n\n    self.model = model\n    self.params = default_params\n    self.curr_device = None\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.curr_device","title":"<code>curr_device = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.params","title":"<code>params = default_params</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def configure_optimizers(self):\n    optims = []\n    scheds = []\n\n    optimizer = optim.Adam(\n        self.model.parameters(),\n        lr=self.params[\"LR\"],\n        weight_decay=self.params[\"weight_decay\"],\n    )\n    optims.append(optimizer)\n\n    if self.params.get(\"scheduler_gamma\") is not None:\n        scheduler = optim.lr_scheduler.ExponentialLR(\n            optims[0], gamma=self.params[\"scheduler_gamma\"]\n        )\n        scheds.append(scheduler)\n    return optims, scheds\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.forward","title":"<code>forward(input, **kwargs)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def forward(self, input: Tensor, **kwargs) -&gt; Tensor:\n    return self.model(input, **kwargs)\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.on_validation_end","title":"<code>on_validation_end()</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def on_validation_end(self) -&gt; None:\n    self.sample_sequences()\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.sample_sequences","title":"<code>sample_sequences()</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def sample_sequences(self):\n    # Get sample reconstruction image\n    x = next(iter(self.trainer.datamodule.test_dataloader()))\n    x = x.to(self.curr_device)\n\n    # test_input, test_label = batch\n    reconstructed = self.model.generate(x)\n    vutils.save_image(\n        reconstructed.data,\n        Path(\n            self.logger.log_dir,\n            \"reconstructions\",\n            f\"recons_{self.logger.name}_epoch_{self.current_epoch}.png\",\n        ),\n        normalize=True,\n        nrow=2,\n    )\n\n    # sample from latent space\n    samples = self.model.sample(144, self.curr_device)\n    vutils.save_image(\n        samples.cpu().data,\n        Path(\n            self.logger.log_dir,\n            \"samples\",\n            f\"{self.logger.name}_Epoch_{self.current_epoch}.png\",\n        ),\n        normalize=True,\n        nrow=2,\n    )\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.training_step","title":"<code>training_step(batch, batch_idx, optimizer_idx=0)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def training_step(self, batch, batch_idx, optimizer_idx=0):\n    self.curr_device = batch.device\n\n    results = self.forward(batch)\n    train_loss = self.model.loss_function(\n        *results,\n        M_N=self.params[\n            \"kld_weight\"\n        ],  # al_img.shape[0]/ self.num_train_imgs,\n        optimizer_idx=optimizer_idx,\n        batch_idx=batch_idx,\n    )\n\n    self.log_dict(\n        {key: val.item() for key, val in train_loss.items()}, sync_dist=True\n    )\n\n    return train_loss[\"loss\"]\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.validation_step","title":"<code>validation_step(batch, batch_idx, optimizer_idx=0)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def validation_step(self, batch, batch_idx, optimizer_idx=0):\n    self.curr_device = batch.device\n\n    results = self.forward(batch)\n    val_loss = self.model.loss_function(\n        *results,\n        M_N=1.0,  # real_img.shape[0]/ self.num_val_imgs,\n        optimizer_idx=optimizer_idx,\n        batch_idx=batch_idx,\n    )\n\n    self.log_dict(\n        {f\"val_{key}\": val.item() for key, val in val_loss.items()},\n        sync_dist=True,\n    )\n</code></pre>"},{"location":"reference/caveat/models/base/","title":"caveat.models.base","text":""},{"location":"reference/caveat/models/base/#caveat.models.base.BaseVAE","title":"<code>BaseVAE()</code>","text":"<p>             Bases: <code>Module</code></p> Source code in <code>caveat/models/base.py</code> <pre><code>def __init__(self) -&gt; None:\n    super(BaseVAE, self).__init__()\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.BaseVAE.decode","title":"<code>decode(input)</code>","text":"Source code in <code>caveat/models/base.py</code> <pre><code>def decode(self, input: tensor) -&gt; Any:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.BaseVAE.encode","title":"<code>encode(input)</code>","text":"Source code in <code>caveat/models/base.py</code> <pre><code>def encode(self, input: tensor) -&gt; list[tensor]:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.BaseVAE.forward","title":"<code>forward(*inputs)</code>  <code>abstractmethod</code>","text":"Source code in <code>caveat/models/base.py</code> <pre><code>@abstractmethod\ndef forward(self, *inputs: tensor) -&gt; tensor:\n    pass\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.BaseVAE.generate","title":"<code>generate(x, **kwargs)</code>","text":"Source code in <code>caveat/models/base.py</code> <pre><code>def generate(self, x: tensor, **kwargs) -&gt; tensor:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.BaseVAE.loss_function","title":"<code>loss_function(*inputs, **kwargs)</code>  <code>abstractmethod</code>","text":"Source code in <code>caveat/models/base.py</code> <pre><code>@abstractmethod\ndef loss_function(self, *inputs: Any, **kwargs) -&gt; tensor:\n    pass\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.BaseVAE.sample","title":"<code>sample(batch_size, current_device, **kwargs)</code>","text":"Source code in <code>caveat/models/base.py</code> <pre><code>def sample(self, batch_size: int, current_device: int, **kwargs) -&gt; tensor:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/models/utils/","title":"caveat.models.utils","text":""},{"location":"reference/caveat/models/utils/#caveat.models.utils.argmax_on_axis","title":"<code>argmax_on_axis(batch, axis=-1)</code>","text":"<p>Encoded given axis as one-hot based on argmax for that axis.</p> PARAMETER  DESCRIPTION <code>batch</code> <p>Input tensor.</p> <p> TYPE: <code>tensor</code> </p> <code>axis</code> <p>Axis index to encode. Defaults to -1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>-1</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>One hot encoded tensor.</p> <p> TYPE: <code>tensor</code> </p> Source code in <code>caveat/models/utils.py</code> <pre><code>def argmax_on_axis(batch: tensor, axis: int = -1) -&gt; tensor:\n    \"\"\"Encoded given axis as one-hot based on argmax for that axis.\n\n    Args:\n        batch (tensor): Input tensor.\n        axis (int, optional): Axis index to encode. Defaults to -1.\n\n    Returns:\n        tensor: One hot encoded tensor.\n    \"\"\"\n    batch = batch.swapaxes(axis, -1)\n    argmax = batch.argmax(axis=-1)\n    eye = torch.eye(batch.shape[-1])\n    batch = eye[argmax]\n    return batch.swapaxes(axis, -1)\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.conv_size","title":"<code>conv_size(size, kernel_size=3, stride=2, padding=1, dilation=1)</code>","text":"<p>Calculate output dimensions for 2d convolution.</p> PARAMETER  DESCRIPTION <code>size</code> <p>Input size, may be integer if symetric.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> </p> <code>kernel_size</code> <p>Kernel_size. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>Stride. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>Input padding. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> <code>dilation</code> <p>Dilation. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: Output size.</p> Source code in <code>caveat/models/utils.py</code> <pre><code>def conv_size(\n    size: Union[tuple[int, int], int],\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n    dilation: Union[tuple[int, int], int] = 1,\n) -&gt; np.array:\n    \"\"\"Calculate output dimensions for 2d convolution.\n\n    Args:\n        size (Union[tuple[int, int], int]): Input size, may be integer if symetric.\n        kernel_size (Union[tuple[int, int], int], optional): Kernel_size. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): Stride. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): Input padding. Defaults to 1.\n        dilation (Union[tuple[int, int], int], optional): Dilation. Defaults to 1.\n\n    Returns:\n        np.array: Output size.\n    \"\"\"\n    if isinstance(size, int):\n        size = (size, size)\n    if isinstance(kernel_size, int):\n        kernel_size = (kernel_size, kernel_size)\n    if isinstance(stride, int):\n        stride = (stride, stride)\n    if isinstance(padding, int):\n        padding = (padding, padding)\n    if isinstance(dilation, int):\n        dilation = (dilation, dilation)\n    return (\n        np.array(size)\n        + 2 * np.array(padding)\n        - np.array(dilation) * (np.array(kernel_size) - 1)\n        - 1\n    ) // np.array(stride) + 1\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.transconv_size","title":"<code>transconv_size(size, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)</code>","text":"<p>Calculate output dimension for 2d transpose convolution.</p> PARAMETER  DESCRIPTION <code>size</code> <p>Input size, may be integer if symetric.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> </p> <code>kernel_size</code> <p>Kernel size. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>Stride. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>Input padding. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> <code>dilation</code> <p>Dilation. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> <code>output_padding</code> <p>Output padding. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: Output size.</p> Source code in <code>caveat/models/utils.py</code> <pre><code>def transconv_size(\n    size: Union[tuple[int, int], int],\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n    dilation: Union[tuple[int, int], int] = 1,\n    output_padding: Union[tuple[int, int], int] = 1,\n) -&gt; np.array:\n    \"\"\"Calculate output dimension for 2d transpose convolution.\n\n    Args:\n        size (Union[tuple[int, int], int]): Input size, may be integer if symetric.\n        kernel_size (Union[tuple[int, int], int], optional): Kernel size. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): Stride. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): Input padding. Defaults to 1.\n        dilation (Union[tuple[int, int], int], optional): Dilation. Defaults to 1.\n        output_padding (Union[tuple[int, int], int], optional): Output padding. Defaults to 1.\n\n    Returns:\n        np.array: Output size.\n    \"\"\"\n    if isinstance(size, int):\n        size = (size, size)\n    if isinstance(kernel_size, int):\n        kernel_size = (kernel_size, kernel_size)\n    if isinstance(stride, int):\n        stride = (stride, stride)\n    if isinstance(padding, int):\n        padding = (padding, padding)\n    if isinstance(dilation, int):\n        dilation = (dilation, dilation)\n    if isinstance(output_padding, int):\n        output_padding = (output_padding, output_padding)\n    return (\n        (np.array(size) - 1) * np.array(stride)\n        - 2 * np.array(padding)\n        + np.array(dilation) * (np.array(kernel_size) - 1)\n        + np.array(output_padding)\n        + 1\n    )\n</code></pre>"},{"location":"reference/caveat/models/vae/","title":"caveat.models.vae","text":""},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE","title":"<code>VAE(in_shape, latent_dim, hidden_dims=None, kernel_size=3, stride=2, padding=1, **kwargs)</code>","text":"<p>             Bases: <code>BaseVAE</code></p> <p>Simple VAE model.</p> PARAMETER  DESCRIPTION <code>in_shape</code> <p>description</p> <p> TYPE: <code>tuple[int, int, int]</code> </p> <code>latent_dim</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>hidden_dims</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> DEFAULT: <code>None</code> </p> <code>kernel_size</code> <p>description. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>description. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>description. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> Source code in <code>caveat/models/vae.py</code> <pre><code>def __init__(\n    self,\n    in_shape: tuple[int, int, int],\n    latent_dim: int,\n    hidden_dims: list = None,\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Simple VAE model.\n\n    Args:\n        in_shape (tuple[int, int, int]): _description_\n        latent_dim (int): _description_\n        hidden_dims (list, optional): _description_. Defaults to None.\n        kernel_size (Union[tuple[int, int], int], optional): _description_. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): _description_. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): _description_. Defaults to 1.\n    \"\"\"\n    super(VAE, self).__init__()\n\n    self.latent_dim = latent_dim\n\n    modules = []\n    channels, h, w = in_shape\n\n    # Build Encoder\n    for h_dim in hidden_dims:\n        modules.append(\n            nn.Sequential(\n                nn.Conv2d(\n                    in_channels=channels,\n                    out_channels=h_dim,\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                ),\n                nn.BatchNorm2d(h_dim),\n                nn.LeakyReLU(),\n            )\n        )\n        h, w = conv_size(\n            (h, w), kernel_size=kernel_size, padding=padding, stride=stride\n        )\n        channels = h_dim\n\n    self.shape_before_flattening = (-1, channels, h, w)\n    self.encoder = nn.Sequential(*modules)\n    flat_size = int(channels * h * w)\n    self.fc_mu = nn.Linear(flat_size, latent_dim)\n    self.fc_var = nn.Linear(flat_size, latent_dim)\n\n    # Build Decoder\n    modules = []\n    self.decoder_input = nn.Linear(latent_dim, flat_size)\n    hidden_dims.reverse()\n\n    for i in range(len(hidden_dims) - 1):\n        modules.append(\n            nn.Sequential(\n                nn.ConvTranspose2d(\n                    hidden_dims[i],\n                    channels,\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    output_padding=(0, 1),\n                ),\n                nn.BatchNorm2d(hidden_dims[i + 1]),\n                nn.LeakyReLU(),\n            )\n        )\n\n    self.decoder = nn.Sequential(*modules)\n\n    self.final_layer = nn.Sequential(\n        nn.ConvTranspose2d(\n            hidden_dims[-1],\n            out_channels=in_shape[0],\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            output_padding=(0, 1),\n        ),\n        nn.BatchNorm2d(in_shape[0]),\n        # nn.LeakyReLU(),\n        # nn.Conv2d(\n        #     hidden_dims[-1],\n        #     out_channels=in_shape[0],\n        #     kernel_size=3,\n        #     padding=1,\n        # ),\n        nn.Tanh(),\n    )\n</code></pre>"},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.decoder","title":"<code>decoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.decoder_input","title":"<code>decoder_input = nn.Linear(latent_dim, flat_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.encoder","title":"<code>encoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.fc_mu","title":"<code>fc_mu = nn.Linear(flat_size, latent_dim)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.fc_var","title":"<code>fc_var = nn.Linear(flat_size, latent_dim)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.final_layer","title":"<code>final_layer = nn.Sequential(nn.ConvTranspose2d(hidden_dims[-1], out_channels=in_shape[0], kernel_size=kernel_size, stride=stride, padding=padding, output_padding=(0, 1)), nn.BatchNorm2d(in_shape[0]), nn.Tanh())</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.latent_dim","title":"<code>latent_dim = latent_dim</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.shape_before_flattening","title":"<code>shape_before_flattening = (-1, channels, h, w)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.decode","title":"<code>decode(z)</code>","text":"<p>Maps the given latent codes.</p> PARAMETER  DESCRIPTION <code>z</code> <p>description</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>description</p> <p> TYPE: <code>tensor</code> </p> Source code in <code>caveat/models/vae.py</code> <pre><code>def decode(self, z: tensor) -&gt; tensor:\n    \"\"\"Maps the given latent codes.\n\n    Args:\n        z (tensor): _description_\n\n    Returns:\n        tensor: _description_\n    \"\"\"\n    result = self.decoder_input(z)\n    result = result.view(self.shape_before_flattening)\n    result = self.decoder(result)\n    result = self.final_layer(result)\n    return result\n</code></pre>"},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.encode","title":"<code>encode(input)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER  DESCRIPTION <code>input</code> <p>description</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[tensor]</code> <p>list[tensor]: description</p> Source code in <code>caveat/models/vae.py</code> <pre><code>def encode(self, input: tensor) -&gt; list[tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): _description_\n\n    Returns:\n        list[tensor]: _description_\n    \"\"\"\n    result = self.encoder(input)\n    result = torch.flatten(result, start_dim=1)\n\n    # Split the result into mu and var components\n    # of the latent Gaussian distribution\n    mu = self.fc_mu(result)\n    log_var = self.fc_var(result)\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.forward","title":"<code>forward(input, **kwargs)</code>","text":"<p>Forward pass.</p> PARAMETER  DESCRIPTION <code>input</code> <p>description</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[tensor]</code> <p>list[tensor]: description</p> Source code in <code>caveat/models/vae.py</code> <pre><code>def forward(self, input: tensor, **kwargs) -&gt; list[tensor]:\n    \"\"\"Forward pass.\n\n    Args:\n        input (tensor): _description_\n\n    Returns:\n        list[tensor]: _description_\n    \"\"\"\n    mu, log_var = self.encode(input)\n    z = self.reparameterize(mu, log_var)\n    return [self.decode(z), input, mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.generate","title":"<code>generate(x, **kwargs)</code>","text":"<p>Given an encoder input, return reconstructed output.</p> PARAMETER  DESCRIPTION <code>x</code> <p>[B x C x H x W]</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[B x C x H x W]</p> <p> TYPE: <code>tensor</code> </p> Source code in <code>caveat/models/vae.py</code> <pre><code>def generate(self, x: tensor, **kwargs) -&gt; tensor:\n    \"\"\"Given an encoder input, return reconstructed output.\n\n    Args:\n        x (tensor): [B x C x H x W]\n\n    Returns:\n        tensor: [B x C x H x W]\n    \"\"\"\n\n    samples = self.forward(x)[0]\n    samples = argmax_on_axis(samples, 2)\n    return samples\n</code></pre>"},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.loss_function","title":"<code>loss_function(*args, **kwargs)</code>","text":"<p>Computes the VAE loss function. KL(N(\\mu, \\sigma), N(0, 1)) = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}</p> RETURNS DESCRIPTION <code>dict</code> <p>description</p> <p> TYPE: <code>dict</code> </p> Source code in <code>caveat/models/vae.py</code> <pre><code>def loss_function(self, *args, **kwargs) -&gt; dict:\n    r\"\"\"Computes the VAE loss function.\n    KL(N(\\mu, \\sigma), N(0, 1))\n    = \\log \\frac{1}{\\sigma} + \\frac{\\sigma^2 + \\mu^2}{2} - \\frac{1}{2}\n\n    Returns:\n        dict: _description_\n    \"\"\"\n\n    recons = args[0]\n    input = args[1]\n    mu = args[2]\n    log_var = args[3]\n\n    kld_weight = kwargs[\n        \"M_N\"\n    ]  # Account for the minibatch samples from the dataset\n    recons_loss = F.mse_loss(recons, input)\n\n    kld_loss = torch.mean(\n        -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1),\n        dim=0,\n    )\n\n    loss = recons_loss + kld_weight * kld_loss\n    return {\n        \"loss\": loss,\n        \"Reconstruction_Loss\": recons_loss.detach(),\n        \"KLD\": -kld_loss.detach(),\n    }\n</code></pre>"},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.reparameterize","title":"<code>reparameterize(mu, logvar)</code>","text":"<p>Reparameterization trick to sample from N(mu, var) from N(0,1).</p> PARAMETER  DESCRIPTION <code>mu</code> <p>Mean of the latent Gaussian [B x D]</p> <p> TYPE: <code>tensor</code> </p> <code>logvar</code> <p>Standard deviation of the latent Gaussian [B x D]</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[B x D]</p> <p> TYPE: <code>tensor</code> </p> Source code in <code>caveat/models/vae.py</code> <pre><code>def reparameterize(self, mu: tensor, logvar: tensor) -&gt; tensor:\n    \"\"\"Reparameterization trick to sample from N(mu, var) from N(0,1).\n\n    Args:\n        mu (tensor): Mean of the latent Gaussian [B x D]\n        logvar (tensor): Standard deviation of the latent Gaussian [B x D]\n\n    Returns:\n        tensor: [B x D]\n    \"\"\"\n    std = torch.exp(0.5 * logvar)\n    eps = torch.randn_like(std)\n    return eps * std + mu\n</code></pre>"},{"location":"reference/caveat/models/vae/#caveat.models.vae.VAE.sample","title":"<code>sample(num_samples, current_device, **kwargs)</code>","text":"<p>Sample from the latent space and return the corresponding decoder space map.</p> PARAMETER  DESCRIPTION <code>num_samples</code> <p>Number of samples.</p> <p> TYPE: <code>int</code> </p> <code>current_device</code> <p>Device to run the model</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>description</p> <p> TYPE: <code>tensor</code> </p> Source code in <code>caveat/models/vae.py</code> <pre><code>def sample(self, num_samples: int, current_device: int, **kwargs) -&gt; tensor:\n    \"\"\"Sample from the latent space and return the corresponding decoder space map.\n\n    Args:\n        num_samples (int): Number of samples.\n        current_device (int): Device to run the model\n\n    Returns:\n        tensor: _description_\n    \"\"\"\n\n    z = torch.randn(num_samples, self.latent_dim)\n    z = z.to(current_device)\n    samples = self.decode(z)\n    samples = argmax_on_axis(samples, 2)\n    return samples\n</code></pre>"},{"location":"reference/caveat/run/","title":"caveat.run","text":""},{"location":"reference/caveat/run/#caveat.run.data","title":"<code>data = VAEDataset(path='~/Projects/caveat/examples/example_population.csv')</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/run/#caveat.run.experiment","title":"<code>experiment = Experiment(model)</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/run/#caveat.run.model","title":"<code>model = models.VAE(in_shape=(1, 5, 144), latent_dim=2, hidden_dims=[64, 64], stride=(2, 2))</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/run/#caveat.run.runner","title":"<code>runner = Trainer(logger=tb_logger, callbacks=[LearningRateMonitor(), ModelCheckpoint(save_top_k=2, dirpath=Path(tb_logger.log_dir, 'checkpoints'), monitor='val_loss', save_last=True)], max_epochs=20)</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/run/#caveat.run.tb_logger","title":"<code>tb_logger = TensorBoardLogger(save_dir='logs', name='testVAE')</code>  <code>module-attribute</code>","text":""}]}