{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Deep learning for modelling human activity schedules.</p> <p> </p> <p>Caveat is for building and evaluating models of human activity schedules. Activity schedules are a useful representation of human behaviours, used for modelling transport, energy and epidemiological systems.</p> <p>Activity scheduling is required component of activity-based models. But Caveat also has application for (i) diverse upsampling, (ii) bias correction, (iii) simple forecasting.</p>"},{"location":"#research","title":"Research","text":"<p>Caveat is part of an ongoing research project. Overview of presented work can be found in the papers module, including key information allowing presented results to be reproduced.</p>"},{"location":"#example-applications","title":"Example Applications","text":"<p>Generation for up-sampling or anonymisation an observed population of activity schedules: - <code>caveat run configs/example_run.yaml</code> - train a generative model using an observed population of schedules, sample a new synthetic population of schedules, and evaluate it's quality.</p> <p>Conditional Generation for bias correction and simple forecasting or modelling from an observed population of schedules and attributes: - <code>caveat run configs/example_run_conditional.yaml</code> - train a model using an observed population of schedules with attributes, sample a new population conditional on new person attributes, and evaluate it's quality.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Once installed get started using <code>caveat --help</code>.</p> <p>Caveat provides various commands to facilitate rapid and reproducible experiments. Outputs are written to the (default) <code>logs</code> directory.</p>"},{"location":"#run","title":"Run","text":"<p><code>caveat run --help</code></p> <p>Train and evaluate a model. The run data, encoder, model and other parameters are controlled using a run config. For example:</p> <ul> <li><code>caveat run configs/example_run.yaml</code></li> <li><code>caveat run configs/example_run_conditional.yaml</code> (conditional generation)</li> </ul>"},{"location":"#batch","title":"Batch","text":"<p><code>caveat batch --help</code></p> <p>Batch allows training and comparison of multiple models and/or hyper-params as per a batch config. For example:</p> <ul> <li><code>caveat batch configs/example_batch.yaml</code></li> <li><code>caveat batch configs/example_batch_conditional.yaml</code> (conditional generation)</li> </ul>"},{"location":"#nrun","title":"Nrun","text":"<p><code>caveat nrun --help</code></p> <p>Nrun is a simplified version of batch used to repeat the same model training and evaluation. This is intended to test for variance in model training and sampling. For example, run and evaluate the variance of n=3 of the same experiment using:</p> <ul> <li><code>caveat nrun configs/example_run.yaml --n 3</code></li> </ul> <p>The config is as per a regular run config but <code>seed</code> is ignored.</p>"},{"location":"#ngen","title":"Ngen","text":"<p><code>caveat ngen --help</code></p> <p>As per nrun but only assesses variance from the sampling/generative process (not model training):</p> <ul> <li><code>caveat ngen configs/example_run.yaml --n 3</code></li> </ul>"},{"location":"#evaluate","title":"Evaluate","text":"<p><code>caveat eval --help</code></p> <p>Evaluate the outputs of an existing run (or batch using <code>-b</code>):</p> <ul> <li><code>caveat eval configs/example_run.yaml</code></li> <li><code>caveat eval configs/example_batch_conditional.yaml -b</code> (conditional evaluation of batch)</li> </ul>"},{"location":"#tune","title":"Tune","text":"<p><code>caveat tune --help</code></p> <p>Carry out hyper-parameter tuning using optuna. See the example config <code>config/example_tune.yaml</code>. Tuning runs are recorded in <code>optuna.db</code> and can be reviewed via optuna-dashboard.</p>"},{"location":"#label-joint-and-multi-model-models","title":"Label, joint and multi-model models","text":"<p>We have some fancy model variations for predicting labels from schedules, joint generation of schedules and associated labels, and multi-model runs (segmenting and training a model per label).</p> <p><code>caveat lrun --help</code></p> <p><code>caveat jrun --help</code></p> <p><code>caveat jbatch --help</code></p> <p><code>caveat mmrun --help</code></p>"},{"location":"#logging","title":"Logging","text":"<p>Caveat writes tensorboard logs to a (default) <code>logs/</code> directory. Monitor or review training progress using <code>tensorboard --logdir=logs</code>.</p>"},{"location":"#configuration","title":"Configuration","text":"<p>For help with configuration refer to our documentation.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install caveat, we recommend using the mamba package manager:</p> <pre><code>git clone git@github.com:big-ucl/caveat.git\ncd caveat\nmamba create -n caveat -c conda-forge -c city-modelling-lab -c pytorch --file requirements/base.txt --file requirements/dev.txt\nmamba activate caveat\npip install --no-deps -e .\n</code></pre> <p>Caveat is in development, hence an \"editable\" (<code>-e</code>) install is recommended.</p>"},{"location":"#jupyter-notebooks","title":"Jupyter Notebooks","text":"<p>To run the example notebooks you will need to add a ipython kernel into the mamba environemnt: <code>ipython kernel install --user --name=caveat</code>.</p>"},{"location":"#windoes-and-cuda","title":"Windoes and CUDA","text":"<p>If you want to get a cuda enabled windows install you can try the following mamba create: <pre><code>mamba create -n caveat -c conda-forge -c city-modelling-lab -c pytorch -c nvidia --file requirements/cuda_base.txt --file requirements/dev.txt\n</code></pre> Or lake a look here. Note that you need to have the right version of python. For more detailed instructions, see our documentation.</p>"},{"location":"#optuna","title":"Optuna","text":"<p>Optuna is also a bit finickety. Specifically it seems to be ahead of the grpcio version available on conda-forge. Breaking the mamba build. Current work around is to pip install within the mamba env <code>pip install grpcio==1.70.0</code>. To make sure that this version is used, make sure to use the dev build which includes a conda-forge pip, ensuring everything is discovered correctly.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Note that caveat is work in progress, we maintain example config files but these can be affected by breaking changes. If you find an issue with an example config please report it.</p> <p>See our documentation for additional guides on contribution inclusing reporting problems.</p>"},{"location":"#building-the-documentation","title":"Building the documentation","text":"<p>If you are unable to access the online documentation, you can build the documentation locally. First, install a development environment of caveat, then deploy the documentation using mike:</p> <pre><code>mike deploy develop\nmike serve\n</code></pre> <p>Then you can view the documentation in a browser at http://localhost:8000/.</p>"},{"location":"#credits","title":"Credits","text":"<p>This package was created with Cookiecutter and the arup-group/cookiecutter-pypackage project template.</p>"},{"location":"configuration/","title":"Configuration","text":"<p>To get started we recommend using an existing example config, such as <code>example_run.yaml</code> or <code>example_batch.yaml</code> for a batch command.</p>"},{"location":"configuration/#input-data","title":"Input Data","text":"<p>Caveat expects inputs as .csv format with the following headers.</p>"},{"location":"configuration/#activity-sequences","title":"Activity sequences","text":"pid act start end 0 home 0 390 0 work 390 960 0 home 960 1440 1 home 0 390 1 education 390 960 1 home 960 1440 <ul> <li>pid (person id) field is a unique identifier for each sequence</li> <li>act is a categorical value for the type of activity in the sequence</li> <li>start and end are the start and end times of the activities in the sequence</li> </ul> <p>Times are assumed to be in minutes and should be integers. Valid sequences should be complete, ie the start of an activity should be equal to the end of the previous. The convention is to start at midnight. Such that time can be thought of as minutes since midnight.</p>"},{"location":"configuration/#attributes","title":"Attributes","text":"<p>Caveat supports conditional generation, for which individual input sequences also require attributes.</p> pid gender age employment 0 F 24 FTW 1 M 85 NEET <ul> <li>pid (person id) field is a unique identifier designating the attributes for each above sequence</li> </ul> <p>Other than the <code>pid</code> column, columns can be arbitrarily named and represented with any data type.</p>"},{"location":"configuration/#examples","title":"Examples","text":"<p>There are example toy populations with 1000 sequences in <code>caveat/examples/data</code>. There are also example notebooks for:</p> <ul> <li>Generation of a synthetic population</li> <li>Generation of a population from UK travel diaries (requires access to UK NTS trip data)</li> </ul>"},{"location":"configuration/#modules","title":"Modules","text":"<p>Caveat provides a framework to train and evaluate models. Caveat is composed of the following modules:</p> <ul> <li>Encoding - encoding/decoding inputs into various data representations</li> <li>Model - generative models to learn and synthesize new populations of sequences</li> </ul> <p>For generative models you may also want to use Evaluate to measuring the quality of synthetic populations of sequences.</p> <p>Caveat is designed to be installed and run as a command line application. The above modules are configured using config files. Such that experiments are accessible without code and can be reproduced.</p>"},{"location":"configuration/#encoding","title":"Encoding","text":""},{"location":"configuration/#schedules","title":"Schedules","text":"<p>Input schedules are configured as follows:</p> <pre><code>schedules_path: \"examples/data/synthetic_schedules.csv\"\n</code></pre> <p>We are keen to test different encodings (such as continuous sequences versus discretized time-steps).</p> <p>The encoder and it's parameters are defined in the config <code>encoder</code> group. For example:</p> <pre><code>encoder_params:\n  name: \"discrete\"\n  duration: 1440\n  step_size: 10\n</code></pre> <p>See more examples in <code>caveat/configs</code>.</p> <p>More encoders are defined in the <code>encoders</code> module and should be accessed via <code>caveat.encoders.library</code>.</p> <p>Note that encoders must implement both an encode and decode method so that model outputs can be converted back into the population format for reporting.</p>"},{"location":"configuration/#attributes_1","title":"Attributes","text":"<p>If a conditional model is being trained, an <code>attributes_path</code> should also be specified:</p> <pre><code>attributes_path: \"examples/data/synthetic_attributes.csv\"\n</code></pre> <p>By default a conditional model will generate a synthetic model using the input attributes configured above. Alternately an alternative population of attributes can be configured using a <code>synthetic_attributes_path</code>:</p> <pre><code>synthetic_attributes_path: \"examples/data/some_other_attributes.csv\"\n</code></pre> <p>The encoding of attributes is controlled using the conditionals module, for example:</p> <pre><code>conditionals:\n  gender: nominal\n  age: {ordinal: [0,100]}\n  employment: nominal\n</code></pre>"},{"location":"configuration/#model","title":"Model","text":"<p>The model and it's parameters are defined in the config <code>model_params</code> group. For example:</p> <pre><code>model_params:\n  name: \"conv\"\n  hidden_layers: [64,64]\n  latent_dim: 2\n  stride: [2,2]\n</code></pre> <p>See more examples in <code>caveat.configs</code>.</p> <p>Models are defined in <code>models</code> and should be accessed via <code>caveat.models.library</code>. Models and their training should be specified via the config.</p>"},{"location":"configuration/#experiment-hyper-parameters","title":"Experiment Hyper-parameters","text":"<p>The <code>data_loader</code>, <code>experiment</code> and <code>trainer</code> hyper-params are also configured by similarly named groups. These groups use the standard pytorch-lightning framework.</p> <p>Please refer to the example config files or ask if in doubt.</p>"},{"location":"configuration/#evaluate","title":"Evaluate","text":""},{"location":"configuration/#basic-evaluation","title":"Basic Evaluation","text":"<p>Each model (with weights from the best performing validation step) is used to generate a new \"synthetic\" population of schedules. These \"synthetic\" populations are evaluated by comparing them to an \"target\" population of schedules. By default the input schedules are used as this target. Alternately a new schedules path can be configures using the evaluation params:</p> <pre><code>evaluation_params:\n    schedules_path: \"examples/data/synthetic_schedules.csv\"\n</code></pre> <p>Evaluating the quality of generated populations is subjective. The <code>features</code> module provides functions for extracting features from populations. Such as \"activity durations\". These are then used to make descriptive metrics and distance metrics between the observed and synthetic populations.</p> <p>See examples for additional evaluation inspiration.</p>"},{"location":"configuration/#conditional-evaluation","title":"Conditional Evaluation","text":"<p>When evaluating conditionality, ie the distributions between sequences and attributes, additional configuration is required to segment sequences based on attributes. Evaluation is then made for each segmentation (or sub-population). For example, to evaluate based on different gender and employment attributes:</p> <pre><code>evaluation_params:\n    schedules_path: \"examples/data/synthetic_schedules.csv\"  # this will default to the input schedules\n    split_on: [gender, employment]\n</code></pre> <p>Note that the gender and employment sub-populations are not joint, ie there is not splitting by gender and employment simultaneously.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>caveat is an actively maintained and utilised project.</p>"},{"location":"contributing/#how-to-contribute","title":"How to contribute","text":"<p>to report issues, request features, or exchange with our community, just follow the links below.</p> <p>Is something not working?</p> <p> Report a bug</p> <p>Missing information in our docs?</p> <p> Report a docs issue</p> <p>Want to submit an idea?</p> <p> Request a change</p> <p>Have a question or need help?</p> <p> Ask a question</p>"},{"location":"contributing/#developing-caveat","title":"Developing caveat","text":"<p>To find beginner-friendly existing bugs and feature requests you may like to start out with, take a look at our good first issues.</p>"},{"location":"contributing/#setting-up-a-development-environment","title":"Setting up a development environment","text":"<p>To create a development environment for caveat, with all libraries required for development and quality assurance installed, it is easiest to install caveat using the mamba package manager, as follows:</p> <ol> <li>Install mamba with the Mambaforge executable for your operating system.</li> <li>Open the command line (or the \"miniforge prompt\" in Windows).</li> <li>Download (a.k.a., clone) the caveat repository: <code>git clone git@github.com:fredshone/caveat.git</code></li> <li>Change into the <code>caveat</code> directory: <code>cd caveat</code></li> <li>Create the caveat mamba environment: <code>mamba create -n caveat -c conda-forge --file requirements/base.txt --file requirements/dev.txt</code></li> <li>Activate the caveat mamba environment: <code>mamba activate caveat</code></li> <li>Install the caveat package into the environment, in editable mode and ignoring dependencies (we have dealt with those when creating the mamba environment): <code>pip install --no-deps -e .</code></li> </ol> <p>All together:</p> <pre><code>git clone git@github.com:big-ucl/caveat.git\ncd caveat\nmamba create -n caveat -c conda-forge -c city-modelling-lab -c pytorch --file requirements/base.txt --file requirements/dev.txt\nmamba activate caveat\npip install --no-deps -e .\n</code></pre> <p>Caveat is in development, hence an \"editable\" (<code>-e</code>) install is recommended.</p>"},{"location":"contributing/#jupyter-notebooks","title":"Jupyter Notebooks","text":"<p>To run the example notebooks you will need to add a ipython kernel into the mamba environemnt: <code>ipython kernel install --user --name=caveat</code>.</p>"},{"location":"contributing/#windoes-and-cuda","title":"Windoes and CUDA","text":"<p>If you want to get a cuda enabled windows install you can try the following mamba create: <pre><code>mamba create -n caveat -c conda-forge -c city-modelling-lab -c pytorch -c nvidia --file requirements/cuda_base.txt --file requirements/dev.txt\n</code></pre> Or lake a look here. Note that you need to have the right version of python.</p> <p>If installing directly with pip, you can install these libraries using the <code>dev</code> option, i.e., <code>pip install -e '.[dev]'</code> Either way, you should add your environment as a jupyter kernel, so the example notebooks can run in the tests: <code>ipython kernel install --user --name=caveat</code> If you plan to make changes to the code then please make regular use of the following tools to verify the codebase while you work:</p> <ul> <li><code>pre-commit</code>: run <code>pre-commit install</code> in your command line to load inbuilt checks that will run every time you commit your changes. The checks are: 1. check no large files have been staged, 2. lint python files for major errors, 3. format python files to conform with the PEP8 standard. You can also run these checks yourself at any time to ensure staged changes are clean by calling <code>pre-commit</code>.</li> <li><code>pytest</code> - run the unit test suite and check test coverage.</li> </ul> <p>Note</p> <p>If you already have an environment called <code>caveat</code> on your system (e.g., for a stable installation of the package), you will need to chose a different environment name. You will then need to add this as a pytest argument when running the tests: <code>pytest --nbmake-kernel=[my-env-name]</code>.</p>"},{"location":"contributing/#rapid-fire-testing","title":"Rapid-fire testing","text":"<p>The following options allow you to strip down the test suite to the bare essentials: 1. The test suite includes unit tests and integration tests (in the form of jupyter notebooks found in the <code>examples</code> directory, and tests in the <code>integration_tests</code> diractory). The integration tests can be slow, so if you want to avoid them during development, you should run <code>pytest tests/</code>. 2. You can avoid generating coverage reports, by adding the <code>--no-cov</code> argument: <code>pytest --no-cov</code>. 3. By default, the tests run with up to two parallel threads, to increase this to e.g. 4 threads: <code>pytest -n4</code>.</p> <p>All together:</p> <pre><code>pytest tests/ --no-cov -n4\n</code></pre> <p>Note</p> <p>You cannot debug failing tests and have your tests run in parallel, you will need to set <code>-n0</code> if using the <code>--pdb</code> flag</p>"},{"location":"contributing/#submitting-changes","title":"Submitting changes","text":"<p>To contribute changes:</p> <ol> <li>Fork the project on GitHub.</li> <li>Create a feature branch to work on in your fork (<code>git checkout -b new-fix-or-feature</code>).</li> <li>Test your changes using <code>pytest</code>.</li> <li>Commit your changes to the feature branch (you should have <code>pre-commit</code> installed to ensure your code is correctly formatted when you commit changes).</li> <li>Push the branch to GitHub (<code>git push origin new-fix-or-feature</code>).</li> <li>On GitHub, create a new pull request from the feature branch.</li> </ol>"},{"location":"contributing/#pull-requests","title":"Pull requests","text":"<p>Before submitting a pull request, check whether you have:</p> <ul> <li>Added your changes to <code>CHANGELOG.md</code>.</li> <li>Added or updated documentation for your changes.</li> <li>Added tests if you implemented new functionality.</li> </ul> <p>When opening a pull request, please provide a clear summary of your changes!</p>"},{"location":"contributing/#commit-messages","title":"Commit messages","text":"<p>Please try to write clear commit messages. One-line messages are fine for small changes, but bigger changes should look like this:</p> <pre><code>A brief summary of the commit (max 50 characters)\n\nA paragraph or bullet-point list describing what changed and its impact,\ncovering as many lines as needed.\n</code></pre>"},{"location":"contributing/#code-conventions","title":"Code conventions","text":"<p>Start reading our code and you'll get the hang of it.</p> <p>We mostly follow the official Style Guide for Python Code (PEP8).</p> <p>We have chosen to use the uncompromising code formatter <code>black</code> and the linter <code>ruff</code>. When run from the root directory of this repo, <code>pyproject.toml</code> should ensure that formatting and linting fixes are in line with our custom preferences (e.g., 100 character maximum line length). The philosophy behind using <code>black</code> is to have uniform style throughout the project dictated by code. Since <code>black</code> is designed to minimise diffs, and make patches more human readable, this also makes code reviews more efficient. To make this a smooth experience, you should run <code>pre-commit install</code> after setting up your development environment, so that <code>black</code> makes all the necessary fixes to your code each time you commit, and so that <code>ruff</code> will highlight any errors in your code. If you prefer, you can also set up your IDE to run these two tools whenever you save your files, and to have <code>ruff</code> highlight erroneous code directly as you type. Take a look at their documentation for more information on configuring this.</p> <p>We require all new contributions to have docstrings for all modules, classes and methods. When adding docstrings, we request you use the Google docstring style.</p>"},{"location":"contributing/#release-checklist","title":"Release checklist","text":""},{"location":"contributing/#pre-release","title":"Pre-release","text":"<ul> <li> Make sure all unit and integration tests pass (This is best done by creating a pre-release pull request).</li> <li> Re-run tutorial Jupyter notebooks (<code>pytest examples/ --overwrite</code>).</li> <li> Make sure documentation builds without errors (<code>mike deploy [version]</code>, where <code>[version]</code> is the current minor release of the form <code>X.Y</code>).</li> <li> Make sure the changelog is up-to-date, especially that new features and backward incompatible changes are clearly marked.</li> </ul>"},{"location":"contributing/#create-release","title":"Create release","text":"<ul> <li> Bump the version number in <code>caveat/__init__.py</code></li> <li> Update the changelog with final version number of the form <code>vX.Y.Z</code>, release date, and github <code>compare</code> link (at the bottom of the page).</li> <li> Commit with message <code>Release vX.Y.Z</code>, then add a <code>vX.Y.Z</code> tag.</li> <li> Create a release pull request to verify that the conda package builds successfully.</li> <li> Once the PR is approved and merged, create a release through the GitHub web interface, using the same tag, titling it <code>Release vX.Y.Z</code> and include all the changelog elements that are not flagged as internal.</li> </ul>"},{"location":"contributing/#post-release","title":"Post-release","text":"<ul> <li> Update the changelog, adding a new <code>[Unreleased]</code> heading.</li> <li> Update <code>caveat/__init__.py</code> to the next version appended with <code>.dev0</code>, in preparation for the next main commit.</li> </ul>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#setting-up-a-user-environment","title":"Setting up a user environment","text":"<p>As a <code>caveat</code> user, it is easiest to install using the mamba package manager, as follows:</p> <ol> <li>Install mamba with the Mambaforge executable for your operating system.</li> <li> <p>Open the command line (or the \"miniforge prompt\" in Windows).</p> </li> <li> <p>Create the caveat mamba environment: <code>mamba create -n caveat -c conda-forge -c city-modelling-lab caveat</code></p> </li> <li>Activate the caveat mamba environment: <code>mamba activate caveat</code></li> </ol> <p>All together:</p>"},{"location":"installation/#running-the-example-notebooks","title":"Running the example notebooks","text":"<p>If you have followed the non-developer installation instructions above, you will need to install <code>jupyter</code> into your <code>caveat</code> environment to run the example notebooks:</p> <pre><code>mamba install -n caveat jupyter\n</code></pre> <p>With Jupyter installed, it's easiest to then add the environment as a jupyter kernel:</p> <pre><code>mamba activate caveat\nipython kernel install --user --name=caveat\njupyter notebook\n</code></pre>"},{"location":"installation/#choosing-a-different-environment-name","title":"Choosing a different environment name","text":"<p>If you would like to use a different name to <code>caveat</code> for your mamba environment, the installation becomes (where <code>[my-env-name]</code> is your preferred name for the environment):</p> <pre><code>mamba create -n [my-env-name] -c conda-forge --file requirements/base.txt\nmamba activate [my-env-name]\nipython kernel install --user --name=[my-env-name]\n</code></pre>"},{"location":"installation/#setting-up-a-development-environment","title":"Setting up a development environment","text":"<p>The install instructions are slightly different to create a development environment compared to a user environment:</p> <pre><code>git clone git@github.com:big-ucl/caveat.git\ncd caveat\nmamba create -n caveat -c conda-forge -c city-modelling-lab -c pytorch --file requirements/base.txt --file requirements/dev.txt\nmamba activate caveat\npip install --no-deps -e .\n</code></pre> <p>Caveat is in development, hence an \"editable\" (<code>-e</code>) install is recommended.</p>"},{"location":"installation/#jupyter-notebooks","title":"Jupyter Notebooks","text":"<p>To run the example notebooks you will need to add a ipython kernel into the mamba environemnt: <code>ipython kernel install --user --name=caveat</code>.</p>"},{"location":"installation/#windoes-and-cuda","title":"Windoes and CUDA","text":"<p>If you want to get a cuda enabled windows install you can try the following mamba create: <pre><code>mamba create -n caveat -c conda-forge -c city-modelling-lab -c pytorch -c nvidia --file requirements/cuda_base.txt --file requirements/dev.txt\n</code></pre> Or lake a look here. Note that you need to have the right version of python.</p>"},{"location":"api/cli/","title":"CLI Reference","text":"<p>This page provides documentation for our command line tools.</p>"},{"location":"api/cli/#caveat","title":"caveat","text":"<p>Console script for caveat.</p> <p>Usage:</p> <pre><code>caveat [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> Name Type Description Default <code>--version</code> boolean Show the version and exit. <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-batch","title":"caveat batch","text":"<p>Train and report on a batch of encoders and models as per the given configuration file.</p> <p>Usage:</p> <pre><code>caveat batch [OPTIONS] CONFIG_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--test</code>, <code>-t</code> boolean N/A <code>False</code> <code>--no-gen</code>, <code>-ng</code> boolean N/A <code>False</code> <code>--no-infer</code>, <code>-ni</code> boolean N/A <code>False</code> <code>--stats</code>, <code>-s</code> boolean N/A <code>False</code> <code>--verbose</code>, <code>-v</code> boolean N/A <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-eval","title":"caveat eval","text":"<p>Evaluate on the given observed population and logs directory.</p> <p>Usage:</p> <pre><code>caveat eval [OPTIONS] CONFIG_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--schedules</code> text N/A <code>synthetic_schedules.csv</code> <code>--labels</code> text N/A None <code>--verbose</code>, <code>-v</code> boolean N/A <code>False</code> <code>--stats</code> boolean N/A <code>False</code> <code>--batch</code>, <code>-b</code> boolean N/A <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-jbatch","title":"caveat jbatch","text":"<p>Train and report on a batch of joint models as per the given configuration file.</p> <p>Usage:</p> <pre><code>caveat jbatch [OPTIONS] CONFIG_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--test</code>, <code>-t</code> boolean N/A <code>False</code> <code>--no-infer</code>, <code>-ni</code> boolean N/A <code>False</code> <code>--no-gen</code>, <code>-ng</code> boolean N/A <code>False</code> <code>--verbose</code>, <code>-v</code> boolean N/A <code>False</code> <code>--no_sample</code>, <code>-ns</code> boolean N/A <code>False</code> <code>--patience</code>, <code>-p</code> integer N/A <code>8</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-jrun","title":"caveat jrun","text":"<p>Train and report on a joint model as per the given configuration file.</p> <p>Usage:</p> <pre><code>caveat jrun [OPTIONS] CONFIG_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--test</code>, <code>-t</code> boolean N/A <code>False</code> <code>--no-infer</code>, <code>-ni</code> boolean N/A <code>False</code> <code>--no-gen</code>, <code>-ng</code> boolean N/A <code>False</code> <code>--verbose</code>, <code>-v</code> boolean N/A <code>False</code> <code>--no_sample</code>, <code>-ns</code> boolean N/A <code>False</code> <code>--patience</code>, <code>-p</code> integer N/A <code>8</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-lrun","title":"caveat lrun","text":"<p>Train and test label predicting model.</p> <p>Usage:</p> <pre><code>caveat lrun [OPTIONS] CONFIG_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--verbose</code>, <code>-v</code> boolean N/A <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-mmrun","title":"caveat mmrun","text":"<p>Multi-model variation of run command for brute-force conditionality.</p> <p>Usage:</p> <pre><code>caveat mmrun [OPTIONS] CONFIG_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--test</code>, <code>-t</code> boolean N/A <code>False</code> <code>--no-infer</code>, <code>-ni</code> boolean N/A <code>False</code> <code>--no-gen</code>, <code>-ng</code> boolean N/A <code>False</code> <code>--verbose</code>, <code>-v</code> boolean N/A <code>False</code> <code>--cool-start</code>, <code>-cs</code> boolean N/A <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-ngen","title":"caveat ngen","text":"<p>Train and report variance on n identical runs with varying seeds.</p> <p>Usage:</p> <pre><code>caveat ngen [OPTIONS] CONFIG_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--n</code> integer N/A <code>5</code> <code>--no-infer</code>, <code>-ni</code> boolean N/A <code>False</code> <code>--stats</code>, <code>-s</code> boolean N/A <code>False</code> <code>--verbose</code>, <code>-v</code> boolean N/A <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-nrun","title":"caveat nrun","text":"<p>Train and report variance on n identical runs with varying seeds.</p> <p>Usage:</p> <pre><code>caveat nrun [OPTIONS] CONFIG_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--n</code> integer N/A <code>5</code> <code>--test</code>, <code>-t</code> boolean N/A <code>False</code> <code>--no-gen</code>, <code>-ng</code> boolean N/A <code>False</code> <code>--no-infer</code>, <code>-ni</code> boolean N/A <code>False</code> <code>--stats</code>, <code>-s</code> boolean N/A <code>False</code> <code>--verbose</code>, <code>-v</code> boolean N/A <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-report","title":"caveat report","text":"<p>Report on the given observed population and logs directory.</p> <p>Usage:</p> <pre><code>caveat report [OPTIONS] OBSERVED_PATH LOGS_DIR\n</code></pre> <p>Options:</p> Name Type Description Default <code>--name</code> text N/A <code>synthetic_schedules.csv</code> <code>--verbose</code> boolean N/A <code>False</code> <code>--head</code> integer N/A <code>10</code> <code>--batch</code>, <code>-b</code> boolean N/A <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-run","title":"caveat run","text":"<p>Train and report on an encoder and model as per the given configuration file.</p> <p>Usage:</p> <pre><code>caveat run [OPTIONS] CONFIG_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--test</code>, <code>-t</code> boolean N/A <code>False</code> <code>--no-infer</code>, <code>-ni</code> boolean N/A <code>False</code> <code>--no-gen</code>, <code>-ng</code> boolean N/A <code>False</code> <code>--verbose</code>, <code>-v</code> boolean N/A <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"api/cli/#caveat-tune","title":"caveat tune","text":"<p>Train and report on an encoder and model as per the given configuration file.</p> <p>Usage:</p> <pre><code>caveat tune [OPTIONS] CONFIG_PATH\n</code></pre> <p>Options:</p> Name Type Description Default <code>--test</code>, <code>-t</code> boolean N/A <code>False</code> <code>--no-infer</code>, <code>-ni</code> boolean N/A <code>False</code> <code>--no-gen</code>, <code>-ng</code> boolean N/A <code>False</code> <code>--verbose</code>, <code>-v</code> boolean N/A <code>False</code> <code>--help</code> boolean Show this message and exit. <code>False</code>"},{"location":"examples/1_synthetic_schedules_gen/","title":"Synthetic Schedules Generation","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\n\nimport pandas as pd\n\nfrom caveat.data.synth import ActivityGen\nfrom caveat.data.utils import generate_population, trace_to_pam\nfrom caveat.evaluate.describe.times import (\n    joint_time_distributions_plot,\n    times_distributions_plot,\n)\nfrom caveat.evaluate.describe.transitions import sequence_prob_plot\n</pre> from pathlib import Path  import pandas as pd  from caveat.data.synth import ActivityGen from caveat.data.utils import generate_population, trace_to_pam from caveat.evaluate.describe.times import (     joint_time_distributions_plot,     times_distributions_plot, ) from caveat.evaluate.describe.transitions import sequence_prob_plot In\u00a0[2]: Copied! <pre>write_path = Path(\"tmp/synthetic_population.csv\")\n</pre> write_path = Path(\"tmp/synthetic_population.csv\") In\u00a0[3]: Copied! <pre># Example\ngenerator = ActivityGen()\ngenerator.build()\n\ntrace = generator.run()\nplan = trace_to_pam(trace, generator.map)\nplan.plot()\n</pre> # Example generator = ActivityGen() generator.build()  trace = generator.run() plan = trace_to_pam(trace, generator.map) plan.plot() In\u00a0[\u00a0]: Copied! <pre>population = generate_population(gen=generator, size=100)\npopulation.act = population.act.map(generator.map)\npopulation = population[[\"pid\", \"act\", \"start\", \"end\", \"duration\"]]\npopulation\n</pre> population = generate_population(gen=generator, size=100) population.act = population.act.map(generator.map) population = population[[\"pid\", \"act\", \"start\", \"end\", \"duration\"]] population In\u00a0[\u00a0]: Copied! <pre>write_path.parent.mkdir(exist_ok=True)\npopulation.to_csv(write_path, index=False)\n</pre> write_path.parent.mkdir(exist_ok=True) population.to_csv(write_path, index=False) In\u00a0[\u00a0]: Copied! <pre>def describe_col(population, col: str) -&gt; pd.DataFrame:\n    description = population.groupby(\"act\")[col].describe()[\n        [\"count\", \"mean\", \"std\", \"min\", \"max\"]\n    ]\n    description[\"attribute\"] = col\n    return description\n\n\ndef describe_cols(population, cols: list[str]) -&gt; pd.DataFrame:\n    description = pd.concat(\n        [describe_col(population, c) for c in cols], ignore_index=False\n    )\n    description = description.reset_index().set_index([\"attribute\", \"act\"])\n    return description\n\n\ndescribe_cols(population, [\"start\", \"end\", \"duration\"]).round()\n</pre> def describe_col(population, col: str) -&gt; pd.DataFrame:     description = population.groupby(\"act\")[col].describe()[         [\"count\", \"mean\", \"std\", \"min\", \"max\"]     ]     description[\"attribute\"] = col     return description   def describe_cols(population, cols: list[str]) -&gt; pd.DataFrame:     description = pd.concat(         [describe_col(population, c) for c in cols], ignore_index=False     )     description = description.reset_index().set_index([\"attribute\", \"act\"])     return description   describe_cols(population, [\"start\", \"end\", \"duration\"]).round() In\u00a0[\u00a0]: Copied! <pre>def time_distributions(population: pd.DataFrame, mapping: dict):\n    starts = {k: [] for k in mapping.values()}\n    ends = {k: [] for k in mapping.values()}\n    durations = {k: [] for k in mapping.values()}\n    for act, acts in population.groupby(\"act\"):\n        starts[act] = list(acts.start)\n        ends[act] = list(acts.end)\n        durations[act] = list(acts.duration)\n    return starts, ends, durations\n</pre> def time_distributions(population: pd.DataFrame, mapping: dict):     starts = {k: [] for k in mapping.values()}     ends = {k: [] for k in mapping.values()}     durations = {k: [] for k in mapping.values()}     for act, acts in population.groupby(\"act\"):         starts[act] = list(acts.start)         ends[act] = list(acts.end)         durations[act] = list(acts.duration)     return starts, ends, durations In\u00a0[\u00a0]: Copied! <pre>starts, ends, durations = time_distributions(population, generator.map)\n</pre> starts, ends, durations = time_distributions(population, generator.map) In\u00a0[\u00a0]: Copied! <pre>_ = times_distributions_plot(population, ys={})\n</pre> _ = times_distributions_plot(population, ys={}) In\u00a0[\u00a0]: Copied! <pre>_ = joint_time_distributions_plot(population, ys={})\n</pre> _ = joint_time_distributions_plot(population, ys={}) In\u00a0[\u00a0]: Copied! <pre>_ = sequence_prob_plot(population, ys={}, figsize=(8, 6))\n</pre> _ = sequence_prob_plot(population, ys={}, figsize=(8, 6)) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/1_synthetic_schedules_gen/#synthetic-schedules-generation","title":"Synthetic Schedules Generation\u00b6","text":""},{"location":"examples/1_toy_schedules_gen/","title":"Toy Schedules Generation","text":"In\u00a0[3]: Copied! <pre>from pathlib import Path\n\nimport pandas as pd\nimport random\n\nfrom caveat.data.synth import ActivityGen\nfrom caveat.data.utils import generate_population, trace_to_pam\nfrom caveat.evaluate.describe.times import (\n    joint_time_distributions_plot,\n    times_distributions_plot,\n)\nfrom caveat.evaluate.describe.transitions import sequence_prob_plot\n</pre> from pathlib import Path  import pandas as pd import random  from caveat.data.synth import ActivityGen from caveat.data.utils import generate_population, trace_to_pam from caveat.evaluate.describe.times import (     joint_time_distributions_plot,     times_distributions_plot, ) from caveat.evaluate.describe.transitions import sequence_prob_plot In\u00a0[13]: Copied! <pre>n = 10000\n\nschedules_write_path = Path(\"tmp/toy_schedules.csv\")\nattributes_write_path = Path(\"tmp/toy_attributes.csv\")\n</pre> n = 10000  schedules_write_path = Path(\"tmp/toy_schedules.csv\") attributes_write_path = Path(\"tmp/toy_attributes.csv\")  In\u00a0[14]: Copied! <pre>pids = []\nacts = []\nstarts = []\nends = []\ndurations = []\nfor i in range(n):\n    departure_time = random.randint(300, 600)\n    work_duration = random.randint(120, 600)\n    home_duration = 1440 - work_duration - departure_time\n    t = 0\n    for act, duration in zip(\n        [\"home\", \"work\", \"home\"], [departure_time, work_duration, home_duration]\n    ):\n        pids.append(i)\n        acts.append(act)\n        starts.append(t)\n        t += duration\n        ends.append(t)\n        durations.append(duration)\n\nschedules = pd.DataFrame(\n    {\n        \"pid\": pids,\n        \"act\": acts,\n        \"start\": starts,\n        \"end\": ends,\n        \"duration\": durations,\n    }\n)\nschedules.head()\n</pre> pids = [] acts = [] starts = [] ends = [] durations = [] for i in range(n):     departure_time = random.randint(300, 600)     work_duration = random.randint(120, 600)     home_duration = 1440 - work_duration - departure_time     t = 0     for act, duration in zip(         [\"home\", \"work\", \"home\"], [departure_time, work_duration, home_duration]     ):         pids.append(i)         acts.append(act)         starts.append(t)         t += duration         ends.append(t)         durations.append(duration)  schedules = pd.DataFrame(     {         \"pid\": pids,         \"act\": acts,         \"start\": starts,         \"end\": ends,         \"duration\": durations,     } ) schedules.head()  Out[14]: pid act start end duration 0 0 home 0 571 571 1 0 work 571 842 271 2 0 home 842 1440 598 3 1 home 0 492 492 4 1 work 492 1028 536 In\u00a0[22]: Copied! <pre>pids = []\ngenders = []\nages = []\nwork_statuses = []\neducations = []\nlicenses = []\ncar_accesses = []\n\nfor i in range(n):\n    pids.append(i)\n    genders.append(random.choice([\"m\", \"f\"]))\n    ages.append(random.randint(18, 85))\n    work_statuses.append(random.choice([\"employed\", \"unemployed\"]))\n    educations.append(random.choice([\"low\", \"medium\", \"high\"]))\n    licenses.append(random.choice([\"yes\", \"no\"]))\n    car_accesses.append(random.choice([\"yes\", \"no\"]))\n\nattributes = pd.DataFrame(\n    {\n        \"pid\": pids,\n        \"gender\": genders,\n        \"age\": ages,\n        \"work_status\": work_statuses,\n        \"education\": educations,\n        \"license\": licenses,\n        \"car_access\": car_accesses,\n    }\n)\nattributes.head()\n</pre> pids = [] genders = [] ages = [] work_statuses = [] educations = [] licenses = [] car_accesses = []  for i in range(n):     pids.append(i)     genders.append(random.choice([\"m\", \"f\"]))     ages.append(random.randint(18, 85))     work_statuses.append(random.choice([\"employed\", \"unemployed\"]))     educations.append(random.choice([\"low\", \"medium\", \"high\"]))     licenses.append(random.choice([\"yes\", \"no\"]))     car_accesses.append(random.choice([\"yes\", \"no\"]))  attributes = pd.DataFrame(     {         \"pid\": pids,         \"gender\": genders,         \"age\": ages,         \"work_status\": work_statuses,         \"education\": educations,         \"license\": licenses,         \"car_access\": car_accesses,     } ) attributes.head()  Out[22]: pid gender age work_status education license car_access 0 0 m 54 employed high no no 1 1 f 32 employed medium no no 2 2 f 42 unemployed low yes no 3 3 f 20 unemployed high no no 4 4 f 58 employed medium yes yes In\u00a0[23]: Copied! <pre>schedules_write_path.parent.mkdir(exist_ok=True)\nattributes_write_path.parent.mkdir(exist_ok=True)\nschedules.to_csv(schedules_write_path, index=False)\nattributes.to_csv(attributes_write_path, index=False)\n</pre> schedules_write_path.parent.mkdir(exist_ok=True) attributes_write_path.parent.mkdir(exist_ok=True) schedules.to_csv(schedules_write_path, index=False) attributes.to_csv(attributes_write_path, index=False)  In\u00a0[24]: Copied! <pre>def describe_col(population, col: str) -&gt; pd.DataFrame:\n    description = population.groupby(\"act\")[col].describe()[\n        [\"count\", \"mean\", \"std\", \"min\", \"max\"]\n    ]\n    description[\"attribute\"] = col\n    return description\n\n\ndef describe_cols(population, cols: list[str]) -&gt; pd.DataFrame:\n    description = pd.concat(\n        [describe_col(population, c) for c in cols], ignore_index=False\n    )\n    description = description.reset_index().set_index([\"attribute\", \"act\"])\n    return description\n\n\ndescribe_cols(schedules, [\"start\", \"end\", \"duration\"]).round()\n</pre> def describe_col(population, col: str) -&gt; pd.DataFrame:     description = population.groupby(\"act\")[col].describe()[         [\"count\", \"mean\", \"std\", \"min\", \"max\"]     ]     description[\"attribute\"] = col     return description   def describe_cols(population, cols: list[str]) -&gt; pd.DataFrame:     description = pd.concat(         [describe_col(population, c) for c in cols], ignore_index=False     )     description = description.reset_index().set_index([\"attribute\", \"act\"])     return description   describe_cols(schedules, [\"start\", \"end\", \"duration\"]).round() Out[24]: count mean std min max attribute act start home 20000.0 405.0 422.0 0.0 1192.0 work 10000.0 450.0 87.0 300.0 600.0 end home 20000.0 945.0 499.0 300.0 1440.0 work 10000.0 811.0 164.0 421.0 1192.0 duration home 20000.0 539.0 159.0 248.0 1019.0 work 10000.0 361.0 139.0 120.0 600.0 In\u00a0[25]: Copied! <pre>def time_distributions(population: pd.DataFrame, mapping: dict):\n    starts = {k: [] for k in mapping.values()}\n    ends = {k: [] for k in mapping.values()}\n    durations = {k: [] for k in mapping.values()}\n    for act, acts in population.groupby(\"act\"):\n        starts[act] = list(acts.start)\n        ends[act] = list(acts.end)\n        durations[act] = list(acts.duration)\n    return starts, ends, durations\n</pre> def time_distributions(population: pd.DataFrame, mapping: dict):     starts = {k: [] for k in mapping.values()}     ends = {k: [] for k in mapping.values()}     durations = {k: [] for k in mapping.values()}     for act, acts in population.groupby(\"act\"):         starts[act] = list(acts.start)         ends[act] = list(acts.end)         durations[act] = list(acts.duration)     return starts, ends, durations In\u00a0[26]: Copied! <pre>_ = times_distributions_plot(schedules, ys={})\n</pre> _ = times_distributions_plot(schedules, ys={}) In\u00a0[27]: Copied! <pre>_ = joint_time_distributions_plot(schedules, ys={})\n</pre> _ = joint_time_distributions_plot(schedules, ys={}) In\u00a0[28]: Copied! <pre>_ = sequence_prob_plot(schedules, ys={}, figsize=(8, 6))\n</pre> _ = sequence_prob_plot(schedules, ys={}, figsize=(8, 6)) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/1_toy_schedules_gen/#toy-schedules-generation","title":"Toy Schedules Generation\u00b6","text":"<p>Generate a population (schedules and attributes). Where every schedule is home -&gt; work -&gt; home, with varying durations. Attributes are randomly assigned.</p>"},{"location":"examples/1_toy_work_status_schedules/","title":"Toy Schedules Generation","text":"In\u00a0[9]: Copied! <pre>from pathlib import Path\n\nimport pandas as pd\nfrom numpy.random import choice\nimport random\n\nfrom caveat.data.synth import ActivityGen\nfrom caveat.data.utils import generate_population, trace_to_pam\nfrom caveat.evaluate.describe.times import (\n    joint_time_distributions_plot,\n    times_distributions_plot,\n)\nfrom caveat.evaluate.describe.transitions import sequence_prob_plot\n</pre> from pathlib import Path  import pandas as pd from numpy.random import choice import random  from caveat.data.synth import ActivityGen from caveat.data.utils import generate_population, trace_to_pam from caveat.evaluate.describe.times import (     joint_time_distributions_plot,     times_distributions_plot, ) from caveat.evaluate.describe.transitions import sequence_prob_plot In\u00a0[10]: Copied! <pre>n = 10000\nps = {\n    \"employed\": [0.8, 0.0, 0.2],\n    \"student\": [0.2, 0.6, 0.2],\n    \"unemployed\": [0.1, 0.1, 0.8],\n}\n\nschedules_write_path = Path(\"tmp/toy_noisy_schedules.csv\")\nattributes_write_path = Path(\"tmp/toy_noisy_attributes.csv\")\n</pre> n = 10000 ps = {     \"employed\": [0.8, 0.0, 0.2],     \"student\": [0.2, 0.6, 0.2],     \"unemployed\": [0.1, 0.1, 0.8], }  schedules_write_path = Path(\"tmp/toy_noisy_schedules.csv\") attributes_write_path = Path(\"tmp/toy_noisy_attributes.csv\") In\u00a0[20]: Copied! <pre>pid = []\npids = []\nacts = []\nstarts = []\nends = []\ndurations = []\nwork_statuses = []\n\nfor i in range(n):\n    pid.append(i)\n    work_status = random.choice([\"employed\", \"student\", \"unemployed\"])\n    probs = ps\n    activity = choice([\"work\", \"education\", \"other\"], p=probs[work_status])\n    work_statuses.append(work_status)\n\n    budget = 1440\n    sequence = [\"home\"]\n    seq_durations = []\n\n    if activity in [\"work\", \"education\"]:\n        departure_time = random.randint(400, 500)\n    else:\n        departure_time = random.randint(500, 800)\n    seq_durations.append(departure_time)\n    budget -= departure_time\n\n    sequence.append(activity)\n    if activity == \"other\":\n        act_duration = random.randint(60, 180)\n    elif activity == \"work\":\n        act_duration = random.randint(400, 600)\n    else:\n        act_duration = random.randint(300, 500)\n    seq_durations.append(act_duration)\n    budget -= act_duration\n\n    if budget &gt; 600:\n        sequence.append(\"home\")\n        home_duration = random.randint(60, 240)\n        seq_durations.append(home_duration)\n        budget -= home_duration\n        sequence.append(\"other\")\n        act_duration = random.randint(60, 180)\n        seq_durations.append(act_duration)\n        budget -= act_duration\n\n    sequence.append(\"home\")\n    seq_durations.append(budget)\n    home_duration = budget\n\n    t = 0\n    for act, duration in zip(\n        sequence,\n        seq_durations,\n    ):\n        pids.append(i)\n        acts.append(act)\n        starts.append(t)\n        t += duration\n        ends.append(t)\n        durations.append(duration)\n\nschedules = pd.DataFrame(\n    {\n        \"pid\": pids,\n        \"act\": acts,\n        \"start\": starts,\n        \"end\": ends,\n        \"duration\": durations,\n    }\n)\n\nattributes = pd.DataFrame(\n    {\n        \"pid\": pid,\n        \"work_status\": work_statuses,\n    }\n)\n\nprint(schedules.head(20))\nprint(attributes.head())\n</pre> pid = [] pids = [] acts = [] starts = [] ends = [] durations = [] work_statuses = []  for i in range(n):     pid.append(i)     work_status = random.choice([\"employed\", \"student\", \"unemployed\"])     probs = ps     activity = choice([\"work\", \"education\", \"other\"], p=probs[work_status])     work_statuses.append(work_status)      budget = 1440     sequence = [\"home\"]     seq_durations = []      if activity in [\"work\", \"education\"]:         departure_time = random.randint(400, 500)     else:         departure_time = random.randint(500, 800)     seq_durations.append(departure_time)     budget -= departure_time      sequence.append(activity)     if activity == \"other\":         act_duration = random.randint(60, 180)     elif activity == \"work\":         act_duration = random.randint(400, 600)     else:         act_duration = random.randint(300, 500)     seq_durations.append(act_duration)     budget -= act_duration      if budget &gt; 600:         sequence.append(\"home\")         home_duration = random.randint(60, 240)         seq_durations.append(home_duration)         budget -= home_duration         sequence.append(\"other\")         act_duration = random.randint(60, 180)         seq_durations.append(act_duration)         budget -= act_duration      sequence.append(\"home\")     seq_durations.append(budget)     home_duration = budget      t = 0     for act, duration in zip(         sequence,         seq_durations,     ):         pids.append(i)         acts.append(act)         starts.append(t)         t += duration         ends.append(t)         durations.append(duration)  schedules = pd.DataFrame(     {         \"pid\": pids,         \"act\": acts,         \"start\": starts,         \"end\": ends,         \"duration\": durations,     } )  attributes = pd.DataFrame(     {         \"pid\": pid,         \"work_status\": work_statuses,     } )  print(schedules.head(20)) print(attributes.head()) <pre>    pid        act  start   end  duration\n0     0       home      0   669       669\n1     0      other    669   803       134\n2     0       home    803  1009       206\n3     0      other   1009  1101        92\n4     0       home   1101  1440       339\n5     1       home      0   464       464\n6     1  education    464   869       405\n7     1       home    869  1440       571\n8     2       home      0   581       581\n9     2      other    581   645        64\n10    2       home    645   786       141\n11    2      other    786   942       156\n12    2       home    942  1440       498\n13    3       home      0   737       737\n14    3      other    737   909       172\n15    3       home    909  1440       531\n16    4       home      0   459       459\n17    4       work    459   927       468\n18    4       home    927  1440       513\n19    5       home      0   460       460\n   pid work_status\n0    0     student\n1    1     student\n2    2  unemployed\n3    3  unemployed\n4    4  unemployed\n</pre> In\u00a0[21]: Copied! <pre>schedules_write_path.parent.mkdir(exist_ok=True)\nattributes_write_path.parent.mkdir(exist_ok=True)\nschedules.to_csv(schedules_write_path, index=False)\nattributes.to_csv(attributes_write_path, index=False)\n</pre> schedules_write_path.parent.mkdir(exist_ok=True) attributes_write_path.parent.mkdir(exist_ok=True) schedules.to_csv(schedules_write_path, index=False) attributes.to_csv(attributes_write_path, index=False) In\u00a0[22]: Copied! <pre>def describe_col(population, col: str) -&gt; pd.DataFrame:\n    description = population.groupby(\"act\")[col].describe()[\n        [\"count\", \"mean\", \"std\", \"min\", \"max\"]\n    ]\n    description[\"attribute\"] = col\n    return description\n\n\ndef describe_cols(population, cols: list[str]) -&gt; pd.DataFrame:\n    description = pd.concat(\n        [describe_col(population, c) for c in cols], ignore_index=False\n    )\n    description = description.reset_index().set_index([\"attribute\", \"act\"])\n    return description\n\n\ndescribe_cols(schedules, [\"start\", \"end\", \"duration\"]).round()\n</pre> def describe_col(population, col: str) -&gt; pd.DataFrame:     description = population.groupby(\"act\")[col].describe()[         [\"count\", \"mean\", \"std\", \"min\", \"max\"]     ]     description[\"attribute\"] = col     return description   def describe_cols(population, cols: list[str]) -&gt; pd.DataFrame:     description = pd.concat(         [describe_col(population, c) for c in cols], ignore_index=False     )     description = description.reset_index().set_index([\"attribute\", \"act\"])     return description   describe_cols(schedules, [\"start\", \"end\", \"duration\"]).round() Out[22]: count mean std min max attribute act start education 2336.0 450.0 29.0 400.0 500.0 home 24118.0 527.0 454.0 0.0 1242.0 other 8124.0 773.0 151.0 500.0 1078.0 work 3658.0 450.0 29.0 400.0 500.0 end education 2336.0 850.0 64.0 705.0 993.0 home 24118.0 969.0 424.0 400.0 1440.0 other 8124.0 893.0 155.0 560.0 1242.0 work 3658.0 949.0 64.0 801.0 1099.0 duration education 2336.0 400.0 59.0 300.0 500.0 home 24118.0 442.0 165.0 60.0 800.0 other 8124.0 119.0 35.0 60.0 180.0 work 3658.0 499.0 58.0 400.0 600.0 In\u00a0[23]: Copied! <pre>def time_distributions(population: pd.DataFrame, mapping: dict):\n    starts = {k: [] for k in mapping.values()}\n    ends = {k: [] for k in mapping.values()}\n    durations = {k: [] for k in mapping.values()}\n    for act, acts in population.groupby(\"act\"):\n        starts[act] = list(acts.start)\n        ends[act] = list(acts.end)\n        durations[act] = list(acts.duration)\n    return starts, ends, durations\n</pre> def time_distributions(population: pd.DataFrame, mapping: dict):     starts = {k: [] for k in mapping.values()}     ends = {k: [] for k in mapping.values()}     durations = {k: [] for k in mapping.values()}     for act, acts in population.groupby(\"act\"):         starts[act] = list(acts.start)         ends[act] = list(acts.end)         durations[act] = list(acts.duration)     return starts, ends, durations In\u00a0[24]: Copied! <pre>_ = times_distributions_plot(schedules, ys={})\n</pre> _ = times_distributions_plot(schedules, ys={}) In\u00a0[25]: Copied! <pre>_ = joint_time_distributions_plot(schedules, ys={})\n</pre> _ = joint_time_distributions_plot(schedules, ys={}) In\u00a0[26]: Copied! <pre>_ = sequence_prob_plot(schedules, ys={}, figsize=(8, 6))\n</pre> _ = sequence_prob_plot(schedules, ys={}, figsize=(8, 6)) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/1_toy_work_status_schedules/#toy-schedules-generation","title":"Toy Schedules Generation\u00b6","text":"<p>Generate a population (schedules and attributes). Where every schedule is home -&gt; ACTIVITY -&gt; home, with varying durations. Where ACTIVITY depends on work_status attribute.</p>"},{"location":"examples/2_synthetic_population_gen/","title":"Synthetic Population Generation","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\n\nimport pandas as pd\n\nfrom caveat.data.synth import ActivityGen\nfrom caveat.data.utils import generate_population_conditional, trace_to_pam\nfrom caveat.evaluate.describe.times import (\n    joint_time_distributions_plot,\n    times_distributions_plot,\n)\nfrom caveat.evaluate.describe.transitions import sequence_prob_plot\n</pre> from pathlib import Path  import pandas as pd  from caveat.data.synth import ActivityGen from caveat.data.utils import generate_population_conditional, trace_to_pam from caveat.evaluate.describe.times import (     joint_time_distributions_plot,     times_distributions_plot, ) from caveat.evaluate.describe.transitions import sequence_prob_plot In\u00a0[2]: Copied! <pre>write_path = Path(\"tmp\")\nn = 1000\n</pre> write_path = Path(\"tmp\") n = 1000 In\u00a0[3]: Copied! <pre># FT worker generator\nftw = ActivityGen()\nconfig = ftw.transition_config.copy()\nfor _, kv in config.items():\n    for k, v in kv.items():\n        if k in [\"work\"]:\n            for i, (a, b) in enumerate(v):\n                v[i] = (a, b * 10)\n        if k in [\"education\", \"shop\", \"leisure\"]:\n            for i, (a, b) in enumerate(v):\n                v[i] = (a, b / 10)\nftw.build(config)\n\ntrace = ftw.run()\nplan = trace_to_pam(trace, ftw.map)\nplan.plot()\n</pre> # FT worker generator ftw = ActivityGen() config = ftw.transition_config.copy() for _, kv in config.items():     for k, v in kv.items():         if k in [\"work\"]:             for i, (a, b) in enumerate(v):                 v[i] = (a, b * 10)         if k in [\"education\", \"shop\", \"leisure\"]:             for i, (a, b) in enumerate(v):                 v[i] = (a, b / 10) ftw.build(config)  trace = ftw.run() plan = trace_to_pam(trace, ftw.map) plan.plot() In\u00a0[4]: Copied! <pre># PT worker generator\nptw = ActivityGen()\nconfig = ptw.transition_config.copy()\nfor o, kv in config.items():\n    for k, v in kv.items():\n        if not o == \"work\":\n            continue\n        if k == \"work\":\n            for i, (a, b) in enumerate(v):\n                v[i] = (a, b / 100)\n        if k in [\"shop\", \"leisure\"]:\n            for i, (a, b) in enumerate(v):\n                v[i] = (a, b * 100)\nptw.build(config)\n\ntrace = ptw.run()\nplan = trace_to_pam(trace, ptw.map)\nplan.plot()\n</pre> # PT worker generator ptw = ActivityGen() config = ptw.transition_config.copy() for o, kv in config.items():     for k, v in kv.items():         if not o == \"work\":             continue         if k == \"work\":             for i, (a, b) in enumerate(v):                 v[i] = (a, b / 100)         if k in [\"shop\", \"leisure\"]:             for i, (a, b) in enumerate(v):                 v[i] = (a, b * 100) ptw.build(config)  trace = ptw.run() plan = trace_to_pam(trace, ptw.map) plan.plot() In\u00a0[5]: Copied! <pre># Leisure generator\nneet = ActivityGen()\nconfig = neet.transition_config.copy()\nfor _, kv in config.items():\n    for k, v in kv.items():\n        if k in [\"work\", \"education\"]:\n            for i, (a, b) in enumerate(v):\n                v[i] = (a, 0)\n        if k in [\"shop\", \"leisure\"]:\n            for i, (a, b) in enumerate(v):\n                v[i] = (a, b * 10)\n\nneet.build(config)\n\ntrace = neet.run()\nplan = trace_to_pam(trace, neet.map)\nplan.plot()\n</pre> # Leisure generator neet = ActivityGen() config = neet.transition_config.copy() for _, kv in config.items():     for k, v in kv.items():         if k in [\"work\", \"education\"]:             for i, (a, b) in enumerate(v):                 v[i] = (a, 0)         if k in [\"shop\", \"leisure\"]:             for i, (a, b) in enumerate(v):                 v[i] = (a, b * 10)  neet.build(config)  trace = neet.run() plan = trace_to_pam(trace, neet.map) plan.plot() In\u00a0[6]: Copied! <pre># FTE generator\nfte = ActivityGen()\nconfig = fte.transition_config.copy()\nfor _, kv in config.items():\n    for k, v in kv.items():\n        if k == \"work\":\n            for i, (a, b) in enumerate(v):\n                v[i] = (a, 0)\n        if k == \"education\":\n            for i, (a, b) in enumerate(v):\n                v[i] = (a, b * 100)\n\nfte.build(config)\n\ntrace = fte.run()\nplan = trace_to_pam(trace, fte.map)\nplan.plot()\n</pre> # FTE generator fte = ActivityGen() config = fte.transition_config.copy() for _, kv in config.items():     for k, v in kv.items():         if k == \"work\":             for i, (a, b) in enumerate(v):                 v[i] = (a, 0)         if k == \"education\":             for i, (a, b) in enumerate(v):                 v[i] = (a, b * 100)  fte.build(config)  trace = fte.run() plan = trace_to_pam(trace, fte.map) plan.plot() In\u00a0[7]: Copied! <pre>population = generate_population_conditional(gens=(ftw, ptw, neet, fte), size=n)\npopulation.act = population.act.map(ftw.map)\npopulation = population[\n    [\"pid\", \"act\", \"start\", \"end\", \"duration\", \"gender\", \"age\", \"employment\"]\n]\npopulation\n</pre> population = generate_population_conditional(gens=(ftw, ptw, neet, fte), size=n) population.act = population.act.map(ftw.map) population = population[     [\"pid\", \"act\", \"start\", \"end\", \"duration\", \"gender\", \"age\", \"employment\"] ] population Out[7]: pid act start end duration gender age employment 0 0 home 0 375 375 F 24 FTW 1 0 work 375 1170 795 F 24 FTW 2 0 home 1170 1440 270 F 24 FTW 3 1 home 0 390 390 M 85 NEET 4 1 shop 390 450 60 M 85 NEET ... ... ... ... ... ... ... ... ... 4305 999 home 0 390 390 F 83 NEET 4306 999 shop 390 450 60 F 83 NEET 4307 999 home 450 630 180 F 83 NEET 4308 999 leisure 630 990 360 F 83 NEET 4309 999 home 990 1440 450 F 83 NEET <p>4310 rows \u00d7 8 columns</p> In\u00a0[8]: Copied! <pre># population.to_csv(write_path / \"combined.csv\", index=False)\npopulation[[\"pid\", \"act\", \"start\", \"end\", \"duration\"]].to_csv(\n    write_path / \"synthetic_schedules.csv\", index=False\n)\npopulation[[\"pid\", \"gender\", \"age\", \"employment\"]].drop_duplicates().to_csv(\n    write_path / \"synthetic_attributes.csv\", index=False\n)\n</pre> # population.to_csv(write_path / \"combined.csv\", index=False) population[[\"pid\", \"act\", \"start\", \"end\", \"duration\"]].to_csv(     write_path / \"synthetic_schedules.csv\", index=False ) population[[\"pid\", \"gender\", \"age\", \"employment\"]].drop_duplicates().to_csv(     write_path / \"synthetic_attributes.csv\", index=False ) In\u00a0[9]: Copied! <pre>cs = population.gender.map({\"M\": \"blue\", \"F\": \"red\"})\npopulation.plot(kind=\"scatter\", x=\"age\", y=\"duration\", alpha=0.1, c=cs)\n</pre> cs = population.gender.map({\"M\": \"blue\", \"F\": \"red\"}) population.plot(kind=\"scatter\", x=\"age\", y=\"duration\", alpha=0.1, c=cs) Out[9]: <pre>&lt;Axes: xlabel='age', ylabel='duration'&gt;</pre> In\u00a0[10]: Copied! <pre>def describe_col(population, col: str) -&gt; pd.DataFrame:\n    description = population.groupby(\"act\")[col].describe()[\n        [\"count\", \"mean\", \"std\", \"min\", \"max\"]\n    ]\n    description[\"attribute\"] = col\n    return description\n\n\ndef describe_cols(population, cols: list[str]) -&gt; pd.DataFrame:\n    description = pd.concat(\n        [describe_col(population, c) for c in cols], ignore_index=False\n    )\n    description = description.reset_index().set_index([\"attribute\", \"act\"])\n    return description\n\n\ndescribe_cols(population, [\"start\", \"end\", \"duration\"]).round()\n</pre> def describe_col(population, col: str) -&gt; pd.DataFrame:     description = population.groupby(\"act\")[col].describe()[         [\"count\", \"mean\", \"std\", \"min\", \"max\"]     ]     description[\"attribute\"] = col     return description   def describe_cols(population, cols: list[str]) -&gt; pd.DataFrame:     description = pd.concat(         [describe_col(population, c) for c in cols], ignore_index=False     )     description = description.reset_index().set_index([\"attribute\", \"act\"])     return description   describe_cols(population, [\"start\", \"end\", \"duration\"]).round() Out[10]: count mean std min max attribute act start education 34.0 960.0 129.0 765.0 1125.0 home 2085.0 494.0 490.0 0.0 1290.0 leisure 798.0 565.0 240.0 375.0 1260.0 shop 896.0 529.0 188.0 375.0 1170.0 work 497.0 570.0 299.0 375.0 1275.0 end education 34.0 1038.0 74.0 885.0 1140.0 home 2085.0 907.0 518.0 375.0 1440.0 leisure 798.0 898.0 207.0 420.0 1275.0 shop 896.0 623.0 193.0 390.0 1185.0 work 497.0 1023.0 157.0 735.0 1290.0 duration education 34.0 78.0 60.0 15.0 195.0 home 2085.0 413.0 112.0 15.0 885.0 leisure 798.0 333.0 205.0 15.0 630.0 shop 896.0 94.0 70.0 15.0 420.0 work 497.0 453.0 260.0 15.0 825.0 In\u00a0[11]: Copied! <pre>subpops = {\n    \"males\": population.loc[population.gender == \"M\"],\n    \"females\": population.loc[population.gender == \"F\"],\n    \"young\": population.loc[population.age &lt; 25],\n    \"middle\": population.loc[(population.age &gt;= 25) &amp; (population.age &lt; 65)],\n    \"old\": population.loc[population.age &gt;= 65],\n}\n</pre> subpops = {     \"males\": population.loc[population.gender == \"M\"],     \"females\": population.loc[population.gender == \"F\"],     \"young\": population.loc[population.age &lt; 25],     \"middle\": population.loc[(population.age &gt;= 25) &amp; (population.age &lt; 65)],     \"old\": population.loc[population.age &gt;= 65], } In\u00a0[12]: Copied! <pre>_ = times_distributions_plot(population, ys=subpops)\n</pre> _ = times_distributions_plot(population, ys=subpops) In\u00a0[13]: Copied! <pre>_ = joint_time_distributions_plot(population, ys=subpops, figsize=(12, 12))\n</pre> _ = joint_time_distributions_plot(population, ys=subpops, figsize=(12, 12)) In\u00a0[14]: Copied! <pre>_ = sequence_prob_plot(population, ys=subpops, figsize=(12, 4))\n</pre> _ = sequence_prob_plot(population, ys=subpops, figsize=(12, 4)) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/2_synthetic_population_gen/#synthetic-population-generation","title":"Synthetic Population Generation\u00b6","text":"<p>Generate sythetic schedules and attributes.</p>"},{"location":"examples/3_NTS_population_demo/","title":"Generate Population from National Transport Survey Data","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\n\nimport pandas as pd\nfrom pam import read\nfrom pam.core import Population\nfrom pam.utils import datetime_to_matsim_time\n\nfrom caveat.evaluate.describe.times import (\n    joint_time_distributions_plot,\n    times_distributions_plot,\n)\nfrom caveat.evaluate.describe.transitions import sequence_prob_plot\n</pre> from pathlib import Path  import pandas as pd from pam import read from pam.core import Population from pam.utils import datetime_to_matsim_time  from caveat.evaluate.describe.times import (     joint_time_distributions_plot,     times_distributions_plot, ) from caveat.evaluate.describe.transitions import sequence_prob_plot In\u00a0[2]: Copied! <pre>dir = Path(\"data/dummyNTS/\")\ntrips_csv = dir / \"trips.tab\"\nattributes_csv = dir / \"individuals.tab\"\nhhs_csv = dir / \"households.tab\"\n\n# dir = Path(\"C:/Users/fred/Data/UKDA-5340-tab/tab\")\n# trips_csv = dir / \"trip_eul_2002-2022.tab\"\n# attributes_csv = dir / \"individual_eul_2002-2022.tab\"\n# hhs_csv = dir / \"household_eul_2002-2022.tab\"\n\nyears = [2021]\n\nwrite_dir = Path(\"tmp\")\nwrite_dir.mkdir(exist_ok=True)\nschedules_path = write_dir / \"nts_schedules.csv\"\nattributes_path = write_dir / \"nts_attributes.csv\"\nhome_schedules_path = write_dir / \"nts_home_schedules.csv\"\nhome_attributes_path = write_dir / \"nts_home_attributes.csv\"\n</pre> dir = Path(\"data/dummyNTS/\") trips_csv = dir / \"trips.tab\" attributes_csv = dir / \"individuals.tab\" hhs_csv = dir / \"households.tab\"  # dir = Path(\"C:/Users/fred/Data/UKDA-5340-tab/tab\") # trips_csv = dir / \"trip_eul_2002-2022.tab\" # attributes_csv = dir / \"individual_eul_2002-2022.tab\" # hhs_csv = dir / \"household_eul_2002-2022.tab\"  years = [2021]  write_dir = Path(\"tmp\") write_dir.mkdir(exist_ok=True) schedules_path = write_dir / \"nts_schedules.csv\" attributes_path = write_dir / \"nts_attributes.csv\" home_schedules_path = write_dir / \"nts_home_schedules.csv\" home_attributes_path = write_dir / \"nts_home_attributes.csv\" In\u00a0[3]: Copied! <pre>travel_diaries = pd.read_csv(\n    trips_csv,\n    sep=\"\\t\",\n    usecols=[\n        \"TripID\",\n        \"JourSeq\",\n        \"DayID\",\n        \"IndividualID\",\n        \"HouseholdID\",\n        \"MainMode_B04ID\",\n        \"TripPurpFrom_B01ID\",\n        \"TripPurpTo_B01ID\",\n        \"TripStart\",\n        \"TripEnd\",\n        \"TripOrigGOR_B02ID\",\n        \"TripDestGOR_B02ID\",\n        \"W5\",\n        \"SurveyYear\",\n    ],\n)\ntravel_diaries = travel_diaries.rename(\n    columns={\n        \"TripID\": \"tid\",\n        \"JourSeq\": \"seq\",\n        \"DayID\": \"day\",\n        \"IndividualID\": \"iid\",\n        \"HouseholdID\": \"hid\",\n        \"TripOrigGOR_B02ID\": \"ozone\",\n        \"TripDestGOR_B02ID\": \"dzone\",\n        \"TripPurpFrom_B01ID\": \"oact\",\n        \"TripPurpTo_B01ID\": \"dact\",\n        \"MainMode_B04ID\": \"mode\",\n        \"TripStart\": \"tst\",\n        \"TripEnd\": \"tet\",\n        \"W5\": \"freq\",\n        \"SurveyYear\": \"year\",\n    }\n)\n\ntravel_diaries = travel_diaries[travel_diaries.year.isin(years)]\n\ntravel_diaries.tst = pd.to_numeric(travel_diaries.tst, errors=\"coerce\")\ntravel_diaries.tet = pd.to_numeric(travel_diaries.tet, errors=\"coerce\")\ntravel_diaries.ozone = pd.to_numeric(travel_diaries.ozone, errors=\"coerce\")\ntravel_diaries.dzone = pd.to_numeric(travel_diaries.dzone, errors=\"coerce\")\ntravel_diaries.freq = pd.to_numeric(travel_diaries.freq, errors=\"coerce\")\n\ntravel_diaries[\"did\"] = travel_diaries.groupby(\"iid\")[\"day\"].transform(\n    lambda x: pd.factorize(x)[0] + 1\n)\ntravel_diaries[\"pid\"] = [\n    f\"{i}-{d}\" for i, d in zip(travel_diaries.iid, travel_diaries.did)\n]\n\ntravel_diaries = travel_diaries.loc[\n    travel_diaries.groupby(\"pid\")\n    .filter(lambda x: pd.isnull(x).sum().sum() &lt; 1)\n    .index\n]\n# travel_diaries.freq = travel_diaries.freq / travel_diaries.groupby(\"iid\").day.transform(\"nunique\")\ntravel_diaries.loc[travel_diaries.tet == 0, \"tet\"] = 1440\n\ntravel_diaries = travel_diaries.drop([\"tid\", \"day\", \"year\", \"did\"], axis=1)\n\nmode_mapping = {\n    1: \"walk\",\n    2: \"bike\",\n    3: \"car\",  #'Car/van driver'\n    4: \"car\",  #'Car/van driver'\n    5: \"car\",  #'Motorcycle',\n    6: \"car\",  #'Other private transport',\n    7: \"pt\",  # Bus in London',\n    8: \"pt\",  #'Other local bus',\n    9: \"pt\",  #'Non-local bus',\n    10: \"pt\",  #'London Underground',\n    11: \"pt\",  #'Surface Rail',\n    12: \"car\",  #'Taxi/minicab',\n    13: \"pt\",  #'Other public transport',\n    -10: \"DEAD\",\n    -8: \"NA\",\n}\n\npurp_mapping = {\n    1: \"work\",\n    2: \"work\",  #'In course of work',\n    3: \"education\",\n    4: \"shop\",  #'Food shopping',\n    5: \"shop\",  #'Non food shopping',\n    6: \"medical\",  #'Personal business medical',\n    7: \"other\",  #'Personal business eat/drink',\n    8: \"other\",  #'Personal business other',\n    9: \"other\",  #'Eat/drink with friends',\n    10: \"visit\",  #'Visit friends',\n    11: \"other\",  #'Other social',\n    12: \"other\",  #'Entertain/ public activity',\n    13: \"other\",  #'Sport: participate',\n    14: \"home\",  #'Holiday: base',\n    15: \"other\",  #'Day trip/just walk',\n    16: \"other\",  #'Other non-escort',\n    17: \"escort\",  #'Escort home',\n    18: \"escort\",  #'Escort work',\n    19: \"escort\",  #'Escort in course of work',\n    20: \"escort\",  #'Escort education',\n    21: \"escort\",  #'Escort shopping/personal business',\n    22: \"escort\",  #'Other escort',\n    23: \"home\",  #'Home',\n    -10: \"DEAD\",\n    -8: \"NA\",\n}\n\ntravel_diaries[\"mode\"] = travel_diaries[\"mode\"].map(mode_mapping)\ntravel_diaries[\"oact\"] = travel_diaries[\"oact\"].map(purp_mapping)\ntravel_diaries[\"dact\"] = travel_diaries[\"dact\"].map(purp_mapping)\ntravel_diaries.tst = travel_diaries.tst.astype(int)\ntravel_diaries.tet = travel_diaries.tet.astype(int)\n\ntravel_diaries.head(20)\n</pre> travel_diaries = pd.read_csv(     trips_csv,     sep=\"\\t\",     usecols=[         \"TripID\",         \"JourSeq\",         \"DayID\",         \"IndividualID\",         \"HouseholdID\",         \"MainMode_B04ID\",         \"TripPurpFrom_B01ID\",         \"TripPurpTo_B01ID\",         \"TripStart\",         \"TripEnd\",         \"TripOrigGOR_B02ID\",         \"TripDestGOR_B02ID\",         \"W5\",         \"SurveyYear\",     ], ) travel_diaries = travel_diaries.rename(     columns={         \"TripID\": \"tid\",         \"JourSeq\": \"seq\",         \"DayID\": \"day\",         \"IndividualID\": \"iid\",         \"HouseholdID\": \"hid\",         \"TripOrigGOR_B02ID\": \"ozone\",         \"TripDestGOR_B02ID\": \"dzone\",         \"TripPurpFrom_B01ID\": \"oact\",         \"TripPurpTo_B01ID\": \"dact\",         \"MainMode_B04ID\": \"mode\",         \"TripStart\": \"tst\",         \"TripEnd\": \"tet\",         \"W5\": \"freq\",         \"SurveyYear\": \"year\",     } )  travel_diaries = travel_diaries[travel_diaries.year.isin(years)]  travel_diaries.tst = pd.to_numeric(travel_diaries.tst, errors=\"coerce\") travel_diaries.tet = pd.to_numeric(travel_diaries.tet, errors=\"coerce\") travel_diaries.ozone = pd.to_numeric(travel_diaries.ozone, errors=\"coerce\") travel_diaries.dzone = pd.to_numeric(travel_diaries.dzone, errors=\"coerce\") travel_diaries.freq = pd.to_numeric(travel_diaries.freq, errors=\"coerce\")  travel_diaries[\"did\"] = travel_diaries.groupby(\"iid\")[\"day\"].transform(     lambda x: pd.factorize(x)[0] + 1 ) travel_diaries[\"pid\"] = [     f\"{i}-{d}\" for i, d in zip(travel_diaries.iid, travel_diaries.did) ]  travel_diaries = travel_diaries.loc[     travel_diaries.groupby(\"pid\")     .filter(lambda x: pd.isnull(x).sum().sum() &lt; 1)     .index ] # travel_diaries.freq = travel_diaries.freq / travel_diaries.groupby(\"iid\").day.transform(\"nunique\") travel_diaries.loc[travel_diaries.tet == 0, \"tet\"] = 1440  travel_diaries = travel_diaries.drop([\"tid\", \"day\", \"year\", \"did\"], axis=1)  mode_mapping = {     1: \"walk\",     2: \"bike\",     3: \"car\",  #'Car/van driver'     4: \"car\",  #'Car/van driver'     5: \"car\",  #'Motorcycle',     6: \"car\",  #'Other private transport',     7: \"pt\",  # Bus in London',     8: \"pt\",  #'Other local bus',     9: \"pt\",  #'Non-local bus',     10: \"pt\",  #'London Underground',     11: \"pt\",  #'Surface Rail',     12: \"car\",  #'Taxi/minicab',     13: \"pt\",  #'Other public transport',     -10: \"DEAD\",     -8: \"NA\", }  purp_mapping = {     1: \"work\",     2: \"work\",  #'In course of work',     3: \"education\",     4: \"shop\",  #'Food shopping',     5: \"shop\",  #'Non food shopping',     6: \"medical\",  #'Personal business medical',     7: \"other\",  #'Personal business eat/drink',     8: \"other\",  #'Personal business other',     9: \"other\",  #'Eat/drink with friends',     10: \"visit\",  #'Visit friends',     11: \"other\",  #'Other social',     12: \"other\",  #'Entertain/ public activity',     13: \"other\",  #'Sport: participate',     14: \"home\",  #'Holiday: base',     15: \"other\",  #'Day trip/just walk',     16: \"other\",  #'Other non-escort',     17: \"escort\",  #'Escort home',     18: \"escort\",  #'Escort work',     19: \"escort\",  #'Escort in course of work',     20: \"escort\",  #'Escort education',     21: \"escort\",  #'Escort shopping/personal business',     22: \"escort\",  #'Other escort',     23: \"home\",  #'Home',     -10: \"DEAD\",     -8: \"NA\", }  travel_diaries[\"mode\"] = travel_diaries[\"mode\"].map(mode_mapping) travel_diaries[\"oact\"] = travel_diaries[\"oact\"].map(purp_mapping) travel_diaries[\"dact\"] = travel_diaries[\"dact\"].map(purp_mapping) travel_diaries.tst = travel_diaries.tst.astype(int) travel_diaries.tet = travel_diaries.tet.astype(int)  travel_diaries.head(20) Out[3]: iid hid seq mode oact dact freq tst tet ozone dzone pid 0 1 1 1 car home visit 0.989618 675 683 7 7 1-1 1 1 1 2 car visit other 1.002945 720 735 7 7 1-1 2 1 1 3 car other visit 0.989618 770 780 7 7 1-1 3 1 1 4 car visit home 0.989618 1110 1130 7 7 1-1 4 1 1 1 car home visit 0.999891 760 770 7 7 1-2 5 1 1 2 car visit visit 0.999891 790 805 7 7 1-2 6 1 1 3 car visit other 1.061665 810 825 7 7 1-2 7 1 1 4 car other other 1.061665 845 852 7 7 1-2 8 1 1 5 car other visit 0.999891 865 873 7 7 1-2 9 1 1 6 car visit escort 1.006313 908 914 7 7 1-2 10 1 1 7 car escort home 1.006313 922 926 7 7 1-2 11 1 1 8 car home shop 1.111870 940 955 7 7 1-2 12 1 1 9 car shop visit 0.999891 1015 1032 7 7 1-2 13 1 1 10 car visit home 0.999891 1080 1108 7 7 1-2 14 1 1 1 car home other 1.037060 770 785 7 7 1-3 15 1 1 2 car other home 1.037060 905 917 7 7 1-3 16 1 1 1 car home escort 1.062430 738 752 7 7 1-4 17 1 1 2 car escort work 1.062430 755 761 7 7 1-4 18 1 1 3 car work home 1.017644 1050 1076 7 7 1-4 19 1 1 4 car home other 1.061431 1220 1223 7 7 1-4 In\u00a0[4]: Copied! <pre>columns = {\n    \"SurveyYear\": \"year\",\n    \"IndividualID\": \"iid\",\n    \"HouseholdID\": \"hid\",\n    \"Age_B01ID\": \"age\",\n    \"Sex_B01ID\": \"gender\",\n    \"EdAttn1_B01ID\": \"education\",\n    \"DrivLic_B02ID\": \"license\",\n    \"CarAccess_B01ID\": \"car_access\",\n    \"EcoStat_B02ID\": \"work_status\",\n    \"EthGroupTS_B02ID\": \"ethnicity\",\n}\nattributes = pd.read_csv(\n    attributes_csv, sep=\"\\t\", usecols=columns.keys()\n).rename(columns=columns)\n\nattributes = attributes[attributes.year.isin(years)]\nattributes = attributes[attributes.iid.isin(travel_diaries.iid)]\n\n# expand attributes to days and add pid\npid_to_iid = travel_diaries.set_index(\"pid\")[\"iid\"].to_dict()\nexpanded_attributes = []\nfor k, v in pid_to_iid.items():\n    expanded_attributes.append(attributes[attributes.iid == v].assign(pid=k))\nexpanded_attributes = pd.concat(expanded_attributes)\nassert set(expanded_attributes.pid) == set(travel_diaries.pid)\n\n# fix special values to zero (DEAD, NULL, NA, etc)\nfor c in [\n    \"age\",\n    \"gender\",\n    \"education\",\n    \"license\",\n    \"car_access\",\n    \"work_status\",\n    \"ethnicity\",\n]:\n    expanded_attributes.loc[expanded_attributes[c] &lt; 0, c] = 0\n    expanded_attributes.loc[expanded_attributes[c].isnull(), c] = 0\n\nexpanded_attributes.head()\n</pre> columns = {     \"SurveyYear\": \"year\",     \"IndividualID\": \"iid\",     \"HouseholdID\": \"hid\",     \"Age_B01ID\": \"age\",     \"Sex_B01ID\": \"gender\",     \"EdAttn1_B01ID\": \"education\",     \"DrivLic_B02ID\": \"license\",     \"CarAccess_B01ID\": \"car_access\",     \"EcoStat_B02ID\": \"work_status\",     \"EthGroupTS_B02ID\": \"ethnicity\", } attributes = pd.read_csv(     attributes_csv, sep=\"\\t\", usecols=columns.keys() ).rename(columns=columns)  attributes = attributes[attributes.year.isin(years)] attributes = attributes[attributes.iid.isin(travel_diaries.iid)]  # expand attributes to days and add pid pid_to_iid = travel_diaries.set_index(\"pid\")[\"iid\"].to_dict() expanded_attributes = [] for k, v in pid_to_iid.items():     expanded_attributes.append(attributes[attributes.iid == v].assign(pid=k)) expanded_attributes = pd.concat(expanded_attributes) assert set(expanded_attributes.pid) == set(travel_diaries.pid)  # fix special values to zero (DEAD, NULL, NA, etc) for c in [     \"age\",     \"gender\",     \"education\",     \"license\",     \"car_access\",     \"work_status\",     \"ethnicity\", ]:     expanded_attributes.loc[expanded_attributes[c] &lt; 0, c] = 0     expanded_attributes.loc[expanded_attributes[c].isnull(), c] = 0  expanded_attributes.head() Out[4]: iid hid age gender ethnicity education license car_access work_status year pid 0 1 2002003369 20 2 1 0 1 2 4 2021 1-1 0 1 2002003369 20 2 1 0 1 2 4 2021 1-2 0 1 2002003369 20 2 1 0 1 2 4 2021 1-3 0 1 2002003369 20 2 1 0 1 2 4 2021 1-4 0 1 2002003369 20 2 1 0 1 2 4 2021 1-5 In\u00a0[5]: Copied! <pre># additionally extract attributes from household table\n# add them to individual table for simplicity\ncolumns = {\n    \"HouseholdID\": \"hid\",\n    \"Settlement2011EW_B04ID\": \"area\",\n    \"SurveyYear\": \"year\",\n    \"HHIncQISEngTS_B01ID\": \"income\",\n    \"HHoldNumPeople\": \"hh_size\",\n    \"HHoldStruct_B02ID\": \"hh_composition\",\n    \"HHoldNumChildren\": \"hh_children\",\n    \"NumCar\": \"hh_cars\",\n    \"NumBike\": \"hh_bikes\",\n    \"NumMCycle\": \"hh_motorcycles\",\n}\nhhs = pd.read_csv(hhs_csv, sep=\"\\t\", usecols=columns.keys()).rename(\n    columns=columns\n)\nhhs = hhs[hhs.year.isin(years)]\n\n# add hh attributes to individuals\nfor c in [\n    \"area\",\n    \"income\",\n    \"hh_size\",\n    \"hh_composition\",\n    \"hh_children\",\n    \"hh_cars\",\n    \"hh_bikes\",\n    \"hh_motorcycles\",\n]:\n    mapper = hhs.set_index(\"hid\")[c].to_dict()\n    expanded_attributes[c] = expanded_attributes.hid.map(mapper)\n\nfor c in [\n    \"area\",\n    \"income\",\n    \"hh_size\",\n    \"hh_composition\",\n    \"hh_children\",\n    \"hh_cars\",\n    \"hh_bikes\",\n    \"hh_motorcycles\",\n]:\n    expanded_attributes.loc[expanded_attributes[c] &lt; 0, c] = 0\n    expanded_attributes.loc[expanded_attributes[c].isnull(), c] = 0\n\nexpanded_attributes.drop(\"hid\", axis=1, inplace=True)\n\nexpanded_attributes.head()\n</pre> # additionally extract attributes from household table # add them to individual table for simplicity columns = {     \"HouseholdID\": \"hid\",     \"Settlement2011EW_B04ID\": \"area\",     \"SurveyYear\": \"year\",     \"HHIncQISEngTS_B01ID\": \"income\",     \"HHoldNumPeople\": \"hh_size\",     \"HHoldStruct_B02ID\": \"hh_composition\",     \"HHoldNumChildren\": \"hh_children\",     \"NumCar\": \"hh_cars\",     \"NumBike\": \"hh_bikes\",     \"NumMCycle\": \"hh_motorcycles\", } hhs = pd.read_csv(hhs_csv, sep=\"\\t\", usecols=columns.keys()).rename(     columns=columns ) hhs = hhs[hhs.year.isin(years)]  # add hh attributes to individuals for c in [     \"area\",     \"income\",     \"hh_size\",     \"hh_composition\",     \"hh_children\",     \"hh_cars\",     \"hh_bikes\",     \"hh_motorcycles\", ]:     mapper = hhs.set_index(\"hid\")[c].to_dict()     expanded_attributes[c] = expanded_attributes.hid.map(mapper)  for c in [     \"area\",     \"income\",     \"hh_size\",     \"hh_composition\",     \"hh_children\",     \"hh_cars\",     \"hh_bikes\",     \"hh_motorcycles\", ]:     expanded_attributes.loc[expanded_attributes[c] &lt; 0, c] = 0     expanded_attributes.loc[expanded_attributes[c].isnull(), c] = 0  expanded_attributes.drop(\"hid\", axis=1, inplace=True)  expanded_attributes.head() Out[5]: iid age gender ethnicity education license car_access work_status year pid area income hh_size hh_composition hh_children hh_cars hh_bikes hh_motorcycles 0 1 20 2 1 0 1 2 4 2021 1-1 1 1 1 1 2 1 1 0 0 1 20 2 1 0 1 2 4 2021 1-2 1 1 1 1 2 1 1 0 0 1 20 2 1 0 1 2 4 2021 1-3 1 1 1 1 2 1 1 0 0 1 20 2 1 0 1 2 4 2021 1-4 1 1 1 1 2 1 1 0 0 1 20 2 1 0 1 2 4 2021 1-5 1 1 1 1 2 1 1 0 In\u00a0[6]: Copied! <pre>age_mapping = {\n    1: 0,\n    2: 1,\n    3: 3,\n    4: 5,\n    5: 11,\n    6: 16,\n    7: 17,\n    8: 18,\n    9: 19,\n    10: 20,\n    11: 21,\n    12: 26,\n    13: 30,\n    14: 40,\n    15: 50,\n    16: 60,\n    17: 65,\n    18: 70,\n    19: 75,\n    20: 80,\n    21: 85,\n}\nage_group_mapping = {\n    1: \"&lt;5\",\n    2: \"&lt;5\",\n    3: \"&lt;5\",\n    4: \"5-11\",\n    5: \"11-16\",\n    6: \"16-20\",\n    7: \"16-20\",\n    8: \"16-20\",\n    9: \"16-20\",\n    10: \"20-30\",\n    11: \"20-30\",\n    12: \"20-30\",\n    13: \"30-40\",\n    14: \"40-50\",\n    15: \"50-70\",\n    16: \"50-70\",\n    17: \"50-70\",\n    18: \"70+\",\n    19: \"70+\",\n    20: \"70+\",\n    21: \"70+\",\n}\ngender_mapping = {0: \"unknown\", 1: \"M\", 2: \"F\"}\neducation_mapping = {0: \"unknown\", 1: \"Y\", 2: \"N\"}\nlicense_mapping = {0: \"unknown\", 1: \"yes\", 2: \"yes\", 3: \"no\"}\ncar_access_mapping = {\n    0: \"unknown\",\n    1: \"yes\",\n    2: \"yes\",\n    3: \"yes\",\n    4: \"yes\",\n    5: \"no\",\n    6: \"no\",\n}\n# work_status_mapping = {\n#     0: \"unknown\",\n#     1: \"FT\",\n#     2: \"PT\",\n#     3: \"unemployed\",\n#     4: \"retired\",\n#     5: \"student\",\n#     6: \"other\",\n# }\nwork_status_mapping = {\n    0: \"unemployed\",\n    1: \"employed\",\n    2: \"employed\",\n    3: \"unemployed\",\n    4: \"unemployed\",\n    5: \"student\",\n    6: \"unemployed\",\n}\narea_mapping = {\n    0: \"unknown\",\n    1: \"suburban\",\n    2: \"urban\",\n    3: \"rural\",\n    4: \"rural\",\n    5: \"scotland\",\n}\nethnicity_mapping = {0: \"unknown\", 1: \"white\", 2: \"non-white\"}\nhh_composition_mapping = {\n    0: \"unknown\",\n    1: \"1adult\",\n    2: \"2adults\",\n    3: \"3+adults\",\n    4: \"single_parent\",\n    5: \"2adult_1+child\",\n    6: \"3+adult_1+child\",\n}\nmappings = {\n    \"age\": age_mapping,\n    \"gender\": gender_mapping,\n    \"education\": education_mapping,\n    \"license\": license_mapping,\n    \"car_access\": car_access_mapping,\n    \"work_status\": work_status_mapping,\n    \"area\": area_mapping,\n    \"ethnicity\": ethnicity_mapping,\n    \"hh_composition\": hh_composition_mapping,\n}\n\nexpanded_attributes[\"age_group\"] = expanded_attributes[\"age\"].map(\n    age_group_mapping\n)\n\nfor c, mapping in mappings.items():\n    if c in expanded_attributes.columns:\n        expanded_attributes[c] = expanded_attributes[c].map(mapping)\n</pre> age_mapping = {     1: 0,     2: 1,     3: 3,     4: 5,     5: 11,     6: 16,     7: 17,     8: 18,     9: 19,     10: 20,     11: 21,     12: 26,     13: 30,     14: 40,     15: 50,     16: 60,     17: 65,     18: 70,     19: 75,     20: 80,     21: 85, } age_group_mapping = {     1: \"&lt;5\",     2: \"&lt;5\",     3: \"&lt;5\",     4: \"5-11\",     5: \"11-16\",     6: \"16-20\",     7: \"16-20\",     8: \"16-20\",     9: \"16-20\",     10: \"20-30\",     11: \"20-30\",     12: \"20-30\",     13: \"30-40\",     14: \"40-50\",     15: \"50-70\",     16: \"50-70\",     17: \"50-70\",     18: \"70+\",     19: \"70+\",     20: \"70+\",     21: \"70+\", } gender_mapping = {0: \"unknown\", 1: \"M\", 2: \"F\"} education_mapping = {0: \"unknown\", 1: \"Y\", 2: \"N\"} license_mapping = {0: \"unknown\", 1: \"yes\", 2: \"yes\", 3: \"no\"} car_access_mapping = {     0: \"unknown\",     1: \"yes\",     2: \"yes\",     3: \"yes\",     4: \"yes\",     5: \"no\",     6: \"no\", } # work_status_mapping = { #     0: \"unknown\", #     1: \"FT\", #     2: \"PT\", #     3: \"unemployed\", #     4: \"retired\", #     5: \"student\", #     6: \"other\", # } work_status_mapping = {     0: \"unemployed\",     1: \"employed\",     2: \"employed\",     3: \"unemployed\",     4: \"unemployed\",     5: \"student\",     6: \"unemployed\", } area_mapping = {     0: \"unknown\",     1: \"suburban\",     2: \"urban\",     3: \"rural\",     4: \"rural\",     5: \"scotland\", } ethnicity_mapping = {0: \"unknown\", 1: \"white\", 2: \"non-white\"} hh_composition_mapping = {     0: \"unknown\",     1: \"1adult\",     2: \"2adults\",     3: \"3+adults\",     4: \"single_parent\",     5: \"2adult_1+child\",     6: \"3+adult_1+child\", } mappings = {     \"age\": age_mapping,     \"gender\": gender_mapping,     \"education\": education_mapping,     \"license\": license_mapping,     \"car_access\": car_access_mapping,     \"work_status\": work_status_mapping,     \"area\": area_mapping,     \"ethnicity\": ethnicity_mapping,     \"hh_composition\": hh_composition_mapping, }  expanded_attributes[\"age_group\"] = expanded_attributes[\"age\"].map(     age_group_mapping )  for c, mapping in mappings.items():     if c in expanded_attributes.columns:         expanded_attributes[c] = expanded_attributes[c].map(mapping) In\u00a0[7]: Copied! <pre>pam_population = read.load_travel_diary(\n    trips=travel_diaries,\n    persons_attributes=expanded_attributes,\n    trip_freq_as_person_freq=True,\n)\nprint(pam_population.stats)\npam_population.fix_plans()\nprint(pam_population.stats)\npam_population.random_person().plot()\n</pre> pam_population = read.load_travel_diary(     trips=travel_diaries,     persons_attributes=expanded_attributes,     trip_freq_as_person_freq=True, ) print(pam_population.stats) pam_population.fix_plans() print(pam_population.stats) pam_population.random_person().plot() <pre>Using from-to activity parser using 'oact' and 'dact' columns\nAdding pid-&gt;hh mapping to persons_attributes from trips.\n\n        Unable to load household area ('hzone') - not found in trips_diary or unable to build from attributes.\n        Pam will try to infer home location from activities, but this behaviour is not recommended.\n        \nUsing freq of 'None' for all trips.\n Person pid:2-5 hid:1 plan does not start with 'home' activity: work\n Person pid:2-6 hid:1 plan does not start with 'home' activity: work\n Person pid:2-7 hid:1 plan does not start with 'home' activity: work\n Person pid:3-4 hid:1 plan does not start with 'home' activity: education\n</pre> <pre>{'num_households': 3, 'num_people': 39, 'num_activities': 188, 'num_legs': 149}\n{'num_households': 3, 'num_people': 39, 'num_activities': 175, 'num_legs': 136}\n</pre> In\u00a0[8]: Copied! <pre>def dt_to_min(dt) -&gt; int:\n    h, m, s = datetime_to_matsim_time(dt).split(\":\")\n    return (int(h) * 60) + int(m)\n\n\ndef pam_to_schedules(population: Population) -&gt; pd.DataFrame:\n    \"\"\"write trace of population. Ignoring trips.\"\"\"\n    record = []\n    for uid, (hid, pid, person) in enumerate(population.people()):\n        for i in range(0, len(person.plan) - 1, 2):\n            record.append(\n                [\n                    uid,\n                    hid,\n                    person.plan[i].act,\n                    dt_to_min(person.plan[i].start_time),\n                    dt_to_min(person.plan[i + 1].end_time),\n                ]\n            )\n        record.append(\n            [\n                uid,\n                hid,\n                person.plan[-1].act,\n                dt_to_min(person.plan[-1].start_time),\n                dt_to_min(person.plan[-1].end_time),\n            ]\n        )\n\n    df = pd.DataFrame(record, columns=[\"pid\", \"hid\", \"act\", \"start\", \"end\"])\n    df[\"duration\"] = df.end - df.start\n    return df\n\n\nschedules = pam_to_schedules(population=pam_population)\n\nattributes = pd.DataFrame(\n    [\n        {**{\"pid\": pid}, **p.attributes}\n        for pid, (_, _, p) in enumerate(pam_population.people())\n    ]\n).drop([\"iid\", \"year\"], axis=1)\nattributes.describe()\n\nassert set(schedules.pid).issubset(set(attributes.pid))\n\nschedules.to_csv(schedules_path, index=False)\nattributes.to_csv(attributes_path, index=False)\n\nschedules.describe()\n</pre> def dt_to_min(dt) -&gt; int:     h, m, s = datetime_to_matsim_time(dt).split(\":\")     return (int(h) * 60) + int(m)   def pam_to_schedules(population: Population) -&gt; pd.DataFrame:     \"\"\"write trace of population. Ignoring trips.\"\"\"     record = []     for uid, (hid, pid, person) in enumerate(population.people()):         for i in range(0, len(person.plan) - 1, 2):             record.append(                 [                     uid,                     hid,                     person.plan[i].act,                     dt_to_min(person.plan[i].start_time),                     dt_to_min(person.plan[i + 1].end_time),                 ]             )         record.append(             [                 uid,                 hid,                 person.plan[-1].act,                 dt_to_min(person.plan[-1].start_time),                 dt_to_min(person.plan[-1].end_time),             ]         )      df = pd.DataFrame(record, columns=[\"pid\", \"hid\", \"act\", \"start\", \"end\"])     df[\"duration\"] = df.end - df.start     return df   schedules = pam_to_schedules(population=pam_population)  attributes = pd.DataFrame(     [         {**{\"pid\": pid}, **p.attributes}         for pid, (_, _, p) in enumerate(pam_population.people())     ] ).drop([\"iid\", \"year\"], axis=1) attributes.describe()  assert set(schedules.pid).issubset(set(attributes.pid))  schedules.to_csv(schedules_path, index=False) attributes.to_csv(attributes_path, index=False)  schedules.describe() Out[8]: pid hid start end duration count 175.000000 175.000000 175.000000 175.000000 175.000000 mean 17.520000 1.685714 686.988571 1007.902857 320.914286 std 11.502044 0.921375 416.041844 301.367566 262.947656 min 0.000000 1.000000 0.000000 348.000000 6.000000 25% 8.000000 1.000000 465.000000 785.000000 52.000000 50% 17.000000 1.000000 805.000000 950.000000 320.000000 75% 28.000000 3.000000 967.000000 1308.500000 527.500000 max 38.000000 3.000000 1325.000000 1440.000000 962.000000 In\u00a0[9]: Copied! <pre>_ = times_distributions_plot(schedules, ys={})\n</pre> _ = times_distributions_plot(schedules, ys={}) In\u00a0[10]: Copied! <pre>_ = joint_time_distributions_plot(schedules, ys={})\n</pre> _ = joint_time_distributions_plot(schedules, ys={}) In\u00a0[11]: Copied! <pre>_ = sequence_prob_plot(schedules, ys={}, figsize=(8, 6))\n</pre> _ = sequence_prob_plot(schedules, ys={}, figsize=(8, 6)) In\u00a0[12]: Copied! <pre>def pam_to_population_home_based_plans_only(\n    population: Population,\n) -&gt; pd.DataFrame:\n    \"\"\"Convert population to trace. Only home-based plans are included.\"\"\"\n    record = []\n    for uid, (hid, pid, person) in enumerate(population.people()):\n        person_record = []\n        for i in range(0, len(person.plan) - 1, 2):\n            person_record.append(\n                [\n                    uid,\n                    hid,\n                    person.plan[i].act,\n                    dt_to_min(person.plan[i].start_time),\n                    dt_to_min(person.plan[i + 1].end_time),\n                ]\n            )\n        person_record.append(\n            [\n                uid,\n                hid,\n                person.plan[-1].act,\n                dt_to_min(person.plan[-1].start_time),\n                dt_to_min(person.plan[-1].end_time),\n            ]\n        )\n        if (person_record[0][2] == \"home\") and (person_record[-1][2] == \"home\"):\n            record.extend(person_record)\n\n    df = pd.DataFrame(record, columns=[\"pid\", \"hid\", \"act\", \"start\", \"end\"])\n    df[\"duration\"] = df.end - df.start\n    return df\n\n\nhome_schedules = pam_to_population_home_based_plans_only(pam_population)\n\nhome_attributes = pd.DataFrame(\n    [\n        {**{\"pid\": pid}, **p.attributes}\n        for pid, (_, _, p) in enumerate(pam_population.people())\n    ]\n).drop([\"iid\", \"year\"], axis=1)\nattributes.describe()\n\nassert set(home_schedules.pid).issubset(set(home_attributes.pid))\n\nhome_schedules.to_csv(home_schedules_path, index=False)\nhome_attributes.to_csv(home_attributes_path, index=False)\n</pre> def pam_to_population_home_based_plans_only(     population: Population, ) -&gt; pd.DataFrame:     \"\"\"Convert population to trace. Only home-based plans are included.\"\"\"     record = []     for uid, (hid, pid, person) in enumerate(population.people()):         person_record = []         for i in range(0, len(person.plan) - 1, 2):             person_record.append(                 [                     uid,                     hid,                     person.plan[i].act,                     dt_to_min(person.plan[i].start_time),                     dt_to_min(person.plan[i + 1].end_time),                 ]             )         person_record.append(             [                 uid,                 hid,                 person.plan[-1].act,                 dt_to_min(person.plan[-1].start_time),                 dt_to_min(person.plan[-1].end_time),             ]         )         if (person_record[0][2] == \"home\") and (person_record[-1][2] == \"home\"):             record.extend(person_record)      df = pd.DataFrame(record, columns=[\"pid\", \"hid\", \"act\", \"start\", \"end\"])     df[\"duration\"] = df.end - df.start     return df   home_schedules = pam_to_population_home_based_plans_only(pam_population)  home_attributes = pd.DataFrame(     [         {**{\"pid\": pid}, **p.attributes}         for pid, (_, _, p) in enumerate(pam_population.people())     ] ).drop([\"iid\", \"year\"], axis=1) attributes.describe()  assert set(home_schedules.pid).issubset(set(home_attributes.pid))  home_schedules.to_csv(home_schedules_path, index=False) home_attributes.to_csv(home_attributes_path, index=False)"},{"location":"examples/3_NTS_population_demo/#generate-population-from-national-transport-survey-data","title":"Generate Population from National Transport Survey Data\u00b6","text":"<p>Generate caveat schedules and attributes inputs from UK NTS data.</p> <p>Provided example uses toy data. You can access the real UK travel survey from 2002-2021 from the UK Data Service.</p>"},{"location":"examples/4_creativity/","title":"Creativity","text":"In\u00a0[1]: Copied! <pre>import random\n\nimport pandas as pd\n\nfrom caveat.evaluate.features import creativity\n</pre> import random  import pandas as pd  from caveat.evaluate.features import creativity In\u00a0[2]: Copied! <pre># create some data\nraw = pd.read_csv(\"data/synthetic_schedules.csv\")\n\n\ndef down_sample(df, p):\n    n_samples = int(len(df.pid.unique()) * p)\n    sample_ids = random.sample(list(df.pid.unique()), n_samples)\n    sampled = df[df.pid.isin(sample_ids)]\n    return sampled\n\n\nobserved = down_sample(raw, 0.2)\n\na = down_sample(observed, 0.5)\nb = down_sample(raw, 0.2)\nsynthetic = {\"a\": a, \"b\": b}\n</pre> # create some data raw = pd.read_csv(\"data/synthetic_schedules.csv\")   def down_sample(df, p):     n_samples = int(len(df.pid.unique()) * p)     sample_ids = random.sample(list(df.pid.unique()), n_samples)     sampled = df[df.pid.isin(sample_ids)]     return sampled   observed = down_sample(raw, 0.2)  a = down_sample(observed, 0.5) b = down_sample(raw, 0.2) synthetic = {\"a\": a, \"b\": b} In\u00a0[3]: Copied! <pre>observed_hash = creativity.hash_population(observed)\na_hash = creativity.hash_population(a)\nb_hash = creativity.hash_population(b)\n</pre> observed_hash = creativity.hash_population(observed) a_hash = creativity.hash_population(a) b_hash = creativity.hash_population(b) In\u00a0[4]: Copied! <pre>print(\n    f\"Observed population of size {len(observed)} has diversity of {creativity.diversity(observed, observed_hash)}\"\n)\nprint(\n    f\"Synthetic population A of size {len(a)} has diversity of {creativity.diversity(a, a_hash)}\"\n)\nprint(\n    f\"Synthetic population B of size {len(b)} has diversity of {creativity.diversity(b, b_hash)}\"\n)\n</pre> print(     f\"Observed population of size {len(observed)} has diversity of {creativity.diversity(observed, observed_hash)}\" ) print(     f\"Synthetic population A of size {len(a)} has diversity of {creativity.diversity(a, a_hash)}\" ) print(     f\"Synthetic population B of size {len(b)} has diversity of {creativity.diversity(b, b_hash)}\" ) <pre>Observed population of size 838 has diversity of 0.735\nSynthetic population A of size 419 has diversity of 0.78\nSynthetic population B of size 865 has diversity of 0.695\n</pre> <p>In all cases we have high diversity. Note that that the size of a population also has an impact on diversity. we expect it to be easier to generate a diverse population if it is smaller.</p> In\u00a0[5]: Copied! <pre>print(\n    f\"Synthetic population A of size {len(a)} has novelty of {creativity.novelty(observed_hash, a_hash)}\"\n)\nprint(\n    f\"Synthetic population B of size {len(b)} has novelty of {creativity.novelty(observed_hash, b_hash)}\"\n)\n</pre> print(     f\"Synthetic population A of size {len(a)} has novelty of {creativity.novelty(observed_hash, a_hash)}\" ) print(     f\"Synthetic population B of size {len(b)} has novelty of {creativity.novelty(observed_hash, b_hash)}\" ) <pre>Synthetic population A of size 419 has novelty of 0.0\nSynthetic population B of size 865 has novelty of 0.5611510791366906\n</pre> <p>In our example, population A is sampled from the observed population and therefore has 0 novelty. Population B is sampled from the same larger population (intended to represent the \"real\" population) as the observed so has some novelty.</p>"},{"location":"examples/4_creativity/#creativity","title":"Creativity\u00b6","text":"<p>In addition to correctness we also desire a model to have creativity.</p> <p>Consider a model that generates a new population by sampling randomly from the training population. This model would have excellent or even perfect correctness. However this model would be unable to generate up-sampled populations of sequences without sampling the same data multiple times. More generally this model would be unable to generate sequences not seen in the training data, which in practice is only a small sample of the true population.</p> <p>We therefore also measure and value creativity, which we define as a combination of diversity and novelty.</p>"},{"location":"examples/4_creativity/#diversity","title":"Diversity\u00b6","text":"<p>We consider the diversity of the populations of sequences by counting the number of unique sequences as a proportion of the total number of sequences. We can compare the diversity of two populations in this manner. We consider higher diversity to be good. Ideally as diverse or more so than the training population.</p>"},{"location":"examples/4_creativity/#novelty","title":"Novelty\u00b6","text":"<p>We consider the novelty of a model as how well it can generate sequences not observed in the training population. We measure novelty by counting the number of unique sequences not seen in the training population as a proportion of the total number of sequences in the population. By only considering unique sequences we are are effectively combining our measure of diversity with novelty, and we more generally refer to this metric as creativity.</p>"},{"location":"examples/5_features_and_correctness/","title":"Features and Correctness","text":"In\u00a0[1]: Copied! <pre>import random\n\nimport pandas as pd\n\nfrom caveat.evaluate.describe import features\nfrom caveat.evaluate.describe.times import (\n    joint_time_distributions_plot,\n    times_distributions_plot,\n)\nfrom caveat.evaluate.describe.transitions import sequence_prob_plot\nfrom caveat.evaluate.distance import mape, emd\nfrom caveat.evaluate.features import participation, times\n</pre> import random  import pandas as pd  from caveat.evaluate.describe import features from caveat.evaluate.describe.times import (     joint_time_distributions_plot,     times_distributions_plot, ) from caveat.evaluate.describe.transitions import sequence_prob_plot from caveat.evaluate.distance import mape, emd from caveat.evaluate.features import participation, times In\u00a0[2]: Copied! <pre># create some data\nraw = pd.read_csv(\"data/synthetic_schedules.csv\")\n\n\ndef down_sample(df, p):\n    n_samples = int(len(df.pid.unique()) * p)\n    sample_ids = random.sample(list(df.pid.unique()), n_samples)\n    sampled = df[df.pid.isin(sample_ids)]\n    return sampled\n\n\nobserved = down_sample(raw, 0.2)\n\na = down_sample(observed, 0.2)\nb = down_sample(raw, 0.2)\nsynthetic = {\"a\": a, \"b\": b}\n</pre> # create some data raw = pd.read_csv(\"data/synthetic_schedules.csv\")   def down_sample(df, p):     n_samples = int(len(df.pid.unique()) * p)     sample_ids = random.sample(list(df.pid.unique()), n_samples)     sampled = df[df.pid.isin(sample_ids)]     return sampled   observed = down_sample(raw, 0.2)  a = down_sample(observed, 0.2) b = down_sample(raw, 0.2) synthetic = {\"a\": a, \"b\": b} <p>For example we can extract the start times for each activity and report the averages:</p> In\u00a0[3]: Copied! <pre>starts = times.start_times_by_act(observed)\nfeatures.average(starts)\n</pre> starts = times.start_times_by_act(observed) features.average(starts) Out[3]: <pre>education    0.659226\nhome         0.346557\nleisure      0.398819\nshop         0.370292\nwork         0.388393\ndtype: float64</pre> <p>Note that the starts feature is a dictionary of tuples. Where the first value describes the 'support' of the feature and the second the frequncy of each observation.</p> <p>We can take a better look at the distributions by plotting them:</p> In\u00a0[4]: Copied! <pre>fig = times_distributions_plot(observed, None)\n</pre> fig = times_distributions_plot(observed, None) In\u00a0[5]: Copied! <pre>participation_rates = participation.participation_rates_by_act(observed)\nprint(features.average(participation_rates))\n</pre> participation_rates = participation.participation_rates_by_act(observed) print(features.average(participation_rates)) <pre>education    0.035\nhome         2.115\nleisure      0.785\nshop         0.885\nwork         0.525\ndtype: float64\n</pre> In\u00a0[6]: Copied! <pre>fig = sequence_prob_plot(observed, synthetic, figsize=(12, 4))\n</pre> fig = sequence_prob_plot(observed, synthetic, figsize=(12, 4)) In\u00a0[7]: Copied! <pre>participation_rates = participation.participation_rates_by_seq_act(observed)\nprint(features.average(participation_rates).head(10))\n</pre> participation_rates = participation.participation_rates_by_seq_act(observed) print(features.average(participation_rates).head(10)) <pre>0home         1.000\n10home        0.005\n10leisure     0.010\n11home        0.005\n11work        0.005\n12home        0.005\n1leisure      0.150\n1shop         0.480\n1work         0.370\n2education    0.030\ndtype: float64\n</pre> <p>Or by the enumeration of that type of activity in each sequence:</p> In\u00a0[8]: Copied! <pre>participation_rates = participation.participation_rates_by_act_enum(observed)\nprint(features.average(participation_rates).head(10))\n</pre> participation_rates = participation.participation_rates_by_act_enum(observed) print(features.average(participation_rates).head(10)) <pre>education0    0.035\nhome0         1.000\nhome1         1.000\nhome2         0.095\nhome3         0.015\nhome4         0.005\nleisure0      0.700\nleisure1      0.055\nleisure2      0.020\nleisure3      0.010\ndtype: float64\n</pre> <p>In these examples we use additional segmentation to get more information about the sequence. For example we can differentiate between the participation in (i) education as the third activity (2education) versus the fourth activity (3education), or (ii) the first education activity (education0) versus the second education activity (education1).</p> <p>In all cases we use weighted averaging to combine segmented features into single metrics. Where weighting is ussually the number of each feature in the observed population of sequences.</p> In\u00a0[9]: Copied! <pre>start_durations = times.start_and_duration_by_act_bins(observed, bin_size=10)\n# average 2d averages each dimension and then sums so that we can return an float\nfeatures.average2d(start_durations)\n</pre> start_durations = times.start_and_duration_by_act_bins(observed, bin_size=10) # average 2d averages each dimension and then sums so that we can return an float features.average2d(start_durations) Out[9]: <pre>education    0.722222\nhome         0.633668\nleisure      0.618763\nshop         0.439462\nwork         0.716005\ndtype: float64</pre> In\u00a0[10]: Copied! <pre>fig = joint_time_distributions_plot(observed, None, figsize=(12, 4))\n</pre> fig = joint_time_distributions_plot(observed, None, figsize=(12, 4)) In\u00a0[11]: Copied! <pre>fig = times_distributions_plot(observed, synthetic)\n</pre> fig = times_distributions_plot(observed, synthetic) <p>To make a quantitave comparison between populations of sequences we primarilly use Wassersetin \"earth movers\" distance. This measure the amount of \"work\" required to make one distribuion match another.</p> In\u00a0[12]: Copied! <pre>x = times.start_times_by_act(observed)\nya = times.start_times_by_act(synthetic[\"a\"])\nyb = times.start_times_by_act(synthetic[\"b\"])\nprint(\"synthetic population A: \", emd(x[\"home\"], ya[\"home\"]))\nprint(\"synthetic population B: \", emd(x[\"home\"], yb[\"home\"]))\n</pre> x = times.start_times_by_act(observed) ya = times.start_times_by_act(synthetic[\"a\"]) yb = times.start_times_by_act(synthetic[\"b\"]) print(\"synthetic population A: \", emd(x[\"home\"], ya[\"home\"])) print(\"synthetic population B: \", emd(x[\"home\"], yb[\"home\"])) <pre>synthetic population A:  0.014241666208514305\nsynthetic population B:  0.009556373556720447\n</pre> <p>In this case we might proclaim population B to be better. In practice we will use a lot more features and there will generally be trade-offs between them.</p> <p>For probability features (in particular participation) we also sometime use absolute percentage error. This is particularly useful for highlighting the participation in uncommon activities which are often problematic for generative models.</p> In\u00a0[13]: Copied! <pre>x = participation.participation_prob_by_act(observed)\nya = participation.participation_prob_by_act(synthetic[\"a\"])\nyb = participation.participation_prob_by_act(synthetic[\"b\"])\nprint(\"synthetic population A: \", mape(x[\"leisure\"], ya[\"shop\"]))\nprint(\"synthetic population B: \", mape(x[\"leisure\"], yb[\"shop\"]))\n</pre> x = participation.participation_prob_by_act(observed) ya = participation.participation_prob_by_act(synthetic[\"a\"]) yb = participation.participation_prob_by_act(synthetic[\"b\"]) print(\"synthetic population A: \", mape(x[\"leisure\"], ya[\"shop\"])) print(\"synthetic population B: \", mape(x[\"leisure\"], yb[\"shop\"])) <pre>synthetic population A:  0.09677419354838718\nsynthetic population B:  0.13043478260869576\n</pre> <p>By this metric, population A appears better.</p>"},{"location":"examples/5_features_and_correctness/#features-and-correctness","title":"Features and Correctness\u00b6","text":"<p>We want to be able to describe our populations of sequences and compare them. To do this we extract various distributions, but we call them features. These features are designed such that they can be used to describe and measure correctness as a distance.</p> <p>We define features as belonging to one of the following \"domains\":</p> <ul> <li>Structural features are designed to check for \"structural zeros\", ie outputs that should not be possible.<ul> <li>eg, if each sequence starts with a \"home\" activity</li> <li>eg, if each sequence has a total duration of 24 hours</li> </ul> </li> <li>Participation features check for the occurance of activity types in a sequence, they can be presented as rates or probabilities.<ul> <li>eg, if each sequence participates in the \"work\" activity or not</li> </ul> </li> <li>Transition features describe the ordering of activities within sequences.<ul> <li>eg, how many times a sequence transitions from \"home\" to \"work\"</li> </ul> </li> <li>times/scheduling features describe when activities take place.<ul> <li>eg, the start time of all \"shop\" activities</li> </ul> </li> </ul> <p>We also use frequency features to describe the aggregate probability of an activity taking place in a given time bin. For example, \"X% of agents are at work between 10am and 11am\".</p> <p>We also use uniqueness as a measure of diversity within a population of sequences.</p>"},{"location":"examples/5_features_and_correctness/#feature-structure","title":"Feature Structure\u00b6","text":"<p>Features are commonly segmented into a dictionary of keys and values, where the key describes the segment. Features are commonly segmented by activity or transition type:</p> <pre><code>participation_probability = {\n    \"home\": [1,1,1],\n    \"work\": [1,0,0],\n    \"shop\": [0,1,0]\n}\n</code></pre> <p>In the above example, each feature segment records if each of the 3 segements contained a \"home\", \"work\" or \"shop\" activity.</p> <p>In practice we compress this representation into frequency counts, represented by a tuple of the (i) possible values and (ii) their frequncies, in this simple case we get:</p> <pre><code>participation_probability = {\n    \"home\": ([0, 1], [0, 3]),\n    \"work\": ([0, 1], [2, 1]),\n    \"shop\": ([0, 1], [2, 1]),\n}\n</code></pre>"},{"location":"examples/5_features_and_correctness/#feature-descriptions","title":"Feature Descriptions\u00b6","text":"<p>Features can be described or plotted using functions in the describe module:</p>"},{"location":"examples/5_features_and_correctness/#feature-segmentation","title":"Feature Segmentation\u00b6","text":"<p>We can use more interesting types of segmentation to extact more descriptive features. For example we can enumerate activity type by it's location in the sequence:</p>"},{"location":"examples/5_features_and_correctness/#dimensions","title":"Dimensions\u00b6","text":"<p>Start times are a one dimensional feature, but we can also consider multi-demnsional features:</p>"},{"location":"examples/5_features_and_correctness/#distances","title":"Distances\u00b6","text":"<p>When comparing features we can generally see complex distributions:</p>"},{"location":"examples/6_matsim_seq2seq/","title":"MATSim Plans - Sequence to Sequence","text":"In\u00a0[6]: Copied! <pre>from pathlib import Path\nimport pandas as pd\n\nfrom pam.read.matsim import load_attributes_map_from_v12, stream_matsim_persons\nfrom pam.utils import datetime_to_matsim_time\nfrom pam.core import Population, Person\nfrom pam.activity import Leg\n</pre> from pathlib import Path import pandas as pd  from pam.read.matsim import load_attributes_map_from_v12, stream_matsim_persons from pam.utils import datetime_to_matsim_time from pam.core import Population, Person from pam.activity import Leg In\u00a0[7]: Copied! <pre>dir = Path(\"data/matsim\")\n\n# input paths\noutput_plans_path = dir / \"output_plans.xml\"\niter_50 = dir / \"output_experienced_plans_ITER50.xml\"\nassert iter_50.exists()\niter_100 = dir / \"output_experienced_plans_ITER100.xml\"\nassert iter_100.exists()\niter_150 = dir / \"output_experienced_plans_ITER150.xml\"\nassert iter_150.exists()\n\n# output path\noutput_dir = Path(\"tmp\")\noutput_dir.mkdir(exist_ok=True)\nlhs_path = output_dir / \"lhs.csv\"\nrhs_path = output_dir / \"rhs.csv\"\ncombined_path = output_dir / \"combined.csv\"\nattributes_path = output_dir / \"attributes.csv\"\n</pre> dir = Path(\"data/matsim\")  # input paths output_plans_path = dir / \"output_plans.xml\" iter_50 = dir / \"output_experienced_plans_ITER50.xml\" assert iter_50.exists() iter_100 = dir / \"output_experienced_plans_ITER100.xml\" assert iter_100.exists() iter_150 = dir / \"output_experienced_plans_ITER150.xml\" assert iter_150.exists()  # output path output_dir = Path(\"tmp\") output_dir.mkdir(exist_ok=True) lhs_path = output_dir / \"lhs.csv\" rhs_path = output_dir / \"rhs.csv\" combined_path = output_dir / \"combined.csv\" attributes_path = output_dir / \"attributes.csv\" In\u00a0[8]: Copied! <pre>streamer50 = stream_matsim_persons(\n    iter_50,\n    simplify_pt_trips=True,\n    # crop=True,\n    keep_non_selected=False,\n    leg_attributes=True,\n    leg_route=True,\n)\nstreamer100 = stream_matsim_persons(\n    iter_100,\n    simplify_pt_trips=True,\n    # crop=True,\n    keep_non_selected=False,\n    leg_attributes=True,\n    leg_route=True,\n)\nstreamer150 = stream_matsim_persons(\n    iter_150,\n    simplify_pt_trips=True,\n    # crop=True,\n    keep_non_selected=False,\n    leg_attributes=True,\n    leg_route=True,\n)\nstreamers = [streamer50, streamer100, streamer150]\n</pre> streamer50 = stream_matsim_persons(     iter_50,     simplify_pt_trips=True,     # crop=True,     keep_non_selected=False,     leg_attributes=True,     leg_route=True, ) streamer100 = stream_matsim_persons(     iter_100,     simplify_pt_trips=True,     # crop=True,     keep_non_selected=False,     leg_attributes=True,     leg_route=True, ) streamer150 = stream_matsim_persons(     iter_150,     simplify_pt_trips=True,     # crop=True,     keep_non_selected=False,     leg_attributes=True,     leg_route=True, ) streamers = [streamer50, streamer100, streamer150] In\u00a0[9]: Copied! <pre>def dt_to_min(dt) -&gt; int:\n    h, m, s = datetime_to_matsim_time(dt).split(\":\")\n    return (int(h) * 60) + int(m)\n\n\ndef person_to_schedule(person: Person) -&gt; tuple:\n    score = person.plan.score\n    if score is None:\n        score = 0\n    record = []\n    for component in person.plan:\n        if isinstance(component, Leg):\n            distance = component.euclidean_distance\n            mode = component.mode\n        else:\n            distance = 0\n            mode = \"NA\"\n        record.append(\n            [\n                component.act,\n                dt_to_min(component.start_time),\n                dt_to_min(component.end_time),\n                mode,\n                distance,\n            ]\n        )\n    return (person.pid, (score, [record]))\n\n\ndef pam_to_schedules(population: Population) -&gt; dict:\n    return dict([person_to_schedule(person) for person in population])\n\n\ndef add_pid(record, pid):\n    record = [[pid] + line for line in record]\n    return record\n</pre> def dt_to_min(dt) -&gt; int:     h, m, s = datetime_to_matsim_time(dt).split(\":\")     return (int(h) * 60) + int(m)   def person_to_schedule(person: Person) -&gt; tuple:     score = person.plan.score     if score is None:         score = 0     record = []     for component in person.plan:         if isinstance(component, Leg):             distance = component.euclidean_distance             mode = component.mode         else:             distance = 0             mode = \"NA\"         record.append(             [                 component.act,                 dt_to_min(component.start_time),                 dt_to_min(component.end_time),                 mode,                 distance,             ]         )     return (person.pid, (score, [record]))   def pam_to_schedules(population: Population) -&gt; dict:     return dict([person_to_schedule(person) for person in population])   def add_pid(record, pid):     record = [[pid] + line for line in record]     return record In\u00a0[10]: Copied! <pre>best = pam_to_schedules(streamer50)\n\nlhss = []\nrhss = []\nmapper = {}\ni = 0\n\nfor s, streamer in enumerate(streamers):\n    print(\"streaming: \", s)\n    for person in streamer:\n        pid, (score, (record,)) = person_to_schedule(person)\n        existing_score, existing_records = best[pid]\n        if score &gt; existing_score:\n            new_records = existing_records + [record]\n            for existing in existing_records:\n                if len(record) == len(\n                    existing\n                ):  # protection against cropped plans\n                    lhss.extend(add_pid(existing, i))\n                    rhss.extend(add_pid(record, i))\n                    mapper[i] = pid\n                    i += 1\n            best[pid] = (score, new_records)\n</pre> best = pam_to_schedules(streamer50)  lhss = [] rhss = [] mapper = {} i = 0  for s, streamer in enumerate(streamers):     print(\"streaming: \", s)     for person in streamer:         pid, (score, (record,)) = person_to_schedule(person)         existing_score, existing_records = best[pid]         if score &gt; existing_score:             new_records = existing_records + [record]             for existing in existing_records:                 if len(record) == len(                     existing                 ):  # protection against cropped plans                     lhss.extend(add_pid(existing, i))                     rhss.extend(add_pid(record, i))                     mapper[i] = pid                     i += 1             best[pid] = (score, new_records) <pre>streaming:  0\nstreaming:  1\nstreaming:  2\n</pre> In\u00a0[11]: Copied! <pre>lhs = pd.DataFrame(\n    lhss, columns=[\"pid\", \"act\", \"start\", \"end\", \"mode\", \"distance\"]\n).set_index(\"pid\")\nrhs = pd.DataFrame(\n    rhss, columns=[\"pid\", \"act\", \"start\", \"end\", \"mode\", \"distance\"]\n).set_index(\"pid\")\n</pre> lhs = pd.DataFrame(     lhss, columns=[\"pid\", \"act\", \"start\", \"end\", \"mode\", \"distance\"] ).set_index(\"pid\") rhs = pd.DataFrame(     rhss, columns=[\"pid\", \"act\", \"start\", \"end\", \"mode\", \"distance\"] ).set_index(\"pid\") In\u00a0[12]: Copied! <pre>attributes = load_attributes_map_from_v12(output_plans_path)\nattributes = {k: attributes[v] for k, v in mapper.items()}\nattributes = pd.DataFrame(attributes).T\nattributes.index.name = \"pid\"\nattributes = attributes.fillna(\"unknown\")\nattributes.head()\n</pre> attributes = load_attributes_map_from_v12(output_plans_path) attributes = {k: attributes[v] for k, v in mapper.items()} attributes = pd.DataFrame(attributes).T attributes.index.name = \"pid\" attributes = attributes.fillna(\"unknown\") attributes.head() Out[12]: subpopulation age pid 0 rich yes 1 poor no 2 poor no 3 poor no 4 poor no In\u00a0[13]: Copied! <pre>assert len(lhs.index.unique()) == len(rhs.index.unique()) == len(attributes)\nlen(attributes)\n</pre> assert len(lhs.index.unique()) == len(rhs.index.unique()) == len(attributes) len(attributes) Out[13]: <pre>8</pre> In\u00a0[14]: Copied! <pre>combined = pd.concat(\n    [\n        lhs,\n        rhs.rename(\n            columns={\n                \"act\": \"target_act\",\n                \"start\": \"target_start\",\n                \"end\": \"target_end\",\n                \"mode\": \"target_mode\",\n                \"distance\": \"target_distance\",\n            }\n        ),\n    ],\n    axis=1,\n)\ncombined[\"target_duration\"] = combined[\"target_end\"] - combined[\"target_start\"]\n\nlhs.to_csv(lhs_path)\nrhs.to_csv(rhs_path)\nattributes.to_csv(attributes_path)\ncombined.to_csv(combined_path)\n</pre> combined = pd.concat(     [         lhs,         rhs.rename(             columns={                 \"act\": \"target_act\",                 \"start\": \"target_start\",                 \"end\": \"target_end\",                 \"mode\": \"target_mode\",                 \"distance\": \"target_distance\",             }         ),     ],     axis=1, ) combined[\"target_duration\"] = combined[\"target_end\"] - combined[\"target_start\"]  lhs.to_csv(lhs_path) rhs.to_csv(rhs_path) attributes.to_csv(attributes_path) combined.to_csv(combined_path) In\u00a0[15]: Copied! <pre>from pathlib import Path\nimport pandas as pd\nimport numpy as np\n\nfrom pam.core import Person\nfrom pam.activity import Activity, Leg, Plan\nfrom pam.scoring import CharyparNagelPlanScorer\nfrom pam.utils import minutes_to_datetime\nfrom pam.plot import plot_persons\n</pre> from pathlib import Path import pandas as pd import numpy as np  from pam.core import Person from pam.activity import Activity, Leg, Plan from pam.scoring import CharyparNagelPlanScorer from pam.utils import minutes_to_datetime from pam.plot import plot_persons In\u00a0[16]: Copied! <pre>dir = Path(\"data/seq2seq\")\ntest_path = dir / \"test_input.csv\"\ntarget_path = dir / \"test_target.csv\"\npred_path = dir / \"pred.csv\"\n\ntest = pd.read_csv(test_path)\ntarget = pd.read_csv(target_path)\npred = pd.read_csv(pred_path)\n\nfor df in [test, target, pred]:\n    df[\"duration\"] = df.end - df.start\n\n# pred.distance = test.distance\n# pred.start[pred.start &gt; 1440] = 1440\n# pred.end[pred.end &gt; 1440] = 1440\n</pre> dir = Path(\"data/seq2seq\") test_path = dir / \"test_input.csv\" target_path = dir / \"test_target.csv\" pred_path = dir / \"pred.csv\"  test = pd.read_csv(test_path) target = pd.read_csv(target_path) pred = pd.read_csv(pred_path)  for df in [test, target, pred]:     df[\"duration\"] = df.end - df.start  # pred.distance = test.distance # pred.start[pred.start &gt; 1440] = 1440 # pred.end[pred.end &gt; 1440] = 1440 In\u00a0[17]: Copied! <pre>test.head()\n</pre> test.head() Out[17]: pid act start end mode distance duration 0 0 home 0 420 NaN 0.0 420 1 0 travel 420 427 car 10.1 7 2 0 work 427 990 NaN 0.0 563 3 0 travel 990 997 car 10.1 7 4 0 home 997 1440 NaN 0.0 443 In\u00a0[18]: Copied! <pre>target.head()\n</pre> target.head() Out[18]: pid act start end mode distance duration 0 0 home 0 420 NaN 0.0 420 1 0 travel 420 427 car 10.1 7 2 0 work 427 990 NaN 0.0 563 3 0 travel 990 997 car 10.1 7 4 0 home 997 1440 NaN 0.0 443 In\u00a0[19]: Copied! <pre>pred.head()\n</pre> pred.head() Out[19]: pid act start end mode distance duration 0 0 home 0 300 NaN 0.0 300 1 0 travel 300 400 car 10.1 100 2 0 work 400 990 NaN 0.0 590 3 0 travel 990 997 car 10.1 7 4 0 home 997 1440 NaN 0.0 443 In\u00a0[20]: Copied! <pre># structural check\nmatches = 0\nmisses = 0\n\n\nfor (_, t), (_, p) in zip(test.groupby(\"pid\"), pred.groupby(\"pid\")):\n    if list(t.act) == list(p.act):\n        matches += 1\n    else:\n        misses += 1\nprint(\n    f\"matches: {matches}, misses: {misses}, ratio: {matches / (matches + misses)}\"\n)\n</pre> # structural check matches = 0 misses = 0   for (_, t), (_, p) in zip(test.groupby(\"pid\"), pred.groupby(\"pid\")):     if list(t.act) == list(p.act):         matches += 1     else:         misses += 1 print(     f\"matches: {matches}, misses: {misses}, ratio: {matches / (matches + misses)}\" ) <pre>matches: 8, misses: 0, ratio: 1.0\n</pre> In\u00a0[21]: Copied! <pre># mode shift check\nmode_shifts = 0\ncorrect = 0\nshifts = {}\nfor (_, t), (_, tar), (_, p) in zip(\n    test.groupby(\"pid\"), target.groupby(\"pid\"), pred.groupby(\"pid\")\n):\n    for mt, mtar, mpred in zip(\n        list(t[\"mode\"]), list(tar[\"mode\"]), list(p[\"mode\"])\n    ):\n        if isinstance(mt, str) and (mt != mpred):\n            mode_shifts += 1\n            change = f\"{mt} -&gt; {mpred}\"\n            shifts[change] = shifts.get(change, 0) + 1\n            if mpred == mtar:\n                correct += 1\n\nprint(f\"mode shifts: {mode_shifts}\")\nprint(f\"correct mode shifts: {correct}, ratio: {correct / mode_shifts}\")\nprint(shifts)\n</pre> # mode shift check mode_shifts = 0 correct = 0 shifts = {} for (_, t), (_, tar), (_, p) in zip(     test.groupby(\"pid\"), target.groupby(\"pid\"), pred.groupby(\"pid\") ):     for mt, mtar, mpred in zip(         list(t[\"mode\"]), list(tar[\"mode\"]), list(p[\"mode\"])     ):         if isinstance(mt, str) and (mt != mpred):             mode_shifts += 1             change = f\"{mt} -&gt; {mpred}\"             shifts[change] = shifts.get(change, 0) + 1             if mpred == mtar:                 correct += 1  print(f\"mode shifts: {mode_shifts}\") print(f\"correct mode shifts: {correct}, ratio: {correct / mode_shifts}\") print(shifts) <pre>mode shifts: 2\ncorrect mode shifts: 0, ratio: 0.0\n{'pt -&gt; car': 2}\n</pre> In\u00a0[22]: Copied! <pre># duration check\nlonger = 0\ncorrect_longer = 0\nshorter = 0\ncorrect_shorter = 0\n\nfor (_, t), (_, tar), (_, p) in zip(\n    test.groupby(\"pid\"), target.groupby(\"pid\"), pred.groupby(\"pid\")\n):\n    for dt, dtar, dpred in zip(\n        list(t[\"duration\"]), list(tar[\"duration\"]), list(p[\"duration\"])\n    ):\n        if dpred &gt; dt:\n            longer += 1\n            if dtar &gt; dt:\n                correct_longer += 1\n        elif dpred &lt; dt:\n            shorter += 1\n            if dtar &lt; dt:\n                correct_shorter += 1\n\nprint(\n    f\"longer: {longer}, correct longer: {correct_longer}, ratio: {correct_longer / longer}\"\n)\nprint(\n    f\"shorter: {shorter}, correct shorter: {correct_shorter}, ratio: {correct_shorter / shorter}\"\n)\n</pre> # duration check longer = 0 correct_longer = 0 shorter = 0 correct_shorter = 0  for (_, t), (_, tar), (_, p) in zip(     test.groupby(\"pid\"), target.groupby(\"pid\"), pred.groupby(\"pid\") ):     for dt, dtar, dpred in zip(         list(t[\"duration\"]), list(tar[\"duration\"]), list(p[\"duration\"])     ):         if dpred &gt; dt:             longer += 1             if dtar &gt; dt:                 correct_longer += 1         elif dpred &lt; dt:             shorter += 1             if dtar &lt; dt:                 correct_shorter += 1  print(     f\"longer: {longer}, correct longer: {correct_longer}, ratio: {correct_longer / longer}\" ) print(     f\"shorter: {shorter}, correct shorter: {correct_shorter}, ratio: {correct_shorter / shorter}\" ) <pre>longer: 7, correct longer: 0, ratio: 0.0\nshorter: 5, correct shorter: 0, ratio: 0.0\n</pre> In\u00a0[23]: Copied! <pre># scoring\nconfig = {\n    \"mUM\": 1,\n    \"utilityOfLineSwitch\": -1,\n    \"performing\": 10,\n    \"waiting\": 0,\n    \"waitingPt\": 0,\n    \"lateArrival\": 0,\n    \"earlyDeparture\": 0,\n    \"home\": {\"typicalDuration\": \"10:00:00\", \"minimalDuration\": \"01:00:00\"},\n    \"work\": {\n        \"openingTime\": \"07:00:00\",\n        \"closingTime\": \"19:30:00\",\n        \"minimalDuration\": \"06:00:00\",\n        \"typicalDuration\": \"09:00:00\",\n    },\n    \"delivery\": {\n        \"openingTime\": \"06:00:00\",\n        \"closingTime\": \"20:00:00\",\n        \"minimalDuration\": \"00:30:00\",\n        \"typicalDuration\": \"01:00:00\",\n    },\n    \"depot\": {\n        \"openingTime\": \"00:00:00\",\n        \"closingTime\": \"23:59:59\",\n        \"minimalDuration\": \"00:30:00\",\n        \"typicalDuration\": \"04:00:00\",\n    },\n    \"education\": {\n        \"openingTime\": \"08:30:00\",\n        \"closingTime\": \"17:00:00\",\n        \"minimalDuration\": \"06:00:00\",\n        \"typicalDuration\": \"06:00:00\",\n    },\n    \"other\": {\"minimalDuration\": \"00:10:00\", \"typicalDuration\": \"00:30:00\"},\n    \"shop\": {\n        \"openingTime\": \"08:30:00\",\n        \"closingTime\": \"19:30:00\",\n        \"minimalDuration\": \"00:30:00\",\n        \"typicalDuration\": \"00:30:00\",\n    },\n    \"visit\": {\"minimalDuration\": \"00:30:00\", \"typicalDuration\": \"02:00:00\"},\n    \"medical\": {\n        \"openingTime\": \"09:00:00\",\n        \"closingTime\": \"18:00:00\",\n        \"minimalDuration\": \"00:30:00\",\n        \"typicalDuration\": \"01:00:00\",\n    },\n    \"business\": {\n        \"openingTime\": \"07:30:00\",\n        \"closingTime\": \"20:00:00\",\n        \"minimalDuration\": \"00:30:00\",\n        \"typicalDuration\": \"01:00:00\",\n    },\n    \"escort_home\": {\n        \"minimalDuration\": \"00:05:00\",\n        \"typicalDuration\": \"00:05:00\",\n    },\n    \"escort_work\": {\n        \"openingTime\": \"07:00:00\",\n        \"closingTime\": \"19:30:00\",\n        \"minimalDuration\": \"00:05:00\",\n        \"typicalDuration\": \"00:05:00\",\n    },\n    \"escort_business\": {\n        \"openingTime\": \"07:00:00\",\n        \"closingTime\": \"19:30:00\",\n        \"minimalDuration\": \"00:05:00\",\n        \"typicalDuration\": \"00:05:00\",\n    },\n    \"escort_education\": {\n        \"openingTime\": \"08:30:00\",\n        \"closingTime\": \"17:00:00\",\n        \"minimalDuration\": \"00:05:00\",\n        \"typicalDuration\": \"00:05:00\",\n    },\n    \"escort_other\": {\n        \"minimalDuration\": \"00:05:00\",\n        \"typicalDuration\": \"00:05:00\",\n    },\n    \"escort_shop\": {\n        \"openingTime\": \"08:30:00\",\n        \"closingTime\": \"17:30:00\",\n        \"minimalDuration\": \"00:05:00\",\n        \"typicalDuration\": \"00:05:00\",\n    },\n    \"car\": {\n        \"constant\": -4,\n        \"marginalUtilityOfDistance\": 0,\n        \"marginalUtilityOfTravelling\": -2,\n        \"monetaryDistanceRate\": -0.00009,\n    },\n    \"bike\": {\n        \"constant\": -0.5,\n        \"marginalUtilityOfDistance\": -0.001,\n        \"marginalUtilityOfTravelling\": 0,\n        \"monetaryDistanceRate\": 0,\n    },\n    \"walk\": {\"marginalUtilityOfDistance\": -0.001},\n    \"bus\": {\"monetaryDistanceRate\": -0.0002},\n    \"rail\": {\"monetaryDistanceRate\": -0.0002},\n    \"tram\": {\"monetaryDistanceRate\": -0.001},\n}\nscorer = CharyparNagelPlanScorer(config)\n\n\ndef to_datetime(minutes):\n    return minutes_to_datetime(minutes)\n\n\ndef build_plan(schedule):\n    plan = Plan()\n    try:\n        for _, row in schedule.iterrows():\n            start, end = to_datetime(row.start), to_datetime(row.end)\n            if row.act == \"travel\":\n                plan.add(\n                    Leg(\n                        mode=\"car\",\n                        start_time=start,\n                        end_time=end,\n                        distance=row.distance / 1000,\n                    )\n                )\n            else:\n                plan.add(Activity(act=row.act, start_time=start, end_time=end))\n        return plan\n    except Exception as e:\n        print(e)\n        return None\n\n\ndef score_schedule(schedule):\n    plan = build_plan(schedule)\n    if plan is not None:\n        return scorer.score_plan(plan, config)\n    return 0\n</pre> # scoring config = {     \"mUM\": 1,     \"utilityOfLineSwitch\": -1,     \"performing\": 10,     \"waiting\": 0,     \"waitingPt\": 0,     \"lateArrival\": 0,     \"earlyDeparture\": 0,     \"home\": {\"typicalDuration\": \"10:00:00\", \"minimalDuration\": \"01:00:00\"},     \"work\": {         \"openingTime\": \"07:00:00\",         \"closingTime\": \"19:30:00\",         \"minimalDuration\": \"06:00:00\",         \"typicalDuration\": \"09:00:00\",     },     \"delivery\": {         \"openingTime\": \"06:00:00\",         \"closingTime\": \"20:00:00\",         \"minimalDuration\": \"00:30:00\",         \"typicalDuration\": \"01:00:00\",     },     \"depot\": {         \"openingTime\": \"00:00:00\",         \"closingTime\": \"23:59:59\",         \"minimalDuration\": \"00:30:00\",         \"typicalDuration\": \"04:00:00\",     },     \"education\": {         \"openingTime\": \"08:30:00\",         \"closingTime\": \"17:00:00\",         \"minimalDuration\": \"06:00:00\",         \"typicalDuration\": \"06:00:00\",     },     \"other\": {\"minimalDuration\": \"00:10:00\", \"typicalDuration\": \"00:30:00\"},     \"shop\": {         \"openingTime\": \"08:30:00\",         \"closingTime\": \"19:30:00\",         \"minimalDuration\": \"00:30:00\",         \"typicalDuration\": \"00:30:00\",     },     \"visit\": {\"minimalDuration\": \"00:30:00\", \"typicalDuration\": \"02:00:00\"},     \"medical\": {         \"openingTime\": \"09:00:00\",         \"closingTime\": \"18:00:00\",         \"minimalDuration\": \"00:30:00\",         \"typicalDuration\": \"01:00:00\",     },     \"business\": {         \"openingTime\": \"07:30:00\",         \"closingTime\": \"20:00:00\",         \"minimalDuration\": \"00:30:00\",         \"typicalDuration\": \"01:00:00\",     },     \"escort_home\": {         \"minimalDuration\": \"00:05:00\",         \"typicalDuration\": \"00:05:00\",     },     \"escort_work\": {         \"openingTime\": \"07:00:00\",         \"closingTime\": \"19:30:00\",         \"minimalDuration\": \"00:05:00\",         \"typicalDuration\": \"00:05:00\",     },     \"escort_business\": {         \"openingTime\": \"07:00:00\",         \"closingTime\": \"19:30:00\",         \"minimalDuration\": \"00:05:00\",         \"typicalDuration\": \"00:05:00\",     },     \"escort_education\": {         \"openingTime\": \"08:30:00\",         \"closingTime\": \"17:00:00\",         \"minimalDuration\": \"00:05:00\",         \"typicalDuration\": \"00:05:00\",     },     \"escort_other\": {         \"minimalDuration\": \"00:05:00\",         \"typicalDuration\": \"00:05:00\",     },     \"escort_shop\": {         \"openingTime\": \"08:30:00\",         \"closingTime\": \"17:30:00\",         \"minimalDuration\": \"00:05:00\",         \"typicalDuration\": \"00:05:00\",     },     \"car\": {         \"constant\": -4,         \"marginalUtilityOfDistance\": 0,         \"marginalUtilityOfTravelling\": -2,         \"monetaryDistanceRate\": -0.00009,     },     \"bike\": {         \"constant\": -0.5,         \"marginalUtilityOfDistance\": -0.001,         \"marginalUtilityOfTravelling\": 0,         \"monetaryDistanceRate\": 0,     },     \"walk\": {\"marginalUtilityOfDistance\": -0.001},     \"bus\": {\"monetaryDistanceRate\": -0.0002},     \"rail\": {\"monetaryDistanceRate\": -0.0002},     \"tram\": {\"monetaryDistanceRate\": -0.001}, } scorer = CharyparNagelPlanScorer(config)   def to_datetime(minutes):     return minutes_to_datetime(minutes)   def build_plan(schedule):     plan = Plan()     try:         for _, row in schedule.iterrows():             start, end = to_datetime(row.start), to_datetime(row.end)             if row.act == \"travel\":                 plan.add(                     Leg(                         mode=\"car\",                         start_time=start,                         end_time=end,                         distance=row.distance / 1000,                     )                 )             else:                 plan.add(Activity(act=row.act, start_time=start, end_time=end))         return plan     except Exception as e:         print(e)         return None   def score_schedule(schedule):     plan = build_plan(schedule)     if plan is not None:         return scorer.score_plan(plan, config)     return 0 In\u00a0[24]: Copied! <pre>target_deltas = []\npred_deltas = []\n\n\nfor (_, t), (_, tar), (_, p) in zip(\n    test.groupby(\"pid\"), target.groupby(\"pid\"), pred.groupby(\"pid\")\n):\n    test_score = score_schedule(t)\n    target_deltas.append(score_schedule(tar) - test_score)\n    pred_deltas.append(score_schedule(p) - test_score)\n</pre> target_deltas = [] pred_deltas = []   for (_, t), (_, tar), (_, p) in zip(     test.groupby(\"pid\"), target.groupby(\"pid\"), pred.groupby(\"pid\") ):     test_score = score_schedule(t)     target_deltas.append(score_schedule(tar) - test_score)     pred_deltas.append(score_schedule(p) - test_score) In\u00a0[25]: Copied! <pre>deltas = np.array(pred_deltas)\ndeltas = deltas[~np.isnan(deltas)]\ndeltas\n</pre> deltas = np.array(pred_deltas) deltas = deltas[~np.isnan(deltas)] deltas Out[25]: <pre>array([-16.95975869,  -7.77093747,   0.        ,   0.        ,\n       -12.95851787,   0.        ,  10.1848928 ,  -2.13420831])</pre> In\u00a0[26]: Copied! <pre>print(sum(target_deltas) / len(target_deltas))\nprint(sum(deltas) / len(deltas))\n</pre> print(sum(target_deltas) / len(target_deltas)) print(sum(deltas) / len(deltas)) <pre>0.0\n-3.7048161934973365\n</pre> In\u00a0[27]: Copied! <pre>def plot(idx, test, target, pred):\n    plans = [build_plan(df[df.pid == idx]) for df in [test, target, pred]]\n    persons = [Person(f\"{idx}-{i}\") for i in [\"test\", \"target\", \"pred\"]]\n    for person, plan in zip(persons, plans):\n        person.plan = plan\n    plot_persons(persons)\n\n\nfor i in range(3):\n    plot(i, test, target, pred)\n</pre> def plot(idx, test, target, pred):     plans = [build_plan(df[df.pid == idx]) for df in [test, target, pred]]     persons = [Person(f\"{idx}-{i}\") for i in [\"test\", \"target\", \"pred\"]]     for person, plan in zip(persons, plans):         person.plan = plan     plot_persons(persons)   for i in range(3):     plot(i, test, target, pred) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/6_matsim_seq2seq/#matsim-plans-sequence-to-sequence","title":"MATSim Plans - Sequence to Sequence\u00b6","text":""},{"location":"examples/6_matsim_seq2seq/#part-1-pre-processing","title":"Part 1 - Pre-processing\u00b6","text":"<p>Demo of parsing MATSim (experienced) plans for a sequence to sequence model.</p> <p>MATSim plans from multiple iteration of the same run are processed into plan pairs. Where each pair is composed of an input plan and target plan. Where the target plan is from the same agent but from an iteration with higher utility score for that agent.</p> <p>Note that this extracts plan activities and trips. Each sequence component includes duration, mode and distance.</p>"},{"location":"examples/6_matsim_seq2seq/#part-2-evaluation","title":"Part 2 - Evaluation\u00b6","text":"<p>Demo of comparison of utility scores for input, target and predicted plans to evaluate quality of model outputs.</p>"},{"location":"examples/7_matsim_seq2score/","title":"MATSim Plans - Sequence to Score","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\nimport pandas as pd\n\nfrom pam.read.matsim import load_attributes_map_from_v12, stream_matsim_persons\nfrom pam.utils import datetime_to_matsim_time\nfrom pam.core import Population, Person\nfrom pam.activity import Activity, Plan, Leg\n</pre> from pathlib import Path import pandas as pd  from pam.read.matsim import load_attributes_map_from_v12, stream_matsim_persons from pam.utils import datetime_to_matsim_time from pam.core import Population, Person from pam.activity import Activity, Plan, Leg  In\u00a0[15]: Copied! <pre>dir = Path(\"data/matsim\")\n\n# input paths\noutput_plans_path = dir / \"output_plans.xml\"\niter_50 = dir / \"output_experienced_plans_ITER50.xml\"\nassert iter_50.exists()\niter_100 = dir / \"output_experienced_plans_ITER100.xml\"\nassert iter_100.exists()\niter_150 = dir / \"output_experienced_plans_ITER150.xml\"\nassert iter_150.exists()\n\n# output path\noutput_dir = Path(\"tmp\")\noutput_dir.mkdir(exist_ok=True)\nschedules_path = output_dir / \"combined.csv\"\nattributes_path = output_dir / \"attributes.csv\"\n</pre> dir = Path(\"data/matsim\")  # input paths output_plans_path = dir / \"output_plans.xml\" iter_50 = dir / \"output_experienced_plans_ITER50.xml\" assert iter_50.exists() iter_100 = dir / \"output_experienced_plans_ITER100.xml\" assert iter_100.exists() iter_150 = dir / \"output_experienced_plans_ITER150.xml\" assert iter_150.exists()  # output path output_dir = Path(\"tmp\") output_dir.mkdir(exist_ok=True) schedules_path = output_dir / \"combined.csv\" attributes_path = output_dir / \"attributes.csv\" In\u00a0[16]: Copied! <pre>streamer50 = stream_matsim_persons(\n    iter_50,\n    simplify_pt_trips=True,\n    # crop=True,\n    keep_non_selected=False,\n    leg_attributes=True,\n    leg_route=True,\n)\nstreamer100 = stream_matsim_persons(\n    iter_100,\n    simplify_pt_trips=True,\n    # crop=True,\n    keep_non_selected=False,\n    leg_attributes=True,\n    leg_route=True,\n)\nstreamer150 = stream_matsim_persons(\n    iter_150,\n    simplify_pt_trips=True,\n    # crop=True,\n    keep_non_selected=False,\n    leg_attributes=True,\n    leg_route=True,\n)\nstreamers = [streamer50, streamer100, streamer150]\n</pre> streamer50 = stream_matsim_persons(     iter_50,     simplify_pt_trips=True,     # crop=True,     keep_non_selected=False,     leg_attributes=True,     leg_route=True, ) streamer100 = stream_matsim_persons(     iter_100,     simplify_pt_trips=True,     # crop=True,     keep_non_selected=False,     leg_attributes=True,     leg_route=True, ) streamer150 = stream_matsim_persons(     iter_150,     simplify_pt_trips=True,     # crop=True,     keep_non_selected=False,     leg_attributes=True,     leg_route=True, ) streamers = [streamer50, streamer100, streamer150]  In\u00a0[17]: Copied! <pre>def dt_to_min(dt) -&gt; int:\n    h, m, s = datetime_to_matsim_time(dt).split(\":\")\n    return (int(h) * 60) + int(m)\n\n\ndef person_to_schedule(person: Person) -&gt; tuple:\n    score = person.plan.score\n    record = []\n    for component in person.plan:\n        if isinstance(component, Leg):\n            distance = component.euclidean_distance\n            mode = component.mode\n        else:\n            distance = 0\n            mode = \"NA\"\n        record.append(\n            [\n                component.act,\n                dt_to_min(component.start_time),\n                dt_to_min(component.end_time),\n                mode,\n                distance,\n                score,\n            ]\n        )\n    return person.pid, record\n\n\ndef add_data(record, pid, iteration):\n    record = [[pid, iteration] + line for line in record]\n    return record\n</pre> def dt_to_min(dt) -&gt; int:     h, m, s = datetime_to_matsim_time(dt).split(\":\")     return (int(h) * 60) + int(m)   def person_to_schedule(person: Person) -&gt; tuple:     score = person.plan.score     record = []     for component in person.plan:         if isinstance(component, Leg):             distance = component.euclidean_distance             mode = component.mode         else:             distance = 0             mode = \"NA\"         record.append(             [                 component.act,                 dt_to_min(component.start_time),                 dt_to_min(component.end_time),                 mode,                 distance,                 score,             ]         )     return person.pid, record   def add_data(record, pid, iteration):     record = [[pid, iteration] + line for line in record]     return record In\u00a0[18]: Copied! <pre>schedules = []\nuid = 0\nmapper = {}\n\nfor iteration, streamer in zip([50, 100, 150], streamers):\n    print(\"iteration: \", iteration)\n    for person in streamer:\n        pid, record = person_to_schedule(person)\n        if record:\n            mapper[uid] = pid\n            schedules.extend(add_data(record, uid, iteration))\n            uid += 1\n\nschedules = pd.DataFrame(\n    schedules,\n    columns=[\"pid\", \"iter\", \"act\", \"start\", \"end\", \"mode\", \"distance\", \"score\"],\n).set_index(\"pid\")\n</pre> schedules = [] uid = 0 mapper = {}  for iteration, streamer in zip([50, 100, 150], streamers):     print(\"iteration: \", iteration)     for person in streamer:         pid, record = person_to_schedule(person)         if record:             mapper[uid] = pid             schedules.extend(add_data(record, uid, iteration))             uid += 1  schedules = pd.DataFrame(     schedules,     columns=[\"pid\", \"iter\", \"act\", \"start\", \"end\", \"mode\", \"distance\", \"score\"], ).set_index(\"pid\") <pre>iteration:  50\niteration:  100\niteration:  150\n</pre> In\u00a0[19]: Copied! <pre>attributes = load_attributes_map_from_v12(output_plans_path)\nattributes = {k: attributes[v] for k, v in mapper.items()}\nattributes = pd.DataFrame(attributes).T\nattributes.index.name = \"pid\"\nattributes = attributes.fillna(\"unknown\")\nattributes.head()\n</pre> attributes = load_attributes_map_from_v12(output_plans_path) attributes = {k: attributes[v] for k, v in mapper.items()} attributes = pd.DataFrame(attributes).T attributes.index.name = \"pid\" attributes = attributes.fillna(\"unknown\") attributes.head() Out[19]: subpopulation age pid 0 rich yes 1 poor no 2 poor no 3 poor no 4 poor no In\u00a0[20]: Copied! <pre>schedules.to_csv(schedules_path)\nattributes.to_csv(attributes_path)\n</pre> schedules.to_csv(schedules_path) attributes.to_csv(attributes_path)"},{"location":"examples/7_matsim_seq2score/#matsim-plans-sequence-to-score","title":"MATSim Plans - Sequence to Score\u00b6","text":"<p>Demo of parsing MATSim (experienced) plans for a sequence to score model.</p> <p>MATSim plans from multiple iterations are processed into plan-scores.</p> <p>Note that this extracts plan activities and trips. Each sequence component includes duration, model and distance.</p>"},{"location":"examples/normalising_notes/","title":"Normalising for NLLLoss","text":"In\u00a0[12]: Copied! <pre>import torch\nfrom torch import Tensor, nn\nimport matplotlib.pyplot as plt\nimport numpy as np\n</pre> import torch from torch import Tensor, nn import matplotlib.pyplot as plt import numpy as np In\u00a0[13]: Copied! <pre>for n in range(1, 9):\n    o = torch.rand(128, n)\n    p = nn.Softmax(-1)(o)\n    lp = nn.LogSoftmax(-1)(o)\n    norm = np.log(n)\n    labels = torch.argmax(p, -1)\n\n    loss = nn.NLLLoss()(lp, labels)\n    nloss = loss / norm\n    print(loss, nloss)\n</pre> for n in range(1, 9):     o = torch.rand(128, n)     p = nn.Softmax(-1)(o)     lp = nn.LogSoftmax(-1)(o)     norm = np.log(n)     labels = torch.argmax(p, -1)      loss = nn.NLLLoss()(lp, labels)     nloss = loss / norm     print(loss, nloss) <pre>tensor(0.) tensor(nan)\ntensor(0.5516) tensor(0.7958)\ntensor(0.8900) tensor(0.8101)\ntensor(1.1101) tensor(0.8008)\ntensor(1.2883) tensor(0.8004)\ntensor(1.4584) tensor(0.8140)\ntensor(1.6098) tensor(0.8273)\ntensor(1.7186) tensor(0.8265)\n</pre> In\u00a0[19]: Copied! <pre>def kld(mu: Tensor, log_var: Tensor) -&gt; Tensor:\n    return torch.mean(\n        -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n    )\n</pre> def kld(mu: Tensor, log_var: Tensor) -&gt; Tensor:     return torch.mean(         -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0     ) In\u00a0[22]: Copied! <pre>for n in range(1, 9):\n    fake = torch.rand(128, 128, n)\n    mu = fake.mean(dim=0)\n    log_var = torch.log(fake.var(dim=0))\n    loss = kld(mu, log_var)\n    nloss = loss / n\n    print(loss, nloss)\n</pre> for n in range(1, 9):     fake = torch.rand(128, 128, n)     mu = fake.mean(dim=0)     log_var = torch.log(fake.var(dim=0))     loss = kld(mu, log_var)     nloss = loss / n     print(loss, nloss) <pre>tensor(0.9069) tensor(0.9069)\ntensor(1.8243) tensor(0.9121)\ntensor(2.7375) tensor(0.9125)\ntensor(3.6475) tensor(0.9119)\ntensor(4.5428) tensor(0.9086)\ntensor(5.4654) tensor(0.9109)\ntensor(6.3581) tensor(0.9083)\ntensor(7.3023) tensor(0.9128)\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/normalising_notes/#normalising-for-nllloss","title":"Normalising for NLLLoss\u00b6","text":"<p>Divide NLL by log(N), where N is the size of the choice.</p>"},{"location":"examples/normalising_notes/#normalising-for-kld","title":"Normalising for KLD\u00b6","text":""},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#unreleased","title":"Unreleased","text":""},{"location":"CHANGELOG/#fixed","title":"Fixed","text":""},{"location":"CHANGELOG/#added","title":"Added","text":""},{"location":"CHANGELOG/#changed","title":"Changed","text":""},{"location":"CHANGELOG/#removed","title":"Removed","text":""},{"location":"CHANGELOG/#v010-2023-10-04","title":"[v0.1.0] - 2023-10-04","text":"<p>Initial release.</p>"},{"location":"reference/caveat/callbacks/","title":"caveat.callbacks","text":""},{"location":"reference/caveat/callbacks/#caveat.callbacks.LinearLossScheduler","title":"<code>LinearLossScheduler(config)</code>","text":"<p>               Bases: <code>Callback</code></p> Source code in <code>caveat/callbacks.py</code> <pre><code>def __init__(self, config: dict) -&gt; None:\n    self.min_epochs = config.get(\"min_epochs\", 0)\n    self.kld_schedule = config.get(\"kld_loss_schedule\", None)\n    self.act_schedule = config.get(\"activity_loss_schedule\", None)\n    self.dur_schedule = config.get(\"duration_loss_schedule\", None)\n    self.label_schedule = config.get(\"label_loss_schedule\", None)\n    self.validate_weights_schedule(\"KLD\", self.kld_schedule)\n    self.validate_weights_schedule(\"ACT\", self.act_schedule)\n    self.validate_weights_schedule(\"DUR\", self.dur_schedule)\n    self.validate_weights_schedule(\"ATT\", self.label_schedule)\n</code></pre>"},{"location":"reference/caveat/callbacks/#caveat.callbacks.LinearLossScheduler.act_schedule","title":"<code>act_schedule = config.get('activity_loss_schedule', None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/callbacks/#caveat.callbacks.LinearLossScheduler.dur_schedule","title":"<code>dur_schedule = config.get('duration_loss_schedule', None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/callbacks/#caveat.callbacks.LinearLossScheduler.kld_schedule","title":"<code>kld_schedule = config.get('kld_loss_schedule', None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/callbacks/#caveat.callbacks.LinearLossScheduler.label_schedule","title":"<code>label_schedule = config.get('label_loss_schedule', None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/callbacks/#caveat.callbacks.LinearLossScheduler.min_epochs","title":"<code>min_epochs = config.get('min_epochs', 0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/callbacks/#caveat.callbacks.LinearLossScheduler.on_train_epoch_start","title":"<code>on_train_epoch_start(trainer, pl_module)</code>","text":"Source code in <code>caveat/callbacks.py</code> <pre><code>def on_train_epoch_start(\n    self, trainer: Trainer, pl_module: LightningModule\n) -&gt; None:\n    current_epoch = trainer.current_epoch\n    if self.kld_schedule is not None:\n        s, e = self.kld_schedule\n        if current_epoch &lt; s:\n            pl_module.scheduled_kld_weight = 0.0\n        elif current_epoch &gt;= e:\n            pl_module.scheduled_kld_weight = 1.0\n        else:\n            pl_module.scheduled_kld_weight = (current_epoch - s) / (e - s)\n    if self.act_schedule is not None:\n        s, e = self.act_schedule\n        if current_epoch &lt; s:\n            pl_module.scheduled_act_weight = 0.0\n        elif current_epoch &gt;= e:\n            pl_module.scheduled_act_weight = 1.0\n        else:\n            pl_module.scheduled_act_weight = (current_epoch - s) / (e - s)\n    if self.dur_schedule is not None:\n        s, e = self.dur_schedule\n        if current_epoch &lt; s:\n            pl_module.scheduled_dur_weight = 0.0\n        elif current_epoch &gt;= e:\n            pl_module.scheduled_dur_weight = 1.0\n        else:\n            pl_module.scheduled_dur_weight = (current_epoch - s) / (e - s)\n    if self.label_schedule is not None:\n        s, e = self.label_schedule\n        if current_epoch &lt; s:\n            pl_module.scheduled_label_weight = 0.0\n        elif current_epoch &gt;= e:\n            pl_module.scheduled_label_weight = 1.0\n        else:\n            pl_module.scheduled_label_weight = (current_epoch - s) / (e - s)\n</code></pre>"},{"location":"reference/caveat/callbacks/#caveat.callbacks.LinearLossScheduler.validate_weights_schedule","title":"<code>validate_weights_schedule(name, schedule)</code>","text":"Source code in <code>caveat/callbacks.py</code> <pre><code>def validate_weights_schedule(self, name, schedule):\n    if schedule is None:\n        return None\n    s, e = schedule\n    if s &gt; e:\n        raise ValueError(f\"Invalid schedule for {name}: {schedule}\")\n    if s &lt; 0 or e &lt; 0:\n        raise ValueError(f\"Invalid schedule for {name}: {schedule}\")\n    if e &lt; self.min_epochs:\n        print(\n            f\"WARNING: {name} schedule {schedule} ends after min_epochs {self.min_epochs}\"\n        )\n    print(\n        f\"Found {name} schedule: {s} -&gt; {e}. Check that this is ok with your epochs.\"\n    )\n</code></pre>"},{"location":"reference/caveat/data/augment/","title":"caveat.data.augment","text":""},{"location":"reference/caveat/data/augment/#caveat.data.augment.DiscreteJitter","title":"<code>DiscreteJitter(step_size, jitter=0)</code>","text":"<p>               Bases: <code>ScheduleAugment</code></p> Source code in <code>caveat/data/augment.py</code> <pre><code>def __init__(self, step_size: int, jitter: int = 0):\n\n    self.step_size = step_size\n    self.jitter = jitter\n</code></pre>"},{"location":"reference/caveat/data/augment/#caveat.data.augment.DiscreteJitter.jitter","title":"<code>jitter = jitter</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/augment/#caveat.data.augment.DiscreteJitter.step_size","title":"<code>step_size = step_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/augment/#caveat.data.augment.DiscreteSingleJitter","title":"<code>DiscreteSingleJitter(step_size, jitter=0)</code>","text":"<p>               Bases: <code>ScheduleAugment</code></p> Source code in <code>caveat/data/augment.py</code> <pre><code>def __init__(self, step_size: int, jitter: int = 0):\n\n    self.step_size = step_size\n    self.jitter = jitter\n</code></pre>"},{"location":"reference/caveat/data/augment/#caveat.data.augment.DiscreteSingleJitter.jitter","title":"<code>jitter = jitter</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/augment/#caveat.data.augment.DiscreteSingleJitter.step_size","title":"<code>step_size = step_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/augment/#caveat.data.augment.ScheduleAugment","title":"<code>ScheduleAugment()</code>","text":"Source code in <code>caveat/data/augment.py</code> <pre><code>def __init__(self) -&gt; None:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/data/augment/#caveat.data.augment.SequenceJitter","title":"<code>SequenceJitter(jitter=0.1)</code>","text":"<p>               Bases: <code>ScheduleAugment</code></p> <p>Augment a sequence by adding jitter to the duration of each activity. Note that jitter defines the maximum delay or advance of the activity duration as a proportion. But note that during normalisation of the total plan duration this can be exceeded.</p> PARAMETER DESCRIPTION <code>jitter</code> <p>activity duration maximum delta. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/data/augment.py</code> <pre><code>def __init__(self, jitter: float = 0.1):\n    \"\"\"Augment a sequence by adding jitter to the duration of each activity.\n    Note that jitter defines the maximum delay or advance of the activity duration\n    as a proportion. But note that during normalisation of the total plan duration\n    this can be exceeded.\n\n    Args:\n        jitter (float, optional): activity duration maximum delta. Defaults to 0.1.\n    \"\"\"\n    self.jitter = jitter\n</code></pre>"},{"location":"reference/caveat/data/augment/#caveat.data.augment.SequenceJitter.jitter","title":"<code>jitter = jitter</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/loaders/","title":"caveat.data.loaders","text":""},{"location":"reference/caveat/data/loaders/#caveat.data.loaders.load_and_validate_attributes","title":"<code>load_and_validate_attributes(config, schedules, verbose=True)</code>","text":"<p>Load and validate attributes data from a CSV file.</p> PARAMETER DESCRIPTION <code>config</code> <p>The configuration settings.</p> <p> TYPE: <code>dict</code> </p> <code>schedules</code> <p>The schedules data.</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: The loaded and validated attributes data.</p> RAISES DESCRIPTION <code>UserWarning</code> <p>If no attributes are found in the specified file.</p> Source code in <code>caveat/data/loaders.py</code> <pre><code>def load_and_validate_attributes(\n    config: dict, schedules: pd.DataFrame, verbose: bool = True\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Load and validate attributes data from a CSV file.\n\n    Args:\n        config (dict): The configuration settings.\n        schedules (pd.DataFrame): The schedules data.\n\n    Returns:\n        pd.DataFrame: The loaded and validated attributes data.\n\n    Raises:\n        UserWarning: If no attributes are found in the specified file.\n    \"\"\"\n    # load attributes data\n    if config.get(\"attributes_path\"):\n        data_path = Path(config[\"attributes_path\"])\n        attributes = pd.read_csv(data_path)\n        if attributes.empty:\n            raise UserWarning(f\"No attributes found in {data_path}.\")\n        schedule_pids = set(schedules.pid)\n        attribute_pids = set(attributes.pid)\n        if not schedule_pids == attribute_pids:\n            print(\n                \"&lt;!&gt; Schedules and attributes pids do not match! Attempting to fix.\"\n            )\n            intersection = schedule_pids &amp; attribute_pids\n            if not intersection:\n                raise UserWarning(\n                    \"No common pids found between schedules and attributes/labels.\"\n                )\n            if schedule_pids &gt; intersection:\n                print(\n                    f\"Removing {len(schedule_pids - intersection)} pids from schedules.\"\n                )\n                schedules = schedules.loc[schedules.pid.isin(intersection)]\n            if attribute_pids &gt; intersection:\n                print(\n                    f\"Removing {len(attribute_pids - intersection)} pids from attributes.\"\n                )\n                attributes = attributes.loc[attributes.pid.isin(intersection)]\n        validate_attributes(attributes, config)\n        validate_attributes_index(attributes, schedules)\n        if verbose:\n            print(\n                f\"Loaded {len(attributes)} attributes from {config['attributes_path']}\"\n            )\n    else:\n        attributes = None\n\n    # load synthetic attributes data\n    if attributes is not None:\n        if config.get(\"synthetic_attributes_path\"):\n            data_path = Path(config[\"synthetic_attributes_path\"])\n            synthetic_attributes = pd.read_csv(data_path)\n            if synthetic_attributes.empty:\n                raise UserWarning(\n                    f\"No synthetic attributes found in {data_path}.\"\n                )\n            validate_attributes(synthetic_attributes, config, synthetic=True)\n            if verbose:\n                print(\n                    f\"Loaded {len(synthetic_attributes)} synthetic attributes from {config['synthetic_attributes_path']}\"\n                )\n        else:\n            synthetic_attributes = attributes\n            if verbose:\n                print(\"Using input attributes as synthetic attributes\")\n\n    else:\n        synthetic_attributes = None\n\n    return attributes, synthetic_attributes\n</code></pre>"},{"location":"reference/caveat/data/loaders/#caveat.data.loaders.load_and_validate_schedules","title":"<code>load_and_validate_schedules(data_path)</code>","text":"<p>Load, prepare and validate schedules data from a CSV file.</p> PARAMETER DESCRIPTION <code>data_path</code> <p>The path to the CSV file containing the schedules data.</p> <p> TYPE: <code>Path</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: The loaded and validated schedules data.</p> RAISES DESCRIPTION <code>UserWarning</code> <p>If no data is found in the specified file.</p> Source code in <code>caveat/data/loaders.py</code> <pre><code>def load_and_validate_schedules(data_path: Path) -&gt; pd.DataFrame:\n    \"\"\"\n    Load, prepare and validate schedules data from a CSV file.\n\n    Args:\n        data_path (Path): The path to the CSV file containing the schedules data.\n\n    Returns:\n        pd.DataFrame: The loaded and validated schedules data.\n\n    Raises:\n        UserWarning: If no data is found in the specified file.\n    \"\"\"\n    data = pd.read_csv(data_path)\n    if data.empty:\n        raise UserWarning(f\"No data found in {data_path}.\")\n    validate_schedules(data)\n    data.act = data.act.astype(\"category\")\n    data.start = data.start.astype(\"int\")\n    data.end = data.end.astype(\"int\")\n    data[\"duration\"] = data.end - data.start\n    return data.sort_values(by=[\"pid\", \"start\"])\n</code></pre>"},{"location":"reference/caveat/data/loaders/#caveat.data.loaders.validate_attributes","title":"<code>validate_attributes(attributes, config, synthetic=False)</code>","text":"<p>Validate the attributes data.</p> PARAMETER DESCRIPTION <code>attributes</code> <p>The attributes data to be validated.</p> <p> TYPE: <code>DataFrame</code> </p> <code>config</code> <p>The configuration settings.</p> <p> TYPE: <code>dict</code> </p> <code>synthetic</code> <p>Whether the attributes are synthetic or not. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RAISES DESCRIPTION <code>UserWarning</code> <p>If the attributes data is missing configured conditional columns.</p> Source code in <code>caveat/data/loaders.py</code> <pre><code>def validate_attributes(\n    attributes: pd.DataFrame, config: dict, synthetic=False\n):\n    \"\"\"\n    Validate the attributes data.\n\n    Args:\n        attributes (pd.DataFrame): The attributes data to be validated.\n        config (dict): The configuration settings.\n        synthetic (bool, optional): Whether the attributes are synthetic or not. Defaults to False.\n\n    Raises:\n        UserWarning: If the attributes data is missing configured conditional columns.\n    \"\"\"\n    required_cols = set(config.get(\"conditionals\", {}).keys()) | {\"pid\"}\n    found = set(attributes.columns)\n    print(f\"Found attributes: {found}\")\n    missing = required_cols - found\n    text = \"Synthetic attributes\" if synthetic else \"Attributes\"\n    if missing:\n        raise UserWarning(\n            f\"\"\"\n    {text} data is missing configures conditional columns:\n    Required: {required_cols}.\n    Found: {found}.\n    Please add missing: {missing}.\n    \"\"\"\n        )\n</code></pre>"},{"location":"reference/caveat/data/loaders/#caveat.data.loaders.validate_attributes_index","title":"<code>validate_attributes_index(attributes, schedules)</code>","text":"<p>Sort the attributes data based on the sequence data.</p> PARAMETER DESCRIPTION <code>attributes</code> <p>The attributes data to be sorted.</p> <p> TYPE: <code>DataFrame</code> </p> <code>schedules</code> <p>The schedules data.</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: The sorted attributes data.</p> RAISES DESCRIPTION <code>UserWarning</code> <p>If the schedules and attributes pids do not match or their datatypes do not match.</p> Source code in <code>caveat/data/loaders.py</code> <pre><code>def validate_attributes_index(\n    attributes: pd.DataFrame, schedules: pd.DataFrame\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Sort the attributes data based on the sequence data.\n\n    Args:\n        attributes (pd.DataFrame): The attributes data to be sorted.\n        schedules (pd.DataFrame): The schedules data.\n\n    Returns:\n        pd.DataFrame: The sorted attributes data.\n\n    Raises:\n        UserWarning: If the schedules and attributes pids do not match or their datatypes do not match.\n    \"\"\"\n    seq_index = schedules.pid\n    attr_index = attributes.pid\n    if not seq_index.dtype == attr_index.dtype:\n        raise UserWarning(\n            \"Schedules and attributes pid datatypes do not match, this may result in 'misalignment' of schedules and attributes.\"\n        )\n    if not set(seq_index).issubset(set(attr_index)):\n        raise UserWarning(\"Schedule pids missing from attributes.\")\n    if not set(attr_index).issubset(set(seq_index)):\n        raise UserWarning(\"Attribute pids missing from schedules.\")\n</code></pre>"},{"location":"reference/caveat/data/loaders/#caveat.data.loaders.validate_schedules","title":"<code>validate_schedules(data)</code>","text":"<p>Validate the schedules data.</p> PARAMETER DESCRIPTION <code>data</code> <p>The schedules data to be validated.</p> <p> TYPE: <code>DataFrame</code> </p> RAISES DESCRIPTION <code>UserWarning</code> <p>If the input data is missing required columns.</p> Source code in <code>caveat/data/loaders.py</code> <pre><code>def validate_schedules(data: pd.DataFrame):\n    \"\"\"\n    Validate the schedules data.\n\n    Args:\n        data (pd.DataFrame): The schedules data to be validated.\n\n    Raises:\n        UserWarning: If the input data is missing required columns.\n    \"\"\"\n    required_cols = {\"pid\", \"act\", \"start\", \"end\"}\n    found = set(data.columns)\n    missing = required_cols - found\n    if missing:\n        raise UserWarning(\n            f\"\"\"\n    Input data is missing required columns.\n    Required: {required_cols}.\n    Found: {found}.\n    Please add missing: {missing}.\n    \"\"\"\n        )\n    if \"duration\" not in data.columns:\n        data[\"duration\"] = data.end - data.start\n</code></pre>"},{"location":"reference/caveat/data/module/","title":"caveat.data.module","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.ConditionalDataset","title":"<code>ConditionalDataset(attributes, latent_dim)</code>","text":"<p>               Bases: <code>Dataset</code></p> Source code in <code>caveat/data/module.py</code> <pre><code>def __init__(self, attributes: torch.Tensor, latent_dim: int):\n    self.z = torch.randn(len(attributes), latent_dim)\n    self.attributes = attributes\n</code></pre>"},{"location":"reference/caveat/data/module/#caveat.data.module.ConditionalDataset.attributes","title":"<code>attributes = attributes</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.ConditionalDataset.z","title":"<code>z = torch.randn(len(attributes), latent_dim)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.CustomGenDataset","title":"<code>CustomGenDataset(attributes, z)</code>","text":"<p>               Bases: <code>Dataset</code></p> Source code in <code>caveat/data/module.py</code> <pre><code>def __init__(self, attributes: torch.Tensor, z: torch.Tensor):\n    self.z = z\n    self.attributes = attributes\n</code></pre>"},{"location":"reference/caveat/data/module/#caveat.data.module.CustomGenDataset.attributes","title":"<code>attributes = attributes</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.CustomGenDataset.z","title":"<code>z = z</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule","title":"<code>DataModule(data, val_split=0.1, test_split=None, train_batch_size=128, val_batch_size=128, test_batch_size=128, num_workers=1, pin_memory=False, **kwargs)</code>","text":"<p>               Bases: <code>LightningDataModule</code></p> <p>Torch DataModule.</p> PARAMETER DESCRIPTION <code>data</code> <p>Data</p> <p> TYPE: <code>Dataset</code> </p> <code>val_split</code> <p>description. Defaults to None.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> <code>test_split</code> <p>description. Defaults to 0.1.</p> <p> TYPE: <code>Optional[float]</code> DEFAULT: <code>None</code> </p> <code>train_batch_size</code> <p>description. Defaults to 128.</p> <p> TYPE: <code>int</code> DEFAULT: <code>128</code> </p> <code>val_batch_size</code> <p>description. Defaults to 128.</p> <p> TYPE: <code>int</code> DEFAULT: <code>128</code> </p> <code>test_batch_size</code> <p>description. Defaults to 128.</p> <p> TYPE: <code>int</code> DEFAULT: <code>128</code> </p> <code>num_workers</code> <p>description. Defaults to 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>pin_memory</code> <p>description. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>caveat/data/module.py</code> <pre><code>def __init__(\n    self,\n    data: Dataset,\n    val_split: float = 0.1,\n    test_split: Optional[float] = None,\n    train_batch_size: int = 128,\n    val_batch_size: int = 128,\n    test_batch_size: int = 128,\n    num_workers: int = 1,\n    pin_memory: bool = False,\n    **kwargs,\n):\n    \"\"\"Torch DataModule.\n\n    Args:\n        data (Dataset): Data\n        val_split (float, optional): _description_. Defaults to None.\n        test_split (Optional[float], optional): _description_. Defaults to 0.1.\n        train_batch_size (int, optional): _description_. Defaults to 128.\n        val_batch_size (int, optional): _description_. Defaults to 128.\n        test_batch_size (int, optional): _description_. Defaults to 128.\n        num_workers (int, optional): _description_. Defaults to 0.\n        pin_memory (bool, optional): _description_. Defaults to False.\n    \"\"\"\n    super().__init__()\n\n    self.data = data\n    self.val_split = val_split\n    self.test_split = test_split\n    self.train_batch_size = train_batch_size\n    self.val_batch_size = val_batch_size\n    self.test_batch_size = test_batch_size\n    self.num_workers = num_workers\n    self.pin_memory = pin_memory\n    self.mapping = None\n</code></pre>"},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.data","title":"<code>data = data</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.mapping","title":"<code>mapping = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.num_workers","title":"<code>num_workers = num_workers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.pin_memory","title":"<code>pin_memory = pin_memory</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.test_batch_size","title":"<code>test_batch_size = test_batch_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.test_split","title":"<code>test_split = test_split</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.train_batch_size","title":"<code>train_batch_size = train_batch_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.val_batch_size","title":"<code>val_batch_size = val_batch_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.val_split","title":"<code>val_split = val_split</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.setup","title":"<code>setup(stage=None)</code>","text":"Source code in <code>caveat/data/module.py</code> <pre><code>def setup(self, stage: Optional[str] = None) -&gt; None:\n    if self.test_split is None:\n        (self.train_dataset, self.val_dataset) = (\n            torch.utils.data.random_split(\n                self.data, [1 - self.val_split, self.val_split]\n            )\n        )\n        self.test_dataset = self.val_dataset\n    else:\n        (self.train_dataset, self.val_dataset, self.test_dataset) = (\n            torch.utils.data.random_split(\n                self.data,\n                [\n                    1 - self.val_split - self.test_split,\n                    self.val_split,\n                    self.test_split,\n                ],\n            )\n        )\n</code></pre>"},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.test_dataloader","title":"<code>test_dataloader()</code>","text":"Source code in <code>caveat/data/module.py</code> <pre><code>def test_dataloader(self) -&gt; Union[DataLoader, list[DataLoader]]:\n    return DataLoader(\n        self.test_dataset,\n        batch_size=self.test_batch_size,\n        num_workers=self.num_workers,\n        shuffle=False,\n        pin_memory=self.pin_memory,\n        persistent_workers=True,\n    )\n</code></pre>"},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.train_dataloader","title":"<code>train_dataloader()</code>","text":"Source code in <code>caveat/data/module.py</code> <pre><code>def train_dataloader(self) -&gt; DataLoader:\n    return DataLoader(\n        self.train_dataset,\n        batch_size=self.train_batch_size,\n        num_workers=self.num_workers,\n        shuffle=True,\n        pin_memory=self.pin_memory,\n        persistent_workers=True,\n    )\n</code></pre>"},{"location":"reference/caveat/data/module/#caveat.data.module.DataModule.val_dataloader","title":"<code>val_dataloader()</code>","text":"Source code in <code>caveat/data/module.py</code> <pre><code>def val_dataloader(self) -&gt; Union[DataLoader, list[DataLoader]]:\n    return DataLoader(\n        self.val_dataset,\n        batch_size=self.val_batch_size,\n        num_workers=self.num_workers,\n        shuffle=False,\n        pin_memory=self.pin_memory,\n        persistent_workers=True,\n    )\n</code></pre>"},{"location":"reference/caveat/data/module/#caveat.data.module.ZDataset","title":"<code>ZDataset(num_samples, latent_dim)</code>","text":"<p>               Bases: <code>Dataset</code></p> Source code in <code>caveat/data/module.py</code> <pre><code>def __init__(self, num_samples: int, latent_dim: int):\n    self.z = torch.randn(num_samples, latent_dim)\n</code></pre>"},{"location":"reference/caveat/data/module/#caveat.data.module.ZDataset.z","title":"<code>z = torch.randn(num_samples, latent_dim)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/module/#caveat.data.module.build_custom_gen_dataloader","title":"<code>build_custom_gen_dataloader(attributes, z, batch_size=256, num_workers=4)</code>","text":"Source code in <code>caveat/data/module.py</code> <pre><code>def build_custom_gen_dataloader(\n    attributes: torch.Tensor,\n    z: torch.Tensor,\n    batch_size: int = 256,\n    num_workers: int = 4,\n):\n    print(\n        f\"Building dataloader with {len(attributes)} samples, latent_dim={len(z)}, batch_size={batch_size}, num_workers={num_workers}\"\n    )\n    return DataLoader(\n        CustomGenDataset(attributes, z),\n        batch_size=batch_size,\n        num_workers=num_workers,\n        persistent_workers=True,\n    )\n</code></pre>"},{"location":"reference/caveat/data/module/#caveat.data.module.build_latent_conditional_dataloader","title":"<code>build_latent_conditional_dataloader(attributes, latent_dim, batch_size=256, num_workers=4)</code>","text":"Source code in <code>caveat/data/module.py</code> <pre><code>def build_latent_conditional_dataloader(\n    attributes: torch.Tensor,\n    latent_dim: int,\n    batch_size: int = 256,\n    num_workers: int = 4,\n):\n    print(\n        f\"Building dataloader with {len(attributes)} samples, latent_dim={latent_dim}, batch_size={batch_size}, num_workers={num_workers}\"\n    )\n    return DataLoader(\n        ConditionalDataset(attributes, latent_dim),\n        batch_size=batch_size,\n        num_workers=num_workers,\n        persistent_workers=True,\n    )\n</code></pre>"},{"location":"reference/caveat/data/module/#caveat.data.module.build_latent_dataloader","title":"<code>build_latent_dataloader(num_samples, latent_dim, batch_size=256, num_workers=4)</code>","text":"Source code in <code>caveat/data/module.py</code> <pre><code>def build_latent_dataloader(\n    num_samples, latent_dim: int, batch_size: int = 256, num_workers: int = 4\n):\n    return DataLoader(\n        ZDataset(num_samples, latent_dim),\n        batch_size=batch_size,\n        num_workers=num_workers,\n        persistent_workers=True,\n    )\n</code></pre>"},{"location":"reference/caveat/data/nts/","title":"caveat.data.nts","text":""},{"location":"reference/caveat/data/nts/#caveat.data.nts.dt_to_min","title":"<code>dt_to_min(dt)</code>","text":"Source code in <code>caveat/data/nts.py</code> <pre><code>def dt_to_min(dt) -&gt; int:\n    h, m, s = datetime_to_matsim_time(dt).split(\":\")\n    return (int(h) * 60) + int(m)\n</code></pre>"},{"location":"reference/caveat/data/nts/#caveat.data.nts.is_home_based","title":"<code>is_home_based(plan)</code>","text":"Source code in <code>caveat/data/nts.py</code> <pre><code>def is_home_based(plan: Plan) -&gt; bool:\n    return plan[0].act == \"home\" and plan[-1].act == \"home\"\n</code></pre>"},{"location":"reference/caveat/data/nts/#caveat.data.nts.pam_to_population","title":"<code>pam_to_population(population, filter_home_based=True)</code>","text":"<p>write trace of population. Including trips.</p> Source code in <code>caveat/data/nts.py</code> <pre><code>def pam_to_population(\n    population: Population, filter_home_based: bool = True\n) -&gt; pd.DataFrame:\n    \"\"\"write trace of population. Including trips.\"\"\"\n    record = []\n    for uid, (_, _, person) in enumerate(population.people()):\n        if not filter_home_based or is_home_based(person.plan):\n            for component in person.plan:\n                if isinstance(component, Leg):\n                    act = \"trip\"\n                else:\n                    act = component.act\n                record.append(\n                    [\n                        uid,\n                        act,\n                        dt_to_min(component.start_time),\n                        dt_to_min(component.end_time),\n                    ]\n                )\n    df = pd.DataFrame(record, columns=[\"pid\", \"act\", \"start\", \"end\"])\n    df[\"duration\"] = df.end - df.start\n    return df\n</code></pre>"},{"location":"reference/caveat/data/nts/#caveat.data.nts.pam_to_population_no_trips","title":"<code>pam_to_population_no_trips(population, filter_home_based=True)</code>","text":"<p>write trace of population. Ignoring trips.</p> Source code in <code>caveat/data/nts.py</code> <pre><code>def pam_to_population_no_trips(\n    population: Population, filter_home_based: bool = True\n) -&gt; pd.DataFrame:\n    \"\"\"write trace of population. Ignoring trips.\"\"\"\n    record = []\n    for uid, (_, _, person) in enumerate(population.people()):\n        if not filter_home_based or is_home_based(person.plan):\n            for i in range(0, len(person.plan) - 1, 2):\n                record.append(\n                    [\n                        uid,\n                        person.plan[i].act,\n                        dt_to_min(person.plan[i].start_time),\n                        dt_to_min(person.plan[i + 1].end_time),\n                    ]\n                )\n            record.append(\n                [\n                    uid,\n                    person.plan[-1].act,\n                    dt_to_min(person.plan[-1].start_time),\n                    dt_to_min(person.plan[-1].end_time),\n                ]\n            )\n\n    df = pd.DataFrame(record, columns=[\"pid\", \"act\", \"start\", \"end\"])\n    df[\"duration\"] = df.end - df.start\n    return df\n</code></pre>"},{"location":"reference/caveat/data/nts/#caveat.data.nts.read_into_pam","title":"<code>read_into_pam(path, years)</code>","text":"Source code in <code>caveat/data/nts.py</code> <pre><code>def read_into_pam(path: Union[str, Path], years: list):\n    trips = pd.read_csv(\n        path,\n        sep=\"\\t\",\n        usecols=[\n            \"TripID\",\n            \"JourSeq\",\n            \"DayID\",\n            \"IndividualID\",\n            \"HouseholdID\",\n            \"MainMode_B04ID\",\n            \"TripPurpFrom_B01ID\",\n            \"TripPurpTo_B01ID\",\n            \"TripStart\",\n            \"TripEnd\",\n            \"TripOrigGOR_B02ID\",\n            \"TripDestGOR_B02ID\",\n            \"W5\",\n            \"SurveyYear\",\n        ],\n    )\n\n    trips = trips.rename(\n        columns={  # rename data\n            \"TripID\": \"tid\",\n            \"JourSeq\": \"seq\",\n            \"DayID\": \"day\",\n            \"IndividualID\": \"iid\",\n            \"HouseholdID\": \"hid\",\n            \"TripOrigGOR_B02ID\": \"ozone\",\n            \"TripDestGOR_B02ID\": \"dzone\",\n            \"TripPurpFrom_B01ID\": \"oact\",\n            \"TripPurpTo_B01ID\": \"dact\",\n            \"MainMode_B04ID\": \"mode\",\n            \"TripStart\": \"tst\",\n            \"TripEnd\": \"tet\",\n            \"W5\": \"freq\",\n            \"SurveyYear\": \"year\",\n        }\n    )\n\n    trips = trips[trips.year.isin(years)]\n\n    trips.tst = pd.to_numeric(trips.tst, errors=\"coerce\")\n    trips.tet = pd.to_numeric(trips.tet, errors=\"coerce\")\n    trips.ozone = pd.to_numeric(trips.ozone, errors=\"coerce\")\n    trips.dzone = pd.to_numeric(trips.dzone, errors=\"coerce\")\n    trips.freq = pd.to_numeric(trips.freq, errors=\"coerce\")\n\n    trips[\"did\"] = trips.groupby(\"iid\")[\"day\"].transform(\n        lambda x: pd.factorize(x)[0] + 1\n    )\n    trips[\"pid\"] = [f\"{i}-{d}\" for i, d in zip(trips.iid, trips.did)]\n\n    trips = trips.loc[\n        trips.groupby(\"pid\")\n        .filter(lambda x: pd.isnull(x).sum().sum() &lt; 1)\n        .index\n    ]\n    # travel_diaries.freq = travel_diaries.freq / travel_diaries.groupby(\"iid\").day.transform(\"nunique\")\n    trips.loc[trips.tet == 0, \"tet\"] = 1440\n\n    trips = trips.drop([\"tid\", \"iid\", \"day\", \"year\", \"did\"], axis=1)\n\n    mode_mapping = {\n        1: \"walk\",\n        2: \"bike\",\n        3: \"car\",  #'Car/van driver'\n        4: \"car\",  #'Car/van driver'\n        5: \"car\",  #'Motorcycle',\n        6: \"car\",  #'Other private transport',\n        7: \"pt\",  # Bus in London',\n        8: \"pt\",  #'Other local bus',\n        9: \"pt\",  #'Non-local bus',\n        10: \"pt\",  #'London Underground',\n        11: \"pt\",  #'Surface Rail',\n        12: \"car\",  #'Taxi/minicab',\n        13: \"pt\",  #'Other public transport',\n        -10: \"DEAD\",\n        -8: \"NA\",\n    }\n\n    purp_mapping = {\n        1: \"work\",\n        2: \"work\",  #'In course of work',\n        3: \"education\",\n        4: \"shop\",  #'Food shopping',\n        5: \"shop\",  #'Non food shopping',\n        6: \"medical\",  #'Personal business medical',\n        7: \"other\",  #'Personal business eat/drink',\n        8: \"other\",  #'Personal business other',\n        9: \"other\",  #'Eat/drink with friends',\n        10: \"visit\",  #'Visit friends',\n        11: \"other\",  #'Other social',\n        12: \"other\",  #'Entertain/ public activity',\n        13: \"other\",  #'Sport: participate',\n        14: \"home\",  #'Holiday: base',\n        15: \"other\",  #'Day trip/just walk',\n        16: \"other\",  #'Other non-escort',\n        17: \"escort\",  #'Escort home',\n        18: \"escort\",  #'Escort work',\n        19: \"escort\",  #'Escort in course of work',\n        20: \"escort\",  #'Escort education',\n        21: \"escort\",  #'Escort shopping/personal business',\n        22: \"escort\",  #'Other escort',\n        23: \"home\",  #'Home',\n        -10: \"DEAD\",\n        -8: \"NA\",\n    }\n\n    trips[\"mode\"] = trips[\"mode\"].map(mode_mapping)\n    trips[\"oact\"] = trips[\"oact\"].map(purp_mapping)\n    trips[\"dact\"] = trips[\"dact\"].map(purp_mapping)\n    trips.tst = trips.tst.astype(int)\n    trips.tet = trips.tet.astype(int)\n\n    pam_population = read.load_travel_diary(\n        trips=trips, trip_freq_as_person_freq=True\n    )\n    pam_population.fix_plans()\n    return pam_population\n</code></pre>"},{"location":"reference/caveat/data/nts/#caveat.data.nts.run","title":"<code>run()</code>","text":"Source code in <code>caveat/data/nts.py</code> <pre><code>def run():\n    # inputs\n    trips_csv = \"~/Data/UKDA-5340-tab/tab/trip_eul_2002-2021.tab\"\n    write_dir = Path(\"processed\")\n    write_dir.mkdir(exist_ok=True)\n    years = [2021]\n\n    pop = read_into_pam(trips_csv, years)\n    print(f\"Loaded to pam:\\n{pop.stats}\")\n    jobs = (\n        (pam_to_population, False, \"nts_2021.csv\"),\n        (pam_to_population, True, \"nts_2021_home_based.csv\"),\n        (pam_to_population_no_trips, False, \"nts_2021_acts.csv\"),\n        (pam_to_population_no_trips, True, \"nts_2021_acts_home_based.csv\"),\n    )\n    for f, filter_home_based, name in jobs:\n        print(f\"Filtering {name}\")\n        df = f(pop, filter_home_based)\n        print(f\"Writing {df.pid.nunique()} to {name}\")\n        write_path = write_dir / name\n        write_path.parent.mkdir(exist_ok=True)\n        df.to_csv(write_path, index=False)\n</code></pre>"},{"location":"reference/caveat/data/samplers/","title":"caveat.data.samplers","text":""},{"location":"reference/caveat/data/samplers/#caveat.data.samplers.biased_sample","title":"<code>biased_sample(data, p, threshold=20)</code>","text":"<p>Sample sequences that contain short activities according to the threshold.</p> PARAMETER DESCRIPTION <code>data</code> <p>input sequences data.</p> <p> TYPE: <code>DataFrame</code> </p> <code>p</code> <p>proportion to sample.</p> <p> TYPE: <code>float</code> </p> <code>threshold</code> <p>threshold to sample.</p> <p> TYPE: <code>int</code> DEFAULT: <code>20</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>sampled sequences.</p> Source code in <code>caveat/data/samplers.py</code> <pre><code>def biased_sample(data: DataFrame, p: float, threshold: int = 20):\n    \"\"\"\n    Sample sequences that contain short activities according to the threshold.\n\n    Args:\n        data (DataFrame): input sequences data.\n        p (float): proportion to sample.\n        threshold (int): threshold to sample.\n\n    Returns:\n        DataFrame: sampled sequences.\n    \"\"\"\n    candidates = data.groupby(\"pid\").filter(\n        lambda g: g.duration.min() &lt; threshold\n    )\n    n_samples = int(candidates.pid.nunique() * (1 - p))  # to remove\n    ids = random.sample(list(data.pid.unique()), n_samples)\n    sampled = data[~data.pid.isin(ids)]\n    return sampled\n</code></pre>"},{"location":"reference/caveat/data/samplers/#caveat.data.samplers.random_sample","title":"<code>random_sample(data, p)</code>","text":"<p>Sample a proportion of the data.</p> PARAMETER DESCRIPTION <code>data</code> <p>input sequences data.</p> <p> TYPE: <code>DataFrame</code> </p> <code>p</code> <p>proportion to sample.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>sampled sequences.</p> <p> TYPE: <code>DataFrame</code> </p> Source code in <code>caveat/data/samplers.py</code> <pre><code>def random_sample(data: DataFrame, p: float) -&gt; DataFrame:\n    \"\"\"Sample a proportion of the data.\n\n    Args:\n        data (DataFrame): input sequences data.\n        p (float): proportion to sample.\n\n    Returns:\n        DataFrame: sampled sequences.\n    \"\"\"\n\n    n_samples = int(len(data.pid.unique()) * p)\n    sample_ids = random.sample(list(data.pid.unique()), n_samples)\n    sampled = data[data.pid.isin(sample_ids)]\n    return sampled\n</code></pre>"},{"location":"reference/caveat/data/samplers/#caveat.data.samplers.sample_data","title":"<code>sample_data(sequences, attributes, config)</code>","text":"<p>Sample a proportion of the data based on sampler config.</p> PARAMETER DESCRIPTION <code>sequences</code> <p>input sequences data.</p> <p> TYPE: <code>DataFrame</code> </p> <code>attributes</code> <p>input attributes data.</p> <p> TYPE: <code>Optional[DataFrame]</code> </p> <code>config</code> <p>configuration.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>sampled sequences.</p> Source code in <code>caveat/data/samplers.py</code> <pre><code>def sample_data(\n    sequences: DataFrame, attributes: Optional[DataFrame], config: dict\n):\n    \"\"\"Sample a proportion of the data based on sampler config.\n\n    Args:\n        sequences (DataFrame): input sequences data.\n        attributes (Optional[DataFrame]): input attributes data.\n        config (dict): configuration.\n\n    Returns:\n        DataFrame: sampled sequences.\n    \"\"\"\n    sequences = sample_sequences(sequences, config)\n    if attributes is not None:\n        attributes = select_attributes(attributes, sequences.pid)\n    return sequences, attributes\n</code></pre>"},{"location":"reference/caveat/data/samplers/#caveat.data.samplers.sample_sequences","title":"<code>sample_sequences(data, config)</code>","text":"<p>Sample a proportion of the data based on sampler config.</p> PARAMETER DESCRIPTION <code>data</code> <p>input sequences data.</p> <p> TYPE: <code>DataFrame</code> </p> <code>config</code> <p>configuration.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>sampled sequences.</p> <p> TYPE: <code>DataFrame</code> </p> Source code in <code>caveat/data/samplers.py</code> <pre><code>def sample_sequences(data: DataFrame, config: dict) -&gt; DataFrame:\n    \"\"\"Sample a proportion of the data based on sampler config.\n\n    Args:\n        data (DataFrame): input sequences data.\n        config (dict): configuration.\n\n    Returns:\n        DataFrame: sampled sequences.\n    \"\"\"\n    cnfg = config.get(\"sampler_params\", {})\n    sampler = cnfg.get(\"type\")\n    if sampler in [None, \"none\", \"None\", \"NONE\", \"\"]:\n        return data\n    elif sampler == \"random\":\n        return random_sample(data, p=cnfg[\"p\"])\n    elif sampler == \"biased\":\n        return biased_sample(data, p=cnfg[\"p\"], threshold=cnfg[\"threshold\"])\n    else:\n        raise ValueError(f\"Sampler {sampler} not implemented.\")\n</code></pre>"},{"location":"reference/caveat/data/samplers/#caveat.data.samplers.select_attributes","title":"<code>select_attributes(data, idxs)</code>","text":"Source code in <code>caveat/data/samplers.py</code> <pre><code>def select_attributes(data: DataFrame, idxs: Series) -&gt; DataFrame:\n    return data.copy().set_index(\"pid\").loc[idxs.unique()].reset_index()\n</code></pre>"},{"location":"reference/caveat/data/synth/","title":"caveat.data.synth","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen","title":"<code>ActivityGen()</code>","text":"Source code in <code>caveat/data/synth.py</code> <pre><code>def __init__(self):\n    self.map = {i: s for i, s in enumerate(self.possible_states)}\n    self.steps = self.duration // self.step_size\n    self.transition_weights = None\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.duration","title":"<code>duration = 24 * 60</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.initial_state","title":"<code>initial_state = 0</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.map","title":"<code>map = {i: sfor (i, s) in enumerate(self.possible_states)}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.max_duration_sensitivity","title":"<code>max_duration_sensitivity = np.array([0.1, 0.1, 0.1, 0.1, 0.1])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.max_duration_tollerance","title":"<code>max_duration_tollerance = np.array([12 * 60, 6 * 60, 60, 360, 120])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.min_duration_sensitivity","title":"<code>min_duration_sensitivity = np.array([1.0, 1.2, 1.0, 1.2, 1.0])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.min_duration_tollerance","title":"<code>min_duration_tollerance = np.array([180, 420, 60, 120, 60])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.pivot_adjustment","title":"<code>pivot_adjustment = 60</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.possible_states","title":"<code>possible_states = ['home', 'work', 'shop', 'education', 'leisure']</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.repetition_sensitivity","title":"<code>repetition_sensitivity = np.array([1, 2, 1, 2, 1])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.repetition_tollerance","title":"<code>repetition_tollerance = np.array([10, 1, 1, 1, 2])</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.step_size","title":"<code>step_size = 15</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.steps","title":"<code>steps = self.duration // self.step_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.transition_config","title":"<code>transition_config = {'home': {'home': [(0, 100), (5, 100), (11, 0.1), (23, 100), (24, 100)], 'work': [(0, 0), (6, 0), (9, 0.2), (11, 0.1), (17, 0), (24, 0)], 'shop': [(0, 0), (6, 0), (7, 2), (11, 1), (20, 0), (24, 0)], 'education': [(0, 0), (7.5, 0), (8.5, 5), (11, 0.01), (17, 0.01), (20, 0), (24, 0)], 'leisure': [(0, 0), (6, 0), (9, 2), (16, 0.1), (22, 0), (24, 0)]}, 'work': {'home': [(0, 0), (12, 0), (13, 0.2), (16, 0.5), (17, 1), (24, 100)], 'work': [(0, 100), (12, 100), (20, 0), (24, 0)], 'shop': [(0, 0), (12, 0), (13, 0.1), (14, 0), (18, 0.1), (19, 0), (24, 0)], 'education': [(0, 0), (12, 0), (13, 0.1), (14, 0), (16, 0), (17, 0.1), (19, 0), (24, 0)], 'leisure': [(0, 0), (15, 0), (16, 0.1), (17, 0.2), (24, 0)]}, 'shop': {'home': [(0, 0.3), (23, 1), (24, 1)], 'work': [(0, 0.1), (14, 0.1), (15, 0), (24, 0)], 'shop': [(0, 10), (15, 10), (16, 0), (24, 0)], 'education': [(0, 0.1), (15, 0), (24, 0)], 'leisure': [(0, 0.2), (15, 0), (24, 0)]}, 'education': {'home': [(0, 0), (12, 0), (13, 0.2), (16, 0.1), (17, 100), (24, 100)], 'work': [(0, 0), (12, 1), (15, 0), (24, 0)], 'shop': [(0, 0), (6, 0), (7, 0.1), (11, 0.3), (23, 0), (24, 0)], 'education': [(0, 100), (12, 100), (17, 100), (18, 0), (24, 0)], 'leisure': [(0, 0), (6, 0), (9, 0.1), (16, 0.1), (17, 0), (24, 0)]}, 'leisure': {'home': [(0, 0), (12, 0), (13, 0.2), (16, 0.1), (17, 100), (24, 100)], 'work': [(0, 1), (12, 1), (23, 0), (24, 0)], 'shop': [(0, 0), (6, 0), (7, 0.1), (11, 0.3), (23, 0), (24, 0)], 'education': [(0, 0), (24, 0)], 'leisure': [(0, 100), (19, 100), (23, 0), (24, 0)]}}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.transition_weights","title":"<code>transition_weights = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.build","title":"<code>build(config=None)</code>","text":"Source code in <code>caveat/data/synth.py</code> <pre><code>def build(self, config=None):\n    if config is None:\n        config = self.transition_config\n    num_states = len(self.possible_states)\n    self.transition_weights = np.zeros((num_states, num_states, self.steps))\n    for i in range(num_states):\n        in_state = self.possible_states[i]\n        state_transitions = config[in_state]\n        for j in range(num_states):\n            out_state = self.possible_states[j]\n            pivots = state_transitions[out_state]\n            self.transition_weights[i][j] = interpolate_from_pivots(\n                pivots, self.steps, self.pivot_adjustment, self.step_size\n            )\n\n    self.transition_weights = np.transpose(\n        self.transition_weights, (0, 2, 1)\n    )  # ie [in_state, minute, out_state]\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.max_duration_adjustment","title":"<code>max_duration_adjustment(activity_durations)</code>","text":"<p>Penalise current activity based on duration.</p> PARAMETER DESCRIPTION <code>activity_durations</code> <p>activity durations</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>np.ndarray: transition factor adjustments</p> Source code in <code>caveat/data/synth.py</code> <pre><code>def max_duration_adjustment(\n    self, activity_durations: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"Penalise current activity based on duration.\n\n    Args:\n        activity_durations (np.ndarray): activity durations\n\n    Returns:\n        np.ndarray: transition factor adjustments\n    \"\"\"\n    return 1 / (\n        np.clip(\n            (activity_durations - self.max_duration_tollerance), 1, None\n        )\n        ** self.max_duration_sensitivity\n    )\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.min_duration_adjustment","title":"<code>min_duration_adjustment(activity_durations)</code>","text":"<p>Penalise current activity based on duration.</p> PARAMETER DESCRIPTION <code>activity_durations</code> <p>activity durations</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>np.ndarray: transition factor adjustments</p> Source code in <code>caveat/data/synth.py</code> <pre><code>def min_duration_adjustment(\n    self, activity_durations: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"Penalise current activity based on duration.\n\n    Args:\n        activity_durations (np.ndarray): activity durations\n\n    Returns:\n        np.ndarray: transition factor adjustments\n    \"\"\"\n    return (\n        np.clip(\n            ((self.min_duration_tollerance - activity_durations)), 1, None\n        )\n        ** self.min_duration_sensitivity\n    )\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.repeat_adjustment","title":"<code>repeat_adjustment(activity_counts)</code>","text":"<p>Penalise activities based on how often they have been done.</p> PARAMETER DESCRIPTION <code>activity_counts</code> <p>counts of activity repetitions</p> <p> TYPE: <code>ndarray</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>np.ndarray: transition factor adjustments</p> Source code in <code>caveat/data/synth.py</code> <pre><code>def repeat_adjustment(self, activity_counts: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Penalise activities based on how often they have been done.\n\n    Args:\n        activity_counts (np.ndarray): counts of activity repetitions\n\n    Returns:\n        np.ndarray: transition factor adjustments\n    \"\"\"\n    return 1 / (\n        np.clip((activity_counts - self.repetition_tollerance), 1, None)\n        ** self.repetition_sensitivity\n    )\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.run","title":"<code>run()</code>","text":"<p>summary</p> Source code in <code>caveat/data/synth.py</code> <pre><code>def run(self):\n    \"\"\"_summary_\"\"\"\n    trace = []  # [(act, start, end, dur), (act, start, end, dur), ...]\n    state = self.initial_state\n    activity_counts = np.zeros((len(self.possible_states)))\n    activity_counts[state] += 1\n    activity_durations = np.zeros((len(self.possible_states)))\n    activity_durations[state] += self.step_size\n\n    for step in range(1, self.steps):\n        p = self.transition_probabilities(\n            state, step, activity_counts, activity_durations\n        )\n        new_state = np.random.choice(len(self.possible_states), p=p)\n        if new_state != state:\n            time = step * self.step_size\n            if not trace:  # first transition\n                prev_end = 0\n            else:\n                prev_end = trace[-1][2]\n            trace.append((state, prev_end, time, time - prev_end))\n\n            # update state\n            state = new_state\n            activity_counts[state] += 1\n            activity_durations[state] = 0  # reset\n\n        activity_durations[state] += self.step_size\n\n    # close\n    prev_end = trace[-1][2]\n    trace.append((state, prev_end, self.duration, self.duration - prev_end))\n    return trace\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.ActivityGen.transition_probabilities","title":"<code>transition_probabilities(state, step, activity_counts, activity_durations)</code>","text":"Source code in <code>caveat/data/synth.py</code> <pre><code>def transition_probabilities(\n    self,\n    state,\n    step,\n    activity_counts: np.ndarray,\n    activity_durations: np.ndarray,\n):\n    p = self.transition_weights[state][step]\n    p = (\n        p\n        * self.repeat_adjustment(activity_counts)\n        * self.min_duration_adjustment(activity_durations)\n        * self.max_duration_adjustment(activity_durations)\n    )\n    return p / sum(p)\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.interpolate_from_pivots","title":"<code>interpolate_from_pivots(pivots, size=1440, pivot_adjustment=60, step_size=1)</code>","text":"<p>Create a descretised array of shape 'size' based on given 'pivots'.</p> PARAMETER DESCRIPTION <code>pivots</code> <p>description</p> <p> TYPE: <code>list[tuple[float, float]]</code> </p> <code>size</code> <p>description. Defaults to 1440</p> <p> TYPE: <code>int</code> DEFAULT: <code>1440</code> </p> <code>pivot_adjustment</code> <p>description. Defaults to 60</p> <p> TYPE: <code>int</code> DEFAULT: <code>60</code> </p> <code>step_size</code> <p>Defaults to 1</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>np.ndarray: bins</p> Source code in <code>caveat/data/synth.py</code> <pre><code>def interpolate_from_pivots(\n    pivots: list[tuple[float, float]],\n    size: int = 1440,\n    pivot_adjustment: int = 60,\n    step_size: int = 1,\n) -&gt; np.ndarray:\n    \"\"\"Create a descretised array of shape 'size' based on given 'pivots'.\n\n    Args:\n        pivots (list[tuple[float, float]]): _description_\n        size (int, optional): _description_. Defaults to 1440\n        pivot_adjustment (int, optional): _description_. Defaults to 60\n        step_size (int, optional): Defaults to 1\n\n    Returns:\n        np.ndarray: bins\n    \"\"\"\n    bins = np.zeros((size), dtype=np.float64)\n    for k in range(len(pivots) - 1):\n        a_pivot, a_value = pivots[k]\n        b_pivot, b_value = pivots[k + 1]\n        a_pivot = int(a_pivot * pivot_adjustment / step_size)\n        b_pivot = int(b_pivot * pivot_adjustment / step_size)\n        a = (a_pivot, a_value)\n        b = (b_pivot, b_value)\n        bins[slice(a_pivot, b_pivot)] = interpolate_pivot(a, b)\n    return bins\n</code></pre>"},{"location":"reference/caveat/data/synth/#caveat.data.synth.interpolate_pivot","title":"<code>interpolate_pivot(a, b)</code>","text":"Source code in <code>caveat/data/synth.py</code> <pre><code>def interpolate_pivot(a: tuple[int, float], b: tuple[int, float]) -&gt; np.ndarray:\n    a_pivot, a_value = a\n    b_pivot, b_value = b\n    return np.linspace(a_value, b_value, abs(b_pivot - a_pivot), endpoint=False)\n</code></pre>"},{"location":"reference/caveat/data/utils/","title":"caveat.data.utils","text":""},{"location":"reference/caveat/data/utils/#caveat.data.utils.gen_person","title":"<code>gen_person(gen, pid)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def gen_person(gen, pid) -&gt; pd.DataFrame:\n    trace = gen.run()\n    return trace_to_df(trace, pid=pid)\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.gen_person_conditional","title":"<code>gen_person_conditional(gens, pid)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def gen_person_conditional(gens, pid) -&gt; pd.DataFrame:\n    age = random.randint(5, 100)\n    gender = random.choice([\"M\", \"F\"])\n    employment = \"NEET\"\n    if age &lt; 18:\n        employment = \"FTE\"\n    elif age &lt; 21:\n        if random.random() &lt; 0.4:\n            employment = \"FTE\"\n        elif random.random() &lt; 0.2:\n            employment = \"PTW\"\n        elif random.random() &lt; 0.5:\n            employment = \"FTW\"\n    elif age &lt; 76:\n        p = (100 - age) / 100\n        if gender == \"F\":\n            if random.random() &lt; p / 2:\n                employment = \"FTW\"\n            if random.random() &lt; p:\n                employment = \"PTW\"\n            elif random.random() &lt; 0.1:\n                employment = \"FTE\"\n        elif gender == \"M\":\n            if random.random() &lt; p:\n                employment = \"FTW\"\n\n    if employment == \"FTW\":\n        gen = gens[0]\n    elif employment == \"PTW\":\n        gen = gens[1]\n    elif employment == \"NEET\":\n        gen = gens[2]\n    else:\n        gen = gens[3]\n\n    trace = gen.run()\n    return trace_to_df(\n        trace, pid=pid, age=age, gender=gender, employment=employment\n    )\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.gen_persons","title":"<code>gen_persons(gen, pids)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def gen_persons(gen, pids) -&gt; pd.DataFrame:\n    return pd.concat([gen_person(gen, pid) for pid in pids], ignore_index=True)\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.gen_persons_conditional","title":"<code>gen_persons_conditional(gens, pids)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def gen_persons_conditional(gens, pids) -&gt; pd.DataFrame:\n    return pd.concat(\n        [gen_person_conditional(gens, pid) for pid in pids], ignore_index=True\n    )\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.generate_population","title":"<code>generate_population(gen, size, cores=None)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def generate_population(gen, size: int, cores: int = None):\n    if cores is None:\n        cores = mp.cpu_count()\n\n    batches = list(split(range(size), cores))\n\n    pools = mp.Pool(cores)\n    results = [\n        pools.apply_async(gen_persons, args=(gen, pids)) for pids in batches\n    ]\n    pools.close()\n    pools.join()\n    results = [r.get() for r in results]\n    pop = pd.concat(results, ignore_index=True)\n    return pop\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.generate_population_conditional","title":"<code>generate_population_conditional(gens, size, cores=None)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def generate_population_conditional(gens, size: int, cores: int = None):\n    if cores is None:\n        cores = mp.cpu_count()\n    batches = list(split(range(size), cores))\n    pools = mp.Pool(cores)\n    results = [\n        pools.apply_async(gen_persons_conditional, args=(gens, pids))\n        for pids in batches\n    ]\n    pools.close()\n    pools.join()\n    results = [r.get() for r in results]\n    pop = pd.concat(results, ignore_index=True)\n    return pop\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.split","title":"<code>split(a, n)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def split(a, n):\n    k, m = divmod(len(a), n)\n    return (\n        a[i * k + min(i, m) : (i + 1) * k + min(i + 1, m)] for i in range(n)\n    )\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.trace_to_df","title":"<code>trace_to_df(trace, **kwargs)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def trace_to_df(trace: list[tuple], **kwargs) -&gt; pd.DataFrame:\n    df = pd.DataFrame(trace, columns=[\"act\", \"start\", \"end\", \"duration\"])\n    for k, v in kwargs.items():\n        df[k] = v\n    return df\n</code></pre>"},{"location":"reference/caveat/data/utils/#caveat.data.utils.trace_to_pam","title":"<code>trace_to_pam(trace, mapping)</code>","text":"Source code in <code>caveat/data/utils.py</code> <pre><code>def trace_to_pam(trace: list[tuple], mapping: dict):\n    plan = Plan()\n    for act, start, end, duration in trace:\n        name = mapping[act]\n        plan.add(Activity(act=name, start_time=mtdt(start), end_time=mtdt(end)))\n        plan.add(Trip(mode=\"car\", start_time=mtdt(end), end_time=mtdt(end)))\n    return plan\n</code></pre>"},{"location":"reference/caveat/encoding/base/","title":"caveat.encoding.base","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset","title":"<code>BaseDataset(schedules, act_weights, seq_weights, activity_encodings, activity_weights, augment, labels, label_weights, joint_weights)</code>","text":"<p>               Bases: <code>Dataset</code></p> Source code in <code>caveat/encoding/base.py</code> <pre><code>def __init__(\n    self,\n    schedules: Tensor,\n    act_weights: Optional[Tensor],\n    seq_weights: Optional[Tensor],\n    activity_encodings: int,\n    activity_weights: Optional[Tensor],\n    augment: Optional[ScheduleAugment],\n    labels: Optional[Tensor],\n    label_weights: Optional[Tensor],\n    joint_weights: Optional[Tensor],\n):\n    super(BaseDataset, self).__init__()\n    self.schedules = schedules\n    self.act_weights = act_weights\n    self.seq_weights = seq_weights\n    self.activity_encodings = activity_encodings\n    self.encoding_weights = activity_weights\n    self.augment = augment\n    self.labels = labels\n    self.label_weights = label_weights\n    self.joint_weights = joint_weights\n    self.labels_shape = labels.shape[-1] if labels is not None else None\n</code></pre>"},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.act_weights","title":"<code>act_weights = act_weights</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.activity_encodings","title":"<code>activity_encodings = activity_encodings</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.augment","title":"<code>augment = augment</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.encoding_weights","title":"<code>encoding_weights = activity_weights</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.joint_weights","title":"<code>joint_weights = joint_weights</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.label_weights","title":"<code>label_weights = label_weights</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.labels","title":"<code>labels = labels</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.labels_shape","title":"<code>labels_shape = labels.shape[-1] if labels is not None else None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.schedules","title":"<code>schedules = schedules</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.seq_weights","title":"<code>seq_weights = seq_weights</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseDataset.shape","title":"<code>shape()</code>","text":"Source code in <code>caveat/encoding/base.py</code> <pre><code>def shape(self):\n    return self.schedules[0].shape\n</code></pre>"},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseEncoder","title":"<code>BaseEncoder(schedules, **kwargs)</code>","text":"<p>               Bases: <code>ABC</code></p> Source code in <code>caveat/encoding/base.py</code> <pre><code>def __init__(self, schedules: DataFrame, **kwargs) -&gt; None:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseEncoder.decode","title":"<code>decode(schedules)</code>","text":"Source code in <code>caveat/encoding/base.py</code> <pre><code>def decode(self, schedules: Tensor) -&gt; DataFrame:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.BaseEncoder.encode","title":"<code>encode(schedules, labels, label_weights)</code>","text":"Source code in <code>caveat/encoding/base.py</code> <pre><code>def encode(\n    self,\n    schedules: DataFrame,\n    labels: Optional[Tensor],\n    label_weights: Optional[Tensor],\n) -&gt; Dataset:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset","title":"<code>LHS2RHSDataset(lhs, rhs, lhs_weights, rhs_weights, act_encodings, mode_encodings, activity_weights, augment, labels)</code>","text":"<p>               Bases: <code>Dataset</code></p> Source code in <code>caveat/encoding/base.py</code> <pre><code>def __init__(\n    self,\n    lhs: Tensor,\n    rhs: Tensor,\n    lhs_weights: Optional[Tensor],\n    rhs_weights: Optional[Tensor],\n    act_encodings: int,\n    mode_encodings: int,\n    activity_weights: Optional[Tensor],\n    augment: Optional[ScheduleAugment],\n    labels: Optional[Tensor],\n):\n    super(LHS2RHSDataset, self).__init__()\n    self.lhs = lhs\n    self.rhs = rhs\n    self.lhs_weights = lhs_weights\n    self.rhs_weights = rhs_weights\n    self.activity_encodings = (act_encodings, mode_encodings)\n    self.encoding_weights = activity_weights\n    self.augment = augment\n    self.labels = labels\n    self.labels_shape = labels.shape[-1] if labels is not None else None\n</code></pre>"},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset.activity_encodings","title":"<code>activity_encodings = (act_encodings, mode_encodings)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset.augment","title":"<code>augment = augment</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset.encoding_weights","title":"<code>encoding_weights = activity_weights</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset.labels","title":"<code>labels = labels</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset.labels_shape","title":"<code>labels_shape = labels.shape[-1] if labels is not None else None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset.lhs","title":"<code>lhs = lhs</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset.lhs_weights","title":"<code>lhs_weights = lhs_weights</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset.rhs","title":"<code>rhs = rhs</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset.rhs_weights","title":"<code>rhs_weights = rhs_weights</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.LHS2RHSDataset.shape","title":"<code>shape()</code>","text":"Source code in <code>caveat/encoding/base.py</code> <pre><code>def shape(self):\n    return self.lhs[0].shape\n</code></pre>"},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.PaddedDatatset","title":"<code>PaddedDatatset(schedules, act_weights, seq_weights, activity_encodings, activity_weights, augment, labels, label_weights, joint_weights)</code>","text":"<p>               Bases: <code>BaseDataset</code></p> Source code in <code>caveat/encoding/base.py</code> <pre><code>def __init__(\n    self,\n    schedules: Tensor,\n    act_weights: Optional[Tensor],\n    seq_weights: Optional[Tensor],\n    activity_encodings: int,\n    activity_weights: Optional[Tensor],\n    augment: Optional[ScheduleAugment],\n    labels: Optional[Tensor],\n    label_weights: Optional[Tensor],\n    joint_weights: Optional[Tensor],\n):\n    super(BaseDataset, self).__init__()\n    self.schedules = schedules\n    self.act_weights = act_weights\n    self.seq_weights = seq_weights\n    self.activity_encodings = activity_encodings\n    self.encoding_weights = activity_weights\n    self.augment = augment\n    self.labels = labels\n    self.label_weights = label_weights\n    self.joint_weights = joint_weights\n    self.labels_shape = labels.shape[-1] if labels is not None else None\n</code></pre>"},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.PaddedDatatset.shape","title":"<code>shape()</code>","text":"Source code in <code>caveat/encoding/base.py</code> <pre><code>def shape(self):\n    _, L = self.schedules.shape\n    return (L + 1,)\n</code></pre>"},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.StaggeredDataset","title":"<code>StaggeredDataset(schedules, act_weights, seq_weights, activity_encodings, activity_weights, augment, labels, label_weights, joint_weights)</code>","text":"<p>               Bases: <code>BaseDataset</code></p> Source code in <code>caveat/encoding/base.py</code> <pre><code>def __init__(\n    self,\n    schedules: Tensor,\n    act_weights: Optional[Tensor],\n    seq_weights: Optional[Tensor],\n    activity_encodings: int,\n    activity_weights: Optional[Tensor],\n    augment: Optional[ScheduleAugment],\n    labels: Optional[Tensor],\n    label_weights: Optional[Tensor],\n    joint_weights: Optional[Tensor],\n):\n    super(BaseDataset, self).__init__()\n    self.schedules = schedules\n    self.act_weights = act_weights\n    self.seq_weights = seq_weights\n    self.activity_encodings = activity_encodings\n    self.encoding_weights = activity_weights\n    self.augment = augment\n    self.labels = labels\n    self.label_weights = label_weights\n    self.joint_weights = joint_weights\n    self.labels_shape = labels.shape[-1] if labels is not None else None\n</code></pre>"},{"location":"reference/caveat/encoding/base/#caveat.encoding.base.StaggeredDataset.shape","title":"<code>shape()</code>","text":"Source code in <code>caveat/encoding/base.py</code> <pre><code>def shape(self):\n    return len(self.schedules[0]) - 1, 2\n</code></pre>"},{"location":"reference/caveat/encoding/discrete/","title":"caveat.encoding.discrete","text":""},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoder","title":"<code>DiscreteEncoder(duration=1440, step_size=10, **kwargs)</code>","text":"<p>               Bases: <code>BaseEncoder</code></p> Source code in <code>caveat/encoding/discrete.py</code> <pre><code>def __init__(self, duration: int = 1440, step_size: int = 10, **kwargs):\n    self.duration = duration\n    self.step_size = step_size\n    self.steps = duration // step_size\n    self.jitter = kwargs.get(\"jitter\", 0)\n    self.acts_to_index = None\n    print(\n        f\"DiscreteEncoder: {self.duration=}, {self.step_size=}, {self.jitter=}\"\n    )\n</code></pre>"},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoder.acts_to_index","title":"<code>acts_to_index = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoder.duration","title":"<code>duration = duration</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoder.jitter","title":"<code>jitter = kwargs.get('jitter', 0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoder.step_size","title":"<code>step_size = step_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoder.steps","title":"<code>steps = duration // step_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoder.decode","title":"<code>decode(schedules, argmax=True)</code>","text":"<p>Decode decretised a sequences ([B, C, T, A]) into DataFrame of 'traces', eg:</p> <p>pid | act | start | end</p> <p>pid is taken as sample enumeration.</p> PARAMETER DESCRIPTION <code>encoded</code> <p>description</p> <p> TYPE: <code>Tensor</code> </p> <code>mapping</code> <p>description</p> <p> TYPE: <code>dict</code> </p> <code>length</code> <p>Length of plan in minutes.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: description</p> Source code in <code>caveat/encoding/discrete.py</code> <pre><code>def decode(self, schedules: Tensor, argmax=True) -&gt; pd.DataFrame:\n    \"\"\"Decode decretised a sequences ([B, C, T, A]) into DataFrame of 'traces', eg:\n\n    pid | act | start | end\n\n    pid is taken as sample enumeration.\n\n    Args:\n        encoded (Tensor): _description_\n        mapping (dict): _description_\n        length (int): Length of plan in minutes.\n\n    Returns:\n        pd.DataFrame: _description_\n    \"\"\"\n    if argmax:\n        schedules = torch.argmax(schedules, dim=-1)\n    decoded = []\n\n    for pid in range(len(schedules)):\n        current_act = None\n        act_start = 0\n\n        for step, act_idx in enumerate(schedules[pid]):\n            if int(act_idx) != current_act and current_act is not None:\n                decoded.append(\n                    [\n                        pid,\n                        self.index_to_acts[current_act],\n                        int(act_start * self.step_size),\n                        int(step * self.step_size),\n                    ]\n                )\n                act_start = step\n            current_act = int(act_idx)\n        decoded.append(\n            [\n                pid,\n                self.index_to_acts[current_act],\n                int(act_start * self.step_size),\n                self.duration,\n            ]\n        )\n\n    return pd.DataFrame(decoded, columns=[\"pid\", \"act\", \"start\", \"end\"])\n</code></pre>"},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoder.encode","title":"<code>encode(schedules, labels, label_weights)</code>","text":"Source code in <code>caveat/encoding/discrete.py</code> <pre><code>def encode(\n    self,\n    schedules: pd.DataFrame,\n    labels: Optional[Tensor],\n    label_weights: Optional[Tensor],\n) -&gt; BaseDataset:\n    if self.acts_to_index is None:\n        self.setup_encoder(schedules)\n    return self._encode(schedules, labels, label_weights)\n</code></pre>"},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoder.setup_encoder","title":"<code>setup_encoder(schedules)</code>","text":"Source code in <code>caveat/encoding/discrete.py</code> <pre><code>def setup_encoder(self, schedules: pd.DataFrame) -&gt; None:\n    self.index_to_acts = {\n        i: a for i, a in enumerate(schedules.act.unique())\n    }\n    self.acts_to_index = {a: i for i, a in self.index_to_acts.items()}\n\n    # calc weightings\n    act_freqs = (\n        schedules.groupby(\"act\", observed=True).duration.sum().to_dict()\n    )\n    index_freqs = {self.acts_to_index[k]: v for k, v in act_freqs.items()}\n    ordered_freqs = np.array(\n        [index_freqs[k] for k in range(len(index_freqs))]\n    )\n    weights = 1 / np.log(ordered_freqs)\n    weights = (\n        weights / weights.mean()\n    )  # normalise to average 1 for each activity\n    weights = (\n        weights / self.steps\n    )  # normalise to average 1 for each activity schedule\n    self.encoding_weights = torch.from_numpy(weights).float()\n</code></pre>"},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoderPadded","title":"<code>DiscreteEncoderPadded(duration=1440, step_size=10, **kwargs)</code>","text":"<p>               Bases: <code>BaseEncoder</code></p> Source code in <code>caveat/encoding/discrete.py</code> <pre><code>def __init__(self, duration: int = 1440, step_size: int = 10, **kwargs):\n    self.duration = duration\n    self.step_size = step_size\n    self.steps = duration // step_size\n    self.jitter = kwargs.get(\"jitter\", 0)\n    print(\n        f\"DiscreteEncoderPadded: {self.duration=}, {self.step_size=}, {self.jitter=}\"\n    )\n</code></pre>"},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoderPadded.duration","title":"<code>duration = duration</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoderPadded.jitter","title":"<code>jitter = kwargs.get('jitter', 0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoderPadded.step_size","title":"<code>step_size = step_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoderPadded.steps","title":"<code>steps = duration // step_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoderPadded.decode","title":"<code>decode(schedules)</code>","text":"<p>Decode disretised a sequences ([B, C, T, A]) into DataFrame of 'traces', eg:</p> <p>pid | act | start | end</p> <p>pid is taken as sample enumeration.</p> PARAMETER DESCRIPTION <code>encoded</code> <p>description</p> <p> TYPE: <code>Tensor</code> </p> <code>mapping</code> <p>description</p> <p> TYPE: <code>dict</code> </p> <code>length</code> <p>Length of plan in minutes.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: description</p> Source code in <code>caveat/encoding/discrete.py</code> <pre><code>def decode(self, schedules: Tensor) -&gt; pd.DataFrame:\n    \"\"\"Decode disretised a sequences ([B, C, T, A]) into DataFrame of 'traces', eg:\n\n    pid | act | start | end\n\n    pid is taken as sample enumeration.\n\n    Args:\n        encoded (Tensor): _description_\n        mapping (dict): _description_\n        length (int): Length of plan in minutes.\n\n    Returns:\n        pd.DataFrame: _description_\n    \"\"\"\n    schedules = torch.argmax(schedules, dim=-1)\n    decoded = []\n\n    for pid in range(len(schedules)):\n        current_act = None\n        act_start = 0\n\n        for step, act_idx in enumerate(schedules[pid]):\n            if int(act_idx) != current_act and current_act is not None:\n                decoded.append(\n                    [\n                        pid,\n                        self.index_to_acts[current_act],\n                        int(act_start * self.step_size),\n                        int(step * self.step_size),\n                    ]\n                )\n                act_start = step\n            current_act = int(act_idx)\n\n    return pd.DataFrame(decoded, columns=[\"pid\", \"act\", \"start\", \"end\"])\n</code></pre>"},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.DiscreteEncoderPadded.encode","title":"<code>encode(schedules, conditionals)</code>","text":"Source code in <code>caveat/encoding/discrete.py</code> <pre><code>def encode(\n    self, schedules: pd.DataFrame, conditionals: Optional[Tensor]\n) -&gt; PaddedDatatset:\n    self.index_to_acts = {\n        i + 1: a for i, a in enumerate(schedules.act.unique())\n    }\n    self.index_to_acts[0] = \"&lt;PAD&gt;\"\n    acts_to_index = {a: i for i, a in self.index_to_acts.items()}\n\n    schedules = schedules.copy()\n    schedules.act = schedules.act.map(acts_to_index)\n    activity_encodings = len(acts_to_index)\n\n    # calc weightings\n    weights = (\n        schedules.groupby(\"act\", observed=True).duration.sum().to_dict()\n    )\n    weights[0] = (\n        schedules.pid.nunique() * 60\n    )  # pad weight is equal to 1 hour\n    weights = np.array([weights[k] for k in range(len(weights))])\n    activity_weights = torch.from_numpy(1 / (weights)).float()\n    encoded = discretise_population(\n        schedules, duration=self.duration, step_size=self.step_size\n    )\n    masks = torch.ones(\n        (encoded.shape[0], encoded.shape[-1] + 1), dtype=torch.int8\n    )\n\n    augment = (\n        DiscreteJitter(self.step_size, self.jitter) if self.jitter else None\n    )\n\n    return PaddedDatatset(\n        schedules=encoded.long(),\n        act_weights=masks,\n        seq_weights=torch.ones(encoded.shape[0], 1),\n        activity_encodings=activity_encodings,\n        activity_weights=activity_weights,\n        augment=augment,\n        labels=conditionals,\n        label_weights=None,\n        joint_weights=None,\n    )\n</code></pre>"},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.discretise_population","title":"<code>discretise_population(data, duration, step_size)</code>","text":"<p>Convert given population of activity traces into vector [N, L] of classes. N is the population size. L is time steps.</p> PARAMETER DESCRIPTION <code>data</code> <p>description</p> <p> TYPE: <code>DataFrame</code> </p> <code>duration</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>step_size</code> <p>description</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>torch.tensor: [N, L]</p> Source code in <code>caveat/encoding/discrete.py</code> <pre><code>def discretise_population(\n    data: pd.DataFrame, duration: int, step_size: int\n) -&gt; torch.Tensor:\n    \"\"\"Convert given population of activity traces into vector [N, L] of classes.\n    N is the population size.\n    L is time steps.\n\n    Args:\n        data (pd.DataFrame): _description_\n        duration (int): _description_\n        step_size (int): _description_\n\n    Returns:\n        torch.tensor: [N, L]\n    \"\"\"\n    persons = data.pid.nunique()\n    steps = duration // step_size\n    encoded = np.zeros((persons, steps))\n\n    for pid, (_, trace) in enumerate(data.groupby(\"pid\")):\n        trace_encoding = discretise_trace(\n            acts=trace.act, starts=trace.start, ends=trace.end, length=duration\n        )\n        trace_encoding = down_sample(trace_encoding, step_size)\n        encoded[pid] = trace_encoding  # [N, L]\n    return torch.from_numpy(encoded)\n</code></pre>"},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.discretise_trace","title":"<code>discretise_trace(acts, starts, ends, length)</code>","text":"<p>Create categorical encoding from ranges with step of 1.</p> PARAMETER DESCRIPTION <code>acts</code> <p>description</p> <p> TYPE: <code>Iterable[str]</code> </p> <code>starts</code> <p>description</p> <p> TYPE: <code>Iterable[int]</code> </p> <code>ends</code> <p>description</p> <p> TYPE: <code>Iterable[int]</code> </p> <code>length</code> <p>description</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>np.array: description</p> Source code in <code>caveat/encoding/discrete.py</code> <pre><code>def discretise_trace(\n    acts: Iterable[int], starts: Iterable[int], ends: Iterable[int], length: int\n) -&gt; np.ndarray:\n    \"\"\"Create categorical encoding from ranges with step of 1.\n\n    Args:\n        acts (Iterable[str]): _description_\n        starts (Iterable[int]): _description_\n        ends (Iterable[int]): _description_\n        length (int): _description_\n\n    Returns:\n        np.array: _description_\n    \"\"\"\n    encoding = np.zeros((length))\n    for act, start, end in zip(acts, starts, ends):\n        encoding[start:end] = act\n    return encoding\n</code></pre>"},{"location":"reference/caveat/encoding/discrete/#caveat.encoding.discrete.down_sample","title":"<code>down_sample(array, step)</code>","text":"<p>Down-sample by steppiong through given array. todo: Methodology will down sample based on first classification. If we are down sampling a lot (for example from minutes to hours), we would be better of, sampling based on majority class.</p> PARAMETER DESCRIPTION <code>array</code> <p>description</p> <p> TYPE: <code>array</code> </p> <code>step</code> <p>description</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>np.array: description</p> Source code in <code>caveat/encoding/discrete.py</code> <pre><code>def down_sample(array: np.ndarray, step: int) -&gt; np.ndarray:\n    \"\"\"Down-sample by steppiong through given array.\n    todo:\n    Methodology will down sample based on first classification.\n    If we are down sampling a lot (for example from minutes to hours),\n    we would be better of, sampling based on majority class.\n\n    Args:\n        array (np.array): _description_\n        step (int): _description_\n\n    Returns:\n        np.array: _description_\n    \"\"\"\n    return array[::step]\n</code></pre>"},{"location":"reference/caveat/encoding/one_hot/","title":"caveat.encoding.one_hot","text":""},{"location":"reference/caveat/encoding/one_hot/#caveat.encoding.one_hot.descretise_population","title":"<code>descretise_population(data, duration, step_size, class_map)</code>","text":"<p>Convert given population of activity traces into vector [P, C, H, W]. P is the population size. C (channel) is length 1. H is time steps. W is a one-hot encoding of activity type.</p> PARAMETER DESCRIPTION <code>data</code> <p>description</p> <p> TYPE: <code>DataFrame</code> </p> <code>duration</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>step_size</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>class_map</code> <p>description</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>torch.tensor: [P, C, H, W]</p> Source code in <code>caveat/encoding/one_hot.py</code> <pre><code>def descretise_population(\n    data: pd.DataFrame, duration: int, step_size: int, class_map: dict\n) -&gt; torch.Tensor:\n    \"\"\"Convert given population of activity traces into vector [P, C, H, W].\n    P is the population size.\n    C (channel) is length 1.\n    H is time steps.\n    W is a one-hot encoding of activity type.\n\n    Args:\n        data (pd.DataFrame): _description_\n        duration (int): _description_\n        step_size (int): _description_\n        class_map (dict): _description_\n\n    Returns:\n        torch.tensor: [P, C, H, W]\n    \"\"\"\n    persons = data.pid.nunique()\n    num_classes = len(class_map)\n    steps = duration // step_size\n    encoded = np.zeros((persons, steps, num_classes, 1), dtype=np.float32)\n\n    for pid, (_, trace) in enumerate(data.groupby(\"pid\")):\n        trace_encoding = descretise_trace(\n            acts=trace.act,\n            starts=trace.start,\n            ends=trace.end,\n            length=duration,\n            class_map=class_map,\n        )\n        trace_encoding = down_sample(trace_encoding, step_size)\n        trace_encoding = one_hot(trace_encoding, num_classes)\n        trace_encoding = trace_encoding.reshape(steps, num_classes, 1)\n        encoded[pid] = trace_encoding  # [B, H, W, C]\n    encoded = encoded.transpose(0, 3, 1, 2)  # [B, C, H, W]\n    return torch.from_numpy(encoded)\n</code></pre>"},{"location":"reference/caveat/encoding/one_hot/#caveat.encoding.one_hot.descretise_trace","title":"<code>descretise_trace(acts, starts, ends, length, class_map)</code>","text":"<p>Create categorical encoding from ranges with step of 1.</p> PARAMETER DESCRIPTION <code>acts</code> <p>description</p> <p> TYPE: <code>Iterable[str]</code> </p> <code>starts</code> <p>description</p> <p> TYPE: <code>Iterable[int]</code> </p> <code>ends</code> <p>description</p> <p> TYPE: <code>Iterable[int]</code> </p> <code>length</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>class_map</code> <p>description</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>np.array: description</p> Source code in <code>caveat/encoding/one_hot.py</code> <pre><code>def descretise_trace(\n    acts: Iterable[str],\n    starts: Iterable[int],\n    ends: Iterable[int],\n    length: int,\n    class_map: dict,\n) -&gt; np.ndarray:\n    \"\"\"Create categorical encoding from ranges with step of 1.\n\n    Args:\n        acts (Iterable[str]): _description_\n        starts (Iterable[int]): _description_\n        ends (Iterable[int]): _description_\n        length (int): _description_\n        class_map (dict): _description_\n\n    Returns:\n        np.array: _description_\n    \"\"\"\n    encoding = np.zeros((length), dtype=np.int8)\n    for act, start, end in zip(acts, starts, ends):\n        encoding[start:end] = class_map[act]\n    return encoding\n</code></pre>"},{"location":"reference/caveat/encoding/one_hot/#caveat.encoding.one_hot.down_sample","title":"<code>down_sample(array, step)</code>","text":"<p>Down-sample by stepping through given array. todo: Methodology will down sample based on first classification. If we are down sampling a lot (for example from minutes to hours), we would be better of, samplig based on majority class.</p> PARAMETER DESCRIPTION <code>array</code> <p>description</p> <p> TYPE: <code>array</code> </p> <code>step</code> <p>description</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>np.array: description</p> Source code in <code>caveat/encoding/one_hot.py</code> <pre><code>def down_sample(array: np.ndarray, step: int) -&gt; np.ndarray:\n    \"\"\"Down-sample by stepping through given array.\n    todo:\n    Methodology will down sample based on first classification.\n    If we are down sampling a lot (for example from minutes to hours),\n    we would be better of, samplig based on majority class.\n\n    Args:\n        array (np.array): _description_\n        step (int): _description_\n\n    Returns:\n        np.array: _description_\n    \"\"\"\n    return array[::step]\n</code></pre>"},{"location":"reference/caveat/encoding/one_hot/#caveat.encoding.one_hot.one_hot","title":"<code>one_hot(target, num_classes)</code>","text":"<p>One hot encoding of given categorical array.</p> PARAMETER DESCRIPTION <code>target</code> <p>description</p> <p> TYPE: <code>array</code> </p> <code>num_classes</code> <p>description</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>ndarray</code> <p>np.array: description</p> Source code in <code>caveat/encoding/one_hot.py</code> <pre><code>def one_hot(target: np.ndarray, num_classes: int) -&gt; np.ndarray:\n    \"\"\"One hot encoding of given categorical array.\n\n    Args:\n        target (np.array): _description_\n        num_classes (int): _description_\n\n    Returns:\n        np.array: _description_\n    \"\"\"\n    return np.eye(num_classes)[target]\n</code></pre>"},{"location":"reference/caveat/encoding/seq2score/","title":"caveat.encoding.seq2score","text":""},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder","title":"<code>Seq2ScoreEncoder(max_length=16, norm_duration=2880, **kwargs)</code>","text":"<p>               Bases: <code>BaseEncoder</code></p> Source code in <code>caveat/encoding/seq2score.py</code> <pre><code>def __init__(\n    self, max_length: int = 16, norm_duration: int = 2880, **kwargs\n):\n    self.max_length = max_length\n    self.norm_duration = norm_duration\n    self.jitter = kwargs.get(\"jitter\", 0)\n</code></pre>"},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder.jitter","title":"<code>jitter = kwargs.get('jitter', 0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder.norm_duration","title":"<code>norm_duration = norm_duration</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder.decode","title":"<code>decode(schedules)</code>","text":"<p>Decode a sequences ([N, max_length, encoding]) into DataFrame of 'traces', eg:</p> <p>pid | act | start | end</p> <p>enumeration of seq is used for pid.</p> PARAMETER DESCRIPTION <code>schedules</code> <p>description</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: description</p> Source code in <code>caveat/encoding/seq2score.py</code> <pre><code>def decode(self, schedules: Tensor) -&gt; pd.DataFrame:\n    \"\"\"Decode a sequences ([N, max_length, encoding]) into DataFrame of 'traces', eg:\n\n    pid | act | start | end\n\n    enumeration of seq is used for pid.\n\n    Args:\n        schedules (Tensor): _description_\n\n    Returns:\n        pd.DataFrame: _description_\n    \"\"\"\n    schedules = self.pack(schedules)\n    return self.to_dataframe(schedules)\n</code></pre>"},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder.decode_input","title":"<code>decode_input(schedules)</code>","text":"Source code in <code>caveat/encoding/seq2score.py</code> <pre><code>def decode_input(self, schedules: Tensor) -&gt; pd.DataFrame:\n    return self.to_dataframe(schedules)\n</code></pre>"},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder.decode_output","title":"<code>decode_output(schedules)</code>","text":"Source code in <code>caveat/encoding/seq2score.py</code> <pre><code>def decode_output(self, schedules: Tensor) -&gt; pd.DataFrame:\n    return pd.DataFrame(schedules.numpy(), columns=[\"score\"])\n</code></pre>"},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder.decode_target","title":"<code>decode_target(schedules)</code>","text":"Source code in <code>caveat/encoding/seq2score.py</code> <pre><code>def decode_target(self, schedules: Tensor) -&gt; pd.DataFrame:\n    return pd.DataFrame(schedules.numpy(), columns=[\"score\"])\n</code></pre>"},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder.encode","title":"<code>encode(schedules, labels)</code>","text":"Source code in <code>caveat/encoding/seq2score.py</code> <pre><code>def encode(\n    self, schedules: pd.DataFrame, labels: Optional[Tensor]\n) -&gt; LHS2RHSDataset:\n    # act encoding\n    self.sos = 0\n    self.eos = 1\n    acts = set(schedules.act.unique())\n    self.index_to_acts = {i + 2: a for i, a in enumerate(acts)}\n    self.index_to_acts[0] = \"&lt;SOS&gt;\"\n    self.index_to_acts[1] = \"&lt;EOS&gt;\"\n    acts_to_index = {a: i for i, a in self.index_to_acts.items()}\n\n    # mode encoding\n    modes = set(schedules[\"mode\"].unique())\n    self.index_to_modes = {i: m for i, m in enumerate(modes)}\n    self.modes_to_index = {m: i for i, m in self.index_to_modes.items()}\n\n    self.act_encodings = len(self.index_to_acts)\n    self.mode_encodings = len(self.index_to_modes)\n\n    self.max_distance = schedules.distance.max()\n\n    self.max_score = schedules.score.max()\n\n    # prepare schedules dataframe\n    schedules = schedules.copy()\n    schedules.duration = schedules.duration / self.norm_duration\n    schedules.act = schedules.act.map(acts_to_index)\n    schedules[\"mode\"] = schedules[\"mode\"].map(self.modes_to_index)\n    schedules[\"distance\"] = schedules[\"distance\"] / self.max_distance\n    schedules[\"score\"] = schedules[\"score\"] / self.max_score\n\n    # encode\n    encoded_schedules, encoded_target, masks = self._encode_sequences(\n        schedules, self.max_length\n    )\n\n    # augment\n    augment = SequenceJitter(self.jitter) if self.jitter else None\n\n    return LHS2RHSDataset(\n        lhs=encoded_schedules,\n        rhs=encoded_target,\n        lhs_weights=masks,\n        rhs_weights=masks,\n        act_encodings=len(self.index_to_acts),\n        mode_encodings=len(self.index_to_modes),\n        activity_weights=None,\n        augment=augment,\n        labels=labels,\n    )\n</code></pre>"},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder.pack","title":"<code>pack(schedules)</code>","text":"Source code in <code>caveat/encoding/seq2score.py</code> <pre><code>def pack(self, schedules: Tensor) -&gt; Tensor:\n    schedules, durations, modes, distances = torch.split(\n        schedules, [self.act_encodings, 1, self.mode_encodings, 1], dim=-1\n    )\n    schedules = schedules.argmax(dim=-1).unsqueeze(-1)\n    modes = modes.argmax(dim=-1).unsqueeze(-1)\n    return torch.cat([schedules, durations, modes, distances], dim=-1)\n</code></pre>"},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.Seq2ScoreEncoder.to_dataframe","title":"<code>to_dataframe(schedules)</code>","text":"Source code in <code>caveat/encoding/seq2score.py</code> <pre><code>def to_dataframe(self, schedules: Tensor):\n    schedules, durations, modes, distances = torch.split(\n        schedules, [1, 1, 1, 1], dim=-1\n    )\n    decoded = []\n    for pid in range(len(schedules)):\n        act_start = 0\n        for act_idx, duration, mode_idx, distance in zip(\n            schedules[pid], durations[pid], modes[pid], distances[pid]\n        ):\n            if int(act_idx) == self.sos:\n                continue\n            if int(act_idx) == self.eos:\n                break\n            duration = int(duration * self.norm_duration)\n            decoded.append(\n                [\n                    pid,\n                    self.index_to_acts[int(act_idx)],\n                    act_start,\n                    act_start + duration,\n                    self.index_to_modes[int(mode_idx)],\n                    float(distance * self.max_distance),\n                ]\n            )\n            act_start += duration\n\n    df = pd.DataFrame(\n        decoded, columns=[\"pid\", \"act\", \"start\", \"end\", \"mode\", \"distance\"]\n    )\n    df[\"duration\"] = df.end - df.start\n    return df\n</code></pre>"},{"location":"reference/caveat/encoding/seq2score/#caveat.encoding.seq2score.encode_sequences","title":"<code>encode_sequences(acts, durations, modes, distances, max_length, encoding_width, act_weights, sos, eos)</code>","text":"Source code in <code>caveat/encoding/seq2score.py</code> <pre><code>def encode_sequences(\n    acts: list[int],\n    durations: list[float],\n    modes: list[int],\n    distances: list[float],\n    max_length: int,\n    encoding_width: int,\n    act_weights: np.ndarray,\n    sos: int,\n    eos: int,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n\n    encoding = np.zeros((max_length, encoding_width), dtype=np.float32)\n    weights = np.zeros((max_length), dtype=np.float32)\n    # SOS\n    encoding[0][0] = sos\n    # mask includes sos\n    weights[0] = act_weights[sos]\n\n    for i in range(1, max_length):\n        if i &lt; len(acts) + 1:\n            encoding[i][0] = acts[i - 1]\n            encoding[i][1] = durations[i - 1]\n            encoding[i][2] = modes[i - 1]\n            encoding[i][3] = distances[i - 1]\n            weights[i] = act_weights[acts[i - 1]]\n        elif i &lt; len(acts) + 2:\n            encoding[i][0] = eos\n            # mask includes first eos\n            weights[i] = act_weights[eos]\n        else:\n            encoding[i][0] = eos\n            # act weights are 0 for padding eos\n\n    return encoding, weights\n</code></pre>"},{"location":"reference/caveat/encoding/seq2seq/","title":"caveat.encoding.seq2seq","text":""},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder","title":"<code>Seq2SeqEncoder(max_length=16, norm_duration=2880, **kwargs)</code>","text":"<p>               Bases: <code>BaseEncoder</code></p> Source code in <code>caveat/encoding/seq2seq.py</code> <pre><code>def __init__(\n    self, max_length: int = 16, norm_duration: int = 2880, **kwargs\n):\n    self.max_length = max_length\n    self.norm_duration = norm_duration\n    self.jitter = kwargs.get(\"jitter\", 0)\n</code></pre>"},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder.jitter","title":"<code>jitter = kwargs.get('jitter', 0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder.norm_duration","title":"<code>norm_duration = norm_duration</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder.decode","title":"<code>decode(schedules)</code>","text":"<p>Decode a sequences ([N, max_length, encoding]) into DataFrame of 'traces', eg:</p> <p>pid | act | start | end</p> <p>enumeration of seq is used for pid.</p> PARAMETER DESCRIPTION <code>schedules</code> <p>description</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: description</p> Source code in <code>caveat/encoding/seq2seq.py</code> <pre><code>def decode(self, schedules: Tensor) -&gt; pd.DataFrame:\n    \"\"\"Decode a sequences ([N, max_length, encoding]) into DataFrame of 'traces', eg:\n\n    pid | act | start | end\n\n    enumeration of seq is used for pid.\n\n    Args:\n        schedules (Tensor): _description_\n\n    Returns:\n        pd.DataFrame: _description_\n    \"\"\"\n    schedules = self.pack(schedules)\n    return self.to_dataframe(schedules)\n</code></pre>"},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder.decode_input","title":"<code>decode_input(schedules)</code>","text":"Source code in <code>caveat/encoding/seq2seq.py</code> <pre><code>def decode_input(self, schedules: Tensor) -&gt; pd.DataFrame:\n    return self.to_dataframe(schedules)\n</code></pre>"},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder.decode_output","title":"<code>decode_output(schedules)</code>","text":"Source code in <code>caveat/encoding/seq2seq.py</code> <pre><code>def decode_output(self, schedules: Tensor) -&gt; pd.DataFrame:\n    return self.decode(schedules)\n</code></pre>"},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder.decode_target","title":"<code>decode_target(schedules)</code>","text":"Source code in <code>caveat/encoding/seq2seq.py</code> <pre><code>def decode_target(self, schedules: Tensor) -&gt; pd.DataFrame:\n    return self.to_dataframe(schedules)\n</code></pre>"},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder.encode","title":"<code>encode(schedules, labels)</code>","text":"Source code in <code>caveat/encoding/seq2seq.py</code> <pre><code>def encode(\n    self, schedules: pd.DataFrame, labels: Optional[Tensor]\n) -&gt; LHS2RHSDataset:\n    # act encoding\n    self.sos = 0\n    self.eos = 1\n    acts = set(schedules.act.unique()) | set(schedules.target_act.unique())\n    self.index_to_acts = {i + 2: a for i, a in enumerate(acts)}\n    self.index_to_acts[0] = \"&lt;SOS&gt;\"\n    self.index_to_acts[1] = \"&lt;EOS&gt;\"\n    acts_to_index = {a: i for i, a in self.index_to_acts.items()}\n\n    # mode encoding\n    modes = set(schedules[\"mode\"].unique()) | set(\n        schedules[\"target_mode\"].unique()\n    )\n    self.index_to_modes = {i: m for i, m in enumerate(modes)}\n    self.modes_to_index = {m: i for i, m in self.index_to_modes.items()}\n\n    self.act_encodings = len(self.index_to_acts)\n    self.mode_encodings = len(self.index_to_modes)\n\n    self.max_distance = schedules.distance.max()\n\n    # prepare schedules dataframe\n    schedules = schedules.copy()\n    schedules.duration = schedules.duration / self.norm_duration\n    schedules.target_duration = (\n        schedules.target_duration / self.norm_duration\n    )\n    schedules.act = schedules.act.map(acts_to_index)\n    schedules.target_act = schedules.target_act.map(acts_to_index)\n    schedules[\"mode\"] = schedules[\"mode\"].map(self.modes_to_index)\n    schedules[\"target_mode\"] = schedules[\"target_mode\"].map(\n        self.modes_to_index\n    )\n    schedules[\"distance\"] = schedules[\"distance\"] / self.max_distance\n    schedules[\"target_distance\"] = (\n        schedules[\"target_distance\"] / self.max_distance\n    )\n\n    # encode\n    encoded_schedules, encoded_target, masks = self._encode_sequences(\n        schedules, self.max_length\n    )\n\n    # augment\n    augment = SequenceJitter(self.jitter) if self.jitter else None\n\n    return LHS2RHSDataset(\n        lhs=encoded_schedules,\n        rhs=encoded_target,\n        lhs_weights=masks,\n        rhs_weights=masks,\n        act_encodings=len(self.index_to_acts),\n        mode_encodings=len(self.index_to_modes),\n        activity_weights=None,\n        augment=augment,\n        labels=labels,\n    )\n</code></pre>"},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder.pack","title":"<code>pack(schedules)</code>","text":"Source code in <code>caveat/encoding/seq2seq.py</code> <pre><code>def pack(self, schedules: Tensor) -&gt; Tensor:\n    schedules, durations, modes, distances = torch.split(\n        schedules, [self.act_encodings, 1, self.mode_encodings, 1], dim=-1\n    )\n    schedules = schedules.argmax(dim=-1).unsqueeze(-1)\n    modes = modes.argmax(dim=-1).unsqueeze(-1)\n    return torch.cat([schedules, durations, modes, distances], dim=-1)\n</code></pre>"},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.Seq2SeqEncoder.to_dataframe","title":"<code>to_dataframe(schedules)</code>","text":"Source code in <code>caveat/encoding/seq2seq.py</code> <pre><code>def to_dataframe(self, schedules: Tensor):\n    schedules, durations, modes, distances = torch.split(\n        schedules, [1, 1, 1, 1], dim=-1\n    )\n    decoded = []\n    for pid in range(len(schedules)):\n        act_start = 0\n        for act_idx, duration, mode_idx, distance in zip(\n            schedules[pid], durations[pid], modes[pid], distances[pid]\n        ):\n            if int(act_idx) == self.sos:\n                continue\n            if int(act_idx) == self.eos:\n                break\n            duration = int(duration * self.norm_duration)\n            decoded.append(\n                [\n                    pid,\n                    self.index_to_acts[int(act_idx)],\n                    act_start,\n                    act_start + duration,\n                    self.index_to_modes[int(mode_idx)],\n                    float(distance * self.max_distance),\n                ]\n            )\n            act_start += duration\n\n    df = pd.DataFrame(\n        decoded, columns=[\"pid\", \"act\", \"start\", \"end\", \"mode\", \"distance\"]\n    )\n    df[\"duration\"] = df.end - df.start\n\n    return df\n</code></pre>"},{"location":"reference/caveat/encoding/seq2seq/#caveat.encoding.seq2seq.encode_sequences","title":"<code>encode_sequences(acts, durations, modes, distances, target_acts, target_durations, target_modes, target_distances, max_length, encoding_width, act_weights, sos, eos)</code>","text":"Source code in <code>caveat/encoding/seq2seq.py</code> <pre><code>def encode_sequences(\n    acts: list[int],\n    durations: list[float],\n    modes: list[int],\n    distances: list[float],\n    target_acts: list[int],\n    target_durations: list[float],\n    target_modes: list[int],\n    target_distances: list[float],\n    max_length: int,\n    encoding_width: int,\n    act_weights: np.ndarray,\n    sos: int,\n    eos: int,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n\n    encoding = np.zeros((max_length, encoding_width), dtype=np.float32)\n    target = np.zeros((max_length, encoding_width), dtype=np.float32)\n    weights = np.zeros((max_length), dtype=np.float32)\n    # SOS\n    encoding[0][0] = sos\n    target[0][0] = sos\n    # mask includes sos\n    weights[0] = act_weights[sos]\n\n    for i in range(1, max_length):\n        if i &lt; len(acts) + 1:\n            encoding[i][0] = acts[i - 1]\n            encoding[i][1] = durations[i - 1]\n            encoding[i][2] = modes[i - 1]\n            encoding[i][3] = distances[i - 1]\n            target[i][0] = target_acts[i - 1]\n            target[i][1] = target_durations[i - 1]\n            target[i][2] = target_modes[i - 1]\n            target[i][3] = target_distances[i - 1]\n            weights[i] = act_weights[acts[i - 1]]\n        elif i &lt; len(acts) + 2:\n            encoding[i][0] = eos\n            target[i][0] = eos\n            # mask includes first eos\n            weights[i] = act_weights[eos]\n        else:\n            encoding[i][0] = eos\n            target[i][0] = eos\n            # act weights are 0 for padding eos\n\n    return encoding, target, weights\n</code></pre>"},{"location":"reference/caveat/encoding/seq_weighting/","title":"caveat.encoding.seq_weighting","text":""},{"location":"reference/caveat/encoding/seq_weighting/#caveat.encoding.seq_weighting.act_weight_library","title":"<code>act_weight_library = {'unit': unit_weights, 'act_inverse': act_inverse_weights, 'act_dur_inverse': act_and_dur_inverse_weights}</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/encoding/seq_weighting/#caveat.encoding.seq_weighting.seq_weight_library","title":"<code>seq_weight_library = {'unit': unit_weight, 'act_inverse': seq_inverse_weight, 'act_dur_inverse': act_and_dur_inverse_weight, 'max': seq_max_weight}</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/encoding/seq_weighting/#caveat.encoding.seq_weighting.act_and_dur_inverse_weight","title":"<code>act_and_dur_inverse_weight(sequences, sos_idx=0, eos_idx=1, trim_eos=True)</code>","text":"Source code in <code>caveat/encoding/seq_weighting.py</code> <pre><code>def act_and_dur_inverse_weight(\n    sequences: Tensor, sos_idx: int = 0, eos_idx: int = 1, trim_eos: bool = True\n) -&gt; Tensor:\n    activities = sequences[:, :, 0]\n    durations = sequences[:, :, 1]\n    binned = (durations * 144).to(torch.int)  # 10 minute bins\n    combined = torch.stack([activities, binned], dim=-1)\n    _, locs, ws = torch.unique(\n        combined, dim=0, return_counts=True, return_inverse=True\n    )\n    weights = 1 / ws[locs].float()\n    weights = weights / weights.mean()\n    return weights.unsqueeze(-1)\n</code></pre>"},{"location":"reference/caveat/encoding/seq_weighting/#caveat.encoding.seq_weighting.act_and_dur_inverse_weights","title":"<code>act_and_dur_inverse_weights(sequences, sos_idx=0, eos_idx=1, trim_eos=True)</code>","text":"Source code in <code>caveat/encoding/seq_weighting.py</code> <pre><code>def act_and_dur_inverse_weights(\n    sequences: Tensor, sos_idx: int = 0, eos_idx: int = 1, trim_eos: bool = True\n) -&gt; Tensor:\n    activities = sequences[:, :, 0]\n    durations = sequences[:, :, 1]\n    binned = (durations * 144).to(torch.int)  # 10 minute bins\n    combined = torch.stack([activities, binned], dim=-1)\n    _, locs, ws = torch.unique(\n        combined.view(-1, 2), dim=0, return_counts=True, return_inverse=True\n    )\n    # set sos and eos weights\n    ws[sos_idx] = 0\n    ws[eos_idx] = 0\n    max_act_weight = ws.max()\n    ws[eos_idx] = max_act_weight\n    ws[sos_idx] = max_act_weight\n\n    weights = 1 / ws[locs]\n    weights = weights.view(sequences.shape[0], -1)\n\n    if trim_eos:\n        eos_mask = trim_eos_mask(activities, eos_idx)\n        weights = weights * eos_mask  # apply to weights\n\n    weights = weights / weights.mean()\n    return weights\n</code></pre>"},{"location":"reference/caveat/encoding/seq_weighting/#caveat.encoding.seq_weighting.act_inverse_weights","title":"<code>act_inverse_weights(sequences, sos_idx=0, eos_idx=1, trim_eos=True)</code>","text":"Source code in <code>caveat/encoding/seq_weighting.py</code> <pre><code>def act_inverse_weights(\n    sequences: Tensor, sos_idx: int = 0, eos_idx: int = 1, trim_eos: bool = True\n) -&gt; Tensor:\n    activities = sequences[:, :, 0]\n    _, locs, ws = torch.unique(\n        activities, return_counts=True, return_inverse=True\n    )\n    # set sos and eos weights\n    ws[sos_idx] = 0\n    ws[eos_idx] = 0\n    max_act_weight = ws.max()\n    ws[eos_idx] = max_act_weight\n    ws[sos_idx] = max_act_weight\n\n    weights = 1 / ws[locs].float()\n\n    if trim_eos:\n        eos_mask = trim_eos_mask(activities, eos_idx)\n        weights = weights * eos_mask  # apply to weights\n\n    weights = weights / weights.mean()\n\n    return weights\n</code></pre>"},{"location":"reference/caveat/encoding/seq_weighting/#caveat.encoding.seq_weighting.seq_inverse_weight","title":"<code>seq_inverse_weight(sequences, sos_idx=0, eos_idx=1, trim_eos=True)</code>","text":"Source code in <code>caveat/encoding/seq_weighting.py</code> <pre><code>def seq_inverse_weight(\n    sequences: Tensor, sos_idx: int = 0, eos_idx: int = 1, trim_eos: bool = True\n) -&gt; Tensor:\n    activities = sequences[:, :, 0]\n    _, locs, ws = torch.unique(\n        activities, dim=0, return_counts=True, return_inverse=True\n    )\n    weights = 1 / ws[locs].float()\n    weights = weights / weights.mean()\n    return weights.unsqueeze(-1)\n</code></pre>"},{"location":"reference/caveat/encoding/seq_weighting/#caveat.encoding.seq_weighting.seq_max_weight","title":"<code>seq_max_weight(sequences, sos_idx=0, eos_idx=1, trim_eos=True)</code>","text":"Source code in <code>caveat/encoding/seq_weighting.py</code> <pre><code>def seq_max_weight(\n    sequences: Tensor, sos_idx: int = 0, eos_idx: int = 1, trim_eos: bool = True\n) -&gt; Tensor:\n    activities = sequences[:, :, 0]\n    _, locs, ws = torch.unique(\n        activities, return_counts=True, return_inverse=True\n    )\n    # set eos weight to sos weight (ignore trailing eos)\n    ws[eos_idx] = ws[sos_idx]\n    weights = 1 / ws[locs].float()\n\n    if trim_eos:\n        eos_mask = trim_eos_mask(activities, eos_idx)\n        weights = weights * eos_mask  # apply to weights\n\n    weights = weights.max(dim=-1).values.unsqueeze(-1)\n    weights = weights / weights.mean()\n    return weights\n</code></pre>"},{"location":"reference/caveat/encoding/seq_weighting/#caveat.encoding.seq_weighting.trim_eos_mask","title":"<code>trim_eos_mask(activities, eos_idx=1)</code>","text":"Source code in <code>caveat/encoding/seq_weighting.py</code> <pre><code>def trim_eos_mask(activities: Tensor, eos_idx: int = 1) -&gt; Tensor:\n    eos_mask = activities == eos_idx\n    first_eos = eos_mask.to(torch.long).argmax(dim=-1)\n    eos_mask[torch.arange(first_eos.shape[0]), first_eos] = False\n    eos_mask = eos_mask.to(torch.float) * -1 + 1  # reverse\n    return eos_mask\n</code></pre>"},{"location":"reference/caveat/encoding/seq_weighting/#caveat.encoding.seq_weighting.unit_weight","title":"<code>unit_weight(sequences, sos_idx=0, eos_idx=1, trim_eos=True)</code>","text":"Source code in <code>caveat/encoding/seq_weighting.py</code> <pre><code>def unit_weight(\n    sequences: Tensor, sos_idx: int = 0, eos_idx: int = 1, trim_eos: bool = True\n) -&gt; Tensor:\n    B, _, _ = sequences.shape\n    return torch.ones((B, 1)).float()\n</code></pre>"},{"location":"reference/caveat/encoding/seq_weighting/#caveat.encoding.seq_weighting.unit_weights","title":"<code>unit_weights(sequences, sos_idx=0, eos_idx=1, trim_eos=True)</code>","text":"Source code in <code>caveat/encoding/seq_weighting.py</code> <pre><code>def unit_weights(\n    sequences: Tensor, sos_idx: int = 0, eos_idx: int = 1, trim_eos: bool = True\n) -&gt; Tensor:\n    B, L, _ = sequences.shape\n    weights = torch.ones((B, L)).float()\n    if trim_eos:\n        activities = sequences[:, :, 0]\n        eos_mask = trim_eos_mask(activities, eos_idx)\n        weights = weights * eos_mask  # apply to weights\n    return weights\n</code></pre>"},{"location":"reference/caveat/encoding/sequence/","title":"caveat.encoding.sequence","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder","title":"<code>SequenceEncoder(max_length=12, norm_duration=1440, **kwargs)</code>","text":"<p>               Bases: <code>BaseEncoder</code></p> <p>Sequence Encoder for sequences of activities. Also supports conditional attributes.</p> PARAMETER DESCRIPTION <code>max_length</code> <p>description. Defaults to 12.</p> <p> TYPE: <code>int</code> DEFAULT: <code>12</code> </p> <code>norm_duration</code> <p>description. Defaults to 1440.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1440</code> </p> Source code in <code>caveat/encoding/sequence.py</code> <pre><code>def __init__(\n    self, max_length: int = 12, norm_duration: int = 1440, **kwargs\n):\n    \"\"\"Sequence Encoder for sequences of activities. Also supports conditional attributes.\n\n    Args:\n        max_length (int, optional): _description_. Defaults to 12.\n        norm_duration (int, optional): _description_. Defaults to 1440.\n    \"\"\"\n    self.max_length = max_length\n    self.norm_duration = norm_duration\n    self.jitter = kwargs.get(\"jitter\", 0)\n    self.fix_durations = kwargs.get(\"fix_durations\", False)\n    self.encodings = None  # initialise as none so we can check for encoding versus re-encoding\n    self.weighting = kwargs.get(\"weighting\", \"unit\")\n    self.joint_weighting = kwargs.get(\"joint_weighting\", \"unit\")\n    self.trim_eos = kwargs.get(\"trim_eos\", True)\n\n    self.weighter = act_weight_library.get(self.weighting, None)\n    if self.weighter is None:\n        raise ValueError(\n            f\"Unknown Sequence Encoder weighting: {self.weighting}, should be one of: {act_weight_library.keys()}\"\n        )\n\n    self.joint_weighter = seq_weight_library.get(self.joint_weighting, None)\n    if self.joint_weighter is None:\n        raise ValueError(\n            f\"Unknown Sequence Encoder weighting: {self.joint_weighting}, should be one of: {seq_weight_library.keys()}\"\n        )\n\n    print(\n        f\"\"\"Sequence Encoder initialised with:\n    max_length: {self.max_length}\n    norm_duration: {self.norm_duration}\n    jitter: {self.jitter}\n    fix_durations: {self.fix_durations}\n    (act) weighting: {self.weighting}\n    (seq) joint weighting: {self.joint_weighting}\n    trim eos: {self.trim_eos}\n    \"\"\"\n    )\n</code></pre>"},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.dataset","title":"<code>dataset = BaseDataset</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.encodings","title":"<code>encodings = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.fix_durations","title":"<code>fix_durations = kwargs.get('fix_durations', False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.jitter","title":"<code>jitter = kwargs.get('jitter', 0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.joint_weighter","title":"<code>joint_weighter = seq_weight_library.get(self.joint_weighting, None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.joint_weighting","title":"<code>joint_weighting = kwargs.get('joint_weighting', 'unit')</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.norm_duration","title":"<code>norm_duration = norm_duration</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.trim_eos","title":"<code>trim_eos = kwargs.get('trim_eos', True)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.weighter","title":"<code>weighter = act_weight_library.get(self.weighting, None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.weighting","title":"<code>weighting = kwargs.get('weighting', 'unit')</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.decode","title":"<code>decode(schedules, argmax=True)</code>","text":"<p>Decode a sequences ([N, max_length, encoding]) into DataFrame of 'traces', eg:</p> <p>pid | act | start | end</p> <p>enumeration of seq is used for pid.</p> PARAMETER DESCRIPTION <code>schedules</code> <p>description</p> <p> TYPE: <code>Tensor</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: description</p> Source code in <code>caveat/encoding/sequence.py</code> <pre><code>def decode(self, schedules: Tensor, argmax=True) -&gt; pd.DataFrame:\n    \"\"\"Decode a sequences ([N, max_length, encoding]) into DataFrame of 'traces', eg:\n\n    pid | act | start | end\n\n    enumeration of seq is used for pid.\n\n    Args:\n        schedules (Tensor): _description_\n\n    Returns:\n        pd.DataFrame: _description_\n    \"\"\"\n    if argmax:\n        schedules, durations = torch.split(\n            schedules, [self.encodings, 1], dim=-1\n        )\n        schedules = schedules.argmax(dim=-1).numpy()\n    else:\n        schedules, durations = torch.split(schedules, [1, 1], dim=-1)\n\n    decoded = []\n\n    for pid in range(len(schedules)):\n        act_start = 0\n        for act_idx, duration in zip(schedules[pid], durations[pid]):\n            if int(act_idx) == self.sos:\n                continue\n            if int(act_idx) == self.eos:\n                if act_start == 0:\n                    print(f\"Failed to decode pid: {pid}\")\n                    decoded.append(\n                        [pid, \"home\", 0, 0]\n                    )  # todo: hack for empty plan\n                break\n            # denormalise incrementally preserves duration\n            duration = int(duration * self.norm_duration)\n            decoded.append(\n                [\n                    pid,\n                    self.index_to_acts[int(act_idx)],\n                    act_start,\n                    act_start + duration,\n                ]\n            )\n            act_start += duration\n\n    df = pd.DataFrame(decoded, columns=[\"pid\", \"act\", \"start\", \"end\"])\n    df[\"duration\"] = df.end - df.start\n\n    if self.fix_durations:\n        # ensure durations sum to norm duration\n        df = norm_durations(df, self.norm_duration)\n        # ensure last end time is norm duration\n        df = fix_end_durations(df, self.norm_duration)\n        df[\"duration\"] = df.end - df.start\n\n    return df\n</code></pre>"},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.encode","title":"<code>encode(schedules, labels, label_weights)</code>","text":"Source code in <code>caveat/encoding/sequence.py</code> <pre><code>def encode(\n    self,\n    schedules: pd.DataFrame,\n    labels: Optional[Tensor],\n    label_weights: Optional[Tensor],\n) -&gt; BaseDataset:\n    if labels is not None:\n        assert schedules.pid.nunique() == labels.shape[0]\n    if self.encodings is None:\n        self.setup_encoder(schedules)\n    return self._encode(schedules, labels, label_weights)\n</code></pre>"},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoder.setup_encoder","title":"<code>setup_encoder(schedules)</code>","text":"Source code in <code>caveat/encoding/sequence.py</code> <pre><code>def setup_encoder(self, schedules: pd.DataFrame) -&gt; None:\n    self.sos = 0\n    self.eos = 1\n\n    self.index_to_acts = {\n        int(i + 2): a for i, a in enumerate(schedules.act.unique())\n    }\n    self.index_to_acts[0] = \"&lt;SOS&gt;\"\n    self.index_to_acts[1] = \"&lt;EOS&gt;\"\n    self.acts_to_index = {a: i for i, a in self.index_to_acts.items()}\n\n    self.encodings = len(self.index_to_acts)\n</code></pre>"},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoderStaggered","title":"<code>SequenceEncoderStaggered(max_length=12, norm_duration=1440, **kwargs)</code>","text":"<p>               Bases: <code>SequenceEncoder</code></p> Source code in <code>caveat/encoding/sequence.py</code> <pre><code>def __init__(\n    self, max_length: int = 12, norm_duration: int = 1440, **kwargs\n):\n    \"\"\"Sequence Encoder for sequences of activities. Also supports conditional attributes.\n\n    Args:\n        max_length (int, optional): _description_. Defaults to 12.\n        norm_duration (int, optional): _description_. Defaults to 1440.\n    \"\"\"\n    self.max_length = max_length\n    self.norm_duration = norm_duration\n    self.jitter = kwargs.get(\"jitter\", 0)\n    self.fix_durations = kwargs.get(\"fix_durations\", False)\n    self.encodings = None  # initialise as none so we can check for encoding versus re-encoding\n    self.weighting = kwargs.get(\"weighting\", \"unit\")\n    self.joint_weighting = kwargs.get(\"joint_weighting\", \"unit\")\n    self.trim_eos = kwargs.get(\"trim_eos\", True)\n\n    self.weighter = act_weight_library.get(self.weighting, None)\n    if self.weighter is None:\n        raise ValueError(\n            f\"Unknown Sequence Encoder weighting: {self.weighting}, should be one of: {act_weight_library.keys()}\"\n        )\n\n    self.joint_weighter = seq_weight_library.get(self.joint_weighting, None)\n    if self.joint_weighter is None:\n        raise ValueError(\n            f\"Unknown Sequence Encoder weighting: {self.joint_weighting}, should be one of: {seq_weight_library.keys()}\"\n        )\n\n    print(\n        f\"\"\"Sequence Encoder initialised with:\n    max_length: {self.max_length}\n    norm_duration: {self.norm_duration}\n    jitter: {self.jitter}\n    fix_durations: {self.fix_durations}\n    (act) weighting: {self.weighting}\n    (seq) joint weighting: {self.joint_weighting}\n    trim eos: {self.trim_eos}\n    \"\"\"\n    )\n</code></pre>"},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.SequenceEncoderStaggered.dataset","title":"<code>dataset = StaggeredDataset</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.encode_sequence","title":"<code>encode_sequence(acts, durations, max_length, encoding_width, sos, eos)</code>","text":"<p>Create sequence encoding from ranges.</p> PARAMETER DESCRIPTION <code>acts</code> <p>description</p> <p> TYPE: <code>Iterable[int]</code> </p> <code>durations</code> <p>description</p> <p> TYPE: <code>Iterable[float]</code> </p> <code>max_length</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>encoding_width</code> <p>description</p> <p> TYPE: <code>dict</code> </p> <code>sos</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>eos</code> <p>description</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Tuple[ndarray, ndarray]</code> <p>np.ndarray: description</p> Source code in <code>caveat/encoding/sequence.py</code> <pre><code>def encode_sequence(\n    acts: list[int],\n    durations: list[float],\n    max_length: int,\n    encoding_width: int,\n    sos: int,\n    eos: int,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Create sequence encoding from ranges.\n\n    Args:\n        acts (Iterable[int]): _description_\n        durations (Iterable[float]): _description_\n        max_length (int): _description_\n        encoding_width (dict): _description_\n        sos (int): _description_\n        eos (int): _description_\n\n    Returns:\n        np.ndarray: _description_\n    \"\"\"\n    encoding = np.zeros((max_length, encoding_width), dtype=np.float32)\n    encoding[0][0] = sos\n\n    for i in range(1, max_length):\n        if i &lt; len(acts) + 1:\n            encoding[i][0] = acts[i - 1]\n            encoding[i][1] = durations[i - 1]\n        elif i &lt; len(acts) + 2:\n            encoding[i][0] = eos\n        else:\n            encoding[i][0] = eos\n\n    return encoding\n</code></pre>"},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.fix_end_durations","title":"<code>fix_end_durations(data, end_duration)</code>","text":"Source code in <code>caveat/encoding/sequence.py</code> <pre><code>def fix_end_durations(data: pd.DataFrame, end_duration: int) -&gt; pd.DataFrame:\n    data.loc[data.groupby(data.pid).tail(1).index, \"end\"] = end_duration\n    return data\n</code></pre>"},{"location":"reference/caveat/encoding/sequence/#caveat.encoding.sequence.norm_durations","title":"<code>norm_durations(data, target_duration)</code>","text":"Source code in <code>caveat/encoding/sequence.py</code> <pre><code>def norm_durations(data: pd.DataFrame, target_duration: int) -&gt; pd.DataFrame:\n    def norm_plan_durations(plan: pd.DataFrame):\n        plan_duration = plan.duration.sum()\n        if plan_duration == 0:\n            print(\"Zero duration plan found, cannot normalise\")\n            return plan\n        if plan_duration != target_duration:\n            r = target_duration / plan_duration\n            plan.duration = (plan.duration * r).astype(int)\n            accumulated = list(plan.duration.cumsum())\n            plan.start = [0] + accumulated[:-1]\n            plan.end = accumulated\n        return plan.reset_index(drop=True)\n\n    data = (\n        data.groupby(data.pid).apply(norm_plan_durations).reset_index(drop=True)\n    )\n    return data\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/features/","title":"caveat.evaluate.describe.features","text":""},{"location":"reference/caveat/evaluate/describe/features/#caveat.evaluate.describe.features.actual","title":"<code>actual(features)</code>","text":"Source code in <code>caveat/evaluate/describe/features.py</code> <pre><code>def actual(features: dict[str, float]) -&gt; Series:\n    return Series(features)\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/features/#caveat.evaluate.describe.features.average","title":"<code>average(features)</code>","text":"Source code in <code>caveat/evaluate/describe/features.py</code> <pre><code>def average(features: dict[str, tuple[ndarray, ndarray]]) -&gt; Series:\n    weighted_average = {}\n    for k, (v, w) in features.items():\n        if w.sum() &gt; 0:\n            weighted_average[k] = np.average(v, axis=0, weights=w).sum()\n        else:\n            weighted_average[k] = 0\n    return Series(weighted_average)\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/features/#caveat.evaluate.describe.features.average2d","title":"<code>average2d(features)</code>","text":"Source code in <code>caveat/evaluate/describe/features.py</code> <pre><code>def average2d(features: dict[str, tuple[ndarray, ndarray]]) -&gt; Series:\n    return Series(\n        {\n            k: np.average(v, axis=0, weights=w).sum().sum()\n            for k, (v, w) in features.items()\n            if w.sum() &gt; 0\n        }\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/features/#caveat.evaluate.describe.features.average_density","title":"<code>average_density(features)</code>","text":"Source code in <code>caveat/evaluate/describe/features.py</code> <pre><code>def average_density(features: dict[str, tuple[ndarray, ndarray]]) -&gt; Series:\n    total = sum(w.sum() for _, w in features.values())\n    return Series({k: w.sum() / total for k, (v, w) in features.items()})\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/features/#caveat.evaluate.describe.features.average_weight","title":"<code>average_weight(features)</code>","text":"Source code in <code>caveat/evaluate/describe/features.py</code> <pre><code>def average_weight(features: dict[str, tuple[ndarray, ndarray]]) -&gt; Series:\n    return Series({k: w.mean() for k, (v, w) in features.items()})\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/features/#caveat.evaluate.describe.features.feature_length","title":"<code>feature_length(features)</code>","text":"Source code in <code>caveat/evaluate/describe/features.py</code> <pre><code>def feature_length(features: dict[str, tuple[ndarray, ndarray]]) -&gt; Series:\n    return Series({k: len(v) for k, (v, w) in features.items()})\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/features/#caveat.evaluate.describe.features.feature_value","title":"<code>feature_value(features)</code>","text":"Source code in <code>caveat/evaluate/describe/features.py</code> <pre><code>def feature_value(features: dict[str, tuple[ndarray, ndarray]]) -&gt; Series:\n    return Series({k: v[0] for k, (v, w) in features.items()})\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/features/#caveat.evaluate.describe.features.feature_weight","title":"<code>feature_weight(features)</code>","text":"Source code in <code>caveat/evaluate/describe/features.py</code> <pre><code>def feature_weight(features: dict[str, tuple[ndarray, ndarray]]) -&gt; Series:\n    return Series({k: w.sum() for k, (v, w) in features.items()})\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/frequency/","title":"caveat.evaluate.describe.frequency","text":""},{"location":"reference/caveat/evaluate/describe/frequency/#caveat.evaluate.describe.frequency.frequency_plots","title":"<code>frequency_plots(observed, ys, **kwargs)</code>","text":"Source code in <code>caveat/evaluate/describe/frequency.py</code> <pre><code>def frequency_plots(\n    observed: DataFrame, ys: Optional[dict[DataFrame]], **kwargs\n):\n    if ys is None:\n        ys = dict()\n    acts = list(observed.act.value_counts(ascending=False).index)\n    class_map = {n: i for i, n in enumerate(acts)}\n\n    n_plots = len(ys) + 2\n    ratios = [1 for _ in range(n_plots)]\n    ratios[-1] = 0.3\n\n    cmap = kwargs.pop(\"cmap\", None)\n    if cmap is None:\n        cmap = plt.cm.Set3\n        colors = cmap.colors\n        factor = (len(acts) // len(colors)) + 1\n        cmap = dict(zip(acts, colors * factor))\n\n    fig, axs = plt.subplots(\n        sharex=True,\n        sharey=True,\n        nrows=1,\n        ncols=n_plots,\n        constrained_layout=True,\n        figsize=kwargs.pop(\"figsize\", (15, 4)),\n        gridspec_kw={\"width_ratios\": ratios},\n    )\n\n    name = kwargs.pop(\"observed_title\", \"Observed\")\n\n    plot_agg_acts(name, observed, class_map, ax=axs[0], legend=False, **kwargs)\n\n    # now deal with ys\n    for i, (name, y) in enumerate(ys.items()):\n        ax = axs[i + 1]\n        plot_agg_acts(name, y, class_map, ax=ax, legend=False, **kwargs)\n\n    # legend\n    elements = [Patch(facecolor=cmap[act], label=act.title()) for act in acts]\n    axs[-1].axis(\"off\")\n    axs[-1].legend(handles=elements, loc=\"center left\", frameon=False)\n\n    return fig\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/frequency/#caveat.evaluate.describe.frequency.plot_agg_acts","title":"<code>plot_agg_acts(name, population, class_map, duration=1440, step=10, ax=None, legend=True, **kwargs)</code>","text":"Source code in <code>caveat/evaluate/describe/frequency.py</code> <pre><code>def plot_agg_acts(\n    name: str,\n    population: DataFrame,\n    class_map: dict,\n    duration: int = 1440,\n    step: int = 10,\n    ax=None,\n    legend=True,\n    **kwargs,\n):\n    bins = binned_activity_density(\n        population, duration=duration, step=step, class_map=class_map\n    )\n    columns = list(class_map.keys())\n    totals = bins.sum(0)\n    sorted_cols = [x for _, x in sorted(zip(totals, columns))]\n    df = DataFrame(bins, columns=columns)[sorted_cols]\n    df.index = [\n        datetime(2021, 11, 1, 0) + timedelta(minutes=i * step)\n        for i in range(len(df.index))\n    ]\n    fig = df.plot(\n        kind=\"bar\", stacked=True, width=1, ax=ax, legend=legend, **kwargs\n    )\n    if legend:\n        ax.legend(loc=\"upper right\")\n    ax = fig.axes\n    labels = [\" \" for _ in range(len(df.index))]\n    labels[:: int(120 / step)] = [x.strftime(\"%H:%M\") for x in df.index][\n        :: int(120 / step)\n    ]\n    ax.set_xticklabels(labels)\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"bottom\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n\n    ax.set_xlabel(\"Time of day\")\n    ax.set_ylabel(\"Activity Proportion\")\n    ax.set_title(name)\n    return ax\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/times/","title":"caveat.evaluate.describe.times","text":""},{"location":"reference/caveat/evaluate/describe/times/#caveat.evaluate.describe.times.joint_time_distributions_plot","title":"<code>joint_time_distributions_plot(observed, ys, **kwargs)</code>","text":"Source code in <code>caveat/evaluate/describe/times.py</code> <pre><code>def joint_time_distributions_plot(\n    observed: DataFrame, ys: Optional[dict[DataFrame]], **kwargs\n) -&gt; Figure:\n    if ys is None:\n        ys = dict()\n    acts = list(observed.act.value_counts(ascending=False).index)\n    n_acts = len(acts)\n    rows = len(ys) + 2\n    ratios = [1 for _ in range(rows)]\n    ratios[0] = 0.2\n\n    cmaps = kwargs.pop(\"cmaps\", {})\n    legend = []\n    legend_colours = []\n\n    fig, axs = plt.subplots(\n        rows,\n        observed.act.nunique(),\n        figsize=kwargs.pop(\"figsize\", (12, 5)),\n        sharex=False,\n        sharey=False,\n        constrained_layout=True,\n        gridspec_kw={\"height_ratios\": ratios},\n    )\n\n    # deal with observed first\n    name = kwargs.pop(\"observed_title\", \"Observed\")\n\n    legend.append(name)\n    cmap = cmaps.get(0, \"Blues\")\n    lcolours = colormaps[cmap]([0, 0.5, 1])\n    legend_colours.append(lcolours[int(len(lcolours) / 2)])\n\n    _joint_time_plot(observed, axs[1], acts, cmap=cmap)\n\n    # now deal with ys\n    for i, (name, y) in enumerate(ys.items()):\n\n        legend.append(name)\n        cmap = cmaps.get(i + 1, \"Reds\")\n        lcolours = colormaps[cmap]([0, 0.5, 1])\n        legend_colours.append(lcolours[int(len(lcolours) / 2)])\n\n        _joint_time_plot(y, axs[i + 2], acts, cmap=cmap)\n\n    # xlabel on bottom row\n    for ax in axs[-1]:\n        ax.set_xlabel(\"Start times\", fontsize=8)\n        ax.set_xticks(\n            [240, 480, 720, 960, 1200, 1440],\n            labels=[\"04:00\", \"08:00\", \"12:00\", \"16:00\", \"20:00\", \"24:00\"],\n            rotation=90,\n            fontsize=8,\n        )\n\n    # acts\n    for ax, act in zip(axs[1], acts):\n        ax.set_title(act.title(), fontsize=9)\n\n    # deal with legend\n    for i in range(n_acts):\n        axs[0][i].spines[\"top\"].set_visible(False)\n        axs[0][i].spines[\"right\"].set_visible(False)\n        axs[0][i].spines[\"bottom\"].set_visible(False)\n        axs[0][i].spines[\"left\"].set_visible(False)\n        axs[0][i].set_xticks([])\n        axs[0][i].set_yticks([])\n    for ax in axs[0]:\n        ax.tick_params(axis=\"x\", which=\"both\", length=0.0)\n\n    handles = [\n        patches.Patch(color=c, label=l) for c, l in zip(legend_colours, legend)\n    ]\n    fig.legend(\n        handles=handles,\n        loc=\"upper center\",\n        fontsize=9,\n        ncol=len(ys) + 1,\n        frameon=False,\n    )\n\n    return fig\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/times/#caveat.evaluate.describe.times.times_distributions_plot","title":"<code>times_distributions_plot(observed, ys, **kwargs)</code>","text":"Source code in <code>caveat/evaluate/describe/times.py</code> <pre><code>def times_distributions_plot(\n    observed: DataFrame, ys: Optional[dict[str, DataFrame]], **kwargs\n) -&gt; Figure:\n    ratios = [1 for _ in range(4)]\n    ratios[0] = 0.2\n    fig, axs = plt.subplots(\n        4,\n        observed.act.nunique(),\n        figsize=kwargs.pop(\"figsize\", (12, 5)),\n        sharex=True,\n        sharey=False,\n        # tight_layout=True,\n        constrained_layout=True,\n        gridspec_kw={\"height_ratios\": ratios},\n    )\n    acts = list(observed.act.value_counts(ascending=False).index)\n    name = kwargs.pop(\"observed_title\", \"Observed\")\n    _times_plot(name, observed, acts, axs=axs)\n    if ys is None:\n        return fig\n    for name, y in ys.items():\n        _times_plot(name, y, acts, axs=axs)\n    for ax in axs[0]:\n        ax.tick_params(axis=\"x\", which=\"both\", length=0.0)\n    handles, labels = axs[1][0].get_legend_handles_labels()\n    fig.legend(\n        handles,\n        labels,\n        loc=\"upper center\",\n        fontsize=9,\n        ncol=len(ys) + 1,\n        frameon=False,\n    )\n    return fig\n</code></pre>"},{"location":"reference/caveat/evaluate/describe/transitions/","title":"caveat.evaluate.describe.transitions","text":""},{"location":"reference/caveat/evaluate/describe/transitions/#caveat.evaluate.describe.transitions.sequence_prob_plot","title":"<code>sequence_prob_plot(observed, ys, **kwargs)</code>","text":"Source code in <code>caveat/evaluate/describe/transitions.py</code> <pre><code>def sequence_prob_plot(\n    observed: DataFrame, ys: Optional[dict[DataFrame]], **kwargs\n) -&gt; Figure:\n    acts = list(observed.act.value_counts(ascending=False).index)\n    cmap = kwargs.pop(\"cmap\", None)\n    if cmap is None:\n        cmap = plt.cm.Set3\n        colors = cmap.colors\n        factor = (len(acts) // len(colors)) + 1\n        cmap = dict(zip(acts, colors * factor))\n\n    n_plots = len(ys) + 2\n    ratios = [1 for _ in range(n_plots)]\n    ratios[-1] = 0.3\n\n    fig, axs = plt.subplots(\n        1,\n        n_plots,\n        figsize=kwargs.pop(\"figsize\", (12, 5)),\n        sharex=True,\n        sharey=True,\n        # tight_layout=True,\n        constrained_layout=True,\n        gridspec_kw={\"width_ratios\": ratios},\n    )\n    acts = list(observed.act.value_counts(ascending=False).index)\n    name = kwargs.pop(\"observed_title\", \"Observed\")\n    _probs_plot(name, observed, ax=axs[0], cmap=cmap, ylabel=True)\n\n    if ys is None:\n        return fig\n    for i, (name, y) in enumerate(ys.items()):\n        _probs_plot(name, y, ax=axs[i + 1], cmap=cmap)\n        axs[i + 1].set_title(name)\n\n    elements = [Patch(facecolor=cmap[act], label=act.title()) for act in acts]\n    axs[-1].axis(\"off\")\n    axs[-1].legend(handles=elements, loc=\"center left\", frameon=False)\n\n    return fig\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/scalar/","title":"caveat.evaluate.distance.scalar","text":""},{"location":"reference/caveat/evaluate/distance/scalar/#caveat.evaluate.distance.scalar.abs_av_diff","title":"<code>abs_av_diff(a, b)</code>","text":"Source code in <code>caveat/evaluate/distance/scalar.py</code> <pre><code>def abs_av_diff(\n    a: tuple[np.ndarray, np.ndarray], b: tuple[np.ndarray, np.ndarray]\n) -&gt; float:\n    # TODO test this\n    # unpack\n    ak, aw = a\n    bk, bw = b\n    a_average = (ak * aw).sum() / aw.sum()\n    b_average = (bk * bw).sum() / bw.sum()\n\n    return np.abs(a_average - b_average)\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/scalar/#caveat.evaluate.distance.scalar.clamp","title":"<code>clamp(x)</code>","text":"Source code in <code>caveat/evaluate/distance/scalar.py</code> <pre><code>def clamp(x):\n    if x &gt; 1.0:\n        return 1.0\n    return x\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/scalar/#caveat.evaluate.distance.scalar.mae","title":"<code>mae(a, b)</code>","text":"Source code in <code>caveat/evaluate/distance/scalar.py</code> <pre><code>def mae(\n    a: tuple[np.ndarray, np.ndarray], b: tuple[np.ndarray, np.ndarray]\n) -&gt; float:\n    # TODO test this\n    # requires and b have same support.\n    # unpack\n    _, aw = a\n    _, bw = b\n    return (np.abs(aw - bw)).mean()\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/scalar/#caveat.evaluate.distance.scalar.mape","title":"<code>mape(a, b)</code>","text":"<p>Calculate mean average percentage error between distributions a and b.</p> <p>Clipped at 1.0.</p> PARAMETER DESCRIPTION <code>a</code> <p>Distribution a.</p> <p> TYPE: <code>tuple[ndarray, ndarray]</code> </p> <code>b</code> <p>Distribution b.</p> <p> TYPE: <code>tuple[ndarray, ndarray]</code> </p> RETURNS DESCRIPTION <code>float</code> <p>MAPE.</p> <p> TYPE: <code>float</code> </p> Source code in <code>caveat/evaluate/distance/scalar.py</code> <pre><code>def mape(\n    a: tuple[np.ndarray, np.ndarray], b: tuple[np.ndarray, np.ndarray]\n) -&gt; float:\n    \"\"\"Calculate mean average percentage error between distributions a and b.\n\n    Clipped at 1.0.\n\n    Args:\n        a (tuple[np.ndarray, np.ndarray]): Distribution a.\n        b (tuple[np.ndarray, np.ndarray]): Distribution b.\n\n    Returns:\n        float: MAPE.\n    \"\"\"\n    # TODO test this\n    # unpack\n    ak, aw = a\n    bk, bw = b\n    # calc weighted average\n    akw = (ak * aw).sum() / aw.sum()\n    bkw = (bk * bw).sum() / bw.sum()\n    diff = np.abs(akw - bkw)\n    if diff == 0:\n        return 0.0\n    if bkw == 0:\n        return clamp(diff / akw)\n    return clamp(diff / bkw)\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/scalar/#caveat.evaluate.distance.scalar.mape_scalar","title":"<code>mape_scalar(a, b)</code>","text":"Source code in <code>caveat/evaluate/distance/scalar.py</code> <pre><code>def mape_scalar(a, b):\n    return np.abs((a - b) / a).mean()\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/scalar/#caveat.evaluate.distance.scalar.mse","title":"<code>mse(a, b)</code>","text":"Source code in <code>caveat/evaluate/distance/scalar.py</code> <pre><code>def mse(\n    a: tuple[np.ndarray, np.ndarray], b: tuple[np.ndarray, np.ndarray]\n) -&gt; float:\n    # requires and b have same support.\n    # unpack\n    _, aw = a\n    _, bw = b\n    return ((aw - bw) ** 2).mean()\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/wasserstein/","title":"caveat.evaluate.distance.wasserstein","text":""},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.SinkhornDistance","title":"<code>SinkhornDistance(eps, max_iter, reduction='none')</code>","text":"<p>               Bases: <code>Module</code></p> <p>https://dfdazac.github.io/sinkhorn.html Given two empirical measures each with :math:<code>P_1</code> locations :math:<code>x\\in\\mathbb{R}^{D_1}</code> and :math:<code>P_2</code> locations :math:<code>y\\in\\mathbb{R}^{D_2}</code>, outputs an approximation of the regularized OT cost for point clouds.</p> PARAMETER DESCRIPTION <code>eps</code> <p>regularization coefficient</p> <p> TYPE: <code>float</code> </p> <code>max_iter</code> <p>maximum number of Sinkhorn iterations</p> <p> TYPE: <code>int</code> </p> <code>reduction</code> <p>Specifies the reduction to apply to the output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean': the sum of the output will be divided by the number of elements in the output, 'sum': the output will be summed. Default: 'none'</p> <p> TYPE: <code>string</code> DEFAULT: <code>'none'</code> </p> Shape <ul> <li>Input: :math:<code>(N, P_1, D_1)</code>, :math:<code>(N, P_2, D_2)</code></li> <li>Output: :math:<code>(N)</code> or :math:<code>()</code>, depending on <code>reduction</code></li> </ul> Source code in <code>caveat/evaluate/distance/wasserstein.py</code> <pre><code>def __init__(self, eps, max_iter, reduction=\"none\"):\n    super(SinkhornDistance, self).__init__()\n    self.eps = eps\n    self.max_iter = max_iter\n    self.reduction = reduction\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.SinkhornDistance.eps","title":"<code>eps = eps</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.SinkhornDistance.max_iter","title":"<code>max_iter = max_iter</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.SinkhornDistance.reduction","title":"<code>reduction = reduction</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.SinkhornDistance.M","title":"<code>M(C, u, v)</code>","text":"<p>Modified cost for logarithmic updates</p> Source code in <code>caveat/evaluate/distance/wasserstein.py</code> <pre><code>def M(self, C, u, v):\n    \"Modified cost for logarithmic updates\"\n    return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.SinkhornDistance.ave","title":"<code>ave(u, u1, tau)</code>  <code>staticmethod</code>","text":"<p>Barycenter subroutine, used by kinetic acceleration through extrapolation.</p> Source code in <code>caveat/evaluate/distance/wasserstein.py</code> <pre><code>@staticmethod\ndef ave(u, u1, tau):\n    \"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"\n    return tau * u + (1 - tau) * u1\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.SinkhornDistance.forward","title":"<code>forward(x, y)</code>","text":"Source code in <code>caveat/evaluate/distance/wasserstein.py</code> <pre><code>def forward(self, x, y):\n    # The Sinkhorn algorithm takes as input three variables :\n    print(\"calc cost matrix\")\n    C = self._cost_matrix(x, y)  # Wasserstein cost function\n    x_points = x.shape[-2]\n    y_points = y.shape[-2]\n    if x.dim() == 2:\n        batch_size = 1\n    else:\n        batch_size = x.shape[0]\n\n    # both marginals are fixed with equal weights\n    print(\"mu\")\n    mu = (\n        torch.empty(\n            batch_size, x_points, dtype=torch.float, requires_grad=False\n        )\n        .fill_(1.0 / x_points)\n        .squeeze()\n    )\n    print(\"nu\")\n    nu = (\n        torch.empty(\n            batch_size, y_points, dtype=torch.float, requires_grad=False\n        )\n        .fill_(1.0 / y_points)\n        .squeeze()\n    )\n\n    u = torch.zeros_like(mu)\n    v = torch.zeros_like(nu)\n    # To check if algorithm terminates because of threshold\n    # or max iterations reached\n    actual_nits = 0\n    # Stopping criterion\n    thresh = 1e-1\n\n    # Sinkhorn iterations\n    for i in range(self.max_iter):\n        print(i, \"start\")\n        u1 = u  # useful to check the update\n        u = (\n            self.eps\n            * (\n                torch.log(mu + 1e-8)\n                - torch.logsumexp(self.M(C, u, v), dim=-1)\n            )\n            + u\n        )\n        v = (\n            self.eps\n            * (\n                torch.log(nu + 1e-8)\n                - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)\n            )\n            + v\n        )\n        err = (u - u1).abs().sum(-1).mean()\n        print(i, err.item())\n\n        actual_nits += 1\n        if err.item() &lt; thresh:\n            print(f\"Sinkhorn converged at iteration {i}\")\n            break\n\n    U, V = u, v\n    # Transport plan pi = diag(a)*K*diag(b)\n    pi = torch.exp(self.M(C, U, V))\n    # Sinkhorn distance\n    cost = torch.sum(pi * C, dim=(-2, -1))\n\n    if self.reduction == \"mean\":\n        cost = cost.mean()\n    elif self.reduction == \"sum\":\n        cost = cost.sum()\n\n    return cost, pi, C\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.emd","title":"<code>emd(a, b)</code>","text":"Source code in <code>caveat/evaluate/distance/wasserstein.py</code> <pre><code>def emd(a: tuple[np.array, np.array], b: tuple[np.array, np.array]) -&gt; float:\n    if a[0].ndim == 1:\n        return emd1d(a, b)\n    elif a[0].ndim == 2:\n        return emd2d(a, b)\n    else:\n        raise ValueError(\"Only 1d and 2d features are supported\")\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.emd1d","title":"<code>emd1d(a, b)</code>","text":"Source code in <code>caveat/evaluate/distance/wasserstein.py</code> <pre><code>def emd1d(a: tuple[np.array, np.array], b: tuple[np.array, np.array]) -&gt; float:\n    ak, aw = a\n    bk, bw = b\n    if (\n        aw.sum() == 0\n    ):  # avoid division by zero but also has to assume distribution of just [0]\n        ak = np.array([0.0])\n        aw = np.array([1.0])\n    if bw.sum() == 0:\n        bk = np.array([0.0])\n        bw = np.array([1.0])\n    aw = aw / aw.sum()\n    bw = bw / bw.sum()\n    return emd2_1d(ak, bk, aw, bw, metric=\"cityblock\")\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.emd2d","title":"<code>emd2d(a, b)</code>","text":"Source code in <code>caveat/evaluate/distance/wasserstein.py</code> <pre><code>def emd2d(a: tuple[np.array, np.array], b: tuple[np.array, np.array]) -&gt; float:\n    ak, aw = a\n    bk, bw = b\n    aw = aw / aw.sum()\n    bw = bw / bw.sum()\n    d = dist(ak, bk, metric=\"cityblock\")\n    return emd2(aw, bw, d, check_marginals=False)\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.sinkhorn","title":"<code>sinkhorn(x, y, eps=0.01, max_iter=10, reduction=None)</code>","text":"Source code in <code>caveat/evaluate/distance/wasserstein.py</code> <pre><code>def sinkhorn(\n    x: list[list], y: list[list], eps=0.01, max_iter=10, reduction=None\n):\n    x = torch.tensor(x, dtype=torch.float)\n    y = torch.tensor(y, dtype=torch.float)\n    model = SinkhornDistance(eps=eps, max_iter=max_iter, reduction=reduction)\n    return model(x, y)[0].item()\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.sliced_wasserstein","title":"<code>sliced_wasserstein(x, y, num_proj=100)</code>","text":"<p>https://stats.stackexchange.com/questions/404775/calculate-earth-movers-distance-for-two-grayscale-images</p> Source code in <code>caveat/evaluate/distance/wasserstein.py</code> <pre><code>def sliced_wasserstein(x: list[list], y: list[list], num_proj=100):\n    \"\"\"\n    https://stats.stackexchange.com/questions/404775/calculate-earth-movers-distance-for-two-grayscale-images\n    \"\"\"\n    x = np.array(x)\n    y = np.array(y)\n    dim = x.shape[1]\n    ests = []\n    for _ in range(num_proj):\n        # sample uniformly from the unit sphere\n        dir = np.random.randn(dim)\n        dir /= np.linalg.norm(dir)\n\n        # project the data\n        x_proj = x @ dir\n        y_proj = y @ dir\n\n        # compute 1d wasserstein\n        ests.append(wasserstein_distance(x_proj, y_proj))\n    return np.mean(ests)\n</code></pre>"},{"location":"reference/caveat/evaluate/distance/wasserstein/#caveat.evaluate.distance.wasserstein.wasserstein","title":"<code>wasserstein(x, y)</code>","text":"Source code in <code>caveat/evaluate/distance/wasserstein.py</code> <pre><code>def wasserstein(x: list[list], y: list[list]):\n    return wasserstein_distance(x, y)\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/","title":"caveat.evaluate.evaluate","text":""},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.aggregate_jobs","title":"<code>aggregate_jobs = [(('agg. frequency', frequency.activity_frequencies), feature_weight, ('average freq.', average_density), ('EMD', emd))]</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.count_jobs","title":"<code>count_jobs = [(('total schedules', frequency.count_schedules), feature_value, ('count', feature_value), ('EMD', emd))]</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.participation_rate_jobs","title":"<code>participation_rate_jobs = [(('lengths', structural.sequence_lengths), feature_weight, ('length.', average), ('EMD', emd)), (('participation rate', participation.participation_rates_by_act_enum), feature_weight, ('av. rate', average), ('EMD', emd)), (('pair participation rate', participation.joint_participation_rate), feature_weight, ('av rate.', average), ('EMD', emd))]</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.sample_quality_jobs","title":"<code>sample_quality_jobs = [(('duration', structural.duration_consistency), feature_weight, ('duration', average), ('EMD', emd)), (('home based', structural.start_and_end_acts), feature_weight, ('prob.', average), ('EMD', emd))]</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.time_jobs","title":"<code>time_jobs = [(('start times', times.start_times_by_act_plan_enum), feature_weight, ('average', average), ('EMD', emd)), (('end times', times.end_times_by_act_plan_enum), feature_weight, ('average', average), ('EMD', emd)), (('durations', times.durations_by_act_plan_enum), feature_weight, ('average', average), ('EMD', emd)), (('start-durations', times.start_and_duration_by_act_bins), feature_weight, ('average', average2d), ('EMD', emd))]</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.transition_jobs","title":"<code>transition_jobs = [(('2-gram', transitions.transitions_by_act), feature_weight, ('av. rate', average), ('EMD', emd)), (('3-gram', transitions.transition_3s_by_act), feature_weight, ('av. rate', average), ('EMD', emd))]</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.add_stats","title":"<code>add_stats(data, columns)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def add_stats(data: DataFrame, columns: dict[str, DataFrame]):\n    data[\"mean\"] = data[columns].mean(axis=1)\n    data[\"std\"] = data[columns].std(axis=1)\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.defaulting_get","title":"<code>defaulting_get(features, key, default)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def defaulting_get(\n    features: dict[str, tuple[np.array, np.array]],\n    key: str,\n    default: tuple[np.array, np.array],\n):\n    feature = features.get(key)\n    if feature is None:\n        return default\n    support, weights = feature\n    if len(support) == 0:\n        return default\n    return feature\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.describe","title":"<code>describe(descriptions, distances)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def describe(\n    descriptions: DataFrame, distances: DataFrame\n) -&gt; dict[str, DataFrame]:\n    # features\n    features_descriptions = (\n        descriptions.drop(\"description\", axis=1)\n        .groupby([\"domain\", \"feature\"])\n        .apply(weighted_av)\n    )\n    features_descriptions[\"description\"] = (\n        descriptions[\"description\"].groupby([\"domain\", \"feature\"]).first()\n    )\n\n    features_distances = (\n        distances.drop(\"distance\", axis=1)\n        .groupby([\"domain\", \"feature\"])\n        .apply(distance_weighted_av)\n    )\n    features_distances[\"distance\"] = (\n        distances[\"distance\"].groupby([\"domain\", \"feature\"]).first()\n    )\n\n    # domains\n    domain_descriptions = (\n        features_descriptions.drop(\"description\", axis=1)\n        .groupby(\"domain\")\n        .mean()\n    )\n    domain_distances = (\n        features_distances.drop(\"distance\", axis=1).groupby(\"domain\").mean()\n    )\n\n    frames = {\n        \"descriptions\": descriptions,\n        \"feature_descriptions\": features_descriptions,\n        \"domain_descriptions\": domain_descriptions,\n        \"distances\": distances,\n        \"feature_distances\": features_distances,\n        \"domain_distances\": domain_distances,\n    }\n    return frames\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.describe_feature","title":"<code>describe_feature(model, features, describe)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def describe_feature(\n    model: str,\n    features: dict[str, tuple[np.array, np.array]],\n    describe: Callable,\n):\n    feature_description = describe(features)\n    feature_description.name = model\n    return feature_description\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.describe_splits","title":"<code>describe_splits(descriptions, distances)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def describe_splits(\n    descriptions: DataFrame, distances: DataFrame\n) -&gt; dict[str, DataFrame]:\n    # features\n    features_descriptions = (\n        descriptions.drop(\"description\", axis=1)\n        .groupby([\"domain\", \"feature\", \"sub_pop\"])\n        .apply(weighted_av)\n    )\n    features_descriptions[\"description\"] = (\n        descriptions[\"description\"]\n        .groupby([\"domain\", \"feature\", \"sub_pop\"])\n        .first()\n    )\n\n    features_distances = (\n        distances.drop(\"distance\", axis=1)\n        .groupby([\"domain\", \"feature\", \"sub_pop\"])\n        .apply(distance_weighted_av)\n    )\n    features_distances[\"distance\"] = (\n        distances[\"distance\"].groupby([\"domain\", \"feature\", \"sub_pop\"]).first()\n    )\n\n    # themes\n    domain_descriptions = (\n        features_descriptions.drop(\"description\", axis=1)\n        .groupby(\"domain\")\n        .mean()\n    )\n    domain_distances = (\n        features_distances.drop(\"distance\", axis=1).groupby(\"domain\").mean()\n    )\n\n    frames = {\n        \"descriptions\": descriptions,\n        \"feature_descriptions\": features_descriptions,\n        \"domain_descriptions\": domain_descriptions,\n        \"distances\": distances,\n        \"feature_distances\": features_distances,\n        \"domain_distances\": domain_distances,\n    }\n    return frames\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.distance_weighted_av","title":"<code>distance_weighted_av(report, base_col='observed__weight', weight_col='__weight')</code>","text":"<p>Weighted avergae of dataframe using weights in the weight column and a base column. This deals with cases where models have different features.</p> Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def distance_weighted_av(\n    report: DataFrame,\n    base_col: str = \"observed__weight\",\n    weight_col: str = \"__weight\",\n) -&gt; Series:\n    \"\"\"Weighted avergae of dataframe using weights in the weight column and a base column.\n    This deals with cases where models have different features.\n    \"\"\"\n    cols = list(report.columns)\n    cols = [c for c in cols if not c.endswith(weight_col)]\n    base_weights = report[base_col]\n    scores = DataFrame()\n    for c in cols:\n        weights = report[f\"{c}{weight_col}\"]\n        weights = (weights + base_weights) / 2\n        total = weights.sum()\n        scores[c] = report[c] * weights / total\n    return scores.sum()\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.eval_models_creativity","title":"<code>eval_models_creativity(synthetic_schedules, target_schedules)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def eval_models_creativity(\n    synthetic_schedules: dict[str, DataFrame], target_schedules: DataFrame\n) -&gt; Tuple[DataFrame, DataFrame]:\n    # Evaluate Creativity\n    observed_hash = creativity.hash_population(target_schedules)\n    observed_diversity = creativity.diversity(target_schedules, observed_hash)\n    feature_count = target_schedules.pid.nunique()\n    creativity_descriptions = DataFrame(\n        {\n            \"observed__weight\": [feature_count] * 2,\n            \"observed\": [observed_diversity, 1],\n        }\n    )\n    creativity_distance = DataFrame(\n        {\n            \"observed__weight\": [feature_count] * 2,\n            \"observed\": [1 - observed_diversity, 0],\n        }\n    )\n\n    creativity_descs = []\n    creativity_dists = []\n    for model, y in synthetic_schedules.items():\n        y_hash = creativity.hash_population(y)\n        y_diversity = creativity.diversity(y, y_hash)\n        y_count = y.pid.nunique()\n        creativity_descs.append(\n            Series(\n                [y_diversity, creativity.novelty(observed_hash, y_hash)],\n                name=model,\n            )\n        )\n        creativity_descs.append(  # add feature count\n            Series([y_count, y_count], name=f\"{model}__weight\")\n        )\n        creativity_dists.append(\n            Series(\n                [\n                    1 - y_diversity,\n                    creativity.conservatism(observed_hash, y_hash),\n                ],\n                name=model,\n            )\n        )\n        creativity_dists.append(  # add feature count\n            Series([y_count, y_count], name=f\"{model}__weight\")\n        )\n\n    creativity_descs.append(\n        Series([\"prob. unique\", \"prob. novel\"], name=\"description\")\n    )\n    creativity_dists.append(\n        Series([\"prob. not unique\", \"prob. conservative\"], name=\"distance\")\n    )\n    # combine\n    descriptions = concat(\n        [creativity_descriptions, concat(creativity_descs, axis=1)], axis=1\n    )\n    distances = concat(\n        [creativity_distance, concat(creativity_dists, axis=1)], axis=1\n    )\n    descriptions.index = MultiIndex.from_tuples(\n        [(\"creativity\", \"diversity\", \"all\"), (\"creativity\", \"novelty\", \"all\")],\n        names=[\"domain\", \"feature\", \"segment\"],\n    )\n    distances.index = MultiIndex.from_tuples(\n        [\n            (\"creativity\", \"homogeneity\", \"all\"),\n            (\"creativity\", \"conservatism\", \"all\"),\n        ],\n        names=[\"domain\", \"feature\", \"segment\"],\n    )\n    return descriptions, distances\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.eval_models_density_estimation","title":"<code>eval_models_density_estimation(synthetic_schedules, target_schedules, domain, feature, size, description_job, distance_job)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def eval_models_density_estimation(\n    synthetic_schedules: dict[str, DataFrame],\n    target_schedules: DataFrame,\n    domain: str,\n    feature: Tuple[str, Callable],\n    size: Callable,\n    description_job: Tuple[str, Callable],\n    distance_job: Tuple[str, Callable],\n) -&gt; Tuple[DataFrame, DataFrame]:\n    # unpack tuples\n    feature_name, feature = feature\n    description_name, describe = description_job\n    distance_name, distance_metric = distance_job\n\n    # build observed features\n    observed_features = feature(target_schedules)\n\n    # need to create a default feature for missing sampled features\n    default = extract_default(observed_features)\n\n    # create an observed feature count and description\n    feature_weight = size(observed_features)\n    feature_weight.name = \"observed__weight\"\n\n    description_job = describe(observed_features)\n    feature_descriptions = DataFrame(\n        {\"observed__weight\": feature_weight, \"observed\": description_job}\n    )\n\n    # sort by count and description, drop description and add distance description\n    feature_descriptions = feature_descriptions.sort_values(\n        ascending=False, by=[\"observed__weight\", \"observed\"]\n    )\n\n    feature_distances = feature_descriptions.copy()\n\n    # iterate through samples\n    for model, y in synthetic_schedules.items():\n        synth_features = feature(y)\n        synth_weight = size(synth_features)\n        synth_weight.name = f\"{model}__weight\"\n\n        feature_descriptions = concat(\n            [\n                synth_weight,\n                feature_descriptions,\n                describe_feature(model, synth_features, describe),\n            ],\n            axis=1,\n        )\n\n        # report sampled distances\n        feature_distances = concat(\n            [\n                synth_weight,\n                feature_distances,\n                score_features(\n                    model,\n                    observed_features,\n                    synth_features,\n                    distance_metric,\n                    default,\n                ),\n            ],\n            axis=1,\n        )\n\n    # add domain and feature name to index\n    feature_descriptions[\"description\"] = description_name\n    feature_distances[\"distance\"] = distance_name\n    feature_descriptions.index = MultiIndex.from_tuples(\n        [(domain, feature_name, f) for f in feature_descriptions.index],\n        name=[\"domain\", \"feature\", \"segment\"],\n    )\n    feature_distances.index = MultiIndex.from_tuples(\n        [(domain, feature_name, f) for f in feature_distances.index],\n        name=[\"domain\", \"feature\", \"segment\"],\n    )\n\n    return feature_descriptions, feature_distances\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.evaluate","title":"<code>evaluate(synthetic_schedules, target_schedules, report_stats=True)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def evaluate(\n    synthetic_schedules: dict[str, DataFrame],\n    target_schedules: DataFrame,\n    report_stats: bool = True,\n):\n    descriptions, distances = process(synthetic_schedules, target_schedules)\n    frames = describe(descriptions, distances)\n\n    if report_stats:\n        columns = list(synthetic_schedules.keys())\n        for frame in frames.values():\n            add_stats(data=frame, columns=columns)\n\n    return frames\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.evaluate_subsampled","title":"<code>evaluate_subsampled(synthetic_schedules, synthetic_attributes, target_schedules, target_attributes, split_on, report_stats=True, verbose=False)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def evaluate_subsampled(\n    synthetic_schedules: dict[str, DataFrame],\n    synthetic_attributes: dict[str, DataFrame],\n    target_schedules: DataFrame,\n    target_attributes: DataFrame,\n    split_on: List[str],\n    report_stats: bool = True,\n    verbose: bool = False,\n):\n    descriptions = []\n    distances = []\n    for split in split_on:\n        target_cats = target_attributes[split].unique()\n        for cat in target_cats:\n            target_pids = target_attributes[target_attributes[split] == cat].pid\n            sub_target = target_schedules[\n                target_schedules.pid.isin(target_pids)\n            ]\n            sub_schedules = {}\n            for model, attributes in synthetic_attributes.items():\n                sample_pids = attributes[attributes[split] == cat].pid\n                if verbose:\n                    print(\n                        f\"&gt;&gt;&gt; Subsampled {model} {split}={cat} with {len(sample_pids)}\"\n                    )\n                sample_schedules = synthetic_schedules[model]\n                sub_schedules[model] = sample_schedules[\n                    sample_schedules.pid.isin(sample_pids)\n                ]\n\n            sub_reports = process(\n                synthetic_schedules=sub_schedules, target_schedules=sub_target\n            )\n            for r in sub_reports:  # add sub pop to index\n                names = list(r.index.names) + [\"sub_pop\"]\n                r.index = MultiIndex.from_tuples(\n                    [(*i, f\"{split}={cat}\") for i in r.index], names=names\n                )\n            descriptions.append(sub_reports[0])\n            distances.append(sub_reports[1])\n\n    descriptions = concat(descriptions, axis=0)\n    distances = concat(distances, axis=0)\n\n    frames = describe_splits(descriptions, distances)\n\n    if report_stats:\n        columns = list(synthetic_schedules.keys())\n        for frame in frames.values():\n            add_stats(data=frame, columns=columns)\n\n    return frames\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.extract_default","title":"<code>extract_default(features)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def extract_default(features: dict[str, tuple[np.array, np.array]]):\n    # we use a single feature of zeros as required\n    # look for a zize\n    default_shape = extract_default_shape(features)\n    default_support = np.zeros(default_shape)\n    return (default_support, np.array([1]))\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.extract_default_shape","title":"<code>extract_default_shape(features)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def extract_default_shape(\n    features: dict[str, tuple[np.array, np.array]]\n) -&gt; np.array:\n    for k, _ in iter(features.values()):\n        if len(k) &gt; 0:\n            default_shape = list(k.shape)\n            default_shape[0] = 1\n            return default_shape\n    raise ValueError(\"No features found in the given dictionary.\")\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.print_markdown","title":"<code>print_markdown(data)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def print_markdown(data: DataFrame):\n    print(data.to_markdown(tablefmt=\"fancy_grid\", floatfmt=\".3f\"))\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.process","title":"<code>process(synthetic_schedules, target_schedules)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def process(\n    synthetic_schedules: dict[str, DataFrame], target_schedules: DataFrame\n) -&gt; Tuple[DataFrame, DataFrame]:\n    # evaluate creativity\n    descriptions, distances = eval_models_creativity(\n        synthetic_schedules=synthetic_schedules,\n        target_schedules=target_schedules,\n    )\n\n    for domain, jobs in [\n        (\"count\", count_jobs),\n        (\"sample quality\", sample_quality_jobs),\n        (\"aggregate\", aggregate_jobs),\n        # (\"participation_probs\", participation_prob_jobs),\n        (\"participations\", participation_rate_jobs),\n        (\"transitions\", transition_jobs),\n        (\"timing\", time_jobs),\n    ]:\n        for feature, size, description_job, distance_job in jobs:\n            feature_descriptions, feature_distances = (\n                eval_models_density_estimation(\n                    synthetic_schedules,\n                    target_schedules,\n                    domain,\n                    feature,\n                    size,\n                    description_job,\n                    distance_job,\n                )\n            )\n            descriptions = concat([descriptions, feature_descriptions], axis=0)\n            distances = concat([distances, feature_distances], axis=0)\n\n    # remove nans\n    descriptions = descriptions.fillna(0.0)\n    distances = distances.fillna(0.0)\n    return descriptions, distances\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.rank","title":"<code>rank(data)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def rank(data: DataFrame) -&gt; DataFrame:\n    # feature rank\n    rank = data.drop([\"observed\", \"distance\"], axis=1, errors=\"ignore\").rank(\n        axis=1, method=\"min\"\n    )\n    col_ranks = rank.sum(axis=0)\n    ranked = [i for _, i in sorted(zip(col_ranks, col_ranks.index))]\n    return rank[ranked]\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.report","title":"<code>report(frames, log_dir=None, head=None, verbose=True, suffix='', ranking=False)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def report(\n    frames: dict[str, DataFrame],\n    log_dir: Optional[Path] = None,\n    head: Optional[int] = None,\n    verbose: bool = True,\n    suffix: str = \"\",\n    ranking: bool = False,\n):\n    if head is not None:\n        frames[\"descriptions_short\"] = (\n            frames[\"descriptions\"].groupby([\"domain\", \"feature\"]).head(head)\n        )\n        frames[\"distances_short\"] = (\n            frames[\"distances\"].groupby([\"domain\", \"feature\"]).head(head)\n        )\n    else:\n        # default to full\n        frames[\"descriptions_short\"] = frames[\"descriptions\"]\n        frames[\"distances_short\"] = frames[\"distances\"]\n\n    if log_dir is not None:\n        for name, frame in frames.items():\n            frame.to_csv(Path(log_dir, f\"{name}{suffix}.csv\"))\n\n    if verbose:\n        print(\"\\nDescriptions:\")\n        print_markdown(frames[\"descriptions_short\"])\n        print(\"\\nEvalutions (Distance):\")\n        print_markdown(frames[\"distances_short\"])\n\n    print(\"\\nFeature Descriptions:\")\n    print_markdown(frames[\"feature_descriptions\"])\n    print(\"\\nFeature Evaluations (Distance):\")\n    print_markdown(frames[\"feature_distances\"])\n    if ranking:\n        print(\"\\nFeature Evaluations (Ranked):\")\n        print_markdown(rank(frames[\"feature_distances\"]))\n\n    print(\"\\nDomain Descriptions:\")\n    print_markdown(frames[\"domain_descriptions\"])\n    print(\"\\nDomain Evaluations (Distance):\")\n    print_markdown(frames[\"domain_distances\"])\n    if ranking:\n        print(\"\\nDomain Evaluations (Ranked):\")\n        print_markdown(rank(frames[\"domain_distances\"]))\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.report_splits","title":"<code>report_splits(frames, log_dir=None, head=None, verbose=True, suffix='', ranking=False)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def report_splits(\n    frames: dict[str, DataFrame],\n    log_dir: Optional[Path] = None,\n    head: Optional[int] = None,\n    verbose: bool = True,\n    suffix: str = \"\",\n    ranking: bool = False,\n):\n    if head is not None:\n        frames[\"descriptions_short\"] = (\n            frames[\"descriptions\"]\n            .groupby([\"domain\", \"feature\", \"sub_pop\"])\n            .head(head)\n        )\n        frames[\"distances_short\"] = (\n            frames[\"distances\"]\n            .groupby([\"domain\", \"feature\", \"sub_pop\"])\n            .head(head)\n        )\n    else:\n        # default to full\n        frames[\"descriptions_short\"] = frames[\"descriptions\"]\n        frames[\"distances_short\"] = frames[\"distances\"]\n\n    if log_dir is not None:\n        for name, frame in frames.items():\n            frame.to_csv(Path(log_dir, f\"{name}{suffix}.csv\"))\n\n    if verbose:\n        print(\"\\nDescriptions:\")\n        print_markdown(frames[\"descriptions_short\"])\n        print(\"\\nEvalutions (Distance):\")\n        print_markdown(frames[\"distances_short\"])\n\n    print(\"\\nFeature Descriptions:\")\n    print_markdown(frames[\"feature_descriptions\"])\n    print(\"\\nFeature Evaluations (Distance):\")\n    print_markdown(frames[\"feature_distances\"])\n    if ranking:\n        print(\"\\nFeature Evaluations (Ranked):\")\n        print_markdown(rank(frames[\"feature_distances\"]))\n\n    print(\"\\nDomain Descriptions:\")\n    print_markdown(frames[\"domain_descriptions\"])\n    print(\"\\nDomain Evaluations (Distance):\")\n    print_markdown(frames[\"domain_distances\"])\n    if ranking:\n        print(\"\\nDomain Evaluations (Ranked):\")\n        print_markdown(rank(frames[\"domain_distances\"]))\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.score_features","title":"<code>score_features(model, a, b, distance, default)</code>","text":"Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def score_features(\n    model: str,\n    a: dict[str, tuple[np.array, np.array]],\n    b: dict[str, tuple[np.array, np.array]],\n    distance: Callable,\n    default: tuple[np.array, np.array],\n):\n    index = set(a.keys()) | set(b.keys())\n    metrics = Series(\n        {\n            k: distance(\n                defaulting_get(a, k, default), defaulting_get(b, k, default)\n            )\n            for k in index\n        },\n        name=model,\n    )\n    metrics = metrics.fillna(0)\n    metrics = metrics[np.isfinite(metrics)]\n    return metrics\n</code></pre>"},{"location":"reference/caveat/evaluate/evaluate/#caveat.evaluate.evaluate.weighted_av","title":"<code>weighted_av(report, weight_col='__weight')</code>","text":"<p>Weighted avergae of dataframe using weights in the weight column.</p> Source code in <code>caveat/evaluate/evaluate.py</code> <pre><code>def weighted_av(report: DataFrame, weight_col: str = \"__weight\") -&gt; Series:\n    \"\"\"Weighted avergae of dataframe using weights in the weight column.\"\"\"\n    cols = list(report.columns)\n    cols = [c for c in cols if not c.endswith(weight_col)]\n    scores = DataFrame()\n    for c in cols:\n        weights = report[f\"{c}{weight_col}\"]\n        total = weights.sum()\n        scores[c] = report[c] * weights / total\n    return scores.sum()\n</code></pre>"},{"location":"reference/caveat/evaluate/features/creativity/","title":"caveat.evaluate.features.creativity","text":""},{"location":"reference/caveat/evaluate/features/creativity/#caveat.evaluate.features.creativity.conservatism","title":"<code>conservatism(observed_hashed, synthetic_hashed)</code>","text":"<p>Measure the conservatism of a population as 1-novelty.</p> PARAMETER DESCRIPTION <code>observed_hashed</code> <p>Hashed observed population.</p> <p> TYPE: <code>set[str]</code> </p> <code>synthetic_hashed</code> <p>Hashed synthetic population.</p> <p> TYPE: <code>set[str]</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Conservatism of the synthetic population.</p> <p> TYPE: <code>float</code> </p> Source code in <code>caveat/evaluate/features/creativity.py</code> <pre><code>def conservatism(\n    observed_hashed: set[str], synthetic_hashed: set[str]\n) -&gt; float:\n    \"\"\"Measure the conservatism of a population as 1-novelty.\n\n    Args:\n        observed_hashed (set[str]): Hashed observed population.\n        synthetic_hashed (set[str]): Hashed synthetic population.\n\n    Returns:\n        float: Conservatism of the synthetic population.\n    \"\"\"\n    return 1 - novelty(observed_hashed, synthetic_hashed)\n</code></pre>"},{"location":"reference/caveat/evaluate/features/creativity/#caveat.evaluate.features.creativity.diversity","title":"<code>diversity(population, hashed)</code>","text":"<p>Measure the internal diversity of a population of sequences. This is the ratio of unique sequences to the total number of sequences.</p> PARAMETER DESCRIPTION <code>population</code> <p>Input population of sequences.</p> <p> TYPE: <code>DataFrame</code> </p> <code>hashed</code> <p>Hashed population of sequences.</p> <p> TYPE: <code>set[str]</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Diversity of the population.</p> <p> TYPE: <code>float</code> </p> Source code in <code>caveat/evaluate/features/creativity.py</code> <pre><code>def diversity(population: DataFrame, hashed: set[str]) -&gt; float:\n    \"\"\"Measure the internal diversity of a population of sequences. This is the ratio of unique\n    sequences to the total number of sequences.\n\n    Args:\n        population (DataFrame): Input population of sequences.\n        hashed (set[str]): Hashed population of sequences.\n\n    Returns:\n        float: Diversity of the population.\n    \"\"\"\n    n = population.pid.nunique()\n    if n == 0:\n        return 0\n    unique = len(hashed)\n    return unique / n\n</code></pre>"},{"location":"reference/caveat/evaluate/features/creativity/#caveat.evaluate.features.creativity.hash_population","title":"<code>hash_population(population)</code>","text":"<p>Hash a population of sequences. We first create strings of combined activities and durations. Then create a python set of these strings. This will remove duplicates.</p> PARAMETER DESCRIPTION <code>population</code> <p>Input population of sequences.</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>set[str]</code> <p>set[str]: set of hashed sequences.</p> Source code in <code>caveat/evaluate/features/creativity.py</code> <pre><code>def hash_population(population: DataFrame) -&gt; set[str]:\n    \"\"\"Hash a population of sequences. We first create strings of combined activities and durations.\n    Then create a python set of these strings. This will remove duplicates.\n\n    Args:\n        population (DataFrame): Input population of sequences.\n\n    Returns:\n        set[str]: set of hashed sequences.\n    \"\"\"\n    act_hash = population.act.astype(str) + population.duration.astype(str)\n    return set(act_hash.groupby(population.pid).apply(\"\".join))\n</code></pre>"},{"location":"reference/caveat/evaluate/features/creativity/#caveat.evaluate.features.creativity.homogeneity","title":"<code>homogeneity(population, hashed)</code>","text":"<p>Measure the internal homogeneity of a population of sequences. This is 1-diversity.</p> PARAMETER DESCRIPTION <code>population</code> <p>Input population of sequences.</p> <p> TYPE: <code>DataFrame</code> </p> <code>hashed</code> <p>Hashed population of sequences.</p> <p> TYPE: <code>set[str]</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Homogeneity of the synthetic sample.</p> <p> TYPE: <code>float</code> </p> Source code in <code>caveat/evaluate/features/creativity.py</code> <pre><code>def homogeneity(population: DataFrame, hashed: set[str]) -&gt; float:\n    \"\"\"Measure the internal homogeneity of a population of sequences. This is 1-diversity.\n\n    Args:\n        population (DataFrame): Input population of sequences.\n        hashed (set[str]): Hashed population of sequences.\n\n    Returns:\n        float: Homogeneity of the synthetic sample.\n    \"\"\"\n    return 1 - diversity(population, hashed)\n</code></pre>"},{"location":"reference/caveat/evaluate/features/creativity/#caveat.evaluate.features.creativity.novelty","title":"<code>novelty(observed_hashed, synthetic_hashed)</code>","text":"<p>Measure the novelty of a population by comparing it to an observed population.</p> PARAMETER DESCRIPTION <code>observed_hashed</code> <p>Hashed observed population.</p> <p> TYPE: <code>set[str]</code> </p> <code>synthetic_hashed</code> <p>Hashed synthetic population.</p> <p> TYPE: <code>set[str]</code> </p> RETURNS DESCRIPTION <code>float</code> <p>Novelty of the synthetic population.</p> <p> TYPE: <code>float</code> </p> Source code in <code>caveat/evaluate/features/creativity.py</code> <pre><code>def novelty(observed_hashed: set[str], synthetic_hashed: set[str]) -&gt; float:\n    \"\"\"Measure the novelty of a population by comparing it to an observed population.\n\n    Args:\n        observed_hashed (set[str]): Hashed observed population.\n        synthetic_hashed (set[str]): Hashed synthetic population.\n\n    Returns:\n        float: Novelty of the synthetic population.\n    \"\"\"\n    n = len(synthetic_hashed)\n    if n == 0:\n        return 0\n    return len(synthetic_hashed - observed_hashed) / n\n</code></pre>"},{"location":"reference/caveat/evaluate/features/frequency/","title":"caveat.evaluate.features.frequency","text":""},{"location":"reference/caveat/evaluate/features/frequency/#caveat.evaluate.features.frequency.activity_densities","title":"<code>activity_densities(population, duration=1440, step=15)</code>","text":"Source code in <code>caveat/evaluate/features/frequency.py</code> <pre><code>def activity_densities(\n    population: DataFrame, duration: int = 1440, step: int = 15\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    index_to_acts = {i: a for i, a in enumerate(population.act.unique())}\n    class_map = {a: i for i, a in index_to_acts.items()}\n    bins = binned_activity_density(\n        population=population, class_map=class_map, duration=duration, step=step\n    )\n    support = arange(0, 1, step / duration)\n    return {act: (support, bins[:, i]) for act, i in class_map.items()}\n</code></pre>"},{"location":"reference/caveat/evaluate/features/frequency/#caveat.evaluate.features.frequency.activity_frequencies","title":"<code>activity_frequencies(population, duration=1440, step=15)</code>","text":"Source code in <code>caveat/evaluate/features/frequency.py</code> <pre><code>def activity_frequencies(\n    population: DataFrame, duration: int = 1440, step: int = 15\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    index_to_acts = {i: a for i, a in enumerate(population.act.unique())}\n    class_map = {a: i for i, a in index_to_acts.items()}\n    bins = binned_activity_count(\n        population=population, class_map=class_map, duration=duration, step=step\n    )\n    support = arange(0, 1, step / duration)\n    freqs = {act: (support, bins[:, i]) for act, i in class_map.items()}\n    return freqs\n</code></pre>"},{"location":"reference/caveat/evaluate/features/frequency/#caveat.evaluate.features.frequency.binned_activity_count","title":"<code>binned_activity_count(population, class_map, duration=1440, step=15)</code>","text":"Source code in <code>caveat/evaluate/features/frequency.py</code> <pre><code>def binned_activity_count(\n    population: DataFrame, class_map: dict, duration: int = 1440, step: int = 15\n) -&gt; ndarray:\n    return (\n        descretise_population(\n            population, duration=duration, step_size=step, class_map=class_map\n        )\n        .sum(0)\n        .numpy()\n    )[0, :, :]\n</code></pre>"},{"location":"reference/caveat/evaluate/features/frequency/#caveat.evaluate.features.frequency.binned_activity_density","title":"<code>binned_activity_density(population, class_map, duration=1440, step=15)</code>","text":"Source code in <code>caveat/evaluate/features/frequency.py</code> <pre><code>def binned_activity_density(\n    population: DataFrame, class_map: dict, duration: int = 1440, step: int = 15\n) -&gt; ndarray:\n    return (\n        descretise_population(\n            population, duration=duration, step_size=step, class_map=class_map\n        )\n        .mean(0)\n        .numpy()\n    )[0, :, :]\n</code></pre>"},{"location":"reference/caveat/evaluate/features/frequency/#caveat.evaluate.features.frequency.count_schedules","title":"<code>count_schedules(population)</code>","text":"Source code in <code>caveat/evaluate/features/frequency.py</code> <pre><code>def count_schedules(population: DataFrame) -&gt; int:\n    count = population.pid.nunique()\n    return {\"all\": (np.array([count]), np.array([1]))}\n</code></pre>"},{"location":"reference/caveat/evaluate/features/participation/","title":"caveat.evaluate.features.participation","text":""},{"location":"reference/caveat/evaluate/features/participation/#caveat.evaluate.features.participation.calc_pair_prob","title":"<code>calc_pair_prob(act_counts, pair)</code>","text":"Source code in <code>caveat/evaluate/features/participation.py</code> <pre><code>def calc_pair_prob(act_counts, pair):\n    a, b = pair\n    if a == b:\n        return (act_counts[a] &gt; 1).sum()\n    return ((act_counts[a] &gt; 0) &amp; (act_counts[b] &gt; 0)).sum()\n</code></pre>"},{"location":"reference/caveat/evaluate/features/participation/#caveat.evaluate.features.participation.calc_pair_rate","title":"<code>calc_pair_rate(act_counts, pair)</code>","text":"Source code in <code>caveat/evaluate/features/participation.py</code> <pre><code>def calc_pair_rate(act_counts, pair):\n    a, b = pair\n    if a == b:\n        return ((act_counts[a] / 2).astype(int)).value_counts().to_dict()\n    return (\n        ((act_counts[[a, b]].min(axis=1) / 2).astype(int))\n        .value_counts()\n        .to_dict()\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/features/participation/#caveat.evaluate.features.participation.combinations_with_replacement","title":"<code>combinations_with_replacement(targets, length, prev_array=[])</code>","text":"<p>Returns all possible combinations of elements in the input array with replacement, where each combination has a length of tuple_length.</p> PARAMETER DESCRIPTION <code>targets</code> <p>The input array to generate combinations from.</p> <p> TYPE: <code>list</code> </p> <code>length</code> <p>The length of each combination.</p> <p> TYPE: <code>int</code> </p> <code>prev_array</code> <p>The previous array generated in the recursion. Defaults to [].</p> <p> TYPE: <code>list</code> DEFAULT: <code>[]</code> </p> RETURNS DESCRIPTION <code>list</code> <p>A list of all possible combinations of elements in the input array with replacement.</p> <p> TYPE: <code>list[list]</code> </p> Source code in <code>caveat/evaluate/features/participation.py</code> <pre><code>def combinations_with_replacement(\n    targets: list, length: int, prev_array=[]\n) -&gt; list[list]:\n    \"\"\"\n    Returns all possible combinations of elements in the input array with replacement,\n    where each combination has a length of tuple_length.\n\n    Args:\n        targets (list): The input array to generate combinations from.\n        length (int): The length of each combination.\n        prev_array (list, optional): The previous array generated in the recursion. Defaults to [].\n\n    Returns:\n        list: A list of all possible combinations of elements in the input array with replacement.\n    \"\"\"\n    if len(prev_array) == length:\n        return [prev_array]\n    combs = []\n    for i, val in enumerate(targets):\n        prev_array_extended = prev_array.copy()\n        prev_array_extended.append(val)\n        combs += combinations_with_replacement(\n            targets[i:], length, prev_array_extended\n        )\n    return combs\n</code></pre>"},{"location":"reference/caveat/evaluate/features/participation/#caveat.evaluate.features.participation.joint_participation_prob","title":"<code>joint_participation_prob(population)</code>","text":"<p>Calculate the participation prob for all pairs of activities in the given population.</p> PARAMETER DESCRIPTION <code>population</code> <p>A DataFrame containing the population data.</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>dict[str, tuple[ndarray, ndarray]]</code> <p>pandas.Series: A Series containing the participation rate for all pairs of activities.</p> Source code in <code>caveat/evaluate/features/participation.py</code> <pre><code>def joint_participation_prob(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    \"\"\"\n    Calculate the participation prob for all pairs of activities in the given population.\n\n    Args:\n        population (pandas.DataFrame): A DataFrame containing the population data.\n\n    Returns:\n        pandas.Series: A Series containing the participation rate for all pairs of activities.\n    \"\"\"\n    act_counts = (\n        population.groupby(\"pid\").act.value_counts().unstack(fill_value=0)\n    )\n    acts = list(population.act.unique())\n    pairs = combinations_with_replacement(acts, 2)\n    n = population.pid.nunique()\n    metric = {}\n    for pair in pairs:\n        p = calc_pair_prob(act_counts, pair)\n        metric[\"+\".join(pair)] = (array([0, 1]), array([n - p, p]))\n\n    return metric\n</code></pre>"},{"location":"reference/caveat/evaluate/features/participation/#caveat.evaluate.features.participation.joint_participation_rate","title":"<code>joint_participation_rate(population)</code>","text":"<p>Calculate the participation rate for all pairs of activities in the given population.</p> PARAMETER DESCRIPTION <code>population</code> <p>A DataFrame containing the population data.</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>dict[str, tuple[ndarray, ndarray]]</code> <p>pandas.Series: A Series containing the participation rate for all pairs of activities.</p> Source code in <code>caveat/evaluate/features/participation.py</code> <pre><code>def joint_participation_rate(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    \"\"\"\n    Calculate the participation rate for all pairs of activities in the given population.\n\n    Args:\n        population (pandas.DataFrame): A DataFrame containing the population data.\n\n    Returns:\n        pandas.Series: A Series containing the participation rate for all pairs of activities.\n    \"\"\"\n    act_counts = (\n        population.groupby(\"pid\").act.value_counts().unstack(fill_value=0)\n    )\n    acts = list(population.act.unique())\n    pairs = combinations_with_replacement(acts, 2)\n    metric = {}\n    for pair in pairs:\n        counts = calc_pair_rate(act_counts, pair)\n        keys = array(list(counts.keys()))\n        values = array(list(counts.values()))\n        metric[\"+\".join(pair)] = (keys, values)\n\n    return metric\n</code></pre>"},{"location":"reference/caveat/evaluate/features/participation/#caveat.evaluate.features.participation.participation_prob_by_act","title":"<code>participation_prob_by_act(population)</code>","text":"<p>Calculate the participations by activity for a given population.</p> PARAMETER DESCRIPTION <code>population</code> <p>The population data.</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>dict[str, tuple[ndarray, ndarray]]</code> <p>dict[str, tuple[array, array]]: A dictionary containing the participation for each activity.</p> Source code in <code>caveat/evaluate/features/participation.py</code> <pre><code>def participation_prob_by_act(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    \"\"\"\n    Calculate the participations by activity for a given population.\n\n    Args:\n        population (DataFrame): The population data.\n\n    Returns:\n        dict[str, tuple[array, array]]: A dictionary containing the participation for each activity.\n    \"\"\"\n    metrics = population.groupby([\"pid\", \"act\"], observed=False).size() &gt; 0\n    metrics = metrics.groupby(\"act\", observed=False).sum().to_dict()\n    n = population.pid.nunique()\n    compressed = {}\n    for k, v in metrics.items():\n        compressed[k] = (array([0, 1]), array([(n - v), v]))\n    return compressed\n</code></pre>"},{"location":"reference/caveat/evaluate/features/participation/#caveat.evaluate.features.participation.participation_rates","title":"<code>participation_rates(population)</code>","text":"Source code in <code>caveat/evaluate/features/participation.py</code> <pre><code>def participation_rates(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    rates = population.groupby(\"pid\").act.count()\n    return weighted_features({\"all\": rates.to_list()})\n</code></pre>"},{"location":"reference/caveat/evaluate/features/participation/#caveat.evaluate.features.participation.participation_rates_by_act","title":"<code>participation_rates_by_act(population)</code>","text":"Source code in <code>caveat/evaluate/features/participation.py</code> <pre><code>def participation_rates_by_act(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    rates = population.groupby(\"pid\").act.value_counts().unstack().fillna(0)\n    return weighted_features(rates.to_dict(orient=\"list\"))\n</code></pre>"},{"location":"reference/caveat/evaluate/features/participation/#caveat.evaluate.features.participation.participation_rates_by_act_enum","title":"<code>participation_rates_by_act_enum(population)</code>","text":"Source code in <code>caveat/evaluate/features/participation.py</code> <pre><code>def participation_rates_by_act_enum(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    act_enum = population.act.astype(str) + population.groupby(\n        [\"pid\", \"act\"], as_index=False, observed=False\n    ).cumcount().astype(str)\n    rates = act_enum.groupby(population.pid).value_counts().unstack().fillna(0)\n    return weighted_features(rates.to_dict(orient=\"list\"))\n</code></pre>"},{"location":"reference/caveat/evaluate/features/participation/#caveat.evaluate.features.participation.participation_rates_by_seq_act","title":"<code>participation_rates_by_seq_act(population)</code>","text":"Source code in <code>caveat/evaluate/features/participation.py</code> <pre><code>def participation_rates_by_seq_act(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    actseq = population.groupby(\"pid\", as_index=False).cumcount().astype(\n        str\n    ) + population.act.astype(str)\n    rates = actseq.groupby(population.pid).value_counts().unstack().fillna(0)\n    return weighted_features(rates.to_dict(orient=\"list\"))\n</code></pre>"},{"location":"reference/caveat/evaluate/features/structural/","title":"caveat.evaluate.features.structural","text":""},{"location":"reference/caveat/evaluate/features/structural/#caveat.evaluate.features.structural.duration_consistency","title":"<code>duration_consistency(population, factor=1440)</code>","text":"Source code in <code>caveat/evaluate/features/structural.py</code> <pre><code>def duration_consistency(\n    population: DataFrame, factor: int = 1440\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    durations = population.groupby(\"pid\").duration.sum() / factor\n    return weighted_features({\"total duration\": durations.array})\n</code></pre>"},{"location":"reference/caveat/evaluate/features/structural/#caveat.evaluate.features.structural.sequence_lengths","title":"<code>sequence_lengths(population)</code>","text":"Source code in <code>caveat/evaluate/features/structural.py</code> <pre><code>def sequence_lengths(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    lengths = population.groupby(\"pid\").size().value_counts().sort_index()\n    keys = array(lengths.index)\n    values = array(lengths.values)\n    return {\"sequence lengths\": (keys, values)}\n</code></pre>"},{"location":"reference/caveat/evaluate/features/structural/#caveat.evaluate.features.structural.start_and_end_acts","title":"<code>start_and_end_acts(population, target='home')</code>","text":"Source code in <code>caveat/evaluate/features/structural.py</code> <pre><code>def start_and_end_acts(\n    population: DataFrame, target: str = \"home\"\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    n = len(population.pid.unique())\n    first = (population.groupby(\"pid\").first().act == target).sum()\n    last = (population.groupby(\"pid\").last().act == target).sum()\n    return {\n        f\"first act {target}\": (array([0, 1]), array([(n - first), first])),\n        f\"last act {target}\": (array([0, 1]), array([(n - last), last])),\n    }\n</code></pre>"},{"location":"reference/caveat/evaluate/features/structural/#caveat.evaluate.features.structural.time_consistency","title":"<code>time_consistency(population, target=1440)</code>","text":"Source code in <code>caveat/evaluate/features/structural.py</code> <pre><code>def time_consistency(\n    population: DataFrame, target: int = 1440\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    n = len(population.pid.unique())\n    starts = (population.groupby(\"pid\").first().start == 0).sum()\n    ends = (population.groupby(\"pid\").last().end == target).sum()\n    duration = (population.groupby(\"pid\").duration.sum() == target).sum()\n    return {\n        \"starts at 0\": (array([0, 1]), array([(n - starts), starts])),\n        f\"ends at {target}\": (array([0, 1]), array([(n - ends), ends])),\n        f\"duration is {target}\": (\n            array([0, 1]),\n            array([(n - duration), duration]),\n        ),\n    }\n</code></pre>"},{"location":"reference/caveat/evaluate/features/structural/#caveat.evaluate.features.structural.trip_consistency","title":"<code>trip_consistency(population)</code>","text":"Source code in <code>caveat/evaluate/features/structural.py</code> <pre><code>def trip_consistency(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/","title":"caveat.evaluate.features.times","text":""},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.durations_by_act","title":"<code>durations_by_act(population)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def durations_by_act(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    return weighted_features(\n        population.groupby(\"act\", observed=False)\n        .duration.apply(list)\n        .to_dict(),\n        factor=1440,\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.durations_by_act_plan_enum","title":"<code>durations_by_act_plan_enum(population)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def durations_by_act_plan_enum(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    actseq = population.act.astype(str) + population.groupby(\n        [\"pid\", \"act\"], as_index=False, observed=False\n    ).cumcount().astype(str)\n    return weighted_features(\n        population.groupby(actseq).duration.apply(list).to_dict(), factor=1440\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.durations_by_act_plan_seq","title":"<code>durations_by_act_plan_seq(population)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def durations_by_act_plan_seq(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    actseq = population.groupby(\"pid\", as_index=False).cumcount().astype(\n        str\n    ) + population.act.astype(str)\n    return weighted_features(\n        population.groupby(actseq).duration.apply(list).to_dict(), factor=1440\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.end_times_by_act","title":"<code>end_times_by_act(population)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def end_times_by_act(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    return weighted_features(\n        population.groupby(\"act\", observed=False).end.apply(list).to_dict(),\n        factor=1440,\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.end_times_by_act_plan_enum","title":"<code>end_times_by_act_plan_enum(population)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def end_times_by_act_plan_enum(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    actseq = population.act.astype(str) + population.groupby(\n        [\"pid\", \"act\"], as_index=False, observed=False\n    ).cumcount().astype(str)\n    return weighted_features(\n        population.groupby(actseq).end.apply(list).to_dict(), factor=1440\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.end_times_by_act_plan_seq","title":"<code>end_times_by_act_plan_seq(population)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def end_times_by_act_plan_seq(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    actseq = population.groupby(\"pid\", as_index=False).cumcount().astype(\n        str\n    ) + population.act.astype(str)\n    return weighted_features(\n        population.groupby(actseq).end.apply(list).to_dict(), factor=1440\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.start_and_duration_by_act_bins","title":"<code>start_and_duration_by_act_bins(population, bin_size=15)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def start_and_duration_by_act_bins(\n    population: DataFrame, bin_size: int = 15\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    features = start_durations_by_act(population)\n    return weighted_features(features, bin_size=bin_size, factor=1440)\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.start_durations_by_act","title":"<code>start_durations_by_act(population)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def start_durations_by_act(population: DataFrame) -&gt; dict[str, ndarray]:\n    sds = population.groupby(\"act\", observed=False).apply(zip_columns).to_dict()\n    return sds\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.start_times_by_act","title":"<code>start_times_by_act(population)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def start_times_by_act(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    return weighted_features(\n        population.groupby(\"act\", observed=False).start.apply(list).to_dict(),\n        factor=1440,\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.start_times_by_act_plan_enum","title":"<code>start_times_by_act_plan_enum(population)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def start_times_by_act_plan_enum(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    actseq = population.act.astype(str) + population.groupby(\n        [\"pid\", \"act\"], as_index=False, observed=False\n    ).cumcount().astype(str)\n    return weighted_features(\n        population.groupby(actseq).start.apply(list).to_dict(), factor=1440\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.start_times_by_act_plan_seq","title":"<code>start_times_by_act_plan_seq(population)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def start_times_by_act_plan_seq(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    actseq = population.groupby(\"pid\", as_index=False).cumcount().astype(\n        str\n    ) + population.act.astype(str)\n    return weighted_features(\n        population.groupby(actseq).start.apply(list).to_dict(), factor=1440\n    )\n</code></pre>"},{"location":"reference/caveat/evaluate/features/times/#caveat.evaluate.features.times.zip_columns","title":"<code>zip_columns(group)</code>","text":"Source code in <code>caveat/evaluate/features/times.py</code> <pre><code>def zip_columns(group) -&gt; ndarray:\n    return array([(s, d) for s, d in zip(group.start, group.duration)])\n</code></pre>"},{"location":"reference/caveat/evaluate/features/transitions/","title":"caveat.evaluate.features.transitions","text":""},{"location":"reference/caveat/evaluate/features/transitions/#caveat.evaluate.features.transitions.collect_sequence","title":"<code>collect_sequence(acts)</code>","text":"Source code in <code>caveat/evaluate/features/transitions.py</code> <pre><code>def collect_sequence(acts: Series) -&gt; str:\n    return \"&gt;\".join(acts)\n</code></pre>"},{"location":"reference/caveat/evaluate/features/transitions/#caveat.evaluate.features.transitions.full_sequences","title":"<code>full_sequences(population)</code>","text":"Source code in <code>caveat/evaluate/features/transitions.py</code> <pre><code>def full_sequences(population: DataFrame) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    transitions = population.reset_index()\n    transitions = transitions.set_index([\"index\", \"pid\"])\n    transitions.act = transitions.act.astype(str)\n    transitions = transitions.groupby(\"pid\").act.apply(tour)\n    transitions = (\n        transitions.groupby(\"pid\")\n        .value_counts()\n        .unstack()\n        .fillna(0)\n        .astype(int)\n        .to_dict(orient=\"list\")\n    )\n    return weighted_features(transitions)\n</code></pre>"},{"location":"reference/caveat/evaluate/features/transitions/#caveat.evaluate.features.transitions.sequence_probs","title":"<code>sequence_probs(population)</code>","text":"<p>Calculates the sequence probabilities in the given population DataFrame.</p> PARAMETER DESCRIPTION <code>population</code> <p>A DataFrame containing the population data.</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>A DataFrame containing the probability of each sequence.</p> <p> TYPE: <code>DataFrame</code> </p> Source code in <code>caveat/evaluate/features/transitions.py</code> <pre><code>def sequence_probs(population: DataFrame) -&gt; DataFrame:\n    \"\"\"\n    Calculates the sequence probabilities in the given population DataFrame.\n\n    Args:\n        population (DataFrame): A DataFrame containing the population data.\n\n    Returns:\n        DataFrame: A DataFrame containing the probability of each sequence.\n    \"\"\"\n    metrics = (\n        population.groupby(\"pid\")\n        .act.apply(collect_sequence)\n        .value_counts(normalize=True)\n    )\n    metrics = metrics.sort_values(ascending=False)\n    metrics.index = MultiIndex.from_tuples(\n        [(\"sequence rate\", acts) for acts in metrics.index]\n    )\n    return metrics\n</code></pre>"},{"location":"reference/caveat/evaluate/features/transitions/#caveat.evaluate.features.transitions.tour","title":"<code>tour(acts)</code>","text":"<p>Extracts the tour from the given Series of activities.</p> PARAMETER DESCRIPTION <code>acts</code> <p>A Series containing the activities.</p> <p> TYPE: <code>Series</code> </p> RETURNS DESCRIPTION <code>str</code> <p>A string representation of the tour.</p> <p> TYPE: <code>str</code> </p> Source code in <code>caveat/evaluate/features/transitions.py</code> <pre><code>def tour(acts: Series) -&gt; str:\n    \"\"\"\n    Extracts the tour from the given Series of activities.\n\n    Args:\n        acts (Series): A Series containing the activities.\n\n    Returns:\n        str: A string representation of the tour.\n    \"\"\"\n    return \"&gt;\".join(acts.str[0])\n</code></pre>"},{"location":"reference/caveat/evaluate/features/transitions/#caveat.evaluate.features.transitions.transition_3s_by_act","title":"<code>transition_3s_by_act(population)</code>","text":"Source code in <code>caveat/evaluate/features/transitions.py</code> <pre><code>def transition_3s_by_act(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    transitions = population.reset_index()\n    transitions = transitions.set_index([\"index\", \"pid\"])\n    transitions.act = transitions.act.astype(str)\n    transitions = (\n        transitions.act\n        + \"&gt;\"\n        + transitions.act.shift(-1)\n        + \"&gt;\"\n        + transitions.act.shift(-2)\n    )\n    transitions = transitions.drop(transitions.groupby(\"pid\").tail(2).index)\n    transitions = (\n        transitions.groupby(\"pid\")\n        .value_counts()\n        .unstack()\n        .fillna(0)\n        .astype(int)\n        .to_dict(orient=\"list\")\n    )\n    return weighted_features(transitions)\n</code></pre>"},{"location":"reference/caveat/evaluate/features/transitions/#caveat.evaluate.features.transitions.transitions_by_act","title":"<code>transitions_by_act(population)</code>","text":"Source code in <code>caveat/evaluate/features/transitions.py</code> <pre><code>def transitions_by_act(\n    population: DataFrame,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    transitions = population.reset_index()\n    transitions = transitions.set_index([\"index\", \"pid\"])\n    transitions.act = transitions.act.astype(str)\n    transitions = transitions.act + \"&gt;\" + transitions.act.shift(-1)\n    transitions = transitions.drop(transitions.groupby(\"pid\").tail(1).index)\n    transitions = (\n        transitions.groupby(\"pid\")\n        .value_counts()\n        .unstack()\n        .fillna(0)\n        .astype(int)\n        .to_dict(orient=\"list\")\n    )\n    return weighted_features(transitions)\n</code></pre>"},{"location":"reference/caveat/evaluate/features/utils/","title":"caveat.evaluate.features.utils","text":""},{"location":"reference/caveat/evaluate/features/utils/#caveat.evaluate.features.utils.bin_values","title":"<code>bin_values(values, bin_size)</code>","text":"<p>Bins the input values based on the given bin size.</p> PARAMETER DESCRIPTION <code>values</code> <p>Input values to be binned.</p> <p> TYPE: <code>array</code> </p> <code>bin_size</code> <p>Size of each bin.</p> <p> TYPE: <code>(int, float)</code> </p> RETURNS DESCRIPTION <code>array</code> <p>Binned values.</p> <p> TYPE: <code>ndarray</code> </p> Source code in <code>caveat/evaluate/features/utils.py</code> <pre><code>def bin_values(values: array, bin_size: Union[int, float]) -&gt; ndarray:\n    \"\"\"\n    Bins the input values based on the given bin size.\n\n    Args:\n        values (array): Input values to be binned.\n        bin_size (int, float): Size of each bin.\n\n    Returns:\n        array: Binned values.\n    \"\"\"\n    return (values // bin_size * bin_size) + (bin_size / 2)\n</code></pre>"},{"location":"reference/caveat/evaluate/features/utils/#caveat.evaluate.features.utils.compress_feature","title":"<code>compress_feature(feature, bin_size=None, factor=1440)</code>","text":"<p>Compresses a feature by optionally binning its values and returning unique values with counts.</p> PARAMETER DESCRIPTION <code>feature</code> <p>The feature to compress.</p> <p> TYPE: <code>list</code> </p> <code>bin_size</code> <p>The size of each bin. If None, no binning is performed.</p> <p> TYPE: <code>int</code> DEFAULT: <code>None</code> </p> <code>factor</code> <p>Factor to apply to convert output values.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1440</code> </p> RETURNS DESCRIPTION <code>tuple</code> <p>A tuple containing two arrays and the total weight. The first array contains the unique values, and the second  array contains the counts of each value.</p> <p> TYPE: <code>tuple[ndarray, ndarray]</code> </p> Source code in <code>caveat/evaluate/features/utils.py</code> <pre><code>def compress_feature(\n    feature: list, bin_size: Optional[int] = None, factor: int = 1440\n) -&gt; tuple[ndarray, ndarray]:\n    \"\"\"\n    Compresses a feature by optionally binning its values and returning unique values with counts.\n\n    Args:\n        feature (list): The feature to compress.\n        bin_size (int, optional): The size of each bin. If None, no binning is performed.\n        factor (int): Factor to apply to convert output values.\n\n    Returns:\n        tuple: A tuple containing two arrays and the total weight. The first array contains the unique\n            values, and the second  array contains the counts of each value.\n    \"\"\"\n    try:  # todo remove try-catch\n        s = array(feature)\n        if bin_size is not None:\n            s = bin_values(s, bin_size)\n        ks, ws = unique(s, axis=0, return_counts=True)\n        ks = ks / factor\n        return ks, ws\n    except Exception as e:\n        print(f\"Error: {e}\")\n        print(f\"Feature: {feature}\")\n        raise e\n</code></pre>"},{"location":"reference/caveat/evaluate/features/utils/#caveat.evaluate.features.utils.equals","title":"<code>equals(a, b)</code>","text":"Source code in <code>caveat/evaluate/features/utils.py</code> <pre><code>def equals(\n    a: dict[str, tuple[ndarray, ndarray]], b: dict[str, tuple[ndarray, ndarray]]\n) -&gt; bool:\n    if set(a.keys()) != set(b.keys()):\n        return False\n    for k in a.keys():\n        if not len(a[k][0]) == len(b[k][0]):\n            return False\n        if not len(a[k][1]) == len(b[k][1]):\n            return False\n        if not (a[k][0] == b[k][0]).all():\n            return False\n        if not (a[k][1] == b[k][1]).all():\n            return False\n    return True\n</code></pre>"},{"location":"reference/caveat/evaluate/features/utils/#caveat.evaluate.features.utils.weighted_features","title":"<code>weighted_features(features, bin_size=None, factor=1)</code>","text":"<p>Apply optional binning and value counting to dictionary of features.</p> PARAMETER DESCRIPTION <code>features</code> <p>A dictionary of features to compress.</p> <p> TYPE: <code>dict[array</code> </p> <code>bin_size</code> <p>The size of the bin to use for compression. Defaults to None.</p> <p> TYPE: <code>Optional[int]</code> DEFAULT: <code>None</code> </p> <code>factor</code> <p>Factor to apply to convert output values.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>dict[str, tuple[ndarray, ndarray]]</code> <p>dict[str, tuple[array, array[int]]]: A dictionary of features and weights.</p> Source code in <code>caveat/evaluate/features/utils.py</code> <pre><code>def weighted_features(\n    features: dict[str, ndarray],\n    bin_size: Optional[int] = None,\n    factor: int = 1,\n) -&gt; dict[str, tuple[ndarray, ndarray]]:\n    \"\"\"\n    Apply optional binning and value counting to dictionary of features.\n\n    Args:\n        features (dict[array): A dictionary of features to compress.\n        bin_size (Optional[int]): The size of the bin to use for compression. Defaults to None.\n        factor (int): Factor to apply to convert output values.\n\n    Returns:\n        dict[str, tuple[array, array[int]]]: A dictionary of features and weights.\n    \"\"\"\n    return {\n        k: compress_feature(values, bin_size, factor)\n        for k, values in features.items()\n    }\n</code></pre>"},{"location":"reference/caveat/experiment/","title":"caveat.experiment","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment","title":"<code>Experiment(in_shape, encodings, encoding_weights=None, labels_size=None, sos=0, gen=False, test=False, LR=0.001, weight_decay=0.01, **kwargs)</code>","text":"<p>               Bases: <code>LightningModule</code></p> Source code in <code>caveat/experiment.py</code> <pre><code>def __init__(\n    self,\n    in_shape: tuple,\n    encodings: int,\n    encoding_weights: Optional[Tensor] = None,\n    labels_size: Optional[tuple] = None,\n    sos: int = 0,\n    gen: bool = False,\n    test: bool = False,\n    LR: float = 0.001,\n    weight_decay: float = 0.01,\n    **kwargs,\n) -&gt; None:\n    super(Experiment, self).__init__()\n    self.gen = gen\n    self.test = test\n    self.LR = LR\n    self.weight_decay = weight_decay\n    self.kwargs = kwargs\n    self.curr_device = None\n    self.save_hyperparameters()\n    \"\"\"Base VAE.\n\n    Args:\n        in_shape (tuple[int, int]): [time_step, activity one-hot encoding].\n        encodings (int): Number of activity encodings.\n        encoding_weights (tensor): Weights for activity encodings.\n        labels_size (int, optional): Size of labels encoding. Defaults to None.\n        sos (int, optional): Start of sequence token. Defaults to 0.\n        config: Additional arguments from config.\n    \"\"\"\n    # encoding params\n    self.in_shape = in_shape\n    print(f\"Found input shape: {self.in_shape}\")\n    self.encodings = encodings\n    print(f\"Found encodings: {self.encodings}\")\n    self.encoding_weights = encoding_weights\n    print(f\"Found encoding weights: {self.encoding_weights}\")\n    self.labels_size = labels_size\n    if self.labels_size is not None:\n        print(f\"Found labels size: {self.labels_size}\")\n    self.label_embed_sizes = kwargs.get(\"label_embed_sizes\", None)\n    self.sos = sos\n    print(f\"Found start of sequence token: {self.sos}\")\n    self.teacher_forcing_ratio = kwargs.get(\"teacher_forcing_ratio\", 0.5)\n    print(f\"Found teacher forcing ratio: {self.teacher_forcing_ratio}\")\n\n    # loss function params\n    self.kld_loss_weight = kwargs.get(\"kld_weight\", 0.001)\n    print(f\"Found KLD weight: {self.kld_loss_weight}\")\n\n    self.activity_loss_weight = kwargs.get(\"activity_loss_weight\", 1.0)\n    self.duration_loss_weight = kwargs.get(\"duration_loss_weight\", 1.0)\n    print(f\"Found activity loss weight: {self.activity_loss_weight}\")\n    print(f\"Found duration loss weight: {self.duration_loss_weight}\")\n\n    self.label_loss_weight = kwargs.get(\"label_loss_weight\", 0.0001)\n    print(f\"Found labels loss weight: {self.label_loss_weight}\")\n\n    self.use_mask = kwargs.get(\"use_mask\", True)\n    print(f\"Using mask: {self.use_mask}\")\n\n    self.use_weighted_loss = kwargs.get(\"weighted_loss\", True)\n    print(f\"Using weighted loss: {self.use_weighted_loss}\")\n\n    # set up weighted loss\n    if self.use_weighted_loss and self.encoding_weights is not None:\n        print(\"Using weighted loss function\")\n        self.NLLL = nn.NLLLoss(weight=self.encoding_weights)\n    else:\n        self.NLLL = nn.NLLLoss()\n\n    self.base_NLLL = nn.NLLLoss(reduction=\"none\")\n\n    self.loss = nn.NLLLoss(reduction=\"none\")\n    self.MSE = nn.MSELoss(reduction=\"none\")\n\n    # set up scheduled loss function weights\n    self.scheduled_kld_weight = 1.0\n    self.scheduled_act_weight = 1.0\n    self.scheduled_dur_weight = 1.0\n    self.scheduled_label_weight = 1.0\n\n    self.build(**kwargs)\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.LR","title":"<code>LR = LR</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.MSE","title":"<code>MSE = nn.MSELoss(reduction='none')</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.NLLL","title":"<code>NLLL = nn.NLLLoss(weight=self.encoding_weights)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.activity_loss_weight","title":"<code>activity_loss_weight = kwargs.get('activity_loss_weight', 1.0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.base_NLLL","title":"<code>base_NLLL = nn.NLLLoss(reduction='none')</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.curr_device","title":"<code>curr_device = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.duration_loss_weight","title":"<code>duration_loss_weight = kwargs.get('duration_loss_weight', 1.0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.encoding_weights","title":"<code>encoding_weights = encoding_weights</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.encodings","title":"<code>encodings = encodings</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.gen","title":"<code>gen = gen</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.in_shape","title":"<code>in_shape = in_shape</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.kld_loss_weight","title":"<code>kld_loss_weight = kwargs.get('kld_weight', 0.001)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.kwargs","title":"<code>kwargs = kwargs</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.label_embed_sizes","title":"<code>label_embed_sizes = kwargs.get('label_embed_sizes', None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.label_loss_weight","title":"<code>label_loss_weight = kwargs.get('label_loss_weight', 0.0001)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.labels_size","title":"<code>labels_size = labels_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.loss","title":"<code>loss = nn.NLLLoss(reduction='none')</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.scheduled_act_weight","title":"<code>scheduled_act_weight = 1.0</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.scheduled_dur_weight","title":"<code>scheduled_dur_weight = 1.0</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.scheduled_kld_weight","title":"<code>scheduled_kld_weight = 1.0</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.scheduled_label_weight","title":"<code>scheduled_label_weight = 1.0</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.teacher_forcing_ratio","title":"<code>teacher_forcing_ratio = kwargs.get('teacher_forcing_ratio', 0.5)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.test","title":"<code>test = test</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.use_mask","title":"<code>use_mask = kwargs.get('use_mask', True)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.use_weighted_loss","title":"<code>use_weighted_loss = kwargs.get('weighted_loss', True)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.weight_decay","title":"<code>weight_decay = weight_decay</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def configure_optimizers(self):\n    optimizer = optim.AdamW(\n        self.parameters(), lr=self.LR, weight_decay=self.weight_decay\n    )\n\n    scheduler = self.get_scheduler(optimizer)\n\n    return [optimizer], [scheduler]\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.get_scheduler","title":"<code>get_scheduler(optimizer)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def get_scheduler(self, optimizer):\n    if self.kwargs.get(\"scheduler_gamma\") is not None:\n        print(\"Using ExponentialLR scheduler\")\n        scheduler = optim.lr_scheduler.ExponentialLR(\n            optimizer, gamma=self.kwargs[\"scheduler_gamma\"]\n        )\n\n    elif self.kwargs.get(\"warmup\") is not None:\n        lr_mul = self.kwargs.get(\"lr_mul\", 2)\n        d_model = self.kwargs.get(\"d_model\", 512)\n        n_warmup_steps = self.kwargs.get(\"warmup\")\n        print(\"Using ScheduledOptim scheduler\")\n        scheduler = {\n            \"scheduler\": ScheduledOptim(\n                optimizer,\n                lr_mul=lr_mul,\n                d_model=d_model,\n                n_warmup_steps=n_warmup_steps,\n            ),\n            \"monitor\": \"val_loss\",\n            \"interval\": \"step\",\n        }\n\n    else:\n        raise UserWarning(\"No scheduler specified\")\n\n    return scheduler\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.on_validation_end","title":"<code>on_validation_end()</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def on_validation_end(self) -&gt; None:\n    if self.gen:\n        self.regenerate_val_batch()\n        self.sample_sequences()\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.on_validation_epoch_end","title":"<code>on_validation_epoch_end()</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def on_validation_epoch_end(self) -&gt; None:\n    return super().on_validation_epoch_end()\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.predict_step","title":"<code>predict_step(batch)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def predict_step(self, batch):\n    # YUCK\n    if len(batch) == 2:  # generative process\n        zs, labels = batch\n        return (\n            labels,\n            self.predict(zs, labels=labels, device=self.curr_device),\n            zs,\n        )\n    # inference process\n    (x, _), (_, _), (labels, _) = batch\n    preds, zs = self.infer(x, labels=labels, device=self.curr_device)\n    return x, preds, zs, labels\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.regenerate_batch","title":"<code>regenerate_batch(x, target, name, labels=None)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def regenerate_batch(\n    self,\n    x: Tensor,\n    target: Tensor,\n    name: str,\n    labels: Optional[Tensor] = None,\n):\n    probs, _ = self.infer(x, labels=labels, device=self.curr_device)\n    probs = probs.squeeze()\n    image = unpack(target, probs, self.curr_device)\n    div = torch.ones_like(probs)\n    images = torch.cat((image.squeeze(), div, probs), dim=-1)\n    vutils.save_image(\n        pre_process(images.data),\n        Path(\n            self.logger.log_dir,\n            name,\n            f\"recons_{self.logger.name}_epoch_{self.current_epoch}.png\",\n        ),\n        normalize=False,\n        nrow=1,\n        pad_value=1,\n    )\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.regenerate_val_batch","title":"<code>regenerate_val_batch()</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def regenerate_val_batch(self):\n    (x, _), (y, _), (labels, _) = next(\n        iter(self.trainer.datamodule.val_dataloader())\n    )\n    x = x.to(self.curr_device)\n    y = y.to(self.curr_device)\n    labels = labels.to(self.curr_device)\n    self.regenerate_batch(\n        x, target=y, name=\"reconstructions\", labels=labels\n    )\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.sample_sequences","title":"<code>sample_sequences(name='samples')</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def sample_sequences(self, name: str = \"samples\") -&gt; None:\n    _, _, (labels, _) = next(\n        iter(self.trainer.datamodule.test_dataloader())\n    )\n    labels = labels.to(self.curr_device)\n    z = torch.randn(len(labels), self.latent_dim)\n    y_probs = self.predict(z, labels=labels, device=self.curr_device)\n    vutils.save_image(\n        pre_process(y_probs.cpu().data),\n        Path(\n            self.logger.log_dir,\n            name,\n            f\"{self.logger.name}_epoch_{self.current_epoch}.png\",\n        ),\n        normalize=False,\n        nrow=1,\n        pad_value=1,\n    )\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.test_step","title":"<code>test_step(batch, batch_idx)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def test_step(self, batch, batch_idx):\n    if self.test:\n        (x, x_weights), (y, y_weights), (labels, l_weights) = batch\n        self.curr_device = x.device\n\n        log_probs_x, mu, log_var, z = self.forward(\n            x, labels=labels, input_mask=x_weights\n        )\n        test_loss = self.loss_function(\n            log_probs_x=log_probs_x,\n            mu=mu,\n            log_var=log_var,\n            target=y,\n            weights=y_weights,\n            label_weights=l_weights,\n            # batch_idx=batch_idx,\n        )\n\n        self.log_dict(\n            {f\"test_{key}\": val.item() for key, val in test_loss.items()},\n            sync_dist=True,\n            on_step=False,\n            on_epoch=True,\n            prog_bar=True,\n        )\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def training_step(self, batch, batch_idx):\n    (x, x_weights), (y, y_weights), (labels, l_weights) = batch\n\n    self.curr_device = x.device\n    log_probs, mu, log_var, z = self.forward(\n        x, labels=labels, target=y, input_mask=x_weights\n    )\n    train_loss = self.loss_function(\n        log_probs=log_probs,\n        mu=mu,\n        log_var=log_var,\n        target=y,\n        weights=y_weights,\n        label_weights=l_weights,\n        # batch_idx=batch_idx,\n    )\n    self.log_dict(\n        {key: val.item() for key, val in train_loss.items()}, sync_dist=True\n    )\n\n    return train_loss[\"loss\"]\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.Experiment.validation_step","title":"<code>validation_step(batch, batch_idx, optimizer_idx=0)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def validation_step(self, batch, batch_idx, optimizer_idx=0):\n    (x, x_weights), (y, y_weights), (labels, l_weights) = batch\n    self.curr_device = x.device\n\n    log_probs, mu, log_var, z = self.forward(\n        x, labels=labels, input_mask=x_weights\n    )\n    val_loss = self.loss_function(\n        log_probs=log_probs,\n        mu=mu,\n        log_var=log_var,\n        target=y,\n        weights=y_weights,\n        label_weights=l_weights,\n        # optimizer_idx=optimizer_idx,\n        # batch_idx=batch_idx,\n    )\n\n    self.log_dict(\n        {f\"val_{key}\": val.item() for key, val in val_loss.items()},\n        sync_dist=True,\n        on_step=False,\n        on_epoch=True,\n        prog_bar=True,\n    )\n    self.log(\"hp_metric\", val_loss[\"loss\"])\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.pre_process","title":"<code>pre_process(images)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def pre_process(images):\n    # hack for dealing with outputs encoded as [N, h, w]\n    # need to add channel dim and rearrange to [N, C, h, w]\n    # todo remove C/3d encoder\n    s = images.shape\n    if len(s) == 3:\n        # need to add dim and move channel to front\n        return images.reshape(s[0], s[1], s[2], 1).permute(0, 3, 1, 2)\n    return images\n</code></pre>"},{"location":"reference/caveat/experiment/#caveat.experiment.unpack","title":"<code>unpack(x, y, current_device)</code>","text":"Source code in <code>caveat/experiment.py</code> <pre><code>def unpack(x, y, current_device):\n    if x.dim() == 2:\n        # assume cat encoding and unpack into image\n        channels = y.shape[-1]\n        eye = torch.eye(channels)\n        eye = eye.to(current_device)\n        ximage = eye[x.long()].squeeze()\n        return ximage\n\n    elif x.shape[-1] == 2:\n        # assume cat encoding and unpack into image\n        channels = y.shape[-1] - 1\n        acts, durations = x.split([1, 1], dim=-1)\n        eye = torch.eye(channels)\n        eye = eye.to(current_device)\n        ximage = eye[acts.long()].squeeze()\n        ximage = torch.cat((ximage, durations), dim=-1)\n        return ximage\n    elif 1 in x.shape:\n        print(f\"Unknown encoding; {x.shape}, squeezing\")\n        return unpack(x.squeeze(), y.squeeze(), current_device)\n    else:\n        print(f\"Unknown encoding; {x.shape}, returning input x\")\n    return x\n</code></pre>"},{"location":"reference/caveat/jrunners/","title":"caveat.jrunners","text":""},{"location":"reference/caveat/jrunners/#caveat.jrunners.generate","title":"<code>generate(trainer, population, schedule_encoder, attribute_encoder, config, write_dir, seed, ckpt_path=None)</code>","text":"Source code in <code>caveat/jrunners.py</code> <pre><code>def generate(\n    trainer: Trainer,\n    population: int,\n    schedule_encoder: encoding.BaseEncoder,\n    attribute_encoder: label_encoding.BaseLabelEncoder,\n    config: dict,\n    write_dir: Path,\n    seed: int,\n    ckpt_path: Optional[str] = None,\n) -&gt; DataFrame:\n    torch.manual_seed(seed)\n    if ckpt_path is None:\n        ckpt_path = \"best\"\n    latent_dims = config.get(\"model_params\", {}).get(\"latent_dim\")\n    if latent_dims is None:\n        latent_dims = config.get(\"experiment_params\", {}).get(\"latent_dims\", 2)\n        # default of 2\n    batch_size = config.get(\"generator_params\", {}).get(\"batch_size\", 256)\n\n    if isinstance(population, int):\n        print(f\"\\n======= Sampling {population} new schedules =======\")\n        synthetic_schedules, synthetic_labels, zs = generate_n(\n            trainer,\n            n=population,\n            batch_size=batch_size,\n            latent_dims=latent_dims,\n            seed=seed,\n            ckpt_path=ckpt_path,\n        )\n        synthetic_attributes = None\n\n    synthetic_schedules = schedule_encoder.decode(schedules=synthetic_schedules)\n    data.validate_schedules(synthetic_schedules)\n    synthetic_schedules.to_csv(write_dir / \"synthetic_schedules.csv\")\n\n    synthetic_attributes = attribute_encoder.sample_decode(synthetic_labels)\n    synthetic_attributes.to_csv(write_dir / \"synthetic_labels.csv\")\n\n    DataFrame(zs.cpu().numpy()).to_csv(\n        Path(write_dir, \"synthetic_zs.csv\"), index=False, header=False\n    )\n    return synthetic_schedules, synthetic_attributes, zs\n</code></pre>"},{"location":"reference/caveat/jrunners/#caveat.jrunners.generate_n","title":"<code>generate_n(trainer, n, batch_size, latent_dims, seed, ckpt_path)</code>","text":"Source code in <code>caveat/jrunners.py</code> <pre><code>def generate_n(\n    trainer: Trainer,\n    n: int,\n    batch_size: int,\n    latent_dims: int,\n    seed: int,\n    ckpt_path: str,\n) -&gt; torch.Tensor:\n    torch.manual_seed(seed)\n    dataloaders = data.build_latent_dataloader(n, latent_dims, batch_size)\n    synth = trainer.predict(ckpt_path=ckpt_path, dataloaders=dataloaders)\n    synthetic_schedules, synthetic_labels, zs = zip(*synth)\n    synthetic_schedules = torch.concat(synthetic_schedules)\n    synthetic_labels = repack_labels(synthetic_labels)\n    zs = torch.concat(zs)\n    return synthetic_schedules, synthetic_labels, zs\n</code></pre>"},{"location":"reference/caveat/jrunners/#caveat.jrunners.jbatch_command","title":"<code>jbatch_command(batch_config, stats=False, verbose=False, gen=True, test=False, infer=True, sample=True, patience=8)</code>","text":"<p>Batch runs the training for joint-model variation.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing the configuration parameters.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>caveat/jrunners.py</code> <pre><code>def jbatch_command(\n    batch_config: dict,\n    stats: bool = False,\n    verbose: bool = False,\n    gen: bool = True,\n    test: bool = False,\n    infer=True,\n    sample: bool = True,\n    patience: int = 8,\n) -&gt; None:\n    \"\"\"\n    Batch runs the training for joint-model variation.\n\n    Args:\n        config (dict): A dictionary containing the configuration parameters.\n\n    Returns:\n        None\n    \"\"\"\n\n    global_config = batch_config.pop(\"global\")\n    logger_params = global_config.get(\"logging_params\", {})\n    name = str(\n        logger_params.get(\n            \"name\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        )\n    )\n    log_dir = Path(logger_params.get(\"log_dir\", \"logs\"), name)\n\n    synthetic_schedules_all = {}\n    synthetic_attributes_all = {}\n\n    for name, config in batch_config.items():\n        name = str(name)\n        logger = initiate_logger(log_dir, name)\n\n        # build config for this run\n        combined_config = global_config.copy()\n        combined_config.update(config)\n        seed = combined_config.pop(\"seed\", seeder())\n\n        attribute_encoder = combined_config.get(\"attribute_encoder\", None)\n        if attribute_encoder is None or attribute_encoder != \"tokens\":\n            raise ValueError(\n                \"Joint model requires attribute_encoder to be configured as 'tokens'.\"\n            )\n\n        conditionals = combined_config.get(\"conditionals\", None)\n        if conditionals is None:\n            raise ValueError(\"No conditionals provided in the config.\")\n\n        # load data\n        input_schedules, input_labels, synthetic_labels = load_data(\n            combined_config\n        )\n\n        # encode data\n        attribute_encoder, encoded_labels, label_weights = encode_input_labels(\n            logger.log_dir, input_labels, combined_config\n        )\n\n        schedule_encoder, encoded_schedules, data_loader = encode_schedules(\n            logger.log_dir,\n            input_schedules,\n            encoded_labels,\n            label_weights,\n            combined_config,\n        )\n\n        # train\n        trainer = train(\n            name=name,\n            data_loader=data_loader,\n            encoded_schedules=encoded_schedules,\n            label_encoder=attribute_encoder,\n            config=combined_config,\n            test=test,\n            gen=gen,\n            logger=logger,\n            seed=seed,\n        )\n\n        if test:\n            # test the model\n            run_test(\n                trainer=trainer,\n                schedule_encoder=schedule_encoder,\n                write_dir=Path(logger.log_dir),\n                seed=seed,\n            )\n\n        if infer:\n            test_infer_path = Path(f\"{logger.log_dir}/test_inference\")\n            test_infer_path.mkdir(exist_ok=True, parents=True)\n\n            test_inference(\n                trainer=trainer,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=attribute_encoder,\n                write_dir=test_infer_path,\n                seed=seed,\n            )\n\n        if gen:\n            # prepare synthetic sample size\n            if synthetic_labels is not None:\n                synthetic_population = len(synthetic_labels)\n            else:\n                synthetic_population = input_schedules.pid.nunique()\n\n            if sample:\n                synthetic_labels, synthetic_schedules = target_sample(\n                    conditionals=list(conditionals.keys()),\n                    patience=patience,\n                    synthetic_population=synthetic_population,\n                    trainer=trainer,\n                    schedule_encoder=schedule_encoder,\n                    attribute_encoder=attribute_encoder,\n                    config=combined_config,\n                    log_dir=Path(logger.log_dir),\n                    seed=seed,\n                    synthetic_labels=synthetic_labels,\n                    verbose=verbose,\n                )\n            else:\n                # generate synthetic schedules\n                synthetic_schedules, synthetic_labels, _ = generate(\n                    trainer=trainer,\n                    population=synthetic_population,\n                    schedule_encoder=schedule_encoder,\n                    attribute_encoder=attribute_encoder,\n                    config=combined_config,\n                    write_dir=Path(logger.log_dir),\n                    seed=seed,\n                )\n            synthetic_schedules_all[name] = synthetic_schedules\n            synthetic_attributes_all[name] = synthetic_labels\n\n    if gen:\n        # evaluate synthetic schedules\n        evaluate_synthetics(\n            synthetic_schedules=synthetic_schedules_all,\n            synthetic_attributes=synthetic_attributes_all,\n            default_eval_schedules=input_schedules,\n            default_eval_attributes=input_labels,\n            write_path=Path(log_dir),\n            eval_params=global_config.get(\"evaluation_params\", {}),\n            stats=stats,\n            verbose=verbose,\n        )\n</code></pre>"},{"location":"reference/caveat/jrunners/#caveat.jrunners.jrun_command","title":"<code>jrun_command(config, verbose=False, gen=True, test=False, infer=True, sample=True, patience=8)</code>","text":"<p>Runs the training for joint-model variation.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing the configuration parameters.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>caveat/jrunners.py</code> <pre><code>def jrun_command(\n    config: dict,\n    verbose: bool = False,\n    gen: bool = True,\n    test: bool = False,\n    infer=True,\n    sample: bool = True,\n    patience: int = 8,\n) -&gt; None:\n    \"\"\"\n    Runs the training for joint-model variation.\n\n    Args:\n        config (dict): A dictionary containing the configuration parameters.\n\n    Returns:\n        None\n    \"\"\"\n    labels_encoder_config = config.get(\"labels_encoder\", {})\n    labels_encoder = labels_encoder_config.get(\"name\", None)\n    if labels_encoder is None or labels_encoder != \"tokens\":\n        raise ValueError(\n            \"Joint model requires attribute_encoder to be configured as 'tokens'.\"\n        )\n\n    labels_config = labels_encoder_config.get(\"labels\", None)\n    if labels_config is None:\n        raise ValueError(\"No labels provided in the labels_encoder config.\")\n\n    logger_params = config.get(\"logging_params\", {})\n    log_dir = Path(logger_params.get(\"log_dir\", \"logs\"))\n    name = str(\n        logger_params.get(\n            \"name\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        )\n    )\n    logger = initiate_logger(log_dir, name)\n    seed = config.pop(\"seed\", seeder())\n\n    # load data\n    input_schedules, input_labels, synthetic_labels = load_data(config)\n\n    # encode data\n    labels_encoder, encoded_labels, label_weights = encode_input_labels(\n        logger.log_dir, input_labels, config\n    )\n\n    schedule_encoder, encoded_schedules, data_loader = encode_schedules(\n        logger.log_dir, input_schedules, encoded_labels, label_weights, config\n    )\n\n    # train\n    trainer = train(\n        name=name,\n        data_loader=data_loader,\n        encoded_schedules=encoded_schedules,\n        label_encoder=labels_encoder,\n        config=config,\n        test=test,\n        gen=gen,\n        logger=logger,\n        seed=seed,\n    )\n\n    if test:\n        # test the model\n        run_test(\n            trainer=trainer,\n            schedule_encoder=schedule_encoder,\n            write_dir=Path(logger.log_dir),\n            seed=seed,\n        )\n\n    if infer:\n        test_infer_path = Path(f\"{logger.log_dir}/test_inference\")\n        test_infer_path.mkdir(exist_ok=True, parents=True)\n\n        test_inference(\n            trainer=trainer,\n            schedule_encoder=schedule_encoder,\n            attribute_encoder=labels_encoder,\n            write_dir=test_infer_path,\n            seed=seed,\n        )\n\n    if gen:\n        # prepare target sample size\n        if synthetic_labels is not None:\n            synthetic_population = len(synthetic_labels)\n        else:\n            synthetic_population = input_schedules.pid.nunique()\n\n        if sample:\n            synthetic_labels, synthetic_schedules = target_sample(\n                conditionals=list(labels_config.keys()),\n                patience=patience,\n                synthetic_population=synthetic_population,\n                trainer=trainer,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=labels_encoder,\n                config=config,\n                log_dir=Path(logger.log_dir),\n                seed=seed,\n                synthetic_labels=synthetic_labels,\n                verbose=verbose,\n            )\n        else:\n            # generate synthetic schedules\n            synthetic_schedules, synthetic_labels, _ = generate(\n                trainer=trainer,\n                population=synthetic_population,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=labels_encoder,\n                config=config,\n                write_dir=Path(logger.log_dir),\n                seed=seed,\n            )\n\n        # evaluate synthetic schedules\n        evaluate_synthetics(\n            synthetic_schedules={name: synthetic_schedules},\n            synthetic_attributes={name: synthetic_labels},\n            default_eval_schedules=input_schedules,\n            default_eval_attributes=input_labels,\n            write_path=Path(logger.log_dir),\n            eval_params=config.get(\"evaluation_params\", {}),\n            stats=False,\n            verbose=verbose,\n        )\n</code></pre>"},{"location":"reference/caveat/jrunners/#caveat.jrunners.random_seed","title":"<code>random_seed()</code>","text":"Source code in <code>caveat/jrunners.py</code> <pre><code>def random_seed():\n    return random.randint(1000, 1000000000)\n</code></pre>"},{"location":"reference/caveat/jrunners/#caveat.jrunners.repack_labels","title":"<code>repack_labels(batched_labels)</code>","text":"Source code in <code>caveat/jrunners.py</code> <pre><code>def repack_labels(batched_labels: Tuple[List[Tensor]]) -&gt; List[Tensor]:\n    batched_labels = list(batched_labels)\n    if len(batched_labels) == 1:\n        return batched_labels[0]\n    else:\n        unpacked_labels = batched_labels.pop(0)\n        for batch in batched_labels:\n            for i, labels in enumerate(batch):\n                unpacked_labels[i] = torch.concat((unpacked_labels[i], labels))\n        return unpacked_labels\n</code></pre>"},{"location":"reference/caveat/jrunners/#caveat.jrunners.target_sample","title":"<code>target_sample(conditionals, patience, synthetic_population, trainer, schedule_encoder, attribute_encoder, config, log_dir, seed, synthetic_labels=None, verbose=False)</code>","text":"<p>Sample synthetic schedules and labels for target labels. Repeatedly calls the model generate function until the target labels are sampled. Or runs out of patience.</p> PARAMETER DESCRIPTION <code>conditionals</code> <p>description</p> <p> TYPE: <code>list</code> </p> <code>patience</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>synthetic_population</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>trainer</code> <p>description</p> <p> TYPE: <code>Trainer</code> </p> <code>schedule_encoder</code> <p>description</p> <p> TYPE: <code>BaseEncoder</code> </p> <code>attribute_encoder</code> <p>description</p> <p> TYPE: <code>BaseLabelEncoder</code> </p> <code>config</code> <p>description</p> <p> TYPE: <code>dict</code> </p> <code>log_dir</code> <p>description</p> <p> TYPE: <code>Path</code> </p> <code>seed</code> <p>description</p> <p> TYPE: <code>int</code> </p> <code>synthetic_labels</code> <p>description. Defaults to None.</p> <p> TYPE: <code>Optional[DataFrame]</code> DEFAULT: <code>None</code> </p> <code>verbose</code> <p>description. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>Tuple[DataFrame, DataFrame]</code> <p>Tuple[DataFrame, DataFrame]: description</p> Source code in <code>caveat/jrunners.py</code> <pre><code>def target_sample(\n    conditionals: list,\n    patience: int,\n    synthetic_population: int,\n    trainer: Trainer,\n    schedule_encoder: encoding.BaseEncoder,\n    attribute_encoder: label_encoding.BaseLabelEncoder,\n    config: dict,\n    log_dir: Path,\n    seed: int,\n    synthetic_labels: Optional[DataFrame] = None,\n    verbose: bool = False,\n) -&gt; Tuple[DataFrame, DataFrame]:\n    \"\"\"\n    Sample synthetic schedules and labels for target labels.\n    Repeatedly calls the model generate function until the target labels are sampled.\n    Or runs out of patience.\n\n    Args:\n        conditionals (list): _description_\n        patience (int): _description_\n        synthetic_population (int): _description_\n        trainer (Trainer): _description_\n        schedule_encoder (encoding.BaseEncoder): _description_\n        attribute_encoder (attribute_encoding.BaseLabelEncoder): _description_\n        config (dict): _description_\n        log_dir (Path): _description_\n        seed (int): _description_\n        synthetic_labels (Optional[DataFrame], optional): _description_. Defaults to None.\n        verbose (bool, optional): _description_. Defaults to False.\n\n    Returns:\n        Tuple[DataFrame, DataFrame]: _description_\n    \"\"\"\n\n    print(\n        f\"\\n======= Sampling {synthetic_population} new schedules for target labels =======\"\n    )\n\n    sampler = samplers.TargetLabelSampler(\n        target_labels=synthetic_labels, target_columns=conditionals\n    )\n\n    for _ in range(patience):\n        random.seed(seed)\n        seed = random_seed()\n\n        # generate synthetic schedules\n        synthetic_schedules, synthetic_labels, _ = generate(\n            trainer=trainer,\n            population=synthetic_population,\n            schedule_encoder=schedule_encoder,\n            attribute_encoder=attribute_encoder,\n            config=config,\n            write_dir=log_dir,\n            seed=seed,\n        )\n        sampler.sample(synthetic_labels, synthetic_schedules)\n        sampler.print(verbose=verbose)\n        if sampler.is_done():\n            break\n    sampler.print(verbose=verbose)\n    return sampler.finish()\n</code></pre>"},{"location":"reference/caveat/jrunners/#caveat.jrunners.test_inference","title":"<code>test_inference(trainer, schedule_encoder, attribute_encoder, write_dir, seed, ckpt_path=None)</code>","text":"Source code in <code>caveat/jrunners.py</code> <pre><code>def test_inference(\n    trainer: Trainer,\n    schedule_encoder: encoding.BaseEncoder,\n    attribute_encoder: label_encoding.BaseLabelEncoder,\n    write_dir: Path,\n    seed: int,\n    ckpt_path: Optional[str] = None,\n):\n    torch.manual_seed(seed)\n    if ckpt_path is None:\n        ckpt_path = \"best\"\n\n    print(\"\\n======= Testing Inference =======\")\n    inference = trainer.predict(\n        ckpt_path=ckpt_path, dataloaders=trainer.datamodule.test_dataloader()\n    )\n    input_schedules, inferred_schedules, input_labels, inferred_labels, zs = (\n        zip(*inference)\n    )\n\n    input_schedules = torch.concat(input_schedules)\n    inferred_schedules = torch.concat(inferred_schedules)\n    input_labels = torch.concat(input_labels)\n    inferred_labels = repack_labels(inferred_labels)\n    zs = torch.concat(zs)\n\n    input_schedules = schedule_encoder.decode(input_schedules, argmax=False)\n    data.validate_schedules(input_schedules)\n    input_schedules.to_csv(write_dir / \"input_schedules.csv\")\n\n    inferred_schedules = schedule_encoder.decode(inferred_schedules)\n    data.validate_schedules(inferred_schedules)\n    inferred_schedules.to_csv(write_dir / \"inferred_schedules.csv\")\n\n    if attribute_encoder is not None:\n        attributes = attribute_encoder.decode(input_labels)\n        attributes.to_csv(write_dir / \"input_labels.csv\")\n        inferred_labels = attribute_encoder.sample_decode(inferred_labels)\n        inferred_labels.to_csv(write_dir / \"inferred_labels.csv\")\n\n    DataFrame(zs.cpu().numpy()).to_csv(\n        Path(write_dir, \"zs.csv\"), index=False, header=False\n    )\n</code></pre>"},{"location":"reference/caveat/label_encoding/base/","title":"caveat.label_encoding.base","text":""},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.joint_label_weights_library","title":"<code>joint_label_weights_library = {'unit': unit_weight, 'inverse': inverse_weight, 'log_inverse': log_inverse_weight, 'inverse_log': inverse_log_weight, 'max_inverse': max_weight, 'prod_inverse': product_weight}</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.label_weights_library","title":"<code>label_weights_library = {'unit': unit_weights, 'inverse': inverse_weights}</code>  <code>module-attribute</code>","text":""},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.BaseLabelEncoder","title":"<code>BaseLabelEncoder(config, **kwargs)</code>","text":"<p>Base Attribute Encoder class.</p> Source code in <code>caveat/label_encoding/base.py</code> <pre><code>def __init__(self, config: dict, **kwargs) -&gt; None:\n    \"\"\"Base Attribute Encoder class.\"\"\"\n    self.config = config.copy()\n    self.label_kwargs = {}\n    self.weighting = kwargs.get(\"weighting\", \"unit\")\n    self.joint_weighting = kwargs.get(\"joint_weighting\", \"unit\")\n\n    self.label_weighter = label_weights_library.get(self.weighting, None)\n    if self.label_weighter is None:\n        raise ValueError(\n            f\"Unknown Label Encoder weighting: {self.label_weighting}, should be one of: {label_weights_library.keys()}\"\n        )\n\n    self.joint_weighter = joint_label_weights_library.get(\n        self.joint_weighting, None\n    )\n    if self.joint_weighter is None:\n        raise ValueError(\n            f\"Unknown Label Encoder weighting: {self.joint_weighting}, should be one of: {joint_label_weights_library.keys()}\"\n        )\n\n    print(\n        f\"\"\"Label Encoder {self.__class__.__name__} initialised with:\n        Label weighting: {self.weighting}\n        Joint weighting: {self.joint_weighting}\n        \"\"\"\n    )\n</code></pre>"},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.BaseLabelEncoder.config","title":"<code>config = config.copy()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.BaseLabelEncoder.joint_weighter","title":"<code>joint_weighter = joint_label_weights_library.get(self.joint_weighting, None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.BaseLabelEncoder.joint_weighting","title":"<code>joint_weighting = kwargs.get('joint_weighting', 'unit')</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.BaseLabelEncoder.label_kwargs","title":"<code>label_kwargs = {}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.BaseLabelEncoder.label_weighter","title":"<code>label_weighter = label_weights_library.get(self.weighting, None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.BaseLabelEncoder.weighting","title":"<code>weighting = kwargs.get('weighting', 'unit')</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.BaseLabelEncoder.decode","title":"<code>decode(data)</code>","text":"Source code in <code>caveat/label_encoding/base.py</code> <pre><code>def decode(self, data: Tensor) -&gt; pd.DataFrame:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.BaseLabelEncoder.encode","title":"<code>encode(data)</code>","text":"Source code in <code>caveat/label_encoding/base.py</code> <pre><code>def encode(self, data: pd.DataFrame) -&gt; Tensor:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.onehot_encode","title":"<code>onehot_encode(data, encodings=None)</code>","text":"Source code in <code>caveat/label_encoding/base.py</code> <pre><code>def onehot_encode(data: pd.Series, encodings: Optional[dict] = None) -&gt; Tensor:\n    nominals, encodings = tokenize(data, encodings)\n    nominals = torch.nn.functional.one_hot(\n        nominals.long(), num_classes=len(encodings)\n    ).float()\n    return nominals, encodings\n</code></pre>"},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.ordinal_encode","title":"<code>ordinal_encode(data, min, max)</code>","text":"Source code in <code>caveat/label_encoding/base.py</code> <pre><code>def ordinal_encode(data: pd.Series, min, max) -&gt; Tensor:\n    encoded = Tensor(data.values).unsqueeze(-1)\n    encoded -= min\n    encoded /= max - min\n    return encoded.float()\n</code></pre>"},{"location":"reference/caveat/label_encoding/base/#caveat.label_encoding.base.tokenize","title":"<code>tokenize(data, encodings=None)</code>","text":"Source code in <code>caveat/label_encoding/base.py</code> <pre><code>def tokenize(data: pd.Series, encodings: Optional[dict] = None) -&gt; Tensor:\n    if encodings:\n        missing = set(data.unique()) - set(encodings.keys())\n        if missing:\n            raise UserWarning(\n                f\"\"\"\n                Categories in data do not match existing categories: {missing}.\n                Please specify the new categories in the encoding.\n                Your existing encodings are: {encodings}\n\"\"\"\n            )\n        nominals = pd.Categorical(data, categories=encodings.keys())\n    else:\n        nominals = pd.Categorical(data)\n        encodings = {e: i for i, e in enumerate(nominals.categories)}\n    nominals = torch.tensor(nominals.codes).int()\n    return nominals, encodings\n</code></pre>"},{"location":"reference/caveat/label_encoding/label_weighting/","title":"caveat.label_encoding.label_weighting","text":""},{"location":"reference/caveat/label_encoding/label_weighting/#caveat.label_encoding.label_weighting.inverse_log_weight","title":"<code>inverse_log_weight(labels)</code>","text":"Source code in <code>caveat/label_encoding/label_weighting.py</code> <pre><code>def inverse_log_weight(labels: Tensor) -&gt; Tensor:\n    _, locs, ws = torch.unique(\n        labels, dim=0, return_counts=True, return_inverse=True\n    )\n    weights = 1 / torch.log(ws[locs] + 0.000001)\n    weights = weights / weights.mean()\n    return weights.unsqueeze(-1)\n</code></pre>"},{"location":"reference/caveat/label_encoding/label_weighting/#caveat.label_encoding.label_weighting.inverse_weight","title":"<code>inverse_weight(labels)</code>","text":"Source code in <code>caveat/label_encoding/label_weighting.py</code> <pre><code>def inverse_weight(labels: Tensor) -&gt; Tensor:\n    _, locs, ws = torch.unique(\n        labels, dim=0, return_counts=True, return_inverse=True\n    )\n    weights = 1 / ws[locs].float()\n    weights = weights / weights.mean()\n    return weights.unsqueeze(-1)\n</code></pre>"},{"location":"reference/caveat/label_encoding/label_weighting/#caveat.label_encoding.label_weighting.inverse_weights","title":"<code>inverse_weights(labels)</code>","text":"Source code in <code>caveat/label_encoding/label_weighting.py</code> <pre><code>def inverse_weights(labels: Tensor) -&gt; Tensor:\n    weights = []\n    for i in range(labels.shape[1]):\n        _, locs, ws = torch.unique(\n            labels[:, i], return_counts=True, return_inverse=True\n        )\n        weights.append(ws[locs].float())\n    weights = torch.stack(weights, dim=1)\n    weights = 1 / weights\n    weights = weights / weights.mean()\n    return weights\n</code></pre>"},{"location":"reference/caveat/label_encoding/label_weighting/#caveat.label_encoding.label_weighting.log_inverse_weight","title":"<code>log_inverse_weight(labels)</code>","text":"Source code in <code>caveat/label_encoding/label_weighting.py</code> <pre><code>def log_inverse_weight(labels: Tensor) -&gt; Tensor:\n    _, locs, ws = torch.unique(\n        labels, dim=0, return_counts=True, return_inverse=True\n    )\n    weights = 1 / ws[locs].float()\n    weights = torch.log(weights)\n    weights = weights / weights.mean()\n    return weights.unsqueeze(-1)\n</code></pre>"},{"location":"reference/caveat/label_encoding/label_weighting/#caveat.label_encoding.label_weighting.max_weight","title":"<code>max_weight(labels)</code>","text":"Source code in <code>caveat/label_encoding/label_weighting.py</code> <pre><code>def max_weight(labels: Tensor) -&gt; Tensor:\n    weights = inverse_weights(labels)\n    weights = weights.max(dim=-1).values.unsqueeze(-1)\n    weights = weights / weights.mean()\n    return weights\n</code></pre>"},{"location":"reference/caveat/label_encoding/label_weighting/#caveat.label_encoding.label_weighting.product_weight","title":"<code>product_weight(labels)</code>","text":"Source code in <code>caveat/label_encoding/label_weighting.py</code> <pre><code>def product_weight(labels: Tensor) -&gt; Tensor:\n    weights = inverse_weights(labels)\n    weights = weights.prod(dim=-1).unsqueeze(-1)\n    weights = weights / weights.mean()\n    return weights\n</code></pre>"},{"location":"reference/caveat/label_encoding/label_weighting/#caveat.label_encoding.label_weighting.unit_weight","title":"<code>unit_weight(labels)</code>","text":"Source code in <code>caveat/label_encoding/label_weighting.py</code> <pre><code>def unit_weight(labels: Tensor) -&gt; Tensor:\n    return torch.ones((labels.shape[0], 1)).float()\n</code></pre>"},{"location":"reference/caveat/label_encoding/label_weighting/#caveat.label_encoding.label_weighting.unit_weights","title":"<code>unit_weights(labels)</code>","text":"Source code in <code>caveat/label_encoding/label_weighting.py</code> <pre><code>def unit_weights(labels: Tensor) -&gt; Tensor:\n    weights = torch.ones_like(labels).float()\n    return weights\n</code></pre>"},{"location":"reference/caveat/label_encoding/onehot/","title":"caveat.label_encoding.onehot","text":""},{"location":"reference/caveat/label_encoding/onehot/#caveat.label_encoding.onehot.OneHotAttributeEncoder","title":"<code>OneHotAttributeEncoder(config, **kwargs)</code>","text":"<p>               Bases: <code>BaseLabelEncoder</code></p> Source code in <code>caveat/label_encoding/base.py</code> <pre><code>def __init__(self, config: dict, **kwargs) -&gt; None:\n    \"\"\"Base Attribute Encoder class.\"\"\"\n    self.config = config.copy()\n    self.label_kwargs = {}\n    self.weighting = kwargs.get(\"weighting\", \"unit\")\n    self.joint_weighting = kwargs.get(\"joint_weighting\", \"unit\")\n\n    self.label_weighter = label_weights_library.get(self.weighting, None)\n    if self.label_weighter is None:\n        raise ValueError(\n            f\"Unknown Label Encoder weighting: {self.label_weighting}, should be one of: {label_weights_library.keys()}\"\n        )\n\n    self.joint_weighter = joint_label_weights_library.get(\n        self.joint_weighting, None\n    )\n    if self.joint_weighter is None:\n        raise ValueError(\n            f\"Unknown Label Encoder weighting: {self.joint_weighting}, should be one of: {joint_label_weights_library.keys()}\"\n        )\n\n    print(\n        f\"\"\"Label Encoder {self.__class__.__name__} initialised with:\n        Label weighting: {self.weighting}\n        Joint weighting: {self.joint_weighting}\n        \"\"\"\n    )\n</code></pre>"},{"location":"reference/caveat/label_encoding/onehot/#caveat.label_encoding.onehot.OneHotAttributeEncoder.decode","title":"<code>decode(data)</code>","text":"Source code in <code>caveat/label_encoding/onehot.py</code> <pre><code>def decode(self, data: Tensor) -&gt; pd.DataFrame:\n    decoded = {\"pid\": list(range(data.shape[0]))}\n    for k, v in self.config.items():\n        location, length, column_type = (\n            v[\"location\"],\n            v[\"length\"],\n            v[\"type\"],\n        )\n        if v.get(\"ordinal\") is not None:\n            min, max = v[\"ordinal\"]\n            decoded[k] = pd.Series(\n                data[:, location] * (max - min) + min\n            ).astype(column_type)\n        elif v.get(\"nominal\") is not None:\n            encoding = {i: name for name, i in v[\"nominal\"].items()}\n            decoded[k] = pd.Series(\n                [\n                    encoding[i]\n                    for i in data[:, location : location + length]\n                    .argmax(dim=-1)\n                    .tolist()\n                ]\n            ).astype(column_type)\n        else:\n            raise UserWarning(\n                f\"Unrecognised attribute encoding in configuration: {k, v}\"\n            )\n\n    return pd.DataFrame(decoded)\n</code></pre>"},{"location":"reference/caveat/label_encoding/onehot/#caveat.label_encoding.onehot.OneHotAttributeEncoder.encode","title":"<code>encode(data)</code>","text":"Source code in <code>caveat/label_encoding/onehot.py</code> <pre><code>def encode(self, data: pd.DataFrame) -&gt; Tensor:\n    i = 0\n    encoded = []\n    for k, v in self.config.copy().items():\n        if k not in data.columns:\n            raise UserWarning(f\"Conditional '{k}' not found in attributes\")\n\n        if isinstance(v, dict):  # Pre-defined encoding\n            if v.get(\"ordinal\"):\n                if not isinstance(v.get(\"ordinal\"), list):\n                    raise UserWarning(\n                        \"Ordinal encoding must be a list of (min, max)\"\n                    )\n                self.validate_previous(k, v, i, 1, data[k])\n                min, max = v[\"ordinal\"]\n                encoded.append(ordinal_encode(data[k], min, max))\n                self.config[k].update(\n                    {\"location\": i, \"length\": 1, \"type\": data[k].dtype}\n                )\n                i += 1\n            elif v.get(\"nominal\"):\n                if not isinstance(v.get(\"nominal\"), dict):\n                    raise UserWarning(\n                        \"Nominal encoding must be a dict of categories to index\"\n                    )\n                self.validate_previous(k, v, i, len(v[\"nominal\"]), data[k])\n                nominal_encoded, _ = onehot_encode(data[k], v[\"nominal\"])\n                encoded.append(nominal_encoded)\n                self.config[k].update(\n                    {\n                        \"location\": i,\n                        \"length\": len(v[\"nominal\"]),\n                        \"type\": data[k].dtype,\n                    }\n                )\n                i += len(v[\"nominal\"])\n            else:\n                raise UserWarning(\n                    f\"Unrecognised attribute encoding in configuration: {v}\"\n                )\n\n        elif v == \"nominal\":  # Undefined nominal encoding\n            nominal_encoded, nominal_encodings = onehot_encode(\n                data[k], None\n            )\n            encoded.append(nominal_encoded)\n            self.config[k] = {\n                \"nominal\": nominal_encodings,\n                \"location\": i,\n                \"length\": len(nominal_encodings),\n                \"type\": data[k].dtype,\n            }\n            i += len(nominal_encodings)\n\n        elif v == \"ordinal\":  # Undefined ordinal encoding\n            min = data[k].min()\n            max = data[k].max()\n            encoded.append(ordinal_encode(data[k], min, max))\n            self.config[k] = {\n                \"ordinal\": [min, max],\n                \"location\": i,\n                \"length\": 1,\n                \"type\": data[k].dtype,\n            }\n            i += 1\n\n        else:\n            raise UserWarning(\n                f\"Unrecognised attribute encoding in configuration: {v}\"\n            )\n\n    if not encoded:\n        raise UserWarning(\"No attribute encodeding found.\")\n\n    encoded = torch.cat(encoded, dim=-1)\n\n    # weighting\n    weights = self.label_weighter(encoded)\n    joint_weights = self.joint_weighter(encoded)\n\n    return encoded, (weights, joint_weights)\n</code></pre>"},{"location":"reference/caveat/label_encoding/onehot/#caveat.label_encoding.onehot.OneHotAttributeEncoder.validate_previous","title":"<code>validate_previous(k, v, i, expected_length, data)</code>","text":"Source code in <code>caveat/label_encoding/onehot.py</code> <pre><code>def validate_previous(self, k, v, i, expected_length, data) -&gt; None:\n    prev_location, prev_length, prev_type = (\n        v.get(\"location\"),\n        v.get(\"length\"),\n        v.get(\"type\"),\n    )\n    if prev_location is not None and prev_location != i:\n        raise UserWarning(\n            f\"Ordinal encoding location mismatch for {k}: {prev_location} != {i}\"\n        )\n    if prev_length is not None and prev_length != expected_length:\n        raise UserWarning(\n            f\"Ordinal encoding length mismatch for {k}: {prev_length} != {expected_length}\"\n        )\n    if prev_type is not None and prev_type != data.dtype:\n        raise UserWarning(\n            f\"Ordinal encoding type mismatch for {k}: {prev_type} != {data.dtype}\"\n        )\n</code></pre>"},{"location":"reference/caveat/label_encoding/tokenise/","title":"caveat.label_encoding.tokenise","text":""},{"location":"reference/caveat/label_encoding/tokenise/#caveat.label_encoding.tokenise.TokenAttributeEncoder","title":"<code>TokenAttributeEncoder(config, **kwargs)</code>","text":"<p>               Bases: <code>BaseLabelEncoder</code></p> Source code in <code>caveat/label_encoding/base.py</code> <pre><code>def __init__(self, config: dict, **kwargs) -&gt; None:\n    \"\"\"Base Attribute Encoder class.\"\"\"\n    self.config = config.copy()\n    self.label_kwargs = {}\n    self.weighting = kwargs.get(\"weighting\", \"unit\")\n    self.joint_weighting = kwargs.get(\"joint_weighting\", \"unit\")\n\n    self.label_weighter = label_weights_library.get(self.weighting, None)\n    if self.label_weighter is None:\n        raise ValueError(\n            f\"Unknown Label Encoder weighting: {self.label_weighting}, should be one of: {label_weights_library.keys()}\"\n        )\n\n    self.joint_weighter = joint_label_weights_library.get(\n        self.joint_weighting, None\n    )\n    if self.joint_weighter is None:\n        raise ValueError(\n            f\"Unknown Label Encoder weighting: {self.joint_weighting}, should be one of: {joint_label_weights_library.keys()}\"\n        )\n\n    print(\n        f\"\"\"Label Encoder {self.__class__.__name__} initialised with:\n        Label weighting: {self.weighting}\n        Joint weighting: {self.joint_weighting}\n        \"\"\"\n    )\n</code></pre>"},{"location":"reference/caveat/label_encoding/tokenise/#caveat.label_encoding.tokenise.TokenAttributeEncoder.argmax_decode","title":"<code>argmax_decode(data)</code>","text":"Source code in <code>caveat/label_encoding/tokenise.py</code> <pre><code>def argmax_decode(self, data: List[Tensor]) -&gt; pd.DataFrame:\n    decoded = {\"pid\": list(range(data[0].shape[0]))}\n    for k, v in self.config.items():\n        location, column_type = (v[\"location\"], v[\"type\"])\n        if v.get(\"nominal\") is not None:\n            encoding = {i: name for name, i in v[\"nominal\"].items()}\n            tokens = data[location].argmax(dim=-1).tolist()\n            decoded[k] = pd.Series([encoding[i] for i in tokens]).astype(\n                column_type\n            )\n        else:\n            raise UserWarning(\n                f\"Unrecognised attribute encoding in configuration: {k, v}\"\n            )\n\n    return pd.DataFrame(decoded)\n</code></pre>"},{"location":"reference/caveat/label_encoding/tokenise/#caveat.label_encoding.tokenise.TokenAttributeEncoder.build_config","title":"<code>build_config(data)</code>","text":"Source code in <code>caveat/label_encoding/tokenise.py</code> <pre><code>def build_config(self, data: pd.DataFrame) -&gt; Tensor:\n    self.label_kwargs[\"label_embed_sizes\"] = []\n\n    for i, (k, v) in enumerate(self.config.copy().items()):\n        if k not in data.columns:\n            raise UserWarning(f\"Conditional '{k}' not found in attributes\")\n        if isinstance(v, dict):  # Pre-defined encoding\n            if v.get(\"ordinal\"):\n                raise UserWarning(\n                    \"Ordinal encoding not supported for token encoding, change config to nominal or remove\"\n                )\n            elif v.get(\"nominal\"):\n                if not isinstance(v.get(\"nominal\"), dict):\n                    raise UserWarning(\n                        \"Nominal encoding must be a dict of categories to index\"\n                    )\n                self.config[k].update(\n                    {\"location\": i, \"type\": data[k].dtype}\n                )\n                self.label_kwargs[\"label_embed_sizes\"].append(\n                    data[k].nunique()\n                )\n            else:\n                raise UserWarning(\n                    f\"Unrecognised attribute encoding in configuration: {v}\"\n                )\n\n        elif v == \"nominal\":  # Undefined nominal encoding\n            _, nominal_encodings = tokenize(data[k], None)\n            self.config[k] = {\n                \"nominal\": nominal_encodings,\n                \"location\": i,\n                \"type\": data[k].dtype,\n            }\n            self.label_kwargs[\"label_embed_sizes\"].append(\n                len(nominal_encodings)\n            )\n\n        elif v == \"ordinal\":  # Undefined ordinal encoding\n            raise UserWarning(\n                \"Ordinal encoding not supported for token encoding, change config to nominal or remove\"\n            )\n\n        else:\n            raise UserWarning(\n                f\"Unrecognised attribute encoding in configuration: {v}\"\n            )\n</code></pre>"},{"location":"reference/caveat/label_encoding/tokenise/#caveat.label_encoding.tokenise.TokenAttributeEncoder.decode","title":"<code>decode(data)</code>","text":"Source code in <code>caveat/label_encoding/tokenise.py</code> <pre><code>def decode(self, data: List[Tensor]) -&gt; pd.DataFrame:\n    decoded = {\"pid\": list(range(data.shape[0]))}\n    for k, v in self.config.items():\n        location, column_type = (v[\"location\"], v[\"type\"])\n        if v.get(\"nominal\") is not None:\n            encoding = {i: name for name, i in v[\"nominal\"].items()}\n            tokens = data[:, location].tolist()\n            decoded[k] = pd.Series([encoding[i] for i in tokens]).astype(\n                column_type\n            )\n        else:\n            raise UserWarning(\n                f\"Unrecognised attribute encoding in configuration: {k, v}\"\n            )\n\n    return pd.DataFrame(decoded)\n</code></pre>"},{"location":"reference/caveat/label_encoding/tokenise/#caveat.label_encoding.tokenise.TokenAttributeEncoder.encode","title":"<code>encode(data)</code>","text":"Source code in <code>caveat/label_encoding/tokenise.py</code> <pre><code>def encode(self, data: pd.DataFrame) -&gt; Tuple[Tensor, Tensor]:\n    if not self.label_kwargs:\n        # build config mappings and define label_kwargs\n        self.build_config(data)\n    return self._encode(data)\n</code></pre>"},{"location":"reference/caveat/label_encoding/tokenise/#caveat.label_encoding.tokenise.TokenAttributeEncoder.sample_decode","title":"<code>sample_decode(data)</code>","text":"Source code in <code>caveat/label_encoding/tokenise.py</code> <pre><code>def sample_decode(self, data: List[Tensor]) -&gt; pd.DataFrame:\n    decoded = {\"pid\": list(range(data[0].shape[0]))}\n    for k, v in self.config.items():\n        location, column_type = (v[\"location\"], v[\"type\"])\n        if v.get(\"nominal\") is not None:\n            encoding = {i: name for name, i in v[\"nominal\"].items()}\n            tokens = (\n                torch.multinomial(data[location], num_samples=1)\n                .flatten()\n                .tolist()\n            )\n            decoded[k] = pd.Series([encoding[i] for i in tokens]).astype(\n                column_type\n            )\n        else:\n            raise UserWarning(\n                f\"Unrecognised attribute encoding in configuration: {k, v}\"\n            )\n\n    return pd.DataFrame(decoded)\n</code></pre>"},{"location":"reference/caveat/label_runners/","title":"caveat.label_runners","text":""},{"location":"reference/caveat/label_runners/#caveat.label_runners.label_run_command","title":"<code>label_run_command(config, verbose=False, gen=True, test=False)</code>","text":"<p>Runs the training for label prediction.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing the configuration parameters.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>caveat/label_runners.py</code> <pre><code>def label_run_command(\n    config: dict, verbose: bool = False, gen: bool = True, test: bool = False\n) -&gt; None:\n    \"\"\"\n    Runs the training for label prediction.\n\n    Args:\n        config (dict): A dictionary containing the configuration parameters.\n\n    Returns:\n        None\n    \"\"\"\n    label_encoder = config.get(\"attribute_encoder\", None)\n    if label_encoder is None or label_encoder != \"tokens\":\n        raise ValueError(\n            \"Joint model requires attribute_encoder to be configured as 'tokens'.\"\n        )\n\n    conditionals = config.get(\"conditionals\", None)\n    if conditionals is None:\n        raise ValueError(\"No conditionals provided in the config.\")\n\n    logger_params = config.get(\"logging_params\", {})\n    log_dir = Path(logger_params.get(\"log_dir\", \"logs\"))\n    name = str(\n        logger_params.get(\n            \"name\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        )\n    )\n    logger = initiate_logger(log_dir, name)\n    seed = config.pop(\"seed\", seeder())\n\n    # load data\n    input_schedules, input_labels, _ = load_data(config)\n\n    # encode data\n    label_encoder, encoded_labels, label_weights = encode_input_labels(\n        logger.log_dir, input_labels, config\n    )\n\n    schedule_encoder, encoded_schedules, data_loader = encode_schedules(\n        logger.log_dir, input_schedules, encoded_labels, label_weights, config\n    )\n\n    trainer = train(\n        name=name,\n        data_loader=data_loader,\n        encoded_schedules=encoded_schedules,\n        label_encoder=label_encoder,\n        config=config,\n        test=test,\n        gen=gen,\n        logger=logger,\n        seed=seed,\n    )\n\n    run_test(\n        trainer=trainer,\n        schedule_encoder=schedule_encoder,\n        label_encoder=label_encoder,\n        write_dir=Path(logger.log_dir),\n        seed=seed,\n    )\n</code></pre>"},{"location":"reference/caveat/label_runners/#caveat.label_runners.repack_labels","title":"<code>repack_labels(batched_labels)</code>","text":"Source code in <code>caveat/label_runners.py</code> <pre><code>def repack_labels(batched_labels: Tuple[List[Tensor]]) -&gt; List[Tensor]:\n    batched_labels = list(batched_labels)\n    if len(batched_labels) == 1:\n        return batched_labels[0]\n    else:\n        unpacked_labels = batched_labels.pop(0)\n        for batch in batched_labels:\n            for i, labels in enumerate(batch):\n                unpacked_labels[i] = torch.concat((unpacked_labels[i], labels))\n        return unpacked_labels\n</code></pre>"},{"location":"reference/caveat/label_runners/#caveat.label_runners.run_test","title":"<code>run_test(trainer, schedule_encoder, label_encoder, write_dir, seed, ckpt_path=None)</code>","text":"Source code in <code>caveat/label_runners.py</code> <pre><code>def run_test(\n    trainer: Trainer,\n    schedule_encoder: encoding.BaseEncoder,\n    label_encoder: label_encoding.BaseLabelEncoder,\n    write_dir: Path,\n    seed: int,\n    ckpt_path: Optional[str] = None,\n):\n    torch.manual_seed(seed)\n    print(\"\\n======= Testing =======\")\n    if ckpt_path is None:\n        ckpt_path = \"best\"\n    trainer.test(\n        ckpt_path=ckpt_path, datamodule=trainer.datamodule, verbose=True\n    )\n    print(\"\\n======= Inference =======\")\n    inference = trainer.predict(\n        ckpt_path=ckpt_path, dataloaders=trainer.datamodule.test_dataloader()\n    )\n    input_schedules, input_labels, inferred_labels = zip(*inference)\n\n    input_schedules = torch.concat(input_schedules)\n    input_labels = torch.concat(input_labels)\n    inferred_labels = repack_labels(inferred_labels)\n\n    input_schedules = schedule_encoder.decode(input_schedules, argmax=False)\n    data.validate_schedules(input_schedules)\n    input_schedules.to_csv(write_dir / \"input_schedules.csv\")\n\n    attributes = label_encoder.decode(input_labels)\n    attributes.to_csv(write_dir / \"input_labels.csv\")\n    inferred_labels = label_encoder.sample_decode(inferred_labels)\n    inferred_labels.to_csv(write_dir / \"inferred_labels.csv\")\n</code></pre>"},{"location":"reference/caveat/mmrunners/","title":"caveat.mmrunners","text":""},{"location":"reference/caveat/mmrunners/#caveat.mmrunners.filter_attributes_on_conditionals","title":"<code>filter_attributes_on_conditionals(attributes, columns)</code>","text":"Source code in <code>caveat/mmrunners.py</code> <pre><code>def filter_attributes_on_conditionals(attributes, columns) -&gt; dict:\n    if attributes is None:\n        return None\n    filtered = {}\n    values = attributes[columns].value_counts().index\n    for value in values:\n        selected = attributes.copy()\n        for k, v in zip(columns, value):\n            selected = selected[selected[k] == v]\n        if len(selected) &gt; 0:\n            filtered[value] = selected\n\n    return filtered\n</code></pre>"},{"location":"reference/caveat/mmrunners/#caveat.mmrunners.filter_schedules_on_attributes","title":"<code>filter_schedules_on_attributes(attributes, schedules)</code>","text":"Source code in <code>caveat/mmrunners.py</code> <pre><code>def filter_schedules_on_attributes(attributes, schedules) -&gt; dict:\n    pids = attributes[\"pid\"]\n    return schedules[schedules[\"pid\"].isin(pids)]\n</code></pre>"},{"location":"reference/caveat/mmrunners/#caveat.mmrunners.mmrun_command","title":"<code>mmrun_command(config, verbose=False, gen=True, test=False, infer=True, warm_start=True)</code>","text":"<p>Runs the training for multi-model variation.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing the configuration parameters.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>caveat/mmrunners.py</code> <pre><code>def mmrun_command(\n    config: dict,\n    verbose: bool = False,\n    gen: bool = True,\n    test: bool = False,\n    infer=True,\n    warm_start: bool = True,\n) -&gt; None:\n    \"\"\"\n    Runs the training for multi-model variation.\n\n    Args:\n        config (dict): A dictionary containing the configuration parameters.\n\n    Returns:\n        None\n    \"\"\"\n\n    labels = config.get(\"labels_encoder\", {}).get(\"labels\", None)\n\n    if labels is None:\n        raise ValueError(\"No conditionals provided in the config.\")\n\n    # check conditional encodings\n    for cond, encoding in labels.items():\n        if not encoding == \"nominal\":\n            raise ValueError(\n                f\"{cond} encoding not supported. Only nominal encoding is supported for conditional multi-model training.\"\n            )\n\n    logger_params = config.get(\"logging_params\", {})\n    name = str(\n        logger_params.get(\n            \"name\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        )\n    )\n    log_root = Path(logger_params.get(\"log_dir\", \"logs\"), name)\n\n    seed = config.pop(\"seed\", seeder())\n\n    # load data\n    input_schedules, input_attributes, synthetic_attributes = load_data(config)\n\n    # encode data\n    base_logger = initiate_logger(logger_params.get(\"log_dir\", \"logs\"), name)\n    attribute_encoder, encoded_labels, label_weights = encode_input_labels(\n        base_logger.log_dir, input_attributes, config\n    )\n\n    schedule_encoder, encoded_schedules, data_loader = encode_schedules(\n        base_logger.log_dir,\n        input_schedules.copy(),\n        encoded_labels,\n        label_weights,\n        config,\n    )\n\n    if warm_start:\n        logger = initiate_logger(log_root, \"warm_start\")\n\n        # train\n        warming_trainer = train(\n            name=name,\n            data_loader=data_loader,\n            encoded_schedules=encoded_schedules,\n            label_encoder=attribute_encoder,\n            config=config,\n            test=test,\n            gen=gen,\n            logger=logger,\n            seed=seed,\n            ckpt_path=None,\n        )\n\n        if test:\n            # test the model\n            run_test(\n                trainer=warming_trainer,\n                schedule_encoder=schedule_encoder,\n                write_dir=Path(logger.log_dir),\n                seed=seed,\n            )\n\n        if infer:\n            test_infer_path = Path(f\"{logger.log_dir}/test_inference\")\n            test_infer_path.mkdir(exist_ok=True, parents=True)\n            test_inference(\n                trainer=warming_trainer,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=attribute_encoder,\n                write_dir=test_infer_path,\n                seed=seed,\n            )\n\n    columns = list(labels.keys())\n    attributes_filtered = filter_attributes_on_conditionals(\n        input_attributes, columns\n    )\n    synthetic_attributes_filtered = filter_attributes_on_conditionals(\n        synthetic_attributes, columns\n    )\n\n    combined_schedules = []\n    combined_attributes = []\n    combined_zs = []\n\n    # loop through sub models\n    for keys, sub_attributes in attributes_filtered.items():\n        name = \"_\".join([f\"{k}-{v}\" for k, v in zip(columns, keys)])\n        sub_schedules = filter_schedules_on_attributes(\n            sub_attributes, input_schedules.copy()\n        )\n        if len(sub_schedules) == 0:\n            raise ValueError(f\"No schedules found for {name}.\")\n        print(f\"Found {sub_schedules.pid.nunique()} schedules for {name}.\")\n\n        logger = initiate_logger(log_root, name)\n\n        # encode data\n        attribute_encoder, encoded_labels, label_weights = encode_input_labels(\n            logger.log_dir, sub_attributes, config\n        )\n\n        encoded_schedules = schedule_encoder.encode(\n            schedules=sub_schedules,\n            labels=encoded_labels,\n            label_weights=label_weights,\n        )\n        data_loader = build_dataloader(config, encoded_schedules)\n\n        # train\n        trainer = train(\n            name=name,\n            data_loader=data_loader,\n            encoded_schedules=encoded_schedules,\n            label_encoder=attribute_encoder,\n            config=config,\n            test=test,\n            gen=gen,\n            logger=logger,\n            seed=seed,\n            ckpt_path=(\n                warming_trainer.checkpoint_callback.best_model_path\n                if warm_start\n                else None\n            ),\n        )\n\n        if test:\n            # test the model\n            run_test(\n                trainer=trainer,\n                schedule_encoder=schedule_encoder,\n                write_dir=Path(logger.log_dir),\n                seed=seed,\n            )\n\n        if infer:\n            test_infer_path = Path(f\"{logger.log_dir}/test_inference\")\n            test_infer_path.mkdir(exist_ok=True, parents=True)\n            test_inference(\n                trainer=trainer,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=attribute_encoder,\n                write_dir=test_infer_path,\n                seed=seed,\n            )\n\n        if gen:\n            sub_synthetic_attributes = synthetic_attributes_filtered.get(\n                keys, None\n            )\n            # prepare synthetic attributes\n            if synthetic_attributes is not None:\n                if sub_synthetic_attributes is None:\n                    print(\n                        f\"No synthetic attributes found for {name}. Skipping generation.\"\n                    )\n                    continue\n                synthetic_population, _ = attribute_encoder.encode(\n                    sub_synthetic_attributes\n                )\n            else:\n                synthetic_population = sub_schedules.pid.nunique()\n\n            generated_schedules, generated_attributes, zs = generate(\n                trainer=trainer,\n                population=synthetic_population,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=attribute_encoder,\n                config=config,\n                write_dir=Path(logger.log_dir),\n                seed=seed,\n            )\n\n            # generate synthetic schedules\n            combined_schedules.append(generated_schedules)\n            combined_attributes.append(generated_attributes)\n            combined_zs.append(zs)\n\n    # combine synthetic schedules\n    i = 0\n    for sub_schedules, sub_attributes in zip(\n        combined_schedules, combined_attributes\n    ):\n        sub_schedules.pid = sub_schedules.pid + i\n        sub_attributes.pid = sub_attributes.pid + i\n        i += sub_schedules.pid.max() + 1\n    synthetic_schedules = pd.concat(combined_schedules)\n    synthetic_attributes = pd.concat(combined_attributes)\n    synthetic_zs = torch_concat(combined_zs)\n\n    synthetic_schedules.to_csv(\n        Path(base_logger.log_dir) / \"synthetic_schedules.csv\"\n    )\n    synthetic_attributes.to_csv(\n        Path(base_logger.log_dir) / \"synthetic_attributes.csv\"\n    )\n    pd.DataFrame(synthetic_zs.cpu().numpy()).to_csv(\n        Path(base_logger.log_dir) / \"synthetic_zs.csv\",\n        index=False,\n        header=False,\n    )\n\n    # evaluate synthetic schedules\n    evaluate_synthetics(\n        synthetic_schedules={name: synthetic_schedules},\n        synthetic_attributes={name: synthetic_attributes},\n        default_eval_schedules=input_schedules,\n        default_eval_attributes=input_attributes,\n        write_path=Path(logger.log_dir),\n        eval_params=config.get(\"evaluation_params\", {}),\n        stats=False,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"reference/caveat/models/base/","title":"caveat.models.base","text":""},{"location":"reference/caveat/models/base/#caveat.models.base.Base","title":"<code>Base(in_shape, encodings, encoding_weights=None, labels_size=None, sos=0, gen=False, test=False, LR=0.001, weight_decay=0.01, **kwargs)</code>","text":"<p>               Bases: <code>Experiment</code></p> Source code in <code>caveat/experiment.py</code> <pre><code>def __init__(\n    self,\n    in_shape: tuple,\n    encodings: int,\n    encoding_weights: Optional[Tensor] = None,\n    labels_size: Optional[tuple] = None,\n    sos: int = 0,\n    gen: bool = False,\n    test: bool = False,\n    LR: float = 0.001,\n    weight_decay: float = 0.01,\n    **kwargs,\n) -&gt; None:\n    super(Experiment, self).__init__()\n    self.gen = gen\n    self.test = test\n    self.LR = LR\n    self.weight_decay = weight_decay\n    self.kwargs = kwargs\n    self.curr_device = None\n    self.save_hyperparameters()\n    \"\"\"Base VAE.\n\n    Args:\n        in_shape (tuple[int, int]): [time_step, activity one-hot encoding].\n        encodings (int): Number of activity encodings.\n        encoding_weights (tensor): Weights for activity encodings.\n        labels_size (int, optional): Size of labels encoding. Defaults to None.\n        sos (int, optional): Start of sequence token. Defaults to 0.\n        config: Additional arguments from config.\n    \"\"\"\n    # encoding params\n    self.in_shape = in_shape\n    print(f\"Found input shape: {self.in_shape}\")\n    self.encodings = encodings\n    print(f\"Found encodings: {self.encodings}\")\n    self.encoding_weights = encoding_weights\n    print(f\"Found encoding weights: {self.encoding_weights}\")\n    self.labels_size = labels_size\n    if self.labels_size is not None:\n        print(f\"Found labels size: {self.labels_size}\")\n    self.label_embed_sizes = kwargs.get(\"label_embed_sizes\", None)\n    self.sos = sos\n    print(f\"Found start of sequence token: {self.sos}\")\n    self.teacher_forcing_ratio = kwargs.get(\"teacher_forcing_ratio\", 0.5)\n    print(f\"Found teacher forcing ratio: {self.teacher_forcing_ratio}\")\n\n    # loss function params\n    self.kld_loss_weight = kwargs.get(\"kld_weight\", 0.001)\n    print(f\"Found KLD weight: {self.kld_loss_weight}\")\n\n    self.activity_loss_weight = kwargs.get(\"activity_loss_weight\", 1.0)\n    self.duration_loss_weight = kwargs.get(\"duration_loss_weight\", 1.0)\n    print(f\"Found activity loss weight: {self.activity_loss_weight}\")\n    print(f\"Found duration loss weight: {self.duration_loss_weight}\")\n\n    self.label_loss_weight = kwargs.get(\"label_loss_weight\", 0.0001)\n    print(f\"Found labels loss weight: {self.label_loss_weight}\")\n\n    self.use_mask = kwargs.get(\"use_mask\", True)\n    print(f\"Using mask: {self.use_mask}\")\n\n    self.use_weighted_loss = kwargs.get(\"weighted_loss\", True)\n    print(f\"Using weighted loss: {self.use_weighted_loss}\")\n\n    # set up weighted loss\n    if self.use_weighted_loss and self.encoding_weights is not None:\n        print(\"Using weighted loss function\")\n        self.NLLL = nn.NLLLoss(weight=self.encoding_weights)\n    else:\n        self.NLLL = nn.NLLLoss()\n\n    self.base_NLLL = nn.NLLLoss(reduction=\"none\")\n\n    self.loss = nn.NLLLoss(reduction=\"none\")\n    self.MSE = nn.MSELoss(reduction=\"none\")\n\n    # set up scheduled loss function weights\n    self.scheduled_kld_weight = 1.0\n    self.scheduled_act_weight = 1.0\n    self.scheduled_dur_weight = 1.0\n    self.scheduled_label_weight = 1.0\n\n    self.build(**kwargs)\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.act_seq_loss","title":"<code>act_seq_loss(preds, targets, weights, seq_weights, joint_weights)</code>","text":"<p>Loss function for activity encoding [B, L].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def act_seq_loss(\n    self, preds, targets, weights, seq_weights, joint_weights\n) -&gt; Tensor:\n    \"\"\"Loss function for activity encoding [B, L].\"\"\"\n    B, L, _ = targets.shape\n    losses = self.base_NLLL(\n        preds.view(-1, self.encodings), targets.view(-1).long()\n    )\n    losses = losses * weights.view(-1)\n    losses = losses.view(B, L) * seq_weights\n    if joint_weights is not None:\n        losses = losses * joint_weights\n    return losses.mean()\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/base.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config.get(\"dropout\", 0)\n    length, _ = self.in_shape\n\n    self.encoder = BaseEncoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n    self.decoder = BaseDecoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_n,\n        max_length=length,\n        sos=self.sos,\n    )\n    self.unflattened_shape = (self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.combined_seq_loss","title":"<code>combined_seq_loss(log_probs, mu, log_var, target, mask, **kwargs)</code>","text":"<p>Loss function for sequence encoding [N, L, 2].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def combined_seq_loss(\n    self, log_probs, mu, log_var, target, mask, **kwargs\n) -&gt; dict:\n    \"\"\"Loss function for sequence encoding [N, L, 2].\"\"\"\n    # unpack act probs and durations\n    target_acts, target_durations = self.unpack_encoding(target)\n    pred_acts, pred_durations = self.unpack_encoding(log_probs)\n    pred_durations = torch.exp(pred_durations)\n\n    # normalise mask weights\n    mask = mask / mask.mean(-1).unsqueeze(-1)\n\n    # activity loss\n    recon_act_nlll = self.base_NLLL(\n        pred_acts.view(-1, self.encodings), target_acts.view(-1).long()\n    )\n    act_recon = (recon_act_nlll * mask.view(-1)).mean()\n    act_scheduled_weight = (\n        self.activity_loss_weight * self.scheduled_act_weight\n    )\n    w_act_recon = act_scheduled_weight * act_recon\n\n    # duration loss\n    recon_dur_mse = self.MSE(pred_durations, target_durations)\n    recon_dur_mse = (recon_dur_mse * mask).mean()\n\n    # ends loss\n    target_ends = torch.cumsum(target_durations, dim=-1)\n    pred_ends = torch.cumsum(pred_durations, dim=-1)\n\n    recon_end_mse = self.MSE(pred_ends, target_ends)\n    recon_end_mse = (recon_end_mse * mask).mean()\n\n    dur_scheduled_weight = (\n        self.duration_loss_weight * self.scheduled_dur_weight\n    )\n    w_dur_recon = dur_scheduled_weight * (recon_end_mse + recon_dur_mse)\n\n    # reconstruction loss\n    w_recons_loss = w_act_recon + w_dur_recon\n\n    # kld loss\n    kld_loss = self.kld(mu, log_var)\n    scheduled_kld_weight = self.kld_loss_weight * self.scheduled_kld_weight\n    w_kld_loss = scheduled_kld_weight * kld_loss\n\n    # final loss\n    loss = w_recons_loss + w_kld_loss\n\n    return {\n        \"loss\": loss,\n        \"KLD\": w_kld_loss.detach(),\n        \"recon_loss\": w_recons_loss.detach(),\n        \"act_recon\": w_act_recon.detach(),\n        \"dur_recon\": w_dur_recon.detach(),\n        \"kld_weight\": torch.tensor([scheduled_kld_weight]).float(),\n        \"act_weight\": torch.tensor([act_scheduled_weight]).float(),\n        \"dur_weight\": torch.tensor([dur_scheduled_weight]).float(),\n    }\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output batch as tuple of log probs and probs ([N, L, C]).</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/base.py</code> <pre><code>def decode(self, z: Tensor, target=None, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output batch as tuple of log probs and probs ([N, L, C]).\n    \"\"\"\n    hidden = self.fc_hidden(z)\n    hidden = hidden.unflatten(1, self.unflattened_shape).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # attempt to use teacher forcing by passing target\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.discretized_loss","title":"<code>discretized_loss(log_probs, mu, log_var, target, weights, **kwargs)</code>","text":"<p>Loss function for discretized encoding [N, L].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def discretized_loss(\n    self, log_probs, mu, log_var, target, weights, **kwargs\n) -&gt; dict:\n    \"\"\"Loss function for discretized encoding [N, L].\"\"\"\n    # activity loss\n    recon_act_nlll = self.NLLL(\n        log_probs.squeeze().permute(0, 2, 1), target.long()\n    )\n    scheduled_act_weight = (\n        self.activity_loss_weight * self.scheduled_act_weight\n    )\n    w_recons_loss = scheduled_act_weight * recon_act_nlll\n\n    # kld loss\n    unweighted_kld = self.kld(mu, log_var)\n    scheduled_kld_weight = self.kld_loss_weight * self.scheduled_kld_weight\n    w_kld_loss = scheduled_kld_weight * unweighted_kld\n\n    # loss\n    loss = recon_act_nlll + w_kld_loss\n\n    return {\n        \"loss\": loss,\n        \"KLD\": w_kld_loss.detach(),\n        \"recon_loss\": w_recons_loss.detach(),\n        \"kld_weight\": torch.tensor([scheduled_kld_weight]).float(),\n        \"act_weight\": torch.tensor([scheduled_act_weight]).float(),\n    }\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.discretized_loss_encoded","title":"<code>discretized_loss_encoded(log_probs, mu, log_var, target, mask, **kwargs)</code>","text":"<p>Computes the loss function for discretized encoding [N, L, C].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def discretized_loss_encoded(\n    self, log_probs, mu, log_var, target, mask, **kwargs\n) -&gt; dict:\n    \"\"\"Computes the loss function for discretized encoding [N, L, C].\"\"\"\n\n    target_argmax = target.squeeze().argmax(dim=-1)\n    return self.discretized_loss(\n        log_probs, mu, log_var, target_argmax, mask, **kwargs\n    )\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.dur_seq_loss","title":"<code>dur_seq_loss(preds, targets, weights, seq_weights, joint_weights)</code>","text":"<p>Loss function for durations [B, L].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def dur_seq_loss(\n    self, preds, targets, weights, seq_weights, joint_weights\n) -&gt; Tensor:\n    \"\"\"Loss function for durations [B, L].\"\"\"\n    losses = self.MSE(preds, targets)\n    losses = losses * weights * seq_weights\n    if joint_weights is not None:\n        losses = losses * joint_weights\n    return losses.mean()\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.encode","title":"<code>encode(input, labels)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>list[tensor]: Latent layer input (means and variances) [N, latent_dims].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def encode(self, input: Tensor, labels: Optional[Tensor]) -&gt; list[Tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): Input sequence batch [N, steps, acts].\n\n    Returns:\n        list[tensor]: Latent layer input (means and variances) [N, latent_dims].\n    \"\"\"\n    # [N, L, C]\n    hidden = self.encoder(input)\n    # [N, flatsize]\n\n    # Split the result into mu and var components\n    mu = self.fc_mu(hidden)\n    log_var = self.fc_var(hidden)\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.end_time_seq_loss","title":"<code>end_time_seq_loss(log_probs, mu, log_var, target, mask, **kwargs)</code>","text":"<p>Loss function for sequence encoding [N, L, 2].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def end_time_seq_loss(\n    self, log_probs, mu, log_var, target, mask, **kwargs\n) -&gt; dict:\n    \"\"\"Loss function for sequence encoding [N, L, 2].\"\"\"\n    # unpack act probs and durations\n    target_acts, target_durations = self.unpack_encoding(target)\n    pred_acts, pred_durations = self.unpack_encoding(log_probs)\n    pred_durations = torch.exp(pred_durations)\n\n    # normalise mask weights\n    mask = mask / mask.mean(-1).unsqueeze(-1)\n\n    # activity loss\n    recon_act_nlll = self.base_NLLL(\n        pred_acts.view(-1, self.encodings), target_acts.view(-1).long()\n    )\n    act_recon = (recon_act_nlll * mask.view(-1)).mean()\n    act_scheduled_weight = (\n        self.activity_loss_weight * self.scheduled_act_weight\n    )\n    w_act_recon = act_scheduled_weight * act_recon\n\n    # ends loss\n    target_ends = torch.cumsum(target_durations, dim=-1)\n    pred_ends = torch.cumsum(pred_durations, dim=-1)\n\n    recon_end_mse = self.MSE(pred_ends, target_ends)\n    recon_end_mse = (recon_end_mse * mask).mean()\n    dur_scheduled_weight = (\n        self.duration_loss_weight * self.scheduled_dur_weight\n    )\n    w_dur_recon = dur_scheduled_weight * recon_end_mse\n\n    # reconstruction loss\n    w_recons_loss = w_act_recon + w_dur_recon\n\n    # kld loss\n    kld_loss = self.kld(mu, log_var)\n    scheduled_kld_weight = self.kld_loss_weight * self.scheduled_kld_weight\n    w_kld_loss = scheduled_kld_weight * kld_loss\n\n    # final loss\n    loss = w_recons_loss + w_kld_loss\n\n    return {\n        \"loss\": loss,\n        \"KLD\": w_kld_loss.detach(),\n        \"recon_loss\": w_recons_loss.detach(),\n        \"act_recon\": w_act_recon.detach(),\n        \"dur_recon\": w_dur_recon.detach(),\n        \"kld_weight\": torch.tensor([scheduled_kld_weight]).float(),\n        \"act_weight\": torch.tensor([act_scheduled_weight]).float(),\n        \"dur_weight\": torch.tensor([dur_scheduled_weight]).float(),\n    }\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.forward","title":"<code>forward(x, labels=None, target=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>List[Tensor]</code> <p>list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def forward(\n    self, x: Tensor, labels: Optional[Tensor] = None, target=None, **kwargs\n) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n\n    Returns:\n        list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].\n    \"\"\"\n    mu, log_var = self.encode(x, labels)\n    z = self.reparameterize(mu, log_var)\n    log_probs_x = self.decode(z, labels=labels, target=target)\n    return [log_probs_x, mu, log_var, z]\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.infer","title":"<code>infer(x, device, **kwargs)</code>","text":"<p>Given an encoder input, return reconstructed output and z samples.</p> PARAMETER DESCRIPTION <code>x</code> <p>[N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>(tensor: [N, steps, acts], tensor: [N, latent_dims]).</p> Source code in <code>caveat/models/base.py</code> <pre><code>def infer(self, x: Tensor, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given an encoder input, return reconstructed output and z samples.\n\n    Args:\n        x (tensor): [N, steps, acts].\n\n    Returns:\n        (tensor: [N, steps, acts], tensor: [N, latent_dims]).\n    \"\"\"\n    log_probs_x, _, _, z = self.forward(x, **kwargs)\n    prob_samples = exp(log_probs_x)\n    prob_samples = prob_samples.to(device)\n    z = z.to(device)\n    return prob_samples, z\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.kld","title":"<code>kld(mu, log_var)</code>","text":"Source code in <code>caveat/models/base.py</code> <pre><code>def kld(self, mu: Tensor, log_var: Tensor) -&gt; Tensor:\n    # from https://kvfrans.com/deriving-the-kl/\n    return torch.mean(\n        -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n    )\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.loss_function","title":"<code>loss_function(log_probs, mu, log_var, target, weights, **kwargs)</code>","text":"<p>Computes the loss function. Different models are expected to need different loss functions depending on the data structure. Typically it will either be a sequence encoding [N, L, 2], or discretized encoding [N, L, C] or [N, L].</p> <p>The default is to use the sequence loss function. But child classes can override this method.</p> <p>Returns losses as a dictionary. Which must include the keys \"loss\" and \"recon_loss\".</p> PARAMETER DESCRIPTION <code>log_probs</code> <p>Log probabilities of the output.</p> <p> TYPE: <code>Tensor</code> </p> <code>mu</code> <p>Latent layer means.</p> <p> TYPE: <code>Tensor</code> </p> <code>log_var</code> <p>Latent layer log variances.</p> <p> TYPE: <code>Tensor</code> </p> <code>target</code> <p>Target sequences.</p> <p> TYPE: <code>Tensor</code> </p> <code>weights</code> <p>activity and joint weights.</p> <p> TYPE: <code>(Tensor, Tensor)</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>Losses.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>caveat/models/base.py</code> <pre><code>def loss_function(\n    self,\n    log_probs: Tensor,\n    mu: Tensor,\n    log_var: Tensor,\n    target: Tensor,\n    weights: Tuple[Tensor, Tensor],\n    **kwargs,\n) -&gt; dict:\n    \"\"\"Computes the loss function. Different models are expected to need different loss functions\n    depending on the data structure. Typically it will either be a sequence encoding [N, L, 2],\n    or discretized encoding [N, L, C] or [N, L].\n\n    The default is to use the sequence loss function. But child classes can override this method.\n\n    Returns losses as a dictionary. Which must include the keys \"loss\" and \"recon_loss\".\n\n    Args:\n        log_probs (Tensor): Log probabilities of the output.\n        mu (Tensor): Latent layer means.\n        log_var (Tensor): Latent layer log variances.\n        target (Tensor): Target sequences.\n        weights (Tensor, Tensor): activity and joint weights.\n\n    Returns:\n        dict: Losses.\n    \"\"\"\n\n    return self.seq_loss(\n        log_probs=log_probs,\n        mu=mu,\n        log_var=log_var,\n        target=target,\n        weights=weights,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.pack_encoding","title":"<code>pack_encoding(acts, durations)</code>","text":"<p>Pack the activity and duration into input.</p> PARAMETER DESCRIPTION <code>acts</code> <p>Activity [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> <code>durations</code> <p>Duration [N, steps, 1].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Input sequences [N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/base.py</code> <pre><code>def pack_encoding(self, acts: Tensor, durations: Tensor) -&gt; Tensor:\n    \"\"\"Pack the activity and duration into input.\n\n    Args:\n        acts (tensor): Activity [N, steps, acts].\n        durations (tensor): Duration [N, steps, 1].\n\n    Returns:\n        tensor: Input sequences [N, steps, acts].\n    \"\"\"\n    if len(durations.shape) == 2:\n        durations = durations.unsqueeze(-1)\n    return torch.cat((acts, durations), dim=-1)\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.predict","title":"<code>predict(z, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>z</code> <p>[N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/base.py</code> <pre><code>def predict(self, z: Tensor, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        z (tensor): [N, latent_dims].\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(device)\n    prob_samples = exp(self.decode(z, **kwargs))\n    return prob_samples\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.reparameterize","title":"<code>reparameterize(mu, logvar)</code>","text":"<p>Re-parameterization trick to sample from N(mu, var) from N(0,1).</p> PARAMETER DESCRIPTION <code>mu</code> <p>Mean of the latent Gaussian [N x latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>logvar</code> <p>Standard deviation of the latent Gaussian [N x latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N x latent_dims].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/base.py</code> <pre><code>def reparameterize(self, mu: Tensor, logvar: Tensor) -&gt; Tensor:\n    \"\"\"Re-parameterization trick to sample from N(mu, var) from N(0,1).\n\n    Args:\n        mu (tensor): Mean of the latent Gaussian [N x latent_dims].\n        logvar (tensor): Standard deviation of the latent Gaussian [N x latent_dims].\n\n    Returns:\n        tensor: [N x latent_dims].\n    \"\"\"\n    std = torch.exp(0.5 * logvar)\n    eps = torch.randn_like(std)\n    return (eps * std) + mu\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.seq_loss","title":"<code>seq_loss(log_probs, mu, log_var, target, weights, label_weights=(None, None), **kwargs)</code>","text":"<p>Loss function for sequence encoding [N, L, 2].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def seq_loss(\n    self,\n    log_probs,\n    mu,\n    log_var,\n    target,\n    weights: Tuple[Tensor, Tensor],\n    label_weights: Optional[Tuple[Tensor, Tensor]] = (None, None),\n    **kwargs,\n) -&gt; dict:\n    \"\"\"Loss function for sequence encoding [N, L, 2].\"\"\"\n    # unpack act probs and durations\n    target_acts, target_durs = self.unpack_encoding(target)\n    pred_acts, pred_durs = self.unpack_encoding(log_probs)\n    pred_durs = torch.exp(pred_durs)\n\n    act_weights, seq_weights = weights\n    _, joint_weights = label_weights\n    dur_weights = utils.duration_mask(act_weights)\n\n    # normalise weights to sum to batch size\n    B = act_weights.shape[0]\n    act_weights = B * act_weights / act_weights.sum()\n    seq_weights = B * seq_weights / seq_weights.sum()\n    if joint_weights is not None:\n        joint_weights = B * joint_weights / joint_weights.sum()\n    dur_weights = B * dur_weights / dur_weights.sum()\n\n    # activity loss\n    act_weight = self.activity_loss_weight * self.scheduled_act_weight\n    act_recon = self.act_seq_loss(\n        preds=pred_acts,\n        targets=target_acts,\n        weights=act_weights,\n        seq_weights=seq_weights,\n        joint_weights=joint_weights,\n    )\n    w_act_recon = act_weight * act_recon\n\n    # duration loss\n    dur_weight = self.duration_loss_weight * self.scheduled_dur_weight\n    dur_recon = self.dur_seq_loss(\n        preds=pred_durs,\n        targets=target_durs,\n        weights=dur_weights,\n        seq_weights=seq_weights,\n        joint_weights=joint_weights,\n    )\n    w_dur_recon = dur_weight * dur_recon\n\n    # reconstruction loss\n    w_recons_loss = w_act_recon + w_dur_recon\n\n    # kld loss\n    kld_loss = self.kld(mu, log_var)\n    scheduled_kld_weight = self.kld_loss_weight * self.scheduled_kld_weight\n    w_kld_loss = scheduled_kld_weight * kld_loss\n\n    # final loss\n    loss = w_recons_loss + w_kld_loss\n\n    return {\n        \"loss\": loss,\n        \"KLD\": w_kld_loss.detach(),\n        \"recon_loss\": w_recons_loss.detach(),\n        \"act_recon\": w_act_recon.detach(),\n        \"dur_recon\": w_dur_recon.detach(),\n        \"kld_weight\": torch.tensor([scheduled_kld_weight]).float(),\n        \"act_weight\": torch.tensor([act_weight]).float(),\n        \"dur_weight\": torch.tensor([dur_weight]).float(),\n    }\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.seq_loss_no_kld","title":"<code>seq_loss_no_kld(log_probs, target, weights, label_weights, **kwargs)</code>","text":"<p>Loss function for sequence encoding [N, L, 2].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def seq_loss_no_kld(\n    self, log_probs, target, weights, label_weights, **kwargs\n) -&gt; dict:\n    \"\"\"Loss function for sequence encoding [N, L, 2].\"\"\"\n    # unpack act probs and durations\n    target_acts, target_durs = self.unpack_encoding(target)\n    pred_acts, pred_durs = self.unpack_encoding(log_probs)\n    pred_durs = torch.exp(pred_durs)\n\n    act_weights, seq_weights = weights\n    label_weights, joint_weights = label_weights\n    dur_weights = utils.duration_mask(act_weights)\n\n    assert seq_weights.shape[1] == joint_weights.shape[1] == 1\n\n    # normalise weights to sum to batch size\n    B = act_weights.shape[0]\n    act_weights = B * act_weights / act_weights.sum()\n    seq_weights = B * seq_weights / seq_weights.sum()\n    label_weights = B * label_weights / label_weights.sum()\n    joint_weights = B * joint_weights / joint_weights.sum()\n    dur_weights = B * dur_weights / dur_weights.sum()\n\n    # activity loss\n    act_weight = self.activity_loss_weight * self.scheduled_act_weight\n    act_recon = self.act_seq_loss(\n        preds=pred_acts,\n        targets=target_acts,\n        weights=act_weights,\n        seq_weights=seq_weights,\n        joint_weights=joint_weights,\n    )\n    w_act_recon = act_weight * act_recon\n\n    # duration loss\n    dur_weight = self.duration_loss_weight * self.scheduled_dur_weight\n    dur_recon = self.dur_seq_loss(\n        preds=pred_durs,\n        targets=target_durs,\n        weights=dur_weights,\n        seq_weights=seq_weights,\n        joint_weights=joint_weights,\n    )\n    w_dur_recon = dur_weight * dur_recon\n\n    # reconstruction loss\n    w_recons_loss = w_act_recon + w_dur_recon\n\n    # final loss\n    loss = w_recons_loss\n\n    return {\n        \"loss\": loss,\n        \"recon_loss\": w_recons_loss.detach(),\n        \"act_recon\": w_act_recon.detach(),\n        \"dur_recon\": w_dur_recon.detach(),\n        \"act_weight\": torch.tensor([act_weight]).float(),\n        \"dur_weight\": torch.tensor([dur_weight]).float(),\n    }\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.Base.unpack_encoding","title":"<code>unpack_encoding(input)</code>","text":"<p>Split the input into activity and duration.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequences [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor, Tensor]</code> <p>tuple[tensor, tensor]: [activity [N, steps, acts], duration [N, steps, 1]].</p> Source code in <code>caveat/models/base.py</code> <pre><code>def unpack_encoding(self, input: Tensor) -&gt; tuple[Tensor, Tensor]:\n    \"\"\"Split the input into activity and duration.\n\n    Args:\n        input (tensor): Input sequences [N, steps, acts].\n\n    Returns:\n        tuple[tensor, tensor]: [activity [N, steps, acts], duration [N, steps, 1]].\n    \"\"\"\n    acts = input[:, :, :-1].contiguous()\n    durations = input[:, :, -1:].squeeze(-1).contiguous()\n    return acts, durations\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.BaseDecoder","title":"<code>BaseDecoder(**kwargs)</code>","text":"<p>               Bases: <code>LightningModule</code></p> Source code in <code>caveat/models/base.py</code> <pre><code>def __init__(self, **kwargs):\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.BaseDecoder.forward","title":"<code>forward(x, y)</code>","text":"Source code in <code>caveat/models/base.py</code> <pre><code>def forward(self, x: Tensor, y: Optional[Tensor]) -&gt; Tensor:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.BaseEncoder","title":"<code>BaseEncoder(**kwargs)</code>","text":"<p>               Bases: <code>LightningModule</code></p> Source code in <code>caveat/models/base.py</code> <pre><code>def __init__(self, **kwargs):\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/models/base/#caveat.models.base.BaseEncoder.forward","title":"<code>forward(x, y)</code>","text":"Source code in <code>caveat/models/base.py</code> <pre><code>def forward(self, x: Tensor, y: Optional[Tensor]) -&gt; Tensor:\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/","title":"caveat.models.discrete.auto_discrete_lstm","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.AutoDiscLSTM","title":"<code>AutoDiscLSTM(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer and conditionality.</p> Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with encoder embedding layer and conditionality.\"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires labels_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.AutoDiscLSTM.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = 1  # dummy value for the predict dataloader\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length = self.in_shape[0]\n    bidirectional = config.get(\"bidirectional\", False)\n    top_sampler = config.get(\"top_sampler\", False)\n\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n        top_sampler=top_sampler,\n        bidirectional=bidirectional,\n    )\n    # self.unflattened_shape = (2 * self.hidden_layers, self.hidden_size)\n    if bidirectional:\n        flat_size_encode = self.hidden_n * self.hidden_size * 2 * 2\n        self.adjusted_layers = self.hidden_n * 2\n        self.unflatten_shape = (2 * 2 * self.hidden_n, self.hidden_size)\n    else:\n        flat_size_encode = self.hidden_n * self.hidden_size * 2\n        self.adjusted_layers = self.hidden_n\n        self.unflatten_shape = (2 * self.hidden_n, self.hidden_size)\n    self.fc_hidden = nn.Linear(self.labels_size, flat_size_encode)\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.AutoDiscLSTM.decode","title":"<code>decode(z, labels, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def decode(\n    self, z: None, labels: Tensor, target: Optional[Tensor] = None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    h = self.fc_hidden(labels)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, self.unflatten_shape).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.adjusted_layers\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.AutoDiscLSTM.encode","title":"<code>encode(input)</code>","text":"Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def encode(self, input: Tensor):\n    return None\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.AutoDiscLSTM.forward","title":"<code>forward(x, labels=None, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    labels: Optional[Tensor] = None,\n    target: Optional[Tensor] = None,\n    **kwargs,\n) -&gt; List[Tensor]:\n    log_probs = self.decode(z=x, labels=labels, target=target)\n    return [log_probs, Tensor([]), Tensor([]), Tensor([])]\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.AutoDiscLSTM.loss_function","title":"<code>loss_function(log_probs, target, weights, **kwargs)</code>","text":"<p>Loss function for discretized encoding [N, L].</p> Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def loss_function(\n    self, log_probs: Tensor, target: Tensor, weights: Tensor, **kwargs\n) -&gt; dict:\n    \"\"\"Loss function for discretized encoding [N, L].\"\"\"\n    # activity loss\n    recon_act_nlll = self.NLLL(log_probs.squeeze().permute(0, 2, 1), target)\n\n    # loss\n    loss = recon_act_nlll\n\n    return {\"loss\": loss, \"recon_act_nlll_loss\": recon_act_nlll}\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.AutoDiscLSTM.predict","title":"<code>predict(z, labels, device, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def predict(\n    self, z: Tensor, labels: Tensor, device: int, **kwargs\n) -&gt; Tensor:\n    z = z.to(device)\n    labels = labels.to(device)\n    return exp(self.decode(z=z, labels=labels, kwargs=kwargs))\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0, top_sampler=False, bidirectional=False)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>sos</code> <p>start of sequence token. Defaults to 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>top</code> <p>top1 sampling. Defaults to False.</p> <p> TYPE: <code>bool</code> </p> <code>bidirectional</code> <p>bidirectional lstm. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n    top_sampler: bool = False,\n    bidirectional: bool = False,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n        sos (int): start of sequence token. Defaults to 0.\n        top (bool): top1 sampling. Defaults to False.\n        bidirectional (bool): bidirectional lstm. Defaults to False.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = nn.Embedding(input_size, hidden_size)\n    self.embedding_dropout = nn.Dropout(dropout)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=bidirectional,\n    )\n    self.dropout = nn.Dropout(dropout)\n    if bidirectional:\n        print(\"Using bidirectional LSTM\")\n        self.fc = nn.Linear(hidden_size * 2, output_size)\n    else:\n        self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    if top_sampler:\n        print(\"Using topk sampling\")\n        self.sample = self.topk\n    else:\n        print(\"Using multinomial sampling\")\n        self.sample = self.multinomial\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.embedding_dropout","title":"<code>embedding_dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size * 2, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.sample","title":"<code>sample = self.topk</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.forward","title":"<code>forward(batch_size, hidden, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def forward(self, batch_size, hidden, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, device=hidden.device).long()\n    decoder_input[:, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output)\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.sample(decoder_output)\n\n    acts_logits = torch.cat(outputs, dim=1)  # [N, L, C]\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n\n    return acts_log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def forward_step(self, x, hidden):\n    embedded = self.embedding(x)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.multinomial","title":"<code>multinomial(x)</code>","text":"Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def multinomial(self, x):\n    # [N, 1, encodings]\n    acts = torch.multinomial(self.activity_prob_activation(x.squeeze()), 1)\n    # DETACH?\n    return acts\n</code></pre>"},{"location":"reference/caveat/models/discrete/auto_discrete_lstm/#caveat.models.discrete.auto_discrete_lstm.Decoder.topk","title":"<code>topk(x)</code>","text":"Source code in <code>caveat/models/discrete/auto_discrete_lstm.py</code> <pre><code>def topk(self, x):\n    _, topi = x.topk(1)\n    acts = topi.squeeze(-2).detach()  # detach from history as input\n    # DETACH?\n    return acts\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/","title":"caveat.models.discrete.cond_discrete_conv","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.CondDiscCNN2D","title":"<code>CondDiscCNN2D(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>Convolution based encoder and decoder with encoder embedding layer.</p> Source code in <code>caveat/models/discrete/cond_discrete_conv.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"Convolution based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"Model requires labels_size, please check you have configures a compatible encoder and labels attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.CondDiscCNN2D.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_conv.py</code> <pre><code>def build(self, **config):\n    hidden_layers = list\n    latent_dim = int\n    dropout = Optional[float]\n    kernel_size = Optional[Union[tuple[int, int], int]]\n    stride = Optional[Union[tuple[int, int], int]]\n    padding = Optional[Union[tuple[int, int], int]]\n\n    embed_size = config.get(\"embed_size\", self.encodings)\n    hidden_layers = utils.build_hidden_layers(config)\n    latent_dim = 1\n    dropout = config.get(\"dropout\", 0)\n    kernel_size = config.get(\"kernel_size\", 3)\n    stride = config.get(\"stride\", 2)\n    padding = config.get(\"padding\", 1)\n\n    self.latent_dim = latent_dim\n\n    self.encoder = Encoder(\n        input_size=self.encodings,\n        embed_size=embed_size,\n        in_shape=self.in_shape,\n        hidden_layers=hidden_layers,\n        dropout=dropout,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n    )\n    self.target_shapes = self.encoder.target_shapes\n    self.flat_size = self.encoder.flat_size\n    self.shape_before_flattening = self.encoder.shape_before_flattening\n    self.encoder = None  # just used encoder to get target shapes :(\n\n    self.decoder = Decoder(\n        target_shapes=self.target_shapes,\n        hidden_layers=hidden_layers,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n    )\n\n    self.fc_hidden = nn.Linear(self.labels_size, self.flat_size)\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.CondDiscCNN2D.decode","title":"<code>decode(z, labels, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/discrete/cond_discrete_conv.py</code> <pre><code>def decode(\n    self, z: Tensor, labels: Tensor, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    hidden = self.fc_hidden(labels)\n    hidden = hidden.view(self.shape_before_flattening)\n    log_probs = self.decoder(hidden)\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.CondDiscCNN2D.encode","title":"<code>encode(input)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_conv.py</code> <pre><code>def encode(self, input: Tensor):\n    return None\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.CondDiscCNN2D.forward","title":"<code>forward(x, labels=None, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_conv.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    labels: Optional[Tensor] = None,\n    target: Optional[Tensor] = None,\n    **kwargs,\n) -&gt; List[Tensor]:\n    log_probs = self.decode(z=x, labels=labels, target=target)\n    return [log_probs, Tensor([]), Tensor([]), Tensor([])]\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.CondDiscCNN2D.loss_function","title":"<code>loss_function(log_probs, target, mask, **kwargs)</code>","text":"<p>Loss function for discretized encoding [N, L].</p> Source code in <code>caveat/models/discrete/cond_discrete_conv.py</code> <pre><code>def loss_function(\n    self, log_probs: Tensor, target: Tensor, mask: Tensor, **kwargs\n) -&gt; dict:\n    \"\"\"Loss function for discretized encoding [N, L].\"\"\"\n    # activity loss\n    recon_act_nlll = self.NLLL(log_probs.squeeze().permute(0, 2, 1), target)\n\n    # loss\n    loss = recon_act_nlll\n\n    return {\"loss\": loss, \"recon_act_nlll_loss\": recon_act_nlll}\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.CondDiscCNN2D.predict","title":"<code>predict(z, labels, device, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_conv.py</code> <pre><code>def predict(\n    self, z: Tensor, labels: Tensor, device: int, **kwargs\n) -&gt; Tensor:\n    z = z.to(device)\n    labels = labels.to(device)\n    return exp(self.decode(z=z, labels=labels, kwargs=kwargs))\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Decoder","title":"<code>Decoder(target_shapes, hidden_layers, kernel_size=3, stride=2, padding=1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d Conv Decoder.</p> PARAMETER DESCRIPTION <code>target_shapes</code> <p>list of target shapes from encoder.</p> <p> TYPE: <code>list</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>kernel_size</code> <p>description. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>description. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>description. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> Source code in <code>caveat/models/discrete/cond_discrete_conv.py</code> <pre><code>def __init__(\n    self,\n    target_shapes,\n    hidden_layers: list,\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n):\n    \"\"\"2d Conv Decoder.\n\n    Args:\n        target_shapes (list): list of target shapes from encoder.\n        hidden_layers (list, optional): _description_. Defaults to None.\n        kernel_size (Union[tuple[int, int], int], optional): _description_. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): _description_. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): _description_. Defaults to 1.\n    \"\"\"\n    super(Decoder, self).__init__()\n    modules = []\n    target_shapes.reverse()\n\n    for i in range(len(hidden_layers) - 1):\n        modules.append(\n            nn.Sequential(\n                nn.ConvTranspose2d(\n                    in_channels=target_shapes[i][0],\n                    out_channels=target_shapes[i + 1][0],\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    output_padding=calc_output_padding_2d(\n                        target_shapes[i + 1]\n                    ),\n                    # bias=False,\n                ),\n                nn.BatchNorm2d(target_shapes[i + 1][0]),\n                nn.LeakyReLU(),\n            )\n        )\n\n    # Final layer with Tanh activation\n    modules.append(\n        nn.Sequential(\n            nn.ConvTranspose2d(\n                in_channels=target_shapes[-2][0],\n                out_channels=target_shapes[-1][0],\n                kernel_size=kernel_size,\n                stride=stride,\n                padding=padding,\n                output_padding=calc_output_padding_2d(target_shapes[-1]),\n            ),\n            nn.BatchNorm2d(target_shapes[-1][0]),\n            nn.Tanh(),\n        )\n    )\n\n    self.decoder = nn.Sequential(*modules)\n    self.logprob_activation = nn.LogSoftmax(dim=-1)\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Decoder.decoder","title":"<code>decoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Decoder.logprob_activation","title":"<code>logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Decoder.forward","title":"<code>forward(hidden, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_conv.py</code> <pre><code>def forward(self, hidden, **kwargs):\n    y = self.decoder(hidden)\n    y = y.squeeze(1)  # remove conv channel dim\n    return self.logprob_activation(y)\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Encoder","title":"<code>Encoder(input_size, embed_size, in_shape, hidden_layers, dropout=0.1, kernel_size=3, stride=2, padding=1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d Convolutions Encoder.</p> PARAMETER DESCRIPTION <code>in_shape</code> <p>[C, time_step, activity_encoding].</p> <p> TYPE: <code>tuple[int, int, int]</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> <code>kernel_size</code> <p>description. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>description. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>description. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> Source code in <code>caveat/models/discrete/cond_discrete_conv.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    embed_size: int,\n    in_shape: tuple,\n    hidden_layers: list,\n    dropout: float = 0.1,\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n):\n    \"\"\"2d Convolutions Encoder.\n\n    Args:\n        in_shape (tuple[int, int, int]): [C, time_step, activity_encoding].\n        hidden_layers (list, optional): _description_. Defaults to None.\n        dropout (float): dropout. Defaults to 0.1.\n        kernel_size (Union[tuple[int, int], int], optional): _description_. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): _description_. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): _description_. Defaults to 1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    h = in_shape[0]\n    self.embedding = nn.Embedding(input_size, embed_size)\n    w = embed_size\n    channels = 1\n\n    modules = []\n    self.target_shapes = [(channels, h, w)]\n\n    for hidden_channels in hidden_layers:\n        modules.append(\n            nn.Sequential(\n                nn.Conv2d(\n                    in_channels=channels,\n                    out_channels=hidden_channels,\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    # bias=False,\n                ),\n                nn.BatchNorm2d(hidden_channels),\n                nn.LeakyReLU(),\n            )\n        )\n        h, w = conv2d_size(\n            (h, w), kernel_size=kernel_size, padding=padding, stride=stride\n        )\n        self.target_shapes.append((hidden_channels, h, w))\n        channels = hidden_channels\n\n    self.dropout = nn.Dropout(dropout)\n\n    self.shape_before_flattening = (-1, channels, h, w)\n    self.encoder = nn.Sequential(*modules)\n    self.flat_size = int(channels * h * w)\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Encoder.embedding","title":"<code>embedding = nn.Embedding(input_size, embed_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Encoder.encoder","title":"<code>encoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Encoder.flat_size","title":"<code>flat_size = int(channels * h * w)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Encoder.shape_before_flattening","title":"<code>shape_before_flattening = (-1, channels, h, w)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_conv/#caveat.models.discrete.cond_discrete_conv.Encoder.target_shapes","title":"<code>target_shapes = [(channels, h, w)]</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/","title":"caveat.models.discrete.cond_discrete_lstm","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.CondDiscLSTM","title":"<code>CondDiscLSTM(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer and conditionality.</p> Source code in <code>caveat/models/discrete/cond_discrete_lstm.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with encoder embedding layer and conditionality.\"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"Model requires labels_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.CondDiscLSTM.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_lstm.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = 1  # dummy value for the predict dataloader\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length = self.in_shape[0]\n    bidirectional = config.get(\"bidirectional\", False)\n\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n        bidirectional=bidirectional,\n    )\n    if bidirectional:\n        flat_size_encode = self.hidden_n * self.hidden_size * 2 * 2\n        self.adjusted_layers = self.hidden_n * 2\n        self.unflatten_shape = (2 * 2 * self.hidden_n, self.hidden_size)\n    else:\n        flat_size_encode = self.hidden_n * self.hidden_size * 2\n        self.adjusted_layers = self.hidden_n\n        self.unflatten_shape = (2 * self.hidden_n, self.hidden_size)\n    self.fc_hidden = nn.Linear(self.labels_size, flat_size_encode)\n    self.fc_x = nn.Linear(self.labels_size, self.hidden_size)\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.CondDiscLSTM.decode","title":"<code>decode(z, labels, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/discrete/cond_discrete_lstm.py</code> <pre><code>def decode(\n    self, z: None, labels: Tensor, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    h = self.fc_hidden(labels)\n    x = self.fc_x(labels).unsqueeze(-2)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, self.unflatten_shape).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.adjusted_layers\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n\n    log_probs = self.decoder(hidden=hidden, x=x, target=None)\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.CondDiscLSTM.encode","title":"<code>encode(input)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_lstm.py</code> <pre><code>def encode(self, input: Tensor):\n    return None\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.CondDiscLSTM.forward","title":"<code>forward(x, labels=None, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_lstm.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    labels: Optional[Tensor] = None,\n    target: Optional[Tensor] = None,\n    **kwargs,\n) -&gt; List[Tensor]:\n    log_probs = self.decode(z=x, labels=labels, target=target)\n    return [log_probs, Tensor([]), Tensor([]), Tensor([])]\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.CondDiscLSTM.loss_function","title":"<code>loss_function(log_probs, target, mask, **kwargs)</code>","text":"<p>Loss function for discretized encoding [N, L].</p> Source code in <code>caveat/models/discrete/cond_discrete_lstm.py</code> <pre><code>def loss_function(\n    self, log_probs: Tensor, target: Tensor, mask: Tensor, **kwargs\n) -&gt; dict:\n    \"\"\"Loss function for discretized encoding [N, L].\"\"\"\n    # activity loss\n    recon_act_nlll = self.NLLL(log_probs.squeeze().permute(0, 2, 1), target)\n\n    # loss\n    loss = recon_act_nlll\n\n    return {\"loss\": loss, \"recon_act_nlll_loss\": recon_act_nlll}\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.CondDiscLSTM.predict","title":"<code>predict(z, labels, device, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_lstm.py</code> <pre><code>def predict(\n    self, z: Tensor, labels: Tensor, device: int, **kwargs\n) -&gt; Tensor:\n    z = z.to(device)\n    labels = labels.to(device)\n    return exp(self.decode(z=z, labels=labels, kwargs=kwargs))\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0, bidirectional=True)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder. No teacher forcing. LSTM unit input is labels.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>sos</code> <p>start of sequence token. Defaults to 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>bidirectional</code> <p>bidirectional lstm. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Source code in <code>caveat/models/discrete/cond_discrete_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n    bidirectional: bool = True,\n):\n    \"\"\"LSTM Decoder.\n    No teacher forcing.\n    LSTM unit input is labels.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n        sos (int): start of sequence token. Defaults to 0.\n        bidirectional (bool): bidirectional lstm. Defaults to False.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = nn.Embedding(input_size, hidden_size)\n    self.embedding_dropout = nn.Dropout(dropout)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=bidirectional,\n    )\n    self.dropout = nn.Dropout(dropout)\n    if bidirectional:\n        print(\"Using bidirectional LSTM\")\n        self.fc = nn.Linear(hidden_size * 2, output_size)\n    else:\n        self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.embedding_dropout","title":"<code>embedding_dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size * 2, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.forward","title":"<code>forward(hidden, x, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_lstm.py</code> <pre><code>def forward(self, hidden, x, **kwargs):\n    hidden, cell = hidden\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for _ in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            x, decoder_hidden\n        )\n        outputs.append(decoder_output)\n\n    acts_logits = torch.cat(outputs, dim=1)  # [N, L, C]\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n\n    return acts_log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/cond_discrete_lstm/#caveat.models.discrete.cond_discrete_lstm.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/discrete/cond_discrete_lstm.py</code> <pre><code>def forward_step(self, x, hidden):\n    output, hidden = self.lstm(x, hidden)\n    prediction = self.fc(output)\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/","title":"caveat.models.discrete.vae_discrete_cnn1d","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Decoder","title":"<code>Decoder(encoded_size, target_shapes, dropout=0.1, kernel_size=3, stride=2, padding=0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>1d Conv Decoder.</p> PARAMETER DESCRIPTION <code>encoded_size</code> <p>number of encoding classes and hidden size.</p> <p> TYPE: <code>int</code> </p> <code>target_shapes</code> <p>list of target shapes.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> <code>kernel_size</code> <p>kernel size. Defaults to 3.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>stride. Defaults to 2.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>padding. Defaults to 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_cnn1d.py</code> <pre><code>def __init__(\n    self,\n    encoded_size: int,\n    target_shapes: list,\n    dropout: float = 0.1,\n    kernel_size: int = 3,\n    stride: int = 2,\n    padding: int = 0,\n):\n    \"\"\"1d Conv Decoder.\n\n    Args:\n        encoded_size (int): number of encoding classes and hidden size.\n        target_shapes (list): list of target shapes.\n        dropout (float): dropout. Defaults to 0.1.\n        kernel_size (int): kernel size. Defaults to 3.\n        stride (int): stride. Defaults to 2.\n        padding (int): padding. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.hidden_size = encoded_size\n    modules = []\n    target_shapes.reverse()\n\n    for i in range(len(target_shapes) - 1):\n        c_in, l_in = target_shapes[i]\n        c_out, l_out = target_shapes[i + 1]\n        if c_in == c_out and l_in == l_out:\n            print(\n                \"Skipping transpose convolution:\", c_in, l_in, c_out, l_out\n            )\n            continue\n        in_padding, out_padding = calc_output_padding_1d(\n            length=l_in,\n            target=l_out,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n        )\n        block = [\n            nn.ConvTranspose1d(\n                in_channels=c_in,\n                out_channels=c_out,\n                kernel_size=kernel_size,\n                stride=stride,\n                padding=in_padding,\n                output_padding=out_padding,\n                bias=False,\n            ),\n            nn.BatchNorm1d(c_out),\n        ]\n        if i &lt; len(target_shapes) - 2:\n            block.append(nn.LeakyReLU())\n            block.append(nn.Dropout(dropout))\n        modules.append(nn.Sequential(*block))\n\n    self.decoder = nn.Sequential(*modules)\n    self.logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Decoder.decoder","title":"<code>decoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Decoder.hidden_size","title":"<code>hidden_size = encoded_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Decoder.logprob_activation","title":"<code>logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Decoder.forward","title":"<code>forward(hidden, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_cnn1d.py</code> <pre><code>def forward(self, hidden, **kwargs):\n    y = self.decoder(hidden)\n    y = y.permute(0, 2, 1)\n    return self.logprob_activation(y)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Encoder","title":"<code>Encoder(input_encoding, encoded_size, in_shape, hidden_layers, dropout=0.1, kernel_size=2, stride=2, padding=1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>1d Convolutions Encoder.</p> PARAMETER DESCRIPTION <code>input_encoding</code> <p>number of encoding classes.</p> <p> TYPE: <code>int</code> </p> <code>encoded_size</code> <p>number of encoding classes and hidden size.</p> <p> TYPE: <code>int</code> </p> <code>in_shape</code> <p>[C, time_step, activity_encoding].</p> <p> TYPE: <code>tuple[int, int, int]</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> <code>kernel_size</code> <p>kernel size. Defaults to 2.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>stride</code> <p>stride. Defaults to 2.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>padding. Defaults to 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_cnn1d.py</code> <pre><code>def __init__(\n    self,\n    input_encoding: int,\n    encoded_size: int,\n    in_shape: tuple,\n    hidden_layers: list,\n    dropout: float = 0.1,\n    kernel_size: int = 2,\n    stride: int = 2,\n    padding: int = 1,\n):\n    \"\"\"1d Convolutions Encoder.\n\n    Args:\n        input_encoding (int): number of encoding classes.\n        encoded_size (int): number of encoding classes and hidden size.\n        in_shape (tuple[int, int, int]): [C, time_step, activity_encoding].\n        hidden_layers (list, optional): _description_. Defaults to None.\n        dropout (float): dropout. Defaults to 0.1.\n        kernel_size (int): kernel size. Defaults to 2.\n        stride (int): stride. Defaults to 2.\n        padding (int): padding. Defaults to 1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    length = in_shape[0]\n    channels = encoded_size\n    self.shapes = []\n    modules = []\n\n    self.embedding = nn.Embedding(input_encoding, encoded_size)\n\n    for hidden_channels in hidden_layers:\n        self.shapes.append((channels, length))\n        if length + padding &lt; kernel_size:\n            print(\"Skipping convolution:\", length, kernel_size)\n            break\n        modules.append(\n            nn.Sequential(\n                nn.Conv1d(\n                    in_channels=channels,\n                    out_channels=hidden_channels,\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    bias=False,\n                ),\n                nn.BatchNorm1d(hidden_channels),\n                nn.LeakyReLU(),\n                nn.Dropout(dropout),\n            )\n        )\n        length = conv1d_size(\n            length=length,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n        )\n        channels = hidden_channels\n    self.shapes.append((channels, length))\n\n    self.encoder = nn.Sequential(*modules)\n    self.shape_before_flattening = (-1, channels, length)\n    self.flat_size = int(channels * length)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Encoder.embedding","title":"<code>embedding = nn.Embedding(input_encoding, encoded_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Encoder.encoder","title":"<code>encoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Encoder.flat_size","title":"<code>flat_size = int(channels * length)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Encoder.shape_before_flattening","title":"<code>shape_before_flattening = (-1, channels, length)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Encoder.shapes","title":"<code>shapes = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_cnn1d.py</code> <pre><code>def forward(self, x):\n    y = self.embedding(x.int())\n    y = y.permute(0, 2, 1)\n    y = self.encoder(y)\n    y = y.flatten(start_dim=1)\n    return y\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.VAEDiscCNN1D","title":"<code>VAEDiscCNN1D(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>Convolution based encoder and decoder with encoder embedding layer.</p> Source code in <code>caveat/models/discrete/vae_discrete_cnn1d.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"Convolution based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.VAEDiscCNN1D.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_cnn1d.py</code> <pre><code>def build(self, **config):\n    hidden_layers = list\n    latent_dim = int\n    dropout = Optional[float]\n    kernel_size = Optional[int]\n    stride = Optional[int]\n    padding = Optional[int]\n\n    encoded_size = config.get(\"embed_size\", self.encodings)\n    hidden_layers = hidden_layers = utils.build_hidden_layers(config)\n    latent_dim = config[\"latent_dim\"]\n    dropout = config.get(\"dropout\", 0)\n    kernel_size = config.get(\"kernel_size\", 2)\n    stride = config.get(\"stride\", 2)\n    padding = config.get(\"padding\", 0)\n\n    self.latent_dim = latent_dim\n\n    self.encoder = Encoder(\n        input_encoding=self.encodings,\n        encoded_size=encoded_size,\n        in_shape=self.in_shape,\n        hidden_layers=hidden_layers,\n        dropout=dropout,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n    )\n    self.decoder = Decoder(\n        encoded_size=encoded_size,\n        target_shapes=self.encoder.shapes,\n        dropout=dropout,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n    )\n    self.fc_mu = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_var = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_hidden = nn.Linear(latent_dim, self.encoder.flat_size)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.VAEDiscCNN1D.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_cnn1d.py</code> <pre><code>def decode(self, z: Tensor, target=None, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    hidden = self.fc_hidden(z)\n    hidden = hidden.view(self.encoder.shape_before_flattening)\n    log_probs = self.decoder(hidden)\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn1d/#caveat.models.discrete.vae_discrete_cnn1d.VAEDiscCNN1D.loss_function","title":"<code>loss_function(log_probs, mu, log_var, target, mask, *args, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_cnn1d.py</code> <pre><code>def loss_function(\n    self, log_probs, mu, log_var, target, mask, *args, **kwargs\n) -&gt; dict:\n    return self.discretized_loss(\n        log_probs, mu, log_var, target, mask, *args, **kwargs\n    )\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/","title":"caveat.models.discrete.vae_discrete_cnn2d","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Decoder","title":"<code>Decoder(target_shapes, hidden_layers, kernel_size=3, stride=2, padding=1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d Conv Decoder.</p> PARAMETER DESCRIPTION <code>target_shapes</code> <p>list of target shapes from encoder.</p> <p> TYPE: <code>list</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>kernel_size</code> <p>description. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>description. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>description. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_cnn2d.py</code> <pre><code>def __init__(\n    self,\n    target_shapes,\n    hidden_layers: list,\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n):\n    \"\"\"2d Conv Decoder.\n\n    Args:\n        target_shapes (list): list of target shapes from encoder.\n        hidden_layers (list, optional): _description_. Defaults to None.\n        kernel_size (Union[tuple[int, int], int], optional): _description_. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): _description_. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): _description_. Defaults to 1.\n    \"\"\"\n    super(Decoder, self).__init__()\n    modules = []\n    target_shapes.reverse()\n\n    for i in range(len(hidden_layers) - 1):\n        modules.append(\n            nn.Sequential(\n                nn.ConvTranspose2d(\n                    in_channels=target_shapes[i][0],\n                    out_channels=target_shapes[i + 1][0],\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    output_padding=calc_output_padding_2d(\n                        target_shapes[i + 1]\n                    ),\n                    # bias=False,\n                ),\n                nn.BatchNorm2d(target_shapes[i + 1][0]),\n                nn.LeakyReLU(),\n            )\n        )\n\n    # Final layer with Tanh activation\n    modules.append(\n        nn.Sequential(\n            nn.ConvTranspose2d(\n                in_channels=target_shapes[-2][0],\n                out_channels=target_shapes[-1][0],\n                kernel_size=kernel_size,\n                stride=stride,\n                padding=padding,\n                output_padding=calc_output_padding_2d(target_shapes[-1]),\n            ),\n            nn.BatchNorm2d(target_shapes[-1][0]),\n            nn.Tanh(),\n        )\n    )\n\n    self.decoder = nn.Sequential(*modules)\n    self.logprob_activation = nn.LogSoftmax(dim=-1)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Decoder.decoder","title":"<code>decoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Decoder.logprob_activation","title":"<code>logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Decoder.forward","title":"<code>forward(hidden, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_cnn2d.py</code> <pre><code>def forward(self, hidden, **kwargs):\n    y = self.decoder(hidden)\n    y = y.squeeze(1)  # remove conv channel dim\n    return self.logprob_activation(y)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Encoder","title":"<code>Encoder(input_size, embed_size, in_shape, hidden_layers, dropout=0.1, kernel_size=3, stride=2, padding=1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d Convolutions Encoder.</p> PARAMETER DESCRIPTION <code>in_shape</code> <p>[C, time_step, activity_encoding].</p> <p> TYPE: <code>tuple[int, int, int]</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> <code>kernel_size</code> <p>description. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>description. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>description. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_cnn2d.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    embed_size: int,\n    in_shape: tuple,\n    hidden_layers: list,\n    dropout: float = 0.1,\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n):\n    \"\"\"2d Convolutions Encoder.\n\n    Args:\n        in_shape (tuple[int, int, int]): [C, time_step, activity_encoding].\n        hidden_layers (list, optional): _description_. Defaults to None.\n        dropout (float): dropout. Defaults to 0.1.\n        kernel_size (Union[tuple[int, int], int], optional): _description_. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): _description_. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): _description_. Defaults to 1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    h = in_shape[0]\n    self.embedding = nn.Embedding(input_size, embed_size)\n    w = embed_size\n    channels = 1\n\n    modules = []\n    self.target_shapes = [(channels, h, w)]\n\n    for hidden_channels in hidden_layers:\n        modules.append(\n            nn.Sequential(\n                nn.Conv2d(\n                    in_channels=channels,\n                    out_channels=hidden_channels,\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    # bias=False,\n                ),\n                nn.BatchNorm2d(hidden_channels),\n                nn.LeakyReLU(),\n            )\n        )\n        h, w = conv2d_size(\n            (h, w), kernel_size=kernel_size, padding=padding, stride=stride\n        )\n        self.target_shapes.append((hidden_channels, h, w))\n        channels = hidden_channels\n\n    self.dropout = nn.Dropout(dropout)\n\n    self.shape_before_flattening = (-1, channels, h, w)\n    self.encoder = nn.Sequential(*modules)\n    self.flat_size = int(channels * h * w)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Encoder.embedding","title":"<code>embedding = nn.Embedding(input_size, embed_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Encoder.encoder","title":"<code>encoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Encoder.flat_size","title":"<code>flat_size = int(channels * h * w)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Encoder.shape_before_flattening","title":"<code>shape_before_flattening = (-1, channels, h, w)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Encoder.target_shapes","title":"<code>target_shapes = [(channels, h, w)]</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_cnn2d.py</code> <pre><code>def forward(self, x):\n    y = self.dropout(self.embedding(x.int()))\n    y = y.unsqueeze(1)  # add channel dim for Conv\n    y = self.encoder(y)\n    y = y.flatten(start_dim=1)\n    return y\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.VAEDiscCNN2D","title":"<code>VAEDiscCNN2D(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>Convolution based encoder and decoder with encoder embedding layer.</p> Source code in <code>caveat/models/discrete/vae_discrete_cnn2d.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"Convolution based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.VAEDiscCNN2D.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_cnn2d.py</code> <pre><code>def build(self, **config):\n    hidden_layers = list\n    latent_dim = int\n    dropout = Optional[float]\n    kernel_size = Optional[Union[tuple[int, int], int]]\n    stride = Optional[Union[tuple[int, int], int]]\n    padding = Optional[Union[tuple[int, int], int]]\n\n    embed_size = config.get(\"embed_size\", self.encodings)\n    hidden_layers = utils.build_hidden_layers(config)\n    latent_dim = config[\"latent_dim\"]\n    dropout = config.get(\"dropout\", 0)\n    kernel_size = config.get(\"kernel_size\", 3)\n    stride = config.get(\"stride\", 2)\n    padding = config.get(\"padding\", 1)\n\n    self.latent_dim = latent_dim\n\n    self.encoder = Encoder(\n        input_size=self.encodings,\n        embed_size=embed_size,\n        in_shape=self.in_shape,\n        hidden_layers=hidden_layers,\n        dropout=dropout,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n    )\n    self.decoder = Decoder(\n        target_shapes=self.encoder.target_shapes,\n        hidden_layers=hidden_layers,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n    )\n    self.fc_mu = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_var = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_hidden = nn.Linear(latent_dim, self.encoder.flat_size)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.VAEDiscCNN2D.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_cnn2d.py</code> <pre><code>def decode(self, z: Tensor, target=None, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    hidden = self.fc_hidden(z)\n    hidden = hidden.view(self.encoder.shape_before_flattening)\n    log_probs = self.decoder(hidden)\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_cnn2d/#caveat.models.discrete.vae_discrete_cnn2d.VAEDiscCNN2D.loss_function","title":"<code>loss_function(log_probs, mu, log_var, target, weights, *args, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_cnn2d.py</code> <pre><code>def loss_function(\n    self, log_probs, mu, log_var, target, weights, *args, **kwargs\n) -&gt; dict:\n    return self.discretized_loss(\n        log_probs, mu, log_var, target, weights, *args, **kwargs\n    )\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_fc/","title":"caveat.models.discrete.vae_discrete_fc","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Decoder","title":"<code>Decoder(length, in_size, encoded_size, hidden_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d flatten to 1d then fully connected.</p> PARAMETER DESCRIPTION <code>length</code> <p>number of time steps.</p> <p> TYPE: <code>int</code> </p> <code>in_size</code> <p>input size.</p> <p> TYPE: <code>int</code> </p> <code>encoded_size</code> <p>list of target shapes from encoder.</p> <p> TYPE: <code>list</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_fc.py</code> <pre><code>def __init__(\n    self,\n    length: int,\n    in_size: int,\n    encoded_size: int,\n    hidden_layers: list,\n    dropout: float = 0.1,\n):\n    \"\"\"2d flatten to 1d then fully connected.\n\n    Args:\n        length (int): number of time steps.\n        in_size (int): input size.\n        encoded_size (list): list of target shapes from encoder.\n        hidden_layers (list, optional): _description_. Defaults to None.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.length = length\n    self.hidden_size = encoded_size\n    hidden_layers.reverse()\n    modules = []\n\n    input_size = in_size\n    for i in range(len(hidden_layers)):\n        hidden_channels = hidden_layers[i]\n        size = length * hidden_channels\n        block = [nn.Linear(input_size, size), nn.BatchNorm1d(size)]\n        if i &lt; len(hidden_layers) - 1:\n            block.append(nn.LeakyReLU())\n            block.append(nn.Dropout(dropout))\n        modules.append(nn.Sequential(*block))\n        input_size = size\n\n    # Final layer\n    modules.append(nn.Linear(input_size, length * encoded_size))\n\n    self.dropout = nn.Dropout(dropout)\n    self.decoder = nn.Sequential(*modules)\n    self.logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Decoder.decoder","title":"<code>decoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Decoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Decoder.hidden_size","title":"<code>hidden_size = encoded_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Decoder.length","title":"<code>length = length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Decoder.logprob_activation","title":"<code>logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Decoder.forward","title":"<code>forward(hidden, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_fc.py</code> <pre><code>def forward(self, hidden, **kwargs):\n    y = self.decoder(hidden)\n    y = y.view(-1, self.length, self.hidden_size)\n    return self.logprob_activation(y)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Encoder","title":"<code>Encoder(length, input_encoding, encoded_size, hidden_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d flatten to 1d then fully connected.</p> PARAMETER DESCRIPTION <code>length</code> <p>number of time steps.</p> <p> TYPE: <code>int</code> </p> <code>input_encoding</code> <p>number of encoding classes.</p> <p> TYPE: <code>int</code> </p> <code>encoded_size</code> <p>number of encoding classes and hidden size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_fc.py</code> <pre><code>def __init__(\n    self,\n    length: int,\n    input_encoding: int,\n    encoded_size: int,\n    hidden_layers: list,\n    dropout: float = 0.1,\n):\n    \"\"\"2d flatten to 1d then fully connected.\n\n    Args:\n        length (int): number of time steps.\n        input_encoding (int): number of encoding classes.\n        encoded_size (int): number of encoding classes and hidden size.\n        hidden_layers (list, optional): _description_. Defaults to None.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.embedding = nn.Embedding(input_encoding, encoded_size)\n    modules = []\n\n    input_size = length * encoded_size\n    self.flat_embed_size = input_size\n    for hidden_channels in hidden_layers:\n        size = length * hidden_channels\n        modules.append(\n            nn.Sequential(\n                nn.Linear(input_size, size),\n                nn.BatchNorm1d(size),\n                nn.LeakyReLU(),\n                nn.Dropout(dropout),\n            )\n        )\n        input_size = size\n    self.flat_size = size\n    self.dropout = nn.Dropout(dropout)\n    self.encoder = nn.Sequential(*modules)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Encoder.embedding","title":"<code>embedding = nn.Embedding(input_encoding, encoded_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Encoder.encoder","title":"<code>encoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Encoder.flat_embed_size","title":"<code>flat_embed_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Encoder.flat_size","title":"<code>flat_size = size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_fc.py</code> <pre><code>def forward(self, x):\n    y = self.dropout(self.embedding(x.int()))\n    y = y.flatten(1)\n    y = self.encoder(y)\n    return y\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.VAEDiscFC","title":"<code>VAEDiscFC(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>Fully connected encoder and decoder with embedding layer.</p> Source code in <code>caveat/models/discrete/vae_discrete_fc.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"Fully connected encoder and decoder with embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.VAEDiscFC.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_fc.py</code> <pre><code>def build(self, **config):\n    latent_dim = int\n    dropout = Optional[float]\n\n    encoded_size = config.get(\"embed_size\", self.encodings)\n    hidden_layers = utils.build_hidden_layers(config)\n    latent_dim = config[\"latent_dim\"]\n    dropout = config.get(\"dropout\", 0)\n    self.latent_dim = latent_dim\n\n    self.encoder = Encoder(\n        length=self.in_shape[0],\n        input_encoding=self.encodings,\n        encoded_size=encoded_size,\n        hidden_layers=hidden_layers,\n        dropout=dropout,\n    )\n    # TODO add drop out\n    self.decoder = Decoder(\n        length=self.in_shape[0],\n        in_size=self.encoder.flat_size,\n        encoded_size=encoded_size,\n        hidden_layers=hidden_layers,\n        dropout=dropout,\n    )\n    self.fc_mu = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_var = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_hidden = nn.Linear(latent_dim, self.encoder.flat_size)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.VAEDiscFC.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_fc.py</code> <pre><code>def decode(self, z: Tensor, target=None, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    hidden = self.fc_hidden(z)\n    log_probs = self.decoder(hidden)\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_fc/#caveat.models.discrete.vae_discrete_fc.VAEDiscFC.loss_function","title":"<code>loss_function(log_probs, mu, log_var, target, mask, *args, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_fc.py</code> <pre><code>def loss_function(\n    self, log_probs, mu, log_var, target, mask, *args, **kwargs\n) -&gt; dict:\n    return self.discretized_loss(\n        log_probs, mu, log_var, target, mask, *args, **kwargs\n    )\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/","title":"caveat.models.discrete.vae_discrete_lstm","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = nn.Embedding(input_size, hidden_size)\n    self.embedding_dropout = nn.Dropout(dropout)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.dropout = nn.Dropout(dropout)\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.embedding_dropout","title":"<code>embedding_dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.forward","title":"<code>forward(batch_size, hidden, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_lstm.py</code> <pre><code>def forward(self, batch_size, hidden, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(\n        batch_size, 1, device=hidden.device\n    )  # [N, L=0]\n    decoder_input[:, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output)\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    acts_logits = torch.cat(outputs, dim=1)  # [N, L, C]\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n\n    return acts_log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_lstm.py</code> <pre><code>def forward_step(self, x, hidden):\n    # x = [N, 1]\n    embedded = self.embedding(x.long())  # todo: get longs from encoder\n    # todo: dropout\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, encodings]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Decoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_lstm.py</code> <pre><code>def pack(self, x):\n    # [N, encodings]\n    _, topi = x.topk(1)\n    acts = topi.squeeze(-2).detach()  # detach from history as input\n    # [N, 1]\n    return acts\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Encoder","title":"<code>Encoder(input_size, hidden_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = nn.Embedding(input_size, hidden_size)\n    self.embed_dropout = nn.Dropout(dropout)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm1 = nn.LayerNorm(hidden_size)\n    self.norm2 = nn.LayerNorm(hidden_size)\n    self.hidden_dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Encoder.embed_dropout","title":"<code>embed_dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Encoder.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Encoder.hidden_dropout","title":"<code>hidden_dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Encoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Encoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Encoder.norm1","title":"<code>norm1 = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Encoder.norm2","title":"<code>norm2 = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Encoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_lstm.py</code> <pre><code>def forward(self, x):\n    embedded = self.embedding(x.long())\n    embedded = self.embed_dropout(embedded)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm1(h1)\n    h2 = self.norm2(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    hidden = self.hidden_dropout(hidden)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.VAEDiscLSTM","title":"<code>VAEDiscLSTM(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer.</p> Source code in <code>caveat/models/discrete/vae_discrete_lstm.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.VAEDiscLSTM.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_lstm.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length = self.in_shape[0]\n\n    self.encoder = Encoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.VAEDiscLSTM.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_lstm.py</code> <pre><code>def decode(self, z: Tensor, target=None, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_lstm/#caveat.models.discrete.vae_discrete_lstm.VAEDiscLSTM.loss_function","title":"<code>loss_function(log_probs, mu, log_var, target, mask, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_lstm.py</code> <pre><code>def loss_function(\n    self,\n    log_probs: Tensor,\n    mu: Tensor,\n    log_var: Tensor,\n    target: Tensor,\n    mask: Tensor,\n    **kwargs,\n) -&gt; dict:\n    return super().discretized_loss(\n        log_probs, mu, log_var, target, mask, **kwargs\n    )\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/","title":"caveat.models.discrete.vae_discrete_xattention","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionDecoder","title":"<code>AttentionDecoder(input_size, hidden_size, output_size, num_heads, num_layers, length, dropout=0.0, position_embedding='learnt')</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_heads,\n    num_layers,\n    length,\n    dropout: float = 0.0,\n    position_embedding: str = \"learnt\",\n) -&gt; None:\n    super().__init__()\n    self.embedding = nn.Embedding(input_size, hidden_size)\n    self.embed_dropout = nn.Dropout(dropout)\n\n    if position_embedding == \"learnt\":\n        self.position_embedding = LearntPositionalEncoding(\n            d_model=hidden_size, dropout=dropout, length=length\n        )\n    elif position_embedding == \"fixed\":\n        self.position_embedding = FixedPositionalEncoding(\n            d_model=hidden_size, dropout=dropout, length=length\n        )\n    else:\n        raise ValueError(\n            f\"Positional embedding must be either 'learnt' or 'fixed', got {position_embedding}\"\n        )\n    self.blocks = nn.ModuleList(\n        [\n            DecoderBlock(\n                hidden_size,\n                n_head=num_heads,\n                dropout=dropout,\n                block_size=length,\n            )\n            for _ in range(num_layers)\n        ]\n    )\n    self.ln_f = nn.LayerNorm(hidden_size)\n    self.lm_head = nn.Linear(hidden_size, output_size)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.apply(self._init_weights)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionDecoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionDecoder.blocks","title":"<code>blocks = nn.ModuleList([DecoderBlock(hidden_size, n_head=num_heads, dropout=dropout, block_size=length) for _ in range(num_layers)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionDecoder.embed_dropout","title":"<code>embed_dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionDecoder.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionDecoder.lm_head","title":"<code>lm_head = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionDecoder.ln_f","title":"<code>ln_f = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionDecoder.position_embedding","title":"<code>position_embedding = LearntPositionalEncoding(d_model=hidden_size, dropout=dropout, length=length)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionDecoder.forward","title":"<code>forward(x_encode, x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x_encode, x):\n    # idx and targets are both (B,T) tensor of integers\n    x = self.embedding(x.long())  # (B,T,C)\n    x = self.position_embedding(x)  # (B,T,C)\n\n    for layer in self.blocks:\n        x = layer(x_encode, x)\n\n    x = self.ln_f(x)  # (B,T,C)\n    x = self.lm_head(x)\n    # todo get ride of this ^, needs to be done for cnn too\n\n    acts_log_probs = self.activity_logprob_activation(x)\n\n    return acts_log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionEncoder","title":"<code>AttentionEncoder(input_size, hidden_size, length, n_head, n_layer, dropout=0.0, position_embedding='learnt')</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    length,\n    n_head,\n    n_layer,\n    dropout: float = 0.0,\n    position_embedding: str = \"learnt\",\n):\n    super().__init__()\n    self.embedding = nn.Embedding(input_size, hidden_size)\n    self.embed_dropout = nn.Dropout(dropout)\n\n    if position_embedding == \"learnt\":\n        self.position_embedding = LearntPositionalEncoding(\n            d_model=hidden_size, dropout=0.0, length=length\n        )\n    elif position_embedding == \"fixed\":\n        self.position_embedding = FixedPositionalEncoding(\n            d_model=hidden_size, dropout=0.0, length=length\n        )\n    else:\n        raise ValueError(\n            f\"Positional embedding must be either 'learnt' or 'fixed', got {position_embedding}\"\n        )\n\n    self.blocks = nn.Sequential(\n        *[\n            EncoderBlock(hidden_size, n_head=n_head, dropout=dropout)\n            for _ in range(n_layer)\n        ]\n    )\n    self.ln_f = nn.LayerNorm(hidden_size)  # final layer norm\n    # self.lm_head = nn.Linear(hidden_size, input_size)\n\n    # better init\n    self.apply(self._init_weights)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionEncoder.blocks","title":"<code>blocks = nn.Sequential(*[EncoderBlock(hidden_size, n_head=n_head, dropout=dropout) for _ in range(n_layer)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionEncoder.embed_dropout","title":"<code>embed_dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionEncoder.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionEncoder.ln_f","title":"<code>ln_f = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionEncoder.position_embedding","title":"<code>position_embedding = LearntPositionalEncoding(d_model=hidden_size, dropout=0.0, length=length)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionEncoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x):\n    # idx and targets are both (B,T) tensor of integers\n    x = self.embedding(x.long())  # (B,T,C)\n    x = self.position_embedding(x)  # (B,T,C)\n    x = self.blocks(x)  # (B,T,C)\n    x = self.ln_f(x)  # (B,T,C)\n    x = x.flatten(1)\n\n    return x\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionHead","title":"<code>AttentionHead(head_size, n_embd=10, block_size=128, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>one head of self-attention</p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, head_size, n_embd=10, block_size=128, dropout=0.0):\n    super().__init__()\n    self.key = nn.Linear(n_embd, head_size, bias=False)\n    self.query = nn.Linear(n_embd, head_size, bias=False)\n    self.value = nn.Linear(n_embd, head_size, bias=False)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionHead.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionHead.key","title":"<code>key = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionHead.query","title":"<code>query = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionHead.value","title":"<code>value = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.AttentionHead.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x):\n    # input of size (batch, time-step, channels)\n    # output of size (batch, time-step, head size)\n    k = self.key(x)  # (B,T,hs)\n    q = self.query(x)  # (B,T,hs)\n    # compute attention scores (\"affinities\")\n    wei = (\n        q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n    )  # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)\n    wei = F.softmax(wei, dim=-1)  # (B, T, T)\n    wei = self.dropout(wei)\n    # perform the weighted aggregation of the values\n    v = self.value(x)  # (B,T,hs)\n    out = wei @ v  # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)\n    return out\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.CrossAttentionHead","title":"<code>CrossAttentionHead(head_size, n_embd=10, block_size=128, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>one head of x-attention</p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, head_size, n_embd=10, block_size=128, dropout=0.0):\n    super().__init__()\n    self.key = nn.Linear(n_embd, head_size, bias=False)\n    self.query = nn.Linear(n_embd, head_size, bias=False)\n    self.value = nn.Linear(n_embd, head_size, bias=False)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.CrossAttentionHead.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.CrossAttentionHead.key","title":"<code>key = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.CrossAttentionHead.query","title":"<code>query = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.CrossAttentionHead.value","title":"<code>value = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.CrossAttentionHead.forward","title":"<code>forward(x_encode, x_decode)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x_encode, x_decode):\n    # input of size (batch, time-step, channels)\n    # output of size (batch, time-step, head size)\n    k = self.key(x_encode)  # (B,T,hs)\n    q = self.query(x_decode)  # (B,T,hs)\n    # compute attention scores (\"affinities\")\n    wei = (\n        q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n    )  # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)\n    wei = F.softmax(wei, dim=-1)  # (B, T, T)\n    wei = self.dropout(wei)\n    # perform the weighted aggregation of the values\n    v = self.value(x_encode)  # (B,T,hs)\n    out = wei @ v  # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)\n    return out\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.DecoderBlock","title":"<code>DecoderBlock(n_embd, n_head, block_size, dropout)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, n_embd, n_head, block_size, dropout):\n    # n_embd: embedding dimension, n_head: the number of heads we'd like\n    super().__init__()\n    head_size = n_embd // n_head\n    self.sa = MultiHeadMaskedAttention(\n        num_heads=n_head,\n        head_size=head_size,\n        n_embd=n_embd,\n        block_size=block_size,\n        dropout=dropout,\n    )\n    self.ca = MultiHeadCrossAttention(\n        num_heads=n_head,\n        head_size=head_size,\n        n_embd=n_embd,\n        dropout=dropout,\n    )\n    self.ffwd = FeedFoward(n_embd)\n    self.ln1 = nn.LayerNorm(n_embd)\n    self.ln2 = nn.LayerNorm(n_embd)\n    self.ln3 = nn.LayerNorm(n_embd)\n    self.ln4 = nn.LayerNorm(n_embd)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.DecoderBlock.ca","title":"<code>ca = MultiHeadCrossAttention(num_heads=n_head, head_size=head_size, n_embd=n_embd, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.DecoderBlock.ffwd","title":"<code>ffwd = FeedFoward(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.DecoderBlock.ln1","title":"<code>ln1 = nn.LayerNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.DecoderBlock.ln2","title":"<code>ln2 = nn.LayerNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.DecoderBlock.ln3","title":"<code>ln3 = nn.LayerNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.DecoderBlock.ln4","title":"<code>ln4 = nn.LayerNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.DecoderBlock.sa","title":"<code>sa = MultiHeadMaskedAttention(num_heads=n_head, head_size=head_size, n_embd=n_embd, block_size=block_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.DecoderBlock.forward","title":"<code>forward(x_encode, x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x_encode, x):\n    x = x + self.sa(self.ln1(x))\n    x = x + self.ca(self.ln2(x_encode), self.ln3(x))\n    x = x + self.ffwd(self.ln4(x))\n    return x\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.EncoderBlock","title":"<code>EncoderBlock(n_embd, n_head, dropout)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Transformer block: communication followed by computation</p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, n_embd, n_head, dropout):\n    # n_embd: embedding dimension, n_head: the number of heads we'd like\n    super().__init__()\n    head_size = n_embd // n_head\n    self.sa = MultiHeadAttention(\n        num_heads=n_head,\n        head_size=head_size,\n        n_embd=n_embd,\n        dropout=dropout,\n    )\n    self.ffwd = FeedFoward(n_embd)\n    self.ln1 = nn.LayerNorm(n_embd)\n    self.ln2 = nn.LayerNorm(n_embd)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.EncoderBlock.ffwd","title":"<code>ffwd = FeedFoward(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.EncoderBlock.ln1","title":"<code>ln1 = nn.LayerNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.EncoderBlock.ln2","title":"<code>ln2 = nn.LayerNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.EncoderBlock.sa","title":"<code>sa = MultiHeadAttention(num_heads=n_head, head_size=head_size, n_embd=n_embd, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.EncoderBlock.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x):\n    x = x + self.sa(self.ln1(x))\n    x = x + self.ffwd(self.ln2(x))\n    return x\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.FeedFoward","title":"<code>FeedFoward(n_embd, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>a simple linear layer followed by a non-linearity</p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, n_embd, dropout=0.0):\n    super().__init__()\n    self.net = nn.Sequential(\n        nn.Linear(n_embd, 1 * n_embd),\n        nn.GELU(),\n        nn.Linear(1 * n_embd, n_embd),\n        nn.Dropout(dropout),\n    )\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.FeedFoward.net","title":"<code>net = nn.Sequential(nn.Linear(n_embd, 1 * n_embd), nn.GELU(), nn.Linear(1 * n_embd, n_embd), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.FeedFoward.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x):\n    return self.net(x)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.FixedPositionalEncoding","title":"<code>FixedPositionalEncoding(d_model, dropout=0.0, length=144)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, d_model: int, dropout: float = 0.0, length: int = 144):\n    super().__init__()\n    self.dropout = nn.Dropout(p=dropout)\n\n    position = torch.arange(length).unsqueeze(1)\n    div_term = torch.exp(\n        torch.arange(0, d_model, 2) * (-math.log(length) / d_model)\n    )\n    pe = torch.zeros(length, d_model)\n    pe[:, 0::2] = torch.sin(position * div_term)\n    pe[:, 1::2] = torch.cos(position * div_term)\n    self.register_buffer(\"pe\", pe)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.FixedPositionalEncoding.dropout","title":"<code>dropout = nn.Dropout(p=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.FixedPositionalEncoding.forward","title":"<code>forward(x)</code>","text":"PARAMETER DESCRIPTION <code>x</code> <p>Tensor, shape <code>[seq_len, batch_size, embedding_dim]</code></p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x: Tensor) -&gt; Tensor:\n    \"\"\"\n    Arguments:\n        x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n    \"\"\"\n    _, T, _ = x.shape\n    x = x + self.pe[:T, :]\n    return self.dropout(x)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.LearntPositionalEncoding","title":"<code>LearntPositionalEncoding(d_model, dropout=0.0, length=144)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, d_model: int, dropout: float = 0.0, length: int = 144):\n    super().__init__()\n    self.dropout = nn.Dropout(p=dropout)\n    pe = torch.arange(0, length, dtype=torch.long)  # (T)\n    self.register_buffer(\"pe\", pe)\n    self.embedding = nn.Embedding(length, d_model)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.LearntPositionalEncoding.dropout","title":"<code>dropout = nn.Dropout(p=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.LearntPositionalEncoding.embedding","title":"<code>embedding = nn.Embedding(length, d_model)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.LearntPositionalEncoding.forward","title":"<code>forward(x)</code>","text":"PARAMETER DESCRIPTION <code>x</code> <p>Tensor, shape <code>[seq_len, batch_size, embedding_dim]</code></p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x: Tensor) -&gt; Tensor:\n    \"\"\"\n    Arguments:\n        x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n    \"\"\"\n    _, L, _ = x.shape  # (B,T,C)\n\n    pos_emb = self.embedding(self.pe[:L]).unsqueeze(0)  # (1,L,C)\n    x = x + pos_emb  # (B,L,C)\n    return self.dropout(x)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MaskedAttentionHead","title":"<code>MaskedAttentionHead(head_size, n_embd=10, block_size=128, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>one head of self-attention</p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, head_size, n_embd=10, block_size=128, dropout=0.0):\n    super().__init__()\n    self.key = nn.Linear(n_embd, head_size, bias=False)\n    self.query = nn.Linear(n_embd, head_size, bias=False)\n    self.value = nn.Linear(n_embd, head_size, bias=False)\n    self.register_buffer(\n        \"tril\", torch.tril(torch.ones(block_size, block_size))\n    )\n\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MaskedAttentionHead.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MaskedAttentionHead.key","title":"<code>key = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MaskedAttentionHead.query","title":"<code>query = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MaskedAttentionHead.value","title":"<code>value = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MaskedAttentionHead.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x):\n    B, T, C = x.shape\n    # input of size (batch, time-step, channels)\n    # output of size (batch, time-step, head size)\n    k = self.key(x)  # (B,T,hs)\n    q = self.query(x)  # (B,T,hs)\n    # compute attention scores (\"affinities\")\n    wei = (\n        q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n    )  # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)\n    wei = wei.masked_fill(\n        self.tril[:T, :T] == 0, float(\"-inf\")\n    )  # (B, T, T)\n    wei = F.softmax(wei, dim=-1)  # (B, T, T)\n    wei = self.dropout(wei)\n    # perform the weighted aggregation of the values\n    v = self.value(x)  # (B,T,hs)\n    out = wei @ v  # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)\n    return out\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadAttention","title":"<code>MultiHeadAttention(num_heads, head_size, n_embd=10, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>multiple heads of self-attention in parallel</p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, num_heads, head_size, n_embd=10, dropout=0.0):\n    super().__init__()\n    self.heads = nn.ModuleList(\n        [\n            AttentionHead(head_size=head_size, n_embd=n_embd)\n            for _ in range(num_heads)\n        ]\n    )\n    self.proj = nn.Linear(head_size * num_heads, n_embd)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadAttention.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadAttention.heads","title":"<code>heads = nn.ModuleList([AttentionHead(head_size=head_size, n_embd=n_embd) for _ in range(num_heads)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadAttention.proj","title":"<code>proj = nn.Linear(head_size * num_heads, n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadAttention.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x):\n    out = torch.cat([h(x) for h in self.heads], dim=-1)\n    out = self.dropout(self.proj(out))\n    return out\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadCrossAttention","title":"<code>MultiHeadCrossAttention(num_heads, head_size, n_embd=10, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>multiple heads of masked x-attention in parallel</p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, num_heads, head_size, n_embd=10, dropout=0.0):\n    super().__init__()\n    self.heads = nn.ModuleList(\n        [\n            CrossAttentionHead(head_size=head_size, n_embd=n_embd)\n            for _ in range(num_heads)\n        ]\n    )\n    self.proj = nn.Linear(head_size * num_heads, n_embd)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadCrossAttention.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadCrossAttention.heads","title":"<code>heads = nn.ModuleList([CrossAttentionHead(head_size=head_size, n_embd=n_embd) for _ in range(num_heads)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadCrossAttention.proj","title":"<code>proj = nn.Linear(head_size * num_heads, n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadCrossAttention.forward","title":"<code>forward(x_encode, x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x_encode, x):\n    out = torch.cat([h(x_encode, x) for h in self.heads], dim=-1)\n    out = self.dropout(self.proj(out))\n    return out\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadMaskedAttention","title":"<code>MultiHeadMaskedAttention(num_heads, head_size, block_size, n_embd=10, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Multiple heads of masked self-attention in parallel</p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(\n    self, num_heads, head_size, block_size, n_embd=10, dropout=0.0\n):\n    super().__init__()\n    self.masked_heads = nn.ModuleList(\n        [\n            MaskedAttentionHead(\n                head_size=head_size, n_embd=n_embd, block_size=block_size\n            )\n            for _ in range(num_heads)\n        ]\n    )\n    self.proj = nn.Linear(head_size * num_heads, n_embd)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadMaskedAttention.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadMaskedAttention.masked_heads","title":"<code>masked_heads = nn.ModuleList([MaskedAttentionHead(head_size=head_size, n_embd=n_embd, block_size=block_size) for _ in range(num_heads)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadMaskedAttention.proj","title":"<code>proj = nn.Linear(head_size * num_heads, n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.MultiHeadMaskedAttention.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x):\n    out = torch.cat([h(x) for h in self.masked_heads], dim=-1)\n    out = self.dropout(self.proj(out))\n    return out\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.VAEDiscXTrans","title":"<code>VAEDiscXTrans(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer.</p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.VAEDiscXTrans.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    print(f\"Latent dim: {self.latent_dim}\")\n    self.hidden_size = config[\"hidden_size\"]\n    print(f\"Hidden size: {self.hidden_size}\")\n    self.heads = config[\"heads\"]\n    print(f\"Heads: {self.heads}\")\n    self.hidden_n = config[\"hidden_n\"]\n    print(f\"Hidden n: {self.hidden_n}\")\n    self.dropout = config[\"dropout\"]\n    print(f\"Dropout: {self.dropout}\")\n    self.length = self.in_shape[0]\n    print(f\"Length: {self.length}\")\n    self.position_embedding = config.get(\"position_embedding\", \"learnt\")\n    print(f\"Positional embedding: {self.position_embedding}\")\n    self.sampling = config.get(\"sampling\", False)\n    print(f\"Sampling: {self.sampling}\")\n\n    self.encoder = AttentionEncoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        length=self.length,\n        n_head=self.heads,\n        n_layer=self.hidden_n,\n        dropout=self.dropout,\n        position_embedding=self.position_embedding,\n    )\n    self.decoder = AttentionDecoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings,\n        num_heads=self.heads,\n        num_layers=self.hidden_n,\n        length=self.length,\n        dropout=self.dropout,\n        position_embedding=self.position_embedding,\n    )\n    self.unflattened_shape = (self.length, self.hidden_size)\n    flat_size_encode = self.length * self.hidden_size\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n\n    if config.get(\"share_embed\", False):\n        print(\"Sharing embeddings\")\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.VAEDiscXTrans.decode","title":"<code>decode(z, context=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def decode(\n    self, z: Tensor, context=None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    hidden = self.fc_hidden(z)\n    hidden = hidden.unflatten(1, self.unflattened_shape)\n    log_probs = self.decoder(hidden, context)\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.VAEDiscXTrans.forward","title":"<code>forward(x, target=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>List[Tensor]</code> <p>list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].</p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def forward(self, x: Tensor, target=None, **kwargs) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n\n    Returns:\n        list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].\n    \"\"\"\n    mu, log_var = self.encode(x, labels=None)\n    z = self.reparameterize(mu, log_var)\n\n    if target is not None:  # training\n        log_prob_y = self.decode(z, context=x)\n        return [log_prob_y, mu, log_var, z]\n\n    # no target so assume generating\n    log_prob = self.predict_sequences(z, current_device=z.device)\n    return [log_prob, mu, log_var, z]\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.VAEDiscXTrans.loss_function","title":"<code>loss_function(log_probs, mu, log_var, target, mask, **kwargs)</code>","text":"Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def loss_function(\n    self,\n    log_probs: Tensor,\n    mu: Tensor,\n    log_var: Tensor,\n    target: Tensor,\n    mask: Tensor,\n    **kwargs,\n) -&gt; dict:\n    return self.discretized_loss(\n        log_probs, mu, log_var, target, mask, **kwargs\n    )\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.VAEDiscXTrans.predict","title":"<code>predict(z, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>z</code> <p>[N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def predict(self, z: Tensor, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        z (tensor): [N, latent_dims].\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    log_prob_samples = self.predict_sequences(z, device)\n    return exp(log_prob_samples)\n</code></pre>"},{"location":"reference/caveat/models/discrete/vae_discrete_xattention/#caveat.models.discrete.vae_discrete_xattention.VAEDiscXTrans.predict_sequences","title":"<code>predict_sequences(z, current_device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>z</code> <p>[N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/discrete/vae_discrete_xattention.py</code> <pre><code>def predict_sequences(\n    self, z: Tensor, current_device: int, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        z (tensor): [N, latent_dims].\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(current_device)\n    B = z.shape[0]\n    log_outputs = []\n    sequences = torch.zeros(B, 1, device=z.device)\n    for _ in range(self.length):\n        # get the predictions\n        log_probs = self.decode(z, context=sequences)\n        # focus only on the last time step\n        last_log_probs = log_probs[:, -1, :]  # becomes (B, C)\n        log_outputs.append(last_log_probs.unsqueeze(1))\n        if self.sampling:\n            # sample from the distribution\n            next = torch.multinomial(\n                torch.exp(last_log_probs), num_samples=1\n            )  # (B, 1)\n        else:\n            _, next = last_log_probs.topk(1)\n        # append sampled index to the running sequence\n        sequences = torch.cat((sequences, next), dim=1)  # (B, T+1)\n\n    log_probs = torch.cat(log_outputs, dim=1)\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/embed/","title":"caveat.models.embed","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomCombinedEmbedding","title":"<code>CustomCombinedEmbedding(input_size, hidden_size, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Embedding that combines activity embedding layer and duration and end time.</p> Source code in <code>caveat/models/embed.py</code> <pre><code>def __init__(self, input_size, hidden_size, dropout: float = 0.1):\n    \"\"\"Embedding that combines activity embedding layer and duration and end time.\"\"\"\n    super().__init__()\n    if hidden_size &lt; 3:\n        raise ValueError(\"Hidden size must be at least 3.\")\n    self.embedding = nn.Embedding(input_size, hidden_size - 2)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomCombinedEmbedding.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomCombinedEmbedding.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size - 2)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomCombinedEmbedding.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/embed.py</code> <pre><code>def forward(self, x):\n    embedded, durations = torch.split(x, [1, 1], dim=-1)\n    ends = torch.cumsum(durations, dim=-1)\n    embedded = self.dropout(self.embedding(embedded.int())).squeeze(-2)\n    embedded = torch.cat((embedded, durations, ends), dim=-1)\n    return embedded\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationEmbeddingAddNorm","title":"<code>CustomDurationEmbeddingAddNorm(input_size, hidden_size, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Embedding that combines activity embedding layer and duration.</p> Source code in <code>caveat/models/embed.py</code> <pre><code>def __init__(self, input_size, hidden_size, dropout: float = 0.1):\n    \"\"\"Embedding that combines activity embedding layer and duration.\"\"\"\n    super().__init__()\n    self.embedding = nn.Embedding(input_size, hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationEmbeddingAddNorm.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationEmbeddingAddNorm.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationEmbeddingAddNorm.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/embed.py</code> <pre><code>def forward(self, x):\n    embedded, durations = torch.split(x, [1, 1], dim=-1)\n    embedded = self.dropout(self.embedding(embedded.int())).squeeze(-2)\n    durations = (\n        durations - durations.mean(dim=-2)[:, :, None]\n    )  # lazy normalization\n    embedded = embedded + durations\n    return embedded\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationEmbeddingConcat","title":"<code>CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Embedding that combines activity embedding layer and duration.</p> Source code in <code>caveat/models/embed.py</code> <pre><code>def __init__(self, input_size, hidden_size, dropout: float = 0.1):\n    \"\"\"Embedding that combines activity embedding layer and duration.\"\"\"\n    super().__init__()\n    if hidden_size &lt; 2:\n        raise ValueError(\"Hidden size must be greater than 1.\")\n    self.embedding = nn.Embedding(input_size, hidden_size - 1)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationEmbeddingConcat.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationEmbeddingConcat.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size - 1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationEmbeddingConcat.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/embed.py</code> <pre><code>def forward(self, x):\n    embedded, durations = torch.split(x, [1, 1], dim=-1)\n    embedded = self.dropout(self.embedding(embedded.int())).squeeze(-2)\n    embedded = torch.cat((embedded, durations), dim=-1)\n    return embedded\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationModeDistanceEmbedding","title":"<code>CustomDurationModeDistanceEmbedding(act_embeddings, mode_embeddings, hidden_act_size, hidden_mode_size, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Embedding that combines activity embedding layer and duration and mode distance.</p> Source code in <code>caveat/models/embed.py</code> <pre><code>def __init__(\n    self,\n    act_embeddings,\n    mode_embeddings,\n    hidden_act_size,\n    hidden_mode_size,\n    dropout: float = 0.1,\n):\n    \"\"\"Embedding that combines activity embedding layer and duration and mode distance.\"\"\"\n    super().__init__()\n    self.act_embedding = nn.Embedding(act_embeddings, hidden_act_size)\n    self.mode_embedding = nn.Embedding(mode_embeddings, hidden_mode_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationModeDistanceEmbedding.act_embedding","title":"<code>act_embedding = nn.Embedding(act_embeddings, hidden_act_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationModeDistanceEmbedding.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationModeDistanceEmbedding.mode_embedding","title":"<code>mode_embedding = nn.Embedding(mode_embeddings, hidden_mode_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomDurationModeDistanceEmbedding.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/embed.py</code> <pre><code>def forward(self, x):\n    acts, durations, modes, distances = torch.split(x, [1, 1, 1, 1], dim=-1)\n    acts = self.dropout(self.act_embedding(acts.int())).squeeze(-2)\n    modes = self.dropout(self.mode_embedding(modes.int())).squeeze(-2)\n    embedded = torch.cat((acts, durations, modes, distances), dim=-1)\n    return embedded\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomLinearEmbedding","title":"<code>CustomLinearEmbedding(input_size, hidden_size, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Embedding that combines activity embedding layer and duration using a linear layer.</p> Source code in <code>caveat/models/embed.py</code> <pre><code>def __init__(self, input_size, hidden_size, dropout: float = 0.1):\n    \"\"\"Embedding that combines activity embedding layer and duration using a linear layer.\"\"\"\n    super().__init__()\n    if hidden_size &lt; 2:\n        raise ValueError(\"Hidden size must be greater than 1.\")\n    self.embedding = nn.Embedding(input_size, hidden_size - 1)\n    self.fc = nn.Linear(hidden_size, hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomLinearEmbedding.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomLinearEmbedding.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size - 1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomLinearEmbedding.fc","title":"<code>fc = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.CustomLinearEmbedding.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/embed.py</code> <pre><code>def forward(self, x):\n    embedded, durations = torch.split(x, [1, 1], dim=-1)\n    embedded = self.dropout(self.embedding(embedded.int())).squeeze(-2)\n    embedded = torch.cat((embedded, durations), dim=-1)\n    embedded = self.fc(embedded)\n    return embedded\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.OneHotEmbedding","title":"<code>OneHotEmbedding(input_size, hidden_size, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Embedding that combines activity onehot embedding and duration.</p> Source code in <code>caveat/models/embed.py</code> <pre><code>def __init__(self, input_size, hidden_size, dropout: float = 0.1):\n    \"\"\"Embedding that combines activity onehot embedding and duration.\"\"\"\n    super().__init__()\n    if hidden_size != input_size + 1:\n        raise ValueError(\"Hidden size must be equal to input size plus 1.\")\n    self.classes = input_size\n    self.fc = nn.Linear(hidden_size, hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.OneHotEmbedding.classes","title":"<code>classes = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.OneHotEmbedding.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.OneHotEmbedding.fc","title":"<code>fc = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.OneHotEmbedding.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/embed.py</code> <pre><code>def forward(self, x):\n    embedded, durations = torch.split(x, [1, 1], dim=-1)\n    embedded = self.dropout(\n        nn.functional.one_hot(embedded.int(), self.classes)\n    )\n    embedded = torch.cat((embedded, durations), dim=-1)\n    return embedded\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.OneHotPlusLinearEmbedding","title":"<code>OneHotPlusLinearEmbedding(input_size, hidden_size, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Embedding that combines activity onehot embedding and duration and linear layer.</p> Source code in <code>caveat/models/embed.py</code> <pre><code>def __init__(self, input_size, hidden_size, dropout: float = 0.1):\n    \"\"\"Embedding that combines activity onehot embedding and duration and linear layer.\"\"\"\n    super().__init__()\n    self.classes = input_size\n    self.fc = nn.Linear(hidden_size, hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/embed/#caveat.models.embed.OneHotPlusLinearEmbedding.classes","title":"<code>classes = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.OneHotPlusLinearEmbedding.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.OneHotPlusLinearEmbedding.fc","title":"<code>fc = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/embed/#caveat.models.embed.OneHotPlusLinearEmbedding.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/embed.py</code> <pre><code>def forward(self, x):\n    embedded, durations = torch.split(x, [1, 1], dim=-1)\n    embedded = self.dropout(\n        nn.functional.one_hot(embedded.int(), self.classes)\n    )\n    embedded = torch.cat((embedded, durations), dim=-1)\n    embedded = self.fc(embedded)\n    return embedded\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/experiment/","title":"caveat.models.joint_vaes.experiment","text":""},{"location":"reference/caveat/models/joint_vaes/experiment/#caveat.models.joint_vaes.experiment.JointExperiment","title":"<code>JointExperiment(*args, **kwargs)</code>","text":"<p>               Bases: <code>Experiment</code></p> Source code in <code>caveat/models/joint_vaes/experiment.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    self.label_embed_sizes = kwargs.get(\"label_embed_sizes\", None)\n    if self.label_embed_sizes is None:\n        raise UserWarning(\"ConditionalLSTM requires label_embed_sizes\")\n    if not isinstance(self.label_embed_sizes, list):\n        raise UserWarning(\n            \"ConditionalLSTM requires label_embed_sizes to be a list of label embedding sizes\"\n        )\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/experiment/#caveat.models.joint_vaes.experiment.JointExperiment.label_embed_sizes","title":"<code>label_embed_sizes = kwargs.get('label_embed_sizes', None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/experiment/#caveat.models.joint_vaes.experiment.JointExperiment.on_validation_end","title":"<code>on_validation_end()</code>","text":"Source code in <code>caveat/models/joint_vaes/experiment.py</code> <pre><code>def on_validation_end(self) -&gt; None:\n    if self.gen:\n        self.regenerate_val_batch()\n        self.sample_sequences()\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/experiment/#caveat.models.joint_vaes.experiment.JointExperiment.predict_step","title":"<code>predict_step(batch)</code>","text":"Source code in <code>caveat/models/joint_vaes/experiment.py</code> <pre><code>def predict_step(self, batch):\n    # YUCK\n    if len(batch) == 2:  # generative process\n        zs, labels = batch\n        pred_x, pred_labels = self.predict(\n            zs, conditionals=labels, device=self.curr_device\n        )\n        return (pred_x, pred_labels, zs)\n    # inference process\n    (x, _), (_, _), (labels, _) = batch\n    pred_x, pred_labels, zs = self.infer(\n        x, conditionals=labels, device=self.curr_device\n    )\n    return x, pred_x, labels, pred_labels, zs\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/experiment/#caveat.models.joint_vaes.experiment.JointExperiment.regenerate_batch","title":"<code>regenerate_batch(x, target, name, conditionals=None)</code>","text":"Source code in <code>caveat/models/joint_vaes/experiment.py</code> <pre><code>def regenerate_batch(\n    self,\n    x: Tensor,\n    target: Tensor,\n    name: str,\n    conditionals: Optional[Tensor] = None,\n):\n    probs_x, probs_y, _ = self.infer(\n        x, conditionals=conditionals, device=self.curr_device\n    )\n    probs = probs_x.squeeze()\n    image = unpack(target, probs, self.curr_device)\n    div = torch.ones_like(probs)\n    images = torch.cat((image.squeeze(), div, probs), dim=-1)\n    vutils.save_image(\n        pre_process(images.data),\n        Path(\n            self.logger.log_dir,\n            name,\n            f\"recons_{self.logger.name}_epoch_{self.current_epoch}.png\",\n        ),\n        normalize=False,\n        nrow=1,\n        pad_value=1,\n    )\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/experiment/#caveat.models.joint_vaes.experiment.JointExperiment.regenerate_val_batch","title":"<code>regenerate_val_batch()</code>","text":"Source code in <code>caveat/models/joint_vaes/experiment.py</code> <pre><code>def regenerate_val_batch(self):\n    (x, _), (y, _), (labels, _) = next(\n        iter(self.trainer.datamodule.val_dataloader())\n    )\n    x = x.to(self.curr_device)\n    y = y.to(self.curr_device)\n    labels = labels.to(self.curr_device)\n    self.regenerate_batch(\n        x, target=y, name=\"reconstructions\", conditionals=labels\n    )\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/experiment/#caveat.models.joint_vaes.experiment.JointExperiment.sample_sequences","title":"<code>sample_sequences(name='samples')</code>","text":"Source code in <code>caveat/models/joint_vaes/experiment.py</code> <pre><code>def sample_sequences(self, name: str = \"samples\") -&gt; None:\n    _, _, (labels, _) = next(\n        iter(self.trainer.datamodule.test_dataloader())\n    )\n    labels = labels.to(self.curr_device)\n    z = torch.randn(len(labels), self.latent_dim)\n    probs, _ = self.predict(z, conditionals=labels, device=self.curr_device)\n    vutils.save_image(\n        pre_process(probs.cpu().data),\n        Path(\n            self.logger.log_dir,\n            name,\n            f\"{self.logger.name}_epoch_{self.current_epoch}.png\",\n        ),\n        normalize=False,\n        nrow=1,\n        pad_value=1,\n    )\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/experiment/#caveat.models.joint_vaes.experiment.JointExperiment.test_step","title":"<code>test_step(batch, batch_idx)</code>","text":"Source code in <code>caveat/models/joint_vaes/experiment.py</code> <pre><code>def test_step(self, batch, batch_idx):\n    if self.test:\n        (\n            (x, _),\n            (y, (y_weights, y_joint)),\n            (labels, (label_weights, label_joint)),\n        ) = batch\n        self.curr_device = x.device\n\n        log_probs, mu, log_var, z = self.forward(x, conditionals=labels)\n        test_loss = self.loss_function(\n            log_probs_x=log_probs,\n            mu=mu,\n            log_var=log_var,\n            targets=(y, labels),\n            masks=(y_weights, label_weights),\n            kld_weight=self.kld_loss_weight,\n            duration_weight=self.duration_loss_weight,\n            batch_idx=batch_idx,\n        )\n\n        self.log_dict(\n            {f\"test_{key}\": val.item() for key, val in test_loss.items()},\n            sync_dist=True,\n            on_step=False,\n            on_epoch=True,\n            prog_bar=True,\n        )\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/experiment/#caveat.models.joint_vaes.experiment.JointExperiment.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"Source code in <code>caveat/models/joint_vaes/experiment.py</code> <pre><code>def training_step(self, batch, batch_idx):\n    (\n        (x, _),\n        (y, (y_weights, y_joint)),\n        (labels, (label_weights, label_joint)),\n    ) = batch\n\n    self.curr_device = x.device\n\n    log_probs, mu, log_var, z = self.forward(\n        x, conditionals=labels, target=y\n    )\n    train_loss = self.loss_function(\n        log_probs=log_probs,\n        mu=mu,\n        log_var=log_var,\n        targets=(y, labels),\n        masks=(y_weights, label_weights),\n        kld_weight=self.kld_loss_weight,\n        duration_weight=self.duration_loss_weight,\n        batch_idx=batch_idx,\n    )\n    self.log_dict(\n        {key: val.item() for key, val in train_loss.items()}, sync_dist=True\n    )\n\n    return train_loss[\"loss\"]\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/experiment/#caveat.models.joint_vaes.experiment.JointExperiment.validation_step","title":"<code>validation_step(batch, batch_idx, optimizer_idx=0)</code>","text":"Source code in <code>caveat/models/joint_vaes/experiment.py</code> <pre><code>def validation_step(self, batch, batch_idx, optimizer_idx=0):\n    (\n        (x, _),\n        (y, (y_weights, y_joint)),\n        (labels, (label_weights, label_joint)),\n    ) = batch\n    self.curr_device = x.device\n\n    log_probs, mu, log_var, z = self.forward(x, conditionals=labels)\n    val_loss = self.loss_function(\n        log_probs=log_probs,\n        mu=mu,\n        log_var=log_var,\n        targets=(y, labels),\n        masks=(y_weights, label_weights),\n        kld_weight=self.kld_loss_weight,\n        duration_weight=self.duration_loss_weight,\n        optimizer_idx=optimizer_idx,\n        batch_idx=batch_idx,\n    )\n\n    self.log_dict(\n        {f\"val_{key}\": val.item() for key, val in val_loss.items()},\n        sync_dist=True,\n        on_step=False,\n        on_epoch=True,\n        prog_bar=True,\n    )\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/","title":"caveat.models.joint_vaes.jvae_sequence","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM","title":"<code>JVAESeqLSTM(*args, **kwargs)</code>","text":"<p>               Bases: <code>JointExperiment</code></p> <p>Joint Sequence and Label generating VAE with LSTM sequence encoder and decoder.</p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Joint Sequence and Label generating VAE with LSTM sequence encoder and decoder.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.labels_hidden_size = config.get(\n        \"labels_hidden_size\", self.hidden_size\n    )\n    print(f\"Found label encoder hidden size = {self.labels_hidden_size}\")\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n    self.encoder = ScheduleEncoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n\n    self.decoder = ScheduleDecoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n\n    self.label_encoder = LabelEncoder(\n        label_embed_sizes=self.label_embed_sizes,\n        hidden_size=self.labels_hidden_size,\n        latent_size=self.latent_dim,\n    )\n\n    self.label_decoder = LabelDecoder(\n        attribute_embed_sizes=self.label_embed_sizes,\n        hidden_size=self.labels_hidden_size,\n        latent_size=self.latent_dim,\n    )\n\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_conditionals = nn.Linear(self.labels_size, flat_size_encode)\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    # self.fc_attributes = nn.Linear(self.conditionals_size, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor, Tensor]</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def decode(\n    self, z: Tensor, target=None, **kwargs\n) -&gt; Tuple[Tensor, Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs_x = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs_x = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    # decode labels\n    log_probs_ys = self.label_decoder(z)\n\n    return log_probs_x, log_probs_ys\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.encode","title":"<code>encode(input, conditionals)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>list[tensor]: Latent layer input (means and variances) [N, latent_dims].</p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def encode(self, input: Tensor, conditionals: Tensor) -&gt; list[Tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): Input sequence batch [N, steps, acts].\n\n    Returns:\n        list[tensor]: Latent layer input (means and variances) [N, latent_dims].\n    \"\"\"\n    # schedule encode\n    hidden = self.encoder(input)\n    mu = self.fc_mu(hidden)\n    log_var = self.fc_var(hidden)\n\n    # attributes encode\n    mu_label, log_var_label = self.label_encoder(conditionals)\n    # combine encodings\n    mu += mu_label\n    log_var += log_var_label\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.forward","title":"<code>forward(x, conditionals=None, target=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> <code>conditionals</code> <p>Input attributes [N, Ain].</p> <p> TYPE: <code>tensor</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list</code> <p>[Log probs x, [Log probs y], mu, var].</p> <p> TYPE: <code>List[Tensor]</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    conditionals: Optional[Tensor] = None,\n    target=None,\n    **kwargs,\n) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n        conditionals (tensor): Input attributes [N, Ain].\n\n    Returns:\n        list: [Log probs x, [Log probs y], mu, var].\n    \"\"\"\n    # schedule encode\n    mu, log_var = self.encode(x, conditionals=conditionals)\n    z = self.reparameterize(mu, log_var)\n    log_prob_x, log_prob_y = self.decode(\n        z, conditionals=conditionals, target=target\n    )\n    return [(log_prob_x, log_prob_y), mu, log_var, z]\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.infer","title":"<code>infer(x, device, **kwargs)</code>","text":"<p>Given an encoder input, return reconstructed output and z samples.</p> PARAMETER DESCRIPTION <code>x</code> <p>[N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>(tensor: [N, steps, acts], tensor: [N, latent_dims]).</p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def infer(self, x: Tensor, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given an encoder input, return reconstructed output and z samples.\n\n    Args:\n        x (tensor): [N, steps, acts].\n\n    Returns:\n        (tensor: [N, steps, acts], tensor: [N, latent_dims]).\n    \"\"\"\n    (log_prob_x, log_probs_y), _, _, z = self.forward(x, **kwargs)\n    prob_x = exp(log_prob_x).to(device)\n    probs_y = [exp(lpy) for lpy in log_probs_y]\n    z = z.to(device)\n    return prob_x, probs_y, z\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.kld","title":"<code>kld(mu, log_var)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def kld(self, mu: Tensor, log_var: Tensor) -&gt; Tensor:\n    # from https://kvfrans.com/deriving-the-kl/\n    return torch.mean(\n        -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n    )\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.loss_function","title":"<code>loss_function(log_probs, mu, log_var, targets, masks, **kwargs)</code>","text":"<p>Calculate the loss function for the model.</p> PARAMETER DESCRIPTION <code>log_probs</code> <p>Log probabilities for the output sequence.</p> <p> TYPE: <code>(tensor, tensor)</code> </p> <code>mu</code> <p>Mean of the latent space.</p> <p> TYPE: <code>tensor</code> </p> <code>log_var</code> <p>Log variance of the latent space.</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>Loss dictionary.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def loss_function(\n    self,\n    log_probs: Tuple[Tensor, Tensor],\n    mu: Tensor,\n    log_var: Tensor,\n    targets: Tuple[Tensor, Tensor],\n    masks: Tuple[Tensor, Tensor],\n    **kwargs,\n) -&gt; dict:\n    \"\"\"Calculate the loss function for the model.\n\n    Args:\n        log_probs ((tensor, tensor)): Log probabilities for the output sequence.\n        mu (tensor): Mean of the latent space.\n        log_var (tensor): Log variance of the latent space.\n\n    Returns:\n        dict: Loss dictionary.\n    \"\"\"\n    # unpack inputs\n    log_probs_x, log_probs_ys = log_probs\n    target_x, target_y = targets\n    mask_x, mask_y = masks\n\n    # unpack act probs and durations\n    target_acts, target_durations = self.unpack_encoding(target_x)\n    pred_acts, pred_durations = self.unpack_encoding(log_probs_x)\n    _, L, A = pred_acts.shape\n    pred_durations = exp(pred_durations)\n\n    # normalise mask weights\n    mask_x = mask_x / mask_x.mean(-1).unsqueeze(-1)\n    duration_mask = mask_x.clone()\n    duration_mask[:, 0] = 0.0\n    duration_mask[\n        torch.arange(duration_mask.shape[0]),\n        (mask_x != 0).cumsum(-1).argmax(1),\n    ] = 0.0\n    duration_mask = duration_mask / duration_mask.mean(-1).unsqueeze(-1)\n    mask_y = mask_y / mask_y.mean(-1).unsqueeze(-1)\n\n    # # combined weights\n    # label_weights_combined = mask_y.prod(dim=1)\n    # label_weights_combined = (\n    #     label_weights_combined / label_weights_combined.mean()\n    # )  # average weight 1\n\n    # label loss\n    logs = {}\n    attribute_loss = 0\n    for i, y in enumerate(log_probs_ys):\n        target = target_y[:, i].long()\n        weight = mask_y[:, i]\n        nll = self.base_NLLL(y, target)\n        weighted_nll = (nll * weight).mean()\n        logs[f\"nll_{i}\"] = weighted_nll\n        attribute_loss += weighted_nll\n    # attribute_loss = attribute_loss / len(log_probs_ys)\n    scheduled_label_weight = (\n        self.scheduled_label_weight * self.label_loss_weight\n    )\n    w_label_loss = scheduled_label_weight * attribute_loss\n\n    # activity loss\n    recon_act_nlll = self.base_NLLL(\n        pred_acts.view(-1, self.encodings), target_acts.view(-1).long()\n    )\n    # recon_act_weights = label_weights_combined.repeat_interleave(L) / L\n    recon_act_nlll = recon_act_nlll * mask_x.view(-1)\n    # recon_act_nlll = recon_act_nlll * recon_act_weights\n    recon_act_nlll = recon_act_nlll.mean()\n\n    scheduled_act_weight = (\n        self.scheduled_act_weight * self.activity_loss_weight\n    )\n    w_act_recon = scheduled_act_weight * recon_act_nlll\n\n    # duration loss\n    recon_dur_mse = self.MSE(pred_durations, target_durations)\n    recon_dur_mse = (recon_dur_mse * duration_mask).mean()\n    # recon_dur_mse = recon_dur_mse * label_weights_combined[:, None]\n    scheduled_dur_weight = (\n        self.duration_loss_weight * self.scheduled_dur_weight\n    )\n    w_dur_recon = scheduled_dur_weight * recon_dur_mse\n\n    # TODO: could combine above to only apply mask once\n\n    # schedule reconstruction loss\n    w_schedule_recons_loss = w_act_recon + w_dur_recon\n\n    # recon loss\n    w_recons_loss = w_schedule_recons_loss + w_label_loss\n\n    # kld loss\n    kld_loss = self.kld(mu, log_var)\n    scheduled_kld_weight = self.kld_loss_weight * self.scheduled_kld_weight\n    w_kld_loss = scheduled_kld_weight * kld_loss\n\n    # final loss\n    loss = w_recons_loss + w_kld_loss\n\n    logs.update(\n        {\n            \"loss\": loss,\n            \"KLD\": w_kld_loss.detach(),\n            \"recon_loss\": w_recons_loss.detach(),\n            \"act_recon\": w_act_recon.detach(),\n            \"dur_recon\": w_dur_recon.detach(),\n            \"label_recon\": w_label_loss.detach(),\n            \"kld_weight\": torch.tensor([scheduled_kld_weight]).float(),\n            \"act_weight\": torch.tensor([scheduled_act_weight]).float(),\n            \"dur_weight\": torch.tensor([scheduled_dur_weight]).float(),\n            \"label_weight\": torch.tensor([scheduled_label_weight]).float(),\n        }\n    )\n    return logs\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.pack_encoding","title":"<code>pack_encoding(acts, durations)</code>","text":"<p>Pack the activity and duration into input.</p> PARAMETER DESCRIPTION <code>acts</code> <p>Activity [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> <code>durations</code> <p>Duration [N, steps, 1].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Input sequences [N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def pack_encoding(self, acts: Tensor, durations: Tensor) -&gt; Tensor:\n    \"\"\"Pack the activity and duration into input.\n\n    Args:\n        acts (tensor): Activity [N, steps, acts].\n        durations (tensor): Duration [N, steps, 1].\n\n    Returns:\n        tensor: Input sequences [N, steps, acts].\n    \"\"\"\n    if len(durations.shape) == 2:\n        durations = durations.unsqueeze(-1)\n    return torch.cat((acts, durations), dim=-1)\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.predict","title":"<code>predict(z, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>z</code> <p>[N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def predict(self, z: Tensor, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        z (tensor): [N, latent_dims].\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(device)\n    log_probs_x, log_probs_y = self.decode(z=z, **kwargs)\n    prob_x = exp(log_probs_x)\n    probs_y = [exp(lpy) for lpy in log_probs_y]\n    return prob_x, probs_y\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.reparameterize","title":"<code>reparameterize(mu, logvar)</code>","text":"<p>Re-parameterization trick to sample from N(mu, var) from N(0,1).</p> PARAMETER DESCRIPTION <code>mu</code> <p>Mean of the latent Gaussian [N x latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>logvar</code> <p>Standard deviation of the latent Gaussian [N x latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N x latent_dims].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def reparameterize(self, mu: Tensor, logvar: Tensor) -&gt; Tensor:\n    \"\"\"Re-parameterization trick to sample from N(mu, var) from N(0,1).\n\n    Args:\n        mu (tensor): Mean of the latent Gaussian [N x latent_dims].\n        logvar (tensor): Standard deviation of the latent Gaussian [N x latent_dims].\n\n    Returns:\n        tensor: [N x latent_dims].\n    \"\"\"\n    std = torch.exp(0.5 * logvar)\n    eps = torch.randn_like(std)\n    return (eps * std) + mu\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.JVAESeqLSTM.unpack_encoding","title":"<code>unpack_encoding(input)</code>","text":"<p>Split the input into activity and duration.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequences [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor, Tensor]</code> <p>tuple[tensor, tensor]: [activity [N, steps, acts], duration [N, steps, 1]].</p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def unpack_encoding(self, input: Tensor) -&gt; tuple[Tensor, Tensor]:\n    \"\"\"Split the input into activity and duration.\n\n    Args:\n        input (tensor): Input sequences [N, steps, acts].\n\n    Returns:\n        tuple[tensor, tensor]: [activity [N, steps, acts], duration [N, steps, 1]].\n    \"\"\"\n    acts = input[:, :, :-1].contiguous()\n    durations = input[:, :, -1:].squeeze(-1).contiguous()\n    return acts, durations\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelDecoder","title":"<code>LabelDecoder(attribute_embed_sizes, hidden_size, latent_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def __init__(self, attribute_embed_sizes, hidden_size, latent_size):\n    super(LabelDecoder, self).__init__()\n    self.fc = nn.Linear(latent_size, hidden_size)\n    self.activation = nn.ReLU()\n    self.attribute_nets = nn.ModuleList(\n        [\n            nn.Sequential(nn.Linear(hidden_size, s), nn.LogSoftmax(dim=-1))\n            for s in attribute_embed_sizes\n        ]\n    )\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelDecoder.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelDecoder.attribute_nets","title":"<code>attribute_nets = nn.ModuleList([nn.Sequential(nn.Linear(hidden_size, s), nn.LogSoftmax(dim=-1)) for s in attribute_embed_sizes])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelDecoder.fc","title":"<code>fc = nn.Linear(latent_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelDecoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def forward(self, x):\n    x = self.fc(x)\n    x = self.activation(x)\n    log_probs = [net(x) for net in self.attribute_nets]\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelEncoder","title":"<code>LabelEncoder(label_embed_sizes, hidden_size, latent_size)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Label Encoder using token embedding. Embedding outputs are the same size but use different weights so that they can be different sizes. Each embedding is then stacked and summed to give single encoding.</p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def __init__(self, label_embed_sizes, hidden_size, latent_size):\n    \"\"\"Label Encoder using token embedding.\n    Embedding outputs are the same size but use different weights so that they can be different sizes.\n    Each embedding is then stacked and summed to give single encoding.\"\"\"\n    super(LabelEncoder, self).__init__()\n    self.embeds = nn.ModuleList(\n        [nn.Embedding(s, hidden_size) for s in label_embed_sizes]\n    )\n    self.fc = nn.Linear(hidden_size, hidden_size)\n    self.activation = nn.ReLU()\n    self.fc_mu = nn.Linear(hidden_size, latent_size)\n    self.fc_var = nn.Linear(hidden_size, latent_size)\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelEncoder.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelEncoder.embeds","title":"<code>embeds = nn.ModuleList([nn.Embedding(s, hidden_size) for s in label_embed_sizes])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelEncoder.fc","title":"<code>fc = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelEncoder.fc_mu","title":"<code>fc_mu = nn.Linear(hidden_size, latent_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelEncoder.fc_var","title":"<code>fc_var = nn.Linear(hidden_size, latent_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.LabelEncoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def forward(self, x):\n    x = torch.stack(\n        [embed(x[:, i]) for i, embed in enumerate(self.embeds)], dim=-1\n    ).sum(dim=-1)\n    x = self.fc(x)\n    x = self.activation(x)\n    mu = self.fc_mu(x)\n    log_var = self.fc_var(x)\n    return mu, log_var\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder","title":"<code>ScheduleDecoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0, top_sampler=True)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n    top_sampler: bool = True,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(ScheduleDecoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n\n    if top_sampler:\n        print(\"Decoder using topk sampling\")\n        self.sample = self.topk\n    else:\n        print(\"Decoder using multinomial sampling\")\n        self.sample = self.multinomial\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.sample","title":"<code>sample = self.topk</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.forward","title":"<code>forward(batch_size, hidden, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def forward(self, batch_size, hidden, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def forward_step(self, x, hidden):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.multinomial","title":"<code>multinomial(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def multinomial(self, x):\n    # [N, 1, encodings]\n    acts = torch.multinomial(self.activity_prob_activation(x.squeeze()), 1)\n    # DETACH?\n    return acts\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    act = self.sample(acts)\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleDecoder.topk","title":"<code>topk(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def topk(self, x):\n    _, topi = x.topk(1)\n    act = topi.detach()  # detach from history as input\n    # DETACH?\n    return act\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleEncoder","title":"<code>ScheduleEncoder(input_size, hidden_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(ScheduleEncoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.fc_hidden = nn.Linear(hidden_size, hidden_size)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleEncoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleEncoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleEncoder.fc_hidden","title":"<code>fc_hidden = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleEncoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleEncoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleEncoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleEncoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence/#caveat.models.joint_vaes.jvae_sequence.ScheduleEncoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence.py</code> <pre><code>def forward(self, x):\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/","title":"caveat.models.joint_vaes.jvae_sequence_rerouted","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.AttributeDecoder","title":"<code>AttributeDecoder(label_embed_sizes, hidden_size, latent_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def __init__(self, label_embed_sizes, hidden_size, latent_size):\n    super(AttributeDecoder, self).__init__()\n    self.fc = nn.Linear(latent_size, hidden_size)\n    self.activation = nn.ReLU()\n    self.attribute_nets = nn.ModuleList(\n        [\n            nn.Sequential(\n                # nn.Linear(hidden_size, hidden_size),\n                # nn.ReLU(),\n                # nn.Dropout(0.1),\n                nn.Linear(hidden_size, s),\n                nn.LogSoftmax(dim=-1),\n            )\n            for s in label_embed_sizes\n        ]\n    )\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.AttributeDecoder.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.AttributeDecoder.attribute_nets","title":"<code>attribute_nets = nn.ModuleList([nn.Sequential(nn.Linear(hidden_size, s), nn.LogSoftmax(dim=-1)) for s in label_embed_sizes])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.AttributeDecoder.fc","title":"<code>fc = nn.Linear(latent_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.AttributeDecoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def forward(self, x):\n    x = self.fc(x)\n    x = self.activation(x)\n    log_probs = [net(x) for net in self.attribute_nets]\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted","title":"<code>JVAESeqLSTMRerouted(*args, **kwargs)</code>","text":"<p>               Bases: <code>JointExperiment</code></p> <p>Joint Sequence and Label generating VAE with LSTM sequence encoder and decoder.</p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    Joint Sequence and Label generating VAE with LSTM sequence encoder and decoder.\n    \"\"\"\n\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.label_hidden_size = config.get(\n        \"label_hidden_size\", self.hidden_size\n    )\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n    self.encoder = ScheduleEncoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n\n    self.decoder = ScheduleDecoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n\n    self.label_encoder = LabelEncoder(\n        label_embed_sizes=self.label_embed_sizes,\n        hidden_size=self.label_hidden_size,\n        latent_size=self.latent_dim,\n    )\n\n    self.label_decoder = AttributeDecoder(\n        label_embed_sizes=self.label_embed_sizes,\n        hidden_size=self.label_hidden_size,\n        latent_size=self.latent_dim,\n    )\n\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_conditionals = nn.Linear(self.labels_size, flat_size_encode)\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_attributes = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor, Tensor]</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def decode(\n    self, z: Tensor, target=None, **kwargs\n) -&gt; Tuple[Tensor, Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs_x, hidden_x = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs_x, hidden_x = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    hidden_x = torch.cat(hidden_x).permute(1, 0, 2).flatten(start_dim=1)\n    z_x = self.fc_attributes(hidden_x)\n\n    # decode labels\n    log_probs_ys = self.label_decoder(z_x.detach())\n\n    return log_probs_x, log_probs_ys\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.encode","title":"<code>encode(input, conditionals)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>list[tensor]: Latent layer input (means and variances) [N, latent_dims].</p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def encode(self, input: Tensor, conditionals: Tensor) -&gt; list[Tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): Input sequence batch [N, steps, acts].\n\n    Returns:\n        list[tensor]: Latent layer input (means and variances) [N, latent_dims].\n    \"\"\"\n    # schedule encode\n    hidden = self.encoder(input)\n    mu = self.fc_mu(hidden)\n    log_var = self.fc_var(hidden)\n\n    # attributes encode\n    mu_label, log_var_label = self.label_encoder(conditionals)\n    # combine encodings\n    mu += mu_label\n    log_var += log_var_label\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.forward","title":"<code>forward(x, conditionals=None, target=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> <code>conditionals</code> <p>Input attributes [N, Ain].</p> <p> TYPE: <code>tensor</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list</code> <p>[Log probs x, [Log probs y], mu, var].</p> <p> TYPE: <code>List[Tensor]</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    conditionals: Optional[Tensor] = None,\n    target=None,\n    **kwargs,\n) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n        conditionals (tensor): Input attributes [N, Ain].\n\n    Returns:\n        list: [Log probs x, [Log probs y], mu, var].\n    \"\"\"\n    # schedule encode\n    mu, log_var = self.encode(x, conditionals=conditionals)\n    z = self.reparameterize(mu, log_var)\n    log_prob_x, log_prob_y = self.decode(\n        z, conditionals=conditionals, target=target\n    )\n    return [(log_prob_x, log_prob_y), mu, log_var, z]\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.infer","title":"<code>infer(x, device, **kwargs)</code>","text":"<p>Given an encoder input, return reconstructed output and z samples.</p> PARAMETER DESCRIPTION <code>x</code> <p>[N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>(tensor: [N, steps, acts], tensor: [N, latent_dims]).</p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def infer(self, x: Tensor, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given an encoder input, return reconstructed output and z samples.\n\n    Args:\n        x (tensor): [N, steps, acts].\n\n    Returns:\n        (tensor: [N, steps, acts], tensor: [N, latent_dims]).\n    \"\"\"\n    (log_prob_x, log_probs_y), _, _, z = self.forward(x, **kwargs)\n    prob_x = exp(log_prob_x).to(device)\n    probs_y = [exp(lpy) for lpy in log_probs_y]\n    z = z.to(device)\n    return prob_x, probs_y, z\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.kld","title":"<code>kld(mu, log_var)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def kld(self, mu: Tensor, log_var: Tensor) -&gt; Tensor:\n    # from https://kvfrans.com/deriving-the-kl/\n    return torch.mean(\n        -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n    )\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.loss_function","title":"<code>loss_function(log_probs, mu, log_var, targets, masks, **kwargs)</code>","text":"<p>Calculate the loss function for the model.</p> PARAMETER DESCRIPTION <code>log_probs</code> <p>Log probabilities for the output sequence.</p> <p> TYPE: <code>(tensor, tensor)</code> </p> <code>mu</code> <p>Mean of the latent space.</p> <p> TYPE: <code>tensor</code> </p> <code>log_var</code> <p>Log variance of the latent space.</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>Loss dictionary.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def loss_function(\n    self,\n    log_probs: Tuple[Tensor, Tensor],\n    mu: Tensor,\n    log_var: Tensor,\n    targets: Tuple[Tensor, Tensor],\n    masks: Tuple[Tensor, Tensor],\n    **kwargs,\n) -&gt; dict:\n    \"\"\"Calculate the loss function for the model.\n\n    Args:\n        log_probs ((tensor, tensor)): Log probabilities for the output sequence.\n        mu (tensor): Mean of the latent space.\n        log_var (tensor): Log variance of the latent space.\n\n    Returns:\n        dict: Loss dictionary.\n    \"\"\"\n    # unpack inputs\n    log_probs_x, log_probs_ys = log_probs\n    target_x, target_y = targets\n    mask_x, mask_y = masks\n\n    # unpack act probs and durations\n    target_acts, target_durations = self.unpack_encoding(target_x)\n    pred_acts, pred_durations = self.unpack_encoding(log_probs_x)\n    pred_durations = exp(pred_durations)\n\n    # activity loss\n    recon_act_nlll = self.base_NLLL(\n        pred_acts.view(-1, self.encodings), target_acts.view(-1).long()\n    )\n    recon_act_nlll = (recon_act_nlll * mask_x.view(-1)).sum() / mask_x.sum()\n    scheduled_act_weight = (\n        self.scheduled_act_weight * self.activity_loss_weight\n    )\n    w_act_recon = scheduled_act_weight * recon_act_nlll\n\n    # duration loss\n    recon_dur_mse = self.MSE(pred_durations, target_durations)\n    recon_dur_mse = (recon_dur_mse * mask_x).sum() / mask_x.sum()\n    scheduled_dur_weight = (\n        self.duration_loss_weight * self.scheduled_dur_weight\n    )\n    w_dur_recon = scheduled_dur_weight * recon_dur_mse\n\n    # TODO: could combine above to only apply mask once\n\n    # schedule reconstruction loss\n    w_schedule_recons_loss = w_act_recon + w_dur_recon\n\n    # attributes loss\n    attribute_loss = 0\n    for i, y in enumerate(log_probs_ys):\n        target = target_y[:, i].long()\n        weight = mask_y[:, i].long()\n        nll = self.base_NLLL(y, target)\n        weighted_nll = nll * weight\n        attribute_loss += weighted_nll.sum()\n    attribute_loss = attribute_loss / len(log_probs_ys)\n    scheduled_label_weight = (\n        self.scheduled_label_weight * self.label_loss_weight\n    )\n    w_label_loss = scheduled_label_weight * attribute_loss\n\n    # recon loss\n    w_recons_loss = w_schedule_recons_loss + w_label_loss\n\n    # kld loss\n    kld_loss = self.kld(mu, log_var)\n    scheduled_kld_weight = self.kld_loss_weight * self.scheduled_kld_weight\n    w_kld_loss = scheduled_kld_weight * kld_loss\n\n    # final loss\n    loss = w_recons_loss + w_kld_loss\n\n    return {\n        \"loss\": loss,\n        \"KLD\": w_kld_loss.detach(),\n        \"recon_loss\": w_recons_loss.detach(),\n        \"act_recon\": w_act_recon.detach(),\n        \"dur_recon\": w_dur_recon.detach(),\n        \"label_recon\": w_label_loss.detach(),\n        \"kld_weight\": torch.tensor([scheduled_kld_weight]).float(),\n        \"act_weight\": torch.tensor([scheduled_act_weight]).float(),\n        \"dur_weight\": torch.tensor([scheduled_dur_weight]).float(),\n        \"label_weight\": torch.tensor([scheduled_label_weight]).float(),\n    }\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.pack_encoding","title":"<code>pack_encoding(acts, durations)</code>","text":"<p>Pack the activity and duration into input.</p> PARAMETER DESCRIPTION <code>acts</code> <p>Activity [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> <code>durations</code> <p>Duration [N, steps, 1].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Input sequences [N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def pack_encoding(self, acts: Tensor, durations: Tensor) -&gt; Tensor:\n    \"\"\"Pack the activity and duration into input.\n\n    Args:\n        acts (tensor): Activity [N, steps, acts].\n        durations (tensor): Duration [N, steps, 1].\n\n    Returns:\n        tensor: Input sequences [N, steps, acts].\n    \"\"\"\n    if len(durations.shape) == 2:\n        durations = durations.unsqueeze(-1)\n    return torch.cat((acts, durations), dim=-1)\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.predict","title":"<code>predict(z, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>z</code> <p>[N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def predict(self, z: Tensor, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        z (tensor): [N, latent_dims].\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(device)\n    log_probs_x, log_probs_y = self.decode(z=z, **kwargs)\n    prob_x = exp(log_probs_x)\n    probs_y = [exp(lpy) for lpy in log_probs_y]\n    return prob_x, probs_y\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.reparameterize","title":"<code>reparameterize(mu, logvar)</code>","text":"<p>Re-parameterization trick to sample from N(mu, var) from N(0,1).</p> PARAMETER DESCRIPTION <code>mu</code> <p>Mean of the latent Gaussian [N x latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>logvar</code> <p>Standard deviation of the latent Gaussian [N x latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N x latent_dims].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def reparameterize(self, mu: Tensor, logvar: Tensor) -&gt; Tensor:\n    \"\"\"Re-parameterization trick to sample from N(mu, var) from N(0,1).\n\n    Args:\n        mu (tensor): Mean of the latent Gaussian [N x latent_dims].\n        logvar (tensor): Standard deviation of the latent Gaussian [N x latent_dims].\n\n    Returns:\n        tensor: [N x latent_dims].\n    \"\"\"\n    std = torch.exp(0.5 * logvar)\n    eps = torch.randn_like(std)\n    return (eps * std) + mu\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.JVAESeqLSTMRerouted.unpack_encoding","title":"<code>unpack_encoding(input)</code>","text":"<p>Split the input into activity and duration.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequences [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor, Tensor]</code> <p>tuple[tensor, tensor]: [activity [N, steps, acts], duration [N, steps, 1]].</p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def unpack_encoding(self, input: Tensor) -&gt; tuple[Tensor, Tensor]:\n    \"\"\"Split the input into activity and duration.\n\n    Args:\n        input (tensor): Input sequences [N, steps, acts].\n\n    Returns:\n        tuple[tensor, tensor]: [activity [N, steps, acts], duration [N, steps, 1]].\n    \"\"\"\n    acts = input[:, :, :-1].contiguous()\n    durations = input[:, :, -1:].squeeze(-1).contiguous()\n    return acts, durations\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.LabelEncoder","title":"<code>LabelEncoder(label_embed_sizes, hidden_size, latent_size)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Attribute Encoder using token embedding. Embedding outputs are the same size but use different weights so that they can be different sizes. Each embedding is then stacked and summed to give single encoding.</p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def __init__(self, label_embed_sizes, hidden_size, latent_size):\n    \"\"\"Attribute Encoder using token embedding.\n    Embedding outputs are the same size but use different weights so that they can be different sizes.\n    Each embedding is then stacked and summed to give single encoding.\"\"\"\n    super(LabelEncoder, self).__init__()\n    self.embeds = nn.ModuleList(\n        [nn.Embedding(s, hidden_size) for s in label_embed_sizes]\n    )\n    self.fc = nn.Linear(hidden_size, hidden_size)\n    self.activation = nn.ReLU()\n    self.fc_mu = nn.Linear(hidden_size, latent_size)\n    self.fc_var = nn.Linear(hidden_size, latent_size)\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.LabelEncoder.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.LabelEncoder.embeds","title":"<code>embeds = nn.ModuleList([nn.Embedding(s, hidden_size) for s in label_embed_sizes])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.LabelEncoder.fc","title":"<code>fc = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.LabelEncoder.fc_mu","title":"<code>fc_mu = nn.Linear(hidden_size, latent_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.LabelEncoder.fc_var","title":"<code>fc_var = nn.Linear(hidden_size, latent_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.LabelEncoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def forward(self, x):\n    x = torch.stack(\n        [embed(x[:, i]) for i, embed in enumerate(self.embeds)], dim=-1\n    ).sum(dim=-1)\n    x = self.fc(x)\n    x = self.activation(x)\n    mu = self.fc_mu(x)\n    log_var = self.fc_var(x)\n    return mu, log_var\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder","title":"<code>ScheduleDecoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0, top_sampler=True)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n    top_sampler: bool = True,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(ScheduleDecoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n\n    if top_sampler:\n        print(\"Decoder using topk sampling\")\n        self.sample = self.topk\n    else:\n        print(\"Decoder using multinomial sampling\")\n        self.sample = self.multinomial\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.sample","title":"<code>sample = self.topk</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.forward","title":"<code>forward(batch_size, hidden, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def forward(self, batch_size, hidden, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs, decoder_hidden\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def forward_step(self, x, hidden):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.multinomial","title":"<code>multinomial(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def multinomial(self, x):\n    # [N, 1, encodings]\n    acts = torch.multinomial(self.activity_prob_activation(x.squeeze()), 1)\n    # DETACH?\n    return acts\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    act = self.sample(acts)\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleDecoder.topk","title":"<code>topk(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def topk(self, x):\n    _, topi = x.topk(1)\n    act = topi.detach()  # detach from history as input\n    # DETACH?\n    return act\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleEncoder","title":"<code>ScheduleEncoder(input_size, hidden_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(ScheduleEncoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.fc_hidden = nn.Linear(hidden_size, hidden_size)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleEncoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleEncoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleEncoder.fc_hidden","title":"<code>fc_hidden = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleEncoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleEncoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleEncoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleEncoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/joint_vaes/jvae_sequence_rerouted/#caveat.models.joint_vaes.jvae_sequence_rerouted.ScheduleEncoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/joint_vaes/jvae_sequence_rerouted.py</code> <pre><code>def forward(self, x):\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/experiment/","title":"caveat.models.schedule2label.experiment","text":""},{"location":"reference/caveat/models/schedule2label/experiment/#caveat.models.schedule2label.experiment.LabelExperiment","title":"<code>LabelExperiment(*args, **kwargs)</code>","text":"<p>               Bases: <code>Experiment</code></p> Source code in <code>caveat/models/schedule2label/experiment.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    self.attribute_embed_sizes = kwargs.get(\"attribute_embed_sizes\", None)\n    if self.attribute_embed_sizes is None:\n        raise UserWarning(\"ConditionalLSTM requires attribute_embed_sizes\")\n    if not isinstance(self.attribute_embed_sizes, list):\n        raise UserWarning(\n            \"ConditionalLSTM requires attribute_embed_sizes to be a list of attribute embedding sizes\"\n        )\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/experiment/#caveat.models.schedule2label.experiment.LabelExperiment.attribute_embed_sizes","title":"<code>attribute_embed_sizes = kwargs.get('attribute_embed_sizes', None)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/schedule2label/experiment/#caveat.models.schedule2label.experiment.LabelExperiment.on_validation_end","title":"<code>on_validation_end()</code>","text":"Source code in <code>caveat/models/schedule2label/experiment.py</code> <pre><code>def on_validation_end(self):\n    return None\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/experiment/#caveat.models.schedule2label.experiment.LabelExperiment.predict_step","title":"<code>predict_step(batch)</code>","text":"Source code in <code>caveat/models/schedule2label/experiment.py</code> <pre><code>def predict_step(self, batch):\n    (x, _), (_, _), (target_labels, _) = batch\n    preds = self.predict(x, device=self.curr_device)\n    return x, target_labels, preds\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/experiment/#caveat.models.schedule2label.experiment.LabelExperiment.test_step","title":"<code>test_step(batch, batch_idx)</code>","text":"Source code in <code>caveat/models/schedule2label/experiment.py</code> <pre><code>def test_step(self, batch, batch_idx):\n    (x, _), (y, y_weights), (labels, label_weights) = batch\n    self.curr_device = x.device\n\n    probs = self.forward(x)\n    test_loss = self.loss_function(\n        probs=probs,\n        target=labels,\n        mask=label_weights,\n        duratio_weight=self.duration_loss_weight,\n        batch_idx=batch_idx,\n    )\n\n    self.log_dict(\n        {f\"test_{key}\": val.item() for key, val in test_loss.items()},\n        sync_dist=True,\n        on_step=False,\n        on_epoch=True,\n        prog_bar=True,\n    )\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/experiment/#caveat.models.schedule2label.experiment.LabelExperiment.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"Source code in <code>caveat/models/schedule2label/experiment.py</code> <pre><code>def training_step(self, batch, batch_idx):\n    (x, _), (y, y_mask), (labels, label_mask) = batch\n\n    self.curr_device = x.device\n    probs = self.forward(x)\n    train_loss = self.loss_function(\n        probs=probs, target=labels, mask=label_mask, batch_idx=batch_idx\n    )\n    self.log_dict(\n        {key: val.item() for key, val in train_loss.items()}, sync_dist=True\n    )\n    return train_loss[\"loss\"]\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/experiment/#caveat.models.schedule2label.experiment.LabelExperiment.validation_step","title":"<code>validation_step(batch, batch_idx, optimizer_idx=0)</code>","text":"Source code in <code>caveat/models/schedule2label/experiment.py</code> <pre><code>def validation_step(self, batch, batch_idx, optimizer_idx=0):\n    (x, _), (y, y_weights), (labels, label_weights) = batch\n    self.curr_device = x.device\n\n    probs = self.forward(x)\n    val_loss = self.loss_function(\n        probs=probs,\n        target=labels,\n        mask=label_weights,\n        optimizer_idx=optimizer_idx,\n        batch_idx=batch_idx,\n    )\n\n    self.log_dict(\n        {f\"val_{key}\": val.item() for key, val in val_loss.items()},\n        sync_dist=True,\n        on_step=False,\n        on_epoch=True,\n        prog_bar=True,\n    )\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/","title":"caveat.models.schedule2label.feedforward","text":""},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.AttributeDecoder","title":"<code>AttributeDecoder(attribute_embed_sizes, hidden_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def __init__(self, attribute_embed_sizes, hidden_size):\n    super(AttributeDecoder, self).__init__()\n    self.fc = nn.Linear(hidden_size, hidden_size)\n    self.activation = nn.ReLU()\n    self.attribute_nets = nn.ModuleList(\n        [nn.Linear(hidden_size, s) for s in attribute_embed_sizes]\n    )\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.AttributeDecoder.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.AttributeDecoder.attribute_nets","title":"<code>attribute_nets = nn.ModuleList([nn.Linear(hidden_size, s) for s in attribute_embed_sizes])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.AttributeDecoder.fc","title":"<code>fc = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.AttributeDecoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def forward(self, x):\n    x = self.fc(x)\n    x = self.activation(x)\n    log_probs = [net(x) for net in self.attribute_nets]\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Encoder","title":"<code>Encoder(length, input_size, hidden_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>length</code> <p>length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def __init__(\n    self,\n    length: int,\n    input_size: int,\n    hidden_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        length (int): length of sequences.\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    input_size = hidden_size * length\n    layers = []\n    for _ in range(num_layers):\n        layers.append(nn.Linear(input_size, hidden_size))\n        layers.append(nn.ReLU())\n        input_size = hidden_size\n\n    self.ffs = nn.Sequential(*layers)\n\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Encoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Encoder.ffs","title":"<code>ffs = nn.Sequential(*layers)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Encoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Encoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Encoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def forward(self, x):\n    embedded = self.embedding(x)\n    hidden = self.ffs(embedded.flatten(1))\n    hidden = self.norm(hidden)\n    hidden = self.dropout(hidden)\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Schedule2LabelFeedForward","title":"<code>Schedule2LabelFeedForward(*args, **kwargs)</code>","text":"<p>               Bases: <code>LabelExperiment</code></p> Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Schedule2LabelFeedForward.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def build(self, **config):\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.label_hidden_size = config.get(\n        \"label_hidden_size\", self.hidden_size\n    )\n    self.label_hidden_layers = config.get(\n        \"label_hidden_layers\", self.hidden_n\n    )\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n\n    self.encoder = Encoder(\n        length=length,\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n    self.decoder = AttributeDecoder(\n        attribute_embed_sizes=self.attribute_embed_sizes,\n        hidden_size=self.label_hidden_size,\n    )\n    self.loss = nn.CrossEntropyLoss(reduction=\"none\")\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Schedule2LabelFeedForward.decode","title":"<code>decode(z, **kwargs)</code>","text":"Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def decode(self, z: Tensor, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    return self.decoder(z)\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Schedule2LabelFeedForward.encode","title":"<code>encode(input)</code>","text":"Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def encode(self, input: Tensor) -&gt; Tensor:\n    # [N, L, C]\n    return self.encoder(input)\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Schedule2LabelFeedForward.forward","title":"<code>forward(x, **kwargs)</code>","text":"Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def forward(self, x: Tensor, **kwargs) -&gt; List[Tensor]:\n    z = self.encode(x)\n    return self.decode(z)\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Schedule2LabelFeedForward.loss_function","title":"<code>loss_function(probs, target, mask, **kwargs)</code>","text":"<p>Calculate the loss function for the model.</p> PARAMETER DESCRIPTION <code>log_probs</code> <p>Log probabilities for the output sequence.</p> <p> TYPE: <code>(tensor, tensor)</code> </p> <code>mu</code> <p>Mean of the latent space.</p> <p> TYPE: <code>tensor</code> </p> <code>log_var</code> <p>Log variance of the latent space.</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>Loss dictionary.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def loss_function(\n    self, probs: Tensor, target: Tensor, mask: Tensor, **kwargs\n) -&gt; dict:\n    \"\"\"Calculate the loss function for the model.\n\n    Args:\n        log_probs ((tensor, tensor)): Log probabilities for the output sequence.\n        mu (tensor): Mean of the latent space.\n        log_var (tensor): Log variance of the latent space.\n\n    Returns:\n        dict: Loss dictionary.\n    \"\"\"\n    logs = {}\n    # attributes loss\n    loss = 0\n    for i, y in enumerate(probs):\n        t = target[:, i].long()\n        weight = mask[:, i]\n        weight = weight / weight.mean()  # average weight to 1\n        nll = self.loss(y, t)\n        logs[f\"nll_{i}\"] = nll.mean()\n        weighted_nll = nll * weight\n        logs[f\"weighted_nll_{i}\"] = weighted_nll.mean()\n        loss += weighted_nll.mean()\n    loss = loss / len(probs)\n    scheduled_label_weight = (\n        self.scheduled_label_weight * self.label_loss_weight\n    )\n    weighted_loss = scheduled_label_weight * loss\n\n    logs.update(\n        {\n            \"loss\": weighted_loss,\n            \"weight\": Tensor([scheduled_label_weight]).float(),\n        }\n    )\n    return logs\n</code></pre>"},{"location":"reference/caveat/models/schedule2label/feedforward/#caveat.models.schedule2label.feedforward.Schedule2LabelFeedForward.predict","title":"<code>predict(x, device, **kwargs)</code>","text":"Source code in <code>caveat/models/schedule2label/feedforward.py</code> <pre><code>def predict(self, x: Tensor, device: int, **kwargs) -&gt; Tensor:\n    x = x.to(device)\n    logits_y = self.forward(x=x, **kwargs)\n    probs_y = [nn.functional.softmax(y, dim=-1) for y in logits_y]\n    return probs_y\n</code></pre>"},{"location":"reference/caveat/models/seq2score/lstm/","title":"caveat.models.seq2score.lstm","text":""},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Encoder","title":"<code>Encoder(act_embeddings, mode_embeddings, hidden_size, hidden_act_size, hidden_mode_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>act_embeddings</code> <p>number of activity embeddings.</p> <p> TYPE: <code>int</code> </p> <code>mode_embeddings</code> <p>number of mode embeddings.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_act_size</code> <p>hidden size for activity embeddings.</p> <p> TYPE: <code>int</code> </p> <code>hidden_mode_size</code> <p>hidden size for mode embeddings.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/seq2score/lstm.py</code> <pre><code>def __init__(\n    self,\n    act_embeddings: int,\n    mode_embeddings: int,\n    hidden_size: int,\n    hidden_act_size: int,\n    hidden_mode_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        act_embeddings (int): number of activity embeddings.\n        mode_embeddings (int): number of mode embeddings.\n        hidden_size (int): lstm hidden size.\n        hidden_act_size (int): hidden size for activity embeddings.\n        hidden_mode_size (int): hidden size for mode embeddings.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = CustomDurationModeDistanceEmbedding(\n        act_embeddings=act_embeddings,\n        mode_embeddings=mode_embeddings,\n        hidden_act_size=hidden_act_size,\n        hidden_mode_size=hidden_mode_size,\n        dropout=dropout,\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Encoder.embedding","title":"<code>embedding = CustomDurationModeDistanceEmbedding(act_embeddings=act_embeddings, mode_embeddings=mode_embeddings, hidden_act_size=hidden_act_size, hidden_mode_size=hidden_mode_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Encoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Encoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Encoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Encoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/seq2score/lstm.py</code> <pre><code>def forward(self, x):\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Seq2ScoreLSTM","title":"<code>Seq2ScoreLSTM(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with conditionality.</p> Source code in <code>caveat/models/seq2score/lstm.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with conditionality.\"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires conditionals_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Seq2ScoreLSTM.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/seq2score/lstm.py</code> <pre><code>def build(self, **config):\n    # self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n\n    self.act_encodings, self.mode_encodings = self.encodings\n\n    # encodings\n    if self.hidden_size &lt; 4:\n        raise ValueError(\"Hidden size must be at least 4.\")\n    self.hidden_mode_size = config.get(\"hidden_mode_size\")\n    if self.hidden_mode_size is None:\n        self.hidden_mode_size = (self.hidden_size - 2) // 2\n    self.hidden_act_size = config.get(\"hidden_act_size\")\n    if self.hidden_act_size is None:\n        self.hidden_act_size = self.hidden_size - 2 - self.hidden_mode_size\n\n    self.encoder = Encoder(\n        act_embeddings=self.act_encodings,\n        mode_embeddings=self.mode_encodings,\n        hidden_size=self.hidden_size,\n        hidden_act_size=self.hidden_act_size,\n        hidden_mode_size=self.hidden_mode_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_hidden = nn.Linear(\n        flat_size_encode + self.labels_size, flat_size_encode\n    )\n    self.score_layer = nn.Linear(flat_size_encode, 1)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Seq2ScoreLSTM.decode","title":"<code>decode(z, conditionals, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>List[Tensor]</code> </p> Source code in <code>caveat/models/seq2score/lstm.py</code> <pre><code>def decode(\n    self, z: Tensor, conditionals: Tensor, target=None, **kwargs\n) -&gt; List[Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # add conditionlity to z\n    z = torch.cat((z, conditionals), dim=-1)\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n    h = self.score_layer(h)\n    return h\n</code></pre>"},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Seq2ScoreLSTM.encode","title":"<code>encode(input)</code>","text":"Source code in <code>caveat/models/seq2score/lstm.py</code> <pre><code>def encode(self, input: Tensor) -&gt; Tensor:\n    # [N, L, C]\n    return self.encoder(input)\n</code></pre>"},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Seq2ScoreLSTM.forward","title":"<code>forward(x, conditionals=None, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/seq2score/lstm.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    conditionals: Optional[Tensor] = None,\n    target=None,\n    **kwargs,\n) -&gt; List[Tensor]:\n    z = self.encode(x)  # [N, flat]\n    score = self.decode(z, conditionals=conditionals, target=target)\n    return score\n</code></pre>"},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Seq2ScoreLSTM.loss_function","title":"<code>loss_function(scores, target, mask, **kwargs)</code>","text":"Source code in <code>caveat/models/seq2score/lstm.py</code> <pre><code>def loss_function(\n    self, scores: Tensor, target: Tensor, mask: Tensor, **kwargs\n) -&gt; dict:\n\n    # duration loss\n    loss = self.MSE(scores.squeeze(), target)\n\n    return {\"loss\": loss}\n</code></pre>"},{"location":"reference/caveat/models/seq2score/lstm/#caveat.models.seq2score.lstm.Seq2ScoreLSTM.predict_step","title":"<code>predict_step(batch, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/seq2score/lstm.py</code> <pre><code>def predict_step(self, batch, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        batch\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    (x, _), (y, _), (labels, _) = batch\n    x = x.to(device)\n    return (x, y, labels, self.forward(x=x, conditionals=labels, **kwargs))\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/","title":"caveat.models.seq2seq.lstm","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder","title":"<code>Decoder(act_embeddings, mode_embeddings, hidden_size, hidden_act_size, hidden_mode_size, output_size, num_layers, max_length, dropout=0.0, sos=0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>act_embeddings</code> <p>number of activity embeddings.</p> <p> TYPE: <code>int</code> </p> <code>mode_embeddings</code> <p>number of mode embeddings.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_act_size</code> <p>hidden size for activity embeddings.</p> <p> TYPE: <code>int</code> </p> <code>hidden_mode_size</code> <p>hidden size for mode embeddings.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def __init__(\n    self,\n    act_embeddings: int,\n    mode_embeddings: int,\n    hidden_size,\n    hidden_act_size,\n    hidden_mode_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        act_embeddings (int): number of activity embeddings.\n        mode_embeddings (int): number of mode embeddings.\n        hidden_size (int): lstm hidden size.\n        hidden_act_size (int): hidden size for activity embeddings.\n        hidden_mode_size (int): hidden size for mode embeddings.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.act_embeddings = act_embeddings\n    self.mode_embeddings = mode_embeddings\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n    self.hidden_act_size = hidden_act_size\n    self.hidden_mode_size = hidden_mode_size\n\n    self.embedding = CustomDurationModeDistanceEmbedding(\n        act_embeddings=act_embeddings,\n        mode_embeddings=mode_embeddings,\n        hidden_act_size=hidden_act_size,\n        hidden_mode_size=hidden_mode_size,\n        dropout=dropout,\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Softmax(dim=-2)\n    self.mode_prob_activation = nn.Softmax(dim=-1)\n    self.mode_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.distance_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.act_embeddings","title":"<code>act_embeddings = act_embeddings</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.distance_activation","title":"<code>distance_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.duration_activation","title":"<code>duration_activation = nn.Softmax(dim=-2)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.embedding","title":"<code>embedding = CustomDurationModeDistanceEmbedding(act_embeddings=act_embeddings, mode_embeddings=mode_embeddings, hidden_act_size=hidden_act_size, hidden_mode_size=hidden_mode_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.hidden_act_size","title":"<code>hidden_act_size = hidden_act_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.hidden_mode_size","title":"<code>hidden_mode_size = hidden_mode_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.mode_embeddings","title":"<code>mode_embeddings = mode_embeddings</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.mode_logprob_activation","title":"<code>mode_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.mode_prob_activation","title":"<code>mode_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.forward","title":"<code>forward(batch_size, hidden, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def forward(self, batch_size, hidden, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 4, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations, mode_logits, distances = torch.split(\n        outputs, [self.act_embeddings, 1, self.mode_embeddings, 1], dim=-1\n    )\n    act_log_probs = self.activity_logprob_activation(acts_logits)\n\n    durations = self.duration_activation(durations)\n\n    mode_log_probs = self.mode_logprob_activation(mode_logits)\n\n    distances = self.distance_activation(distances)\n\n    log_prob_outputs = torch.cat(\n        (act_log_probs, durations, mode_log_probs, distances), dim=-1\n    )\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def forward_step(self, x, hidden):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Decoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    act, duration, mode, distance = torch.split(\n        x, [self.act_embeddings, 1, self.mode_embeddings, 1], dim=-1\n    )\n    _, topi = act.topk(1)\n    act = (\n        topi.squeeze(-1).detach().unsqueeze(-1)\n    )  # detach from history as input\n    duration = self.duration_activation(duration)\n    _, topi = mode.topk(1)\n    mode = topi.squeeze(-1).detach().unsqueeze(-1)\n    distance = self.distance_activation(distance)\n    outputs = torch.cat((act, duration, mode, distance), dim=-1)\n    # [N, 1, 4]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Encoder","title":"<code>Encoder(act_embeddings, mode_embeddings, hidden_size, hidden_act_size, hidden_mode_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>act_embeddings</code> <p>number of activity embeddings.</p> <p> TYPE: <code>int</code> </p> <code>mode_embeddings</code> <p>number of mode embeddings.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_act_size</code> <p>hidden size for activity embeddings.</p> <p> TYPE: <code>int</code> </p> <code>hidden_mode_size</code> <p>hidden size for mode embeddings.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def __init__(\n    self,\n    act_embeddings: int,\n    mode_embeddings: int,\n    hidden_size: int,\n    hidden_act_size: int,\n    hidden_mode_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        act_embeddings (int): number of activity embeddings.\n        mode_embeddings (int): number of mode embeddings.\n        hidden_size (int): lstm hidden size.\n        hidden_act_size (int): hidden size for activity embeddings.\n        hidden_mode_size (int): hidden size for mode embeddings.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = CustomDurationModeDistanceEmbedding(\n        act_embeddings=act_embeddings,\n        mode_embeddings=mode_embeddings,\n        hidden_act_size=hidden_act_size,\n        hidden_mode_size=hidden_mode_size,\n        dropout=dropout,\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Encoder.embedding","title":"<code>embedding = CustomDurationModeDistanceEmbedding(act_embeddings=act_embeddings, mode_embeddings=mode_embeddings, hidden_act_size=hidden_act_size, hidden_mode_size=hidden_mode_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Encoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Encoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Encoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Encoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def forward(self, x):\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Seq2SeqLSTM","title":"<code>Seq2SeqLSTM(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with conditionality.</p> Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with conditionality.\"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires conditionals_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Seq2SeqLSTM.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def build(self, **config):\n    # self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n\n    self.act_encodings, self.mode_encodings = self.encodings\n\n    # encodings\n    if self.hidden_size &lt; 4:\n        raise ValueError(\"Hidden size must be at least 4.\")\n    self.hidden_mode_size = config.get(\"hidden_mode_size\")\n    if self.hidden_mode_size is None:\n        self.hidden_mode_size = (self.hidden_size - 2) // 2\n    self.hidden_act_size = config.get(\"hidden_act_size\")\n    if self.hidden_act_size is None:\n        self.hidden_act_size = self.hidden_size - 2 - self.hidden_mode_size\n\n    self.encoder = Encoder(\n        act_embeddings=self.act_encodings,\n        mode_embeddings=self.mode_encodings,\n        hidden_size=self.hidden_size,\n        hidden_act_size=self.hidden_act_size,\n        hidden_mode_size=self.hidden_mode_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n    self.decoder = Decoder(\n        act_embeddings=self.act_encodings,\n        mode_embeddings=self.mode_encodings,\n        hidden_size=self.hidden_size,\n        hidden_act_size=self.hidden_act_size,\n        hidden_mode_size=self.hidden_mode_size,\n        output_size=self.act_encodings + self.mode_encodings + 2,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_hidden = nn.Linear(\n        flat_size_encode + self.labels_size, flat_size_encode\n    )\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Seq2SeqLSTM.decode","title":"<code>decode(z, conditionals, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def decode(\n    self, z: Tensor, conditionals: Tensor, target=None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # add conditionlity to z\n    z = torch.cat((z, conditionals), dim=-1)\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Seq2SeqLSTM.encode","title":"<code>encode(input)</code>","text":"Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def encode(self, input: Tensor) -&gt; Tensor:\n    # [N, L, C]\n    return self.encoder(input)\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Seq2SeqLSTM.forward","title":"<code>forward(x, conditionals=None, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    conditionals: Optional[Tensor] = None,\n    target=None,\n    **kwargs,\n) -&gt; List[Tensor]:\n    z = self.encode(x)  # [N, flat]\n    log_probs = self.decode(z, conditionals=conditionals, target=target)\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Seq2SeqLSTM.loss_function","title":"<code>loss_function(log_probs, target, mask, **kwargs)</code>","text":"Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def loss_function(\n    self, log_probs: Tensor, target: Tensor, mask: Tensor, **kwargs\n) -&gt; dict:\n    # unpack log_probs\n    log_act_probs, durations, log_mode_probs, distances = torch.split(\n        log_probs, [self.act_encodings, 1, self.mode_encodings, 1], dim=-1\n    )\n    # unpack target\n    target_acts, target_durations, target_mode, target_distances = (\n        target.split([1, 1, 1, 1], dim=-1)\n    )\n\n    # acts = input[:, :, :-1].contiguous()\n    # durations = input[:, :, -1:].squeeze(-1).contiguous()\n\n    # activity loss\n    recon_act_nlll = self.base_NLLL(\n        log_act_probs.view(-1, self.act_encodings),\n        target_acts.contiguous().view(-1).long(),\n    )\n    recon_act_nlll = (recon_act_nlll * mask.view(-1)).sum() / mask.sum()\n\n    # duration loss\n    recon_dur_mse = self.duration_loss_weight * self.MSE(\n        durations, target_durations\n    )\n    recon_dur_mse = (recon_dur_mse.squeeze(-1) * mask).sum() / mask.sum()\n\n    # mode loss\n    recon_mode_nlll = self.base_NLLL(\n        log_mode_probs.view(-1, self.mode_encodings),\n        target_mode.contiguous().view(-1).long(),\n    )\n    recon_mode_nlll = (recon_mode_nlll * mask.view(-1)).sum() / mask.sum()\n\n    # distance loss\n    recon_dist_mse = self.MSE(distances, target_distances)\n    recon_dist_mse = (recon_dist_mse.squeeze(-1) * mask).sum() / mask.sum()\n\n    # reconstruction loss\n    recons_loss = (\n        recon_act_nlll + recon_dur_mse + recon_mode_nlll + recon_dist_mse\n    )\n\n    return {\n        \"loss\": recons_loss,\n        \"recon_loss\": recons_loss.detach(),\n        \"recon_act_loss\": recon_act_nlll.detach(),\n        \"recon_duration_loss\": recon_dur_mse.detach(),\n        \"recon_mode_loss\": recon_mode_nlll.detach(),\n        \"recon_distance_loss\": recon_dist_mse.detach(),\n    }\n</code></pre>"},{"location":"reference/caveat/models/seq2seq/lstm/#caveat.models.seq2seq.lstm.Seq2SeqLSTM.predict_step","title":"<code>predict_step(batch, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/seq2seq/lstm.py</code> <pre><code>def predict_step(self, batch, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        batch\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    (x, _), (y, _), (labels, _) = batch\n    x = x.to(device)\n    prob_samples = exp(self.forward(x=x, conditionals=labels, **kwargs))\n    return x, y, labels, prob_samples\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/","title":"caveat.models.sequence.auto_sequence_attention","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder","title":"<code>AttentionDecoder(input_size, output_size, hidden_size, ffwd_size, num_heads, num_layers, length, dropout=0.0, position_embedding='learnt', sos=0)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    output_size,\n    hidden_size,\n    ffwd_size,\n    num_heads,\n    num_layers,\n    length,\n    dropout: float = 0.0,\n    position_embedding: str = \"learnt\",\n    sos: int = 0,\n) -&gt; None:\n    super().__init__()\n    self.output_size = output_size\n    self.max_length = length\n    self.sos = sos\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    if position_embedding == \"learnt\":\n        self.position_embedding = LearntPositionalEncoding(\n            d_model=hidden_size, dropout=dropout, length=length\n        )\n    elif position_embedding == \"fixed\":\n        self.position_embedding = FixedPositionalEncoding(\n            d_model=hidden_size, dropout=dropout, length=length\n        )\n    else:\n        raise ValueError(\n            f\"Positional embedding must be either 'learnt' or 'fixed', got {position_embedding}\"\n        )\n    self.blocks = nn.ModuleList(\n        [\n            DecoderBlockMAskedSelfAttention(\n                hidden_size,\n                n_head=num_heads,\n                dropout=dropout,\n                block_size=length,\n                ffwd_size=ffwd_size,\n            )\n            for _ in range(num_layers)\n        ]\n    )\n    # self.ln_f = nn.LayerNorm(hidden_size)\n    self.lm_head = nn.Linear(hidden_size, output_size)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n    self.apply(self._init_weights)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder.blocks","title":"<code>blocks = nn.ModuleList([DecoderBlockMAskedSelfAttention(hidden_size, n_head=num_heads, dropout=dropout, block_size=length, ffwd_size=ffwd_size) for _ in range(num_layers)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder.lm_head","title":"<code>lm_head = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder.max_length","title":"<code>max_length = length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder.position_embedding","title":"<code>position_embedding = LearntPositionalEncoding(d_model=hidden_size, dropout=dropout, length=length)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionDecoder.forward","title":"<code>forward(target, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, target, mask=None):\n    # idx and targets are both (B,T) tensor of integers\n    outputs = self.embedding(target)  # (B,T,C)\n    outputs = self.position_embedding(outputs)  # (B,T,C)\n    for layer in self.blocks:\n        outputs = layer(outputs, mask)\n\n    # outputs = self.ln_f(outputs)  # (B,T,C)\n    outputs = self.lm_head(outputs)\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = self.duration_activation(durations)\n    durations = torch.log(durations)\n\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionHead","title":"<code>AttentionHead(head_size, n_embd=10, block_size=128, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>one head of self-attention</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(self, head_size, n_embd=10, block_size=128, dropout=0.0):\n    super().__init__()\n    self.key = nn.Linear(n_embd, head_size, bias=False)\n    self.query = nn.Linear(n_embd, head_size, bias=False)\n    self.value = nn.Linear(n_embd, head_size, bias=False)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionHead.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionHead.key","title":"<code>key = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionHead.query","title":"<code>query = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionHead.value","title":"<code>value = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AttentionHead.forward","title":"<code>forward(x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, x, mask=None):\n    # input of size (batch, time-step, channels)\n    # output of size (batch, time-step, head size)\n    k = self.key(x)  # (B,T,hs)\n    q = self.query(x)  # (B,T,hs)\n    # compute attention scores (\"affinities\")\n    wei = (\n        q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n    )  # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)\n    if mask is not None:\n        wei = wei.masked_fill(mask == 0, float(\"-inf\"))  # (B, T, T)\n    wei = F.softmax(wei, dim=-1)  # (B, T, T)\n    wei = self.dropout(wei)\n    # perform the weighted aggregation of the values\n    v = self.value(x)  # (B,T,hs)\n    out = wei @ v  # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AutoSeqAtt","title":"<code>AutoSeqAtt(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer.</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AutoSeqAtt.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.ffwd_size = config.get(\"ffwd_size\", self.hidden_size)\n    self.heads = config[\"heads\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config.get(\"dropout\", 0.0)\n    self.length, _ = self.in_shape\n    self.sampling = config.get(\"sampling\", False)\n    self.position_embedding = config.get(\"position_embedding\", \"fixed\")\n\n    self.decoder = AttentionDecoder(\n        input_size=self.encodings,\n        output_size=self.encodings + 1,\n        hidden_size=self.hidden_size,\n        ffwd_size=self.ffwd_size,\n        num_heads=self.heads,\n        num_layers=self.hidden_n,\n        length=self.length,\n        dropout=self.dropout,\n        position_embedding=self.position_embedding,\n    )\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AutoSeqAtt.decode","title":"<code>decode(context, mask, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def decode(\n    self, context: Tensor, mask: Optional[Tensor], **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    log_probs = self.decoder(context, mask)\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AutoSeqAtt.forward","title":"<code>forward(x, target=None, input_mask=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>List[Tensor]</code> <p>list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(\n    self, x: Tensor, target=None, input_mask=None, **kwargs\n) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n\n    Returns:\n        list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].\n    \"\"\"\n    if input_mask is not None:\n        mask = torch.zeros_like(input_mask)\n        mask[input_mask &gt; 0] = 1.0\n        mask = mask[:, None, :]\n    else:\n        mask = None\n\n    if target is not None:  # training\n        log_prob = self.decode(context=x, mask=mask)\n        return [\n            log_prob,\n            torch.zeros_like(log_prob),\n            torch.zeros_like(log_prob),\n            torch.zeros_like(log_prob),\n        ]\n\n    # no target so assume generating\n    log_prob = self.predict_sequences(current_device=self.curr_device)\n    return [\n        log_prob,\n        torch.zeros_like(log_prob),\n        torch.zeros_like(log_prob),\n        torch.zeros_like(log_prob),\n    ]\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AutoSeqAtt.infer","title":"<code>infer(x, device, input_mask=None, **kwargs)</code>","text":"<p>Given an encoder input, return reconstructed output and z samples.</p> PARAMETER DESCRIPTION <code>x</code> <p>[N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>(tensor: [N, steps, acts], tensor: [N, latent_dims]).</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def infer(\n    self,\n    x: Tensor,\n    device: int,\n    input_mask: Optional[Tensor] = None,\n    **kwargs,\n) -&gt; Tensor:\n    \"\"\"Given an encoder input, return reconstructed output and z samples.\n\n    Args:\n        x (tensor): [N, steps, acts].\n\n    Returns:\n        (tensor: [N, steps, acts], tensor: [N, latent_dims]).\n    \"\"\"\n    log_probs_x, _, _, _ = self.forward(x, input_mask=input_mask, **kwargs)\n    prob_samples = exp(log_probs_x)\n    prob_samples = prob_samples.to(device)\n    return prob_samples, torch.zeros_like(prob_samples)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AutoSeqAtt.loss_function","title":"<code>loss_function(log_probs, target, mask, **kwargs)</code>","text":"<p>Loss function for sequence encoding [N, L, 2].</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def loss_function(self, log_probs, target, mask, **kwargs) -&gt; dict:\n    \"\"\"Loss function for sequence encoding [N, L, 2].\"\"\"\n    # unpack act probs and durations\n    target_acts, target_durations = self.unpack_encoding(target)\n    pred_acts, pred_durations = self.unpack_encoding(log_probs)\n    pred_durations = torch.exp(pred_durations)\n\n    # normalise mask weights\n    mask = mask / mask.mean(-1).unsqueeze(-1)\n    duration_mask = mask.clone()\n    duration_mask[:, 0] = 0.0\n    duration_mask[\n        torch.arange(duration_mask.shape[0]),\n        (mask != 0).cumsum(-1).argmax(1),\n    ] = 0.0\n\n    # activity loss\n    recon_act_nlll = self.base_NLLL(\n        pred_acts.view(-1, self.encodings), target_acts.view(-1).long()\n    )\n    act_recon = (recon_act_nlll * mask.view(-1)).mean()\n    scheduled_act_weight = (\n        self.activity_loss_weight * self.scheduled_act_weight\n    )\n    w_act_recon = scheduled_act_weight * act_recon\n\n    # duration loss\n    recon_dur_mse = self.MSE(pred_durations, target_durations)\n    recon_dur_mse = (recon_dur_mse * duration_mask).mean()\n    scheduled_dur_weight = (\n        self.duration_loss_weight * self.scheduled_dur_weight\n    )\n    w_dur_recon = scheduled_dur_weight * recon_dur_mse\n\n    # reconstruction loss\n    w_recons_loss = w_act_recon + w_dur_recon\n\n    # final loss\n    loss = w_recons_loss\n\n    return {\n        \"loss\": loss,\n        \"recon_loss\": w_recons_loss.detach(),\n        \"act_recon\": w_act_recon.detach(),\n        \"dur_recon\": w_dur_recon.detach(),\n        \"act_weight\": torch.tensor([scheduled_act_weight]).float(),\n        \"dur_weight\": torch.tensor([scheduled_dur_weight]).float(),\n    }\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AutoSeqAtt.predict","title":"<code>predict(z, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>z</code> <p>[N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def predict(self, z, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        z (tensor): [N, latent_dims].\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    log_prob_samples = self.predict_sequences(device)\n    return exp(log_prob_samples)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AutoSeqAtt.predict_sequences","title":"<code>predict_sequences(current_device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>z</code> <p>[N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def predict_sequences(\n    self, current_device: int, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        z (tensor): [N, latent_dims].\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    B = 1024  # todo?\n    log_outputs = []\n    sequence = torch.zeros(B, self.length, 2, device=current_device)\n    sequence[:, :, 0] = self.sos  # all sos with duration 0\n    for i in range(self.length):\n        # get the predictions\n        logits = self.decode(context=sequence, mask=None)\n        # focus only on the last time step\n        logits = logits[:, i, :]  # becomes (B, C)\n        log_outputs.append(logits.unsqueeze(1))\n        prediction = self.sample(logits)\n        # append sampled index to the running sequence\n        sequence[:, i, :] = prediction\n\n    log_probs = torch.cat(log_outputs, dim=1)\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AutoSeqAtt.sample","title":"<code>sample(logits)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def sample(self, logits):\n    acts, duration = torch.split(logits, [self.encodings, 1], dim=-1)\n    if self.sampling:\n        # sample from the distribution\n        act = torch.multinomial(torch.exp(logits), num_samples=1)  # (B, 1)\n    else:\n        _, topi = logits.topk(1)\n        act = (\n            topi.squeeze(-1).detach().unsqueeze(-1)\n        )  # detach from history as input?\n    # [N, 1, encodings+1]\n\n    _, topi = acts.topk(1)\n    act = (\n        topi.squeeze(-1).detach().unsqueeze(-1)\n    )  # detach from history as input\n    duration = self.decoder.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.AutoSeqAtt.validation_step","title":"<code>validation_step(batch, batch_idx, optimizer_idx=0)</code>","text":"<p>Override the validation step to include the target during validation. This is required for self attention.</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def validation_step(self, batch, batch_idx, optimizer_idx=0):\n    \"\"\"Override the validation step to include the target during validation.\n    This is required for self attention.\n    \"\"\"\n\n    (x, _), (y, y_weights), (labels, _) = batch\n    self.curr_device = x.device\n\n    log_probs, mu, log_var, z = self.forward(\n        x, conditionals=labels, target=y\n    )\n    val_loss = self.loss_function(\n        log_probs=log_probs,\n        target=y,\n        mask=y_weights,\n        duration_weight=self.duration_loss_weight,\n        optimizer_idx=optimizer_idx,\n        batch_idx=batch_idx,\n    )\n\n    self.log_dict(\n        {f\"val_{key}\": val.item() for key, val in val_loss.items()},\n        sync_dist=True,\n        on_step=False,\n        on_epoch=True,\n        prog_bar=True,\n    )\n    self.log(\"hp_metric\", val_loss[\"loss\"])\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.CrossAttentionHead","title":"<code>CrossAttentionHead(head_size, n_embd=10, block_size=128, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>one head of x-attention</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(self, head_size, n_embd=10, block_size=128, dropout=0.0):\n    super().__init__()\n    self.key = nn.Linear(n_embd, head_size, bias=False)\n    self.query = nn.Linear(n_embd, head_size, bias=False)\n    self.value = nn.Linear(n_embd, head_size, bias=False)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.CrossAttentionHead.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.CrossAttentionHead.key","title":"<code>key = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.CrossAttentionHead.query","title":"<code>query = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.CrossAttentionHead.value","title":"<code>value = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.CrossAttentionHead.forward","title":"<code>forward(x_encode, x_decode, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, x_encode, x_decode, mask=None):\n    # input of size (batch, time-step, channels)\n    # output of size (batch, time-step, head size)\n    k = self.key(x_encode)  # (B,T,hs)\n    q = self.query(x_decode)  # (B,T,hs)\n    # compute attention scores (\"affinities\")\n    wei = (\n        q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n    )  # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)\n    if mask is not None:\n        wei = wei.masked_fill(mask == 0, float(\"-inf\"))  # (B, T, T)\n    wei = F.softmax(wei, dim=-1)  # (B, T, T)\n    wei = self.dropout(wei)\n    # perform the weighted aggregation of the values\n    v = self.value(x_encode)  # (B,T,hs)\n    out = wei @ v  # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.DecoderBlockMAskedSelfAttention","title":"<code>DecoderBlockMAskedSelfAttention(n_embd, n_head, block_size, dropout, ffwd_size=None)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(\n    self, n_embd, n_head, block_size, dropout, ffwd_size: int = None\n):\n    # n_embd: embedding dimension, n_head: the number of heads we'd like\n    super().__init__()\n    head_size = n_embd // n_head\n    self.self_attention = MultiHeadMaskedAttention(\n        num_heads=n_head,\n        head_size=head_size,\n        n_embd=n_embd,\n        block_size=block_size,\n        dropout=dropout,\n    )\n    self.ffwd = FeedFoward(n_embd=n_embd, ffwd_size=ffwd_size)\n    self.ln1 = nn.RMSNorm(n_embd)\n    self.ln2 = nn.RMSNorm(n_embd)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.DecoderBlockMAskedSelfAttention.ffwd","title":"<code>ffwd = FeedFoward(n_embd=n_embd, ffwd_size=ffwd_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.DecoderBlockMAskedSelfAttention.ln1","title":"<code>ln1 = nn.RMSNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.DecoderBlockMAskedSelfAttention.ln2","title":"<code>ln2 = nn.RMSNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.DecoderBlockMAskedSelfAttention.self_attention","title":"<code>self_attention = MultiHeadMaskedAttention(num_heads=n_head, head_size=head_size, n_embd=n_embd, block_size=block_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.DecoderBlockMAskedSelfAttention.forward","title":"<code>forward(target, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, target, mask=None):\n    target = target + self.self_attention(self.ln1(target), mask)\n    target = target + self.ffwd(self.ln2(target))\n    return target\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.FeedFoward","title":"<code>FeedFoward(n_embd, dropout=0.0, ffwd_size=None)</code>","text":"<p>               Bases: <code>Module</code></p> <p>a simple linear layer followed by a non-linearity</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(self, n_embd, dropout=0.0, ffwd_size=None):\n    super().__init__()\n    if ffwd_size is None:\n        ffwd_size = n_embd * 2\n    self.net = nn.Sequential(\n        nn.Linear(n_embd, ffwd_size),\n        nn.GELU(),\n        nn.Linear(ffwd_size, n_embd),\n        nn.Dropout(dropout),\n    )\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.FeedFoward.net","title":"<code>net = nn.Sequential(nn.Linear(n_embd, ffwd_size), nn.GELU(), nn.Linear(ffwd_size, n_embd), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.FeedFoward.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, x):\n    return self.net(x)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.FixedPositionalEncoding","title":"<code>FixedPositionalEncoding(d_model, dropout=0.0, length=144)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(self, d_model: int, dropout: float = 0.0, length: int = 144):\n    super().__init__()\n    self.dropout = nn.Dropout(p=dropout)\n\n    position = torch.arange(length).unsqueeze(1)\n    div_term = torch.exp(\n        torch.arange(0, d_model, 2) * (-math.log(length) / d_model)\n    )\n    pe = torch.zeros(length, d_model)\n    pe[:, 0::2] = torch.sin(position * div_term)\n    pe[:, 1::2] = torch.cos(position * div_term)\n    self.register_buffer(\"pe\", pe)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.FixedPositionalEncoding.dropout","title":"<code>dropout = nn.Dropout(p=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.FixedPositionalEncoding.forward","title":"<code>forward(x)</code>","text":"PARAMETER DESCRIPTION <code>x</code> <p>Tensor, shape <code>[seq_len, batch_size, embedding_dim]</code></p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, x: Tensor) -&gt; Tensor:\n    \"\"\"\n    Arguments:\n        x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n    \"\"\"\n    _, T, _ = x.shape\n    x = x + self.pe[:T, :]\n    return self.dropout(x)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.LearntPositionalEncoding","title":"<code>LearntPositionalEncoding(d_model, dropout=0.0, length=144)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(self, d_model: int, dropout: float = 0.0, length: int = 144):\n    super().__init__()\n    self.dropout = nn.Dropout(p=dropout)\n    pe = torch.arange(0, length, dtype=torch.long)  # (T)\n    self.register_buffer(\"pe\", pe)\n    self.embedding = nn.Embedding(length, d_model)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.LearntPositionalEncoding.dropout","title":"<code>dropout = nn.Dropout(p=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.LearntPositionalEncoding.embedding","title":"<code>embedding = nn.Embedding(length, d_model)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.LearntPositionalEncoding.forward","title":"<code>forward(x)</code>","text":"PARAMETER DESCRIPTION <code>x</code> <p>Tensor, shape <code>[seq_len, batch_size, embedding_dim]</code></p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, x: Tensor) -&gt; Tensor:\n    \"\"\"\n    Arguments:\n        x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n    \"\"\"\n    _, L, _ = x.shape  # (B,T,C)\n\n    pos_emb = self.embedding(self.pe[:L]).unsqueeze(0)  # (1,L,C)\n    x = x + pos_emb  # (B,L,C)\n    return self.dropout(x)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MaskedAttentionHead","title":"<code>MaskedAttentionHead(head_size, n_embd, block_size, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>one head of self-attention</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(self, head_size, n_embd, block_size, dropout=0.0):\n    super().__init__()\n    self.key = nn.Linear(n_embd, head_size, bias=False)\n    self.query = nn.Linear(n_embd, head_size, bias=False)\n    self.value = nn.Linear(n_embd, head_size, bias=False)\n    self.register_buffer(\n        \"tril\", torch.tril(torch.ones(block_size, block_size), diagonal=0)\n    )\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MaskedAttentionHead.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MaskedAttentionHead.key","title":"<code>key = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MaskedAttentionHead.query","title":"<code>query = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MaskedAttentionHead.value","title":"<code>value = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MaskedAttentionHead.forward","title":"<code>forward(x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, x, mask=None):\n    B, T, C = x.shape\n    # input of size (batch, time-step, channels)\n    # output of size (batch, time-step, head size)\n    k = self.key(x)  # (B,T,hs)\n    q = self.query(x)  # (B,T,hs)\n    # compute attention scores (\"affinities\")\n    wei = (\n        q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n    )  # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)\n    wei = wei.masked_fill(\n        self.tril[:T, :T] == 0, float(\"-inf\")\n    )  # (B, T, T)\n    if mask is not None:\n        wei = wei.masked_fill(mask == 0, float(\"-inf\"))  # (B, T, T)\n    wei = F.softmax(wei, dim=-1)  # (B, T, T)\n    wei = self.dropout(wei)\n    # perform the weighted aggregation of the values\n    v = self.value(x)  # (B,T,hs)\n    out = wei @ v  # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadAttention","title":"<code>MultiHeadAttention(num_heads, head_size, n_embd=10, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>multiple heads of self-attention in parallel</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(self, num_heads, head_size, n_embd=10, dropout=0.0):\n    super().__init__()\n    self.heads = nn.ModuleList(\n        [\n            AttentionHead(head_size=head_size, n_embd=n_embd)\n            for _ in range(num_heads)\n        ]\n    )\n    self.proj = nn.Linear(head_size * num_heads, n_embd)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadAttention.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadAttention.heads","title":"<code>heads = nn.ModuleList([AttentionHead(head_size=head_size, n_embd=n_embd) for _ in range(num_heads)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadAttention.proj","title":"<code>proj = nn.Linear(head_size * num_heads, n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadAttention.forward","title":"<code>forward(x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, x, mask=None):\n    out = torch.cat([h(x, mask) for h in self.heads], dim=-1)\n    out = self.dropout(self.proj(out))\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadCrossAttention","title":"<code>MultiHeadCrossAttention(num_heads, head_size, n_embd=10, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>multiple heads of masked x-attention in parallel</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(self, num_heads, head_size, n_embd=10, dropout=0.0):\n    super().__init__()\n    self.heads = nn.ModuleList(\n        [\n            CrossAttentionHead(head_size=head_size, n_embd=n_embd)\n            for _ in range(num_heads)\n        ]\n    )\n    self.proj = nn.Linear(head_size * num_heads, n_embd)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadCrossAttention.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadCrossAttention.heads","title":"<code>heads = nn.ModuleList([CrossAttentionHead(head_size=head_size, n_embd=n_embd) for _ in range(num_heads)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadCrossAttention.proj","title":"<code>proj = nn.Linear(head_size * num_heads, n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadCrossAttention.forward","title":"<code>forward(x_encode, x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, x_encode, x, mask=None):\n    out = torch.cat([h(x_encode, x, mask) for h in self.heads], dim=-1)\n    out = self.dropout(self.proj(out))\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadMaskedAttention","title":"<code>MultiHeadMaskedAttention(num_heads, head_size, block_size, n_embd, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Multiple heads of masked self-attention in parallel</p> Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def __init__(self, num_heads, head_size, block_size, n_embd, dropout=0.0):\n    super().__init__()\n    self.masked_heads = nn.ModuleList(\n        [\n            MaskedAttentionHead(\n                head_size=head_size, n_embd=n_embd, block_size=block_size\n            )\n            for _ in range(num_heads)\n        ]\n    )\n    self.proj = nn.Linear(head_size * num_heads, n_embd)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadMaskedAttention.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadMaskedAttention.masked_heads","title":"<code>masked_heads = nn.ModuleList([MaskedAttentionHead(head_size=head_size, n_embd=n_embd, block_size=block_size) for _ in range(num_heads)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadMaskedAttention.proj","title":"<code>proj = nn.Linear(head_size * num_heads, n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_attention/#caveat.models.sequence.auto_sequence_attention.MultiHeadMaskedAttention.forward","title":"<code>forward(x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_attention.py</code> <pre><code>def forward(self, x, mask=None):\n    out = torch.cat([h(x, mask) for h in self.masked_heads], dim=-1)\n    out = self.dropout(self.proj(out))\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/","title":"caveat.models.sequence.auto_sequence_lstm","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.AutoSeqLSTM","title":"<code>AutoSeqLSTM(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer and conditionality.</p> Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with encoder embedding layer and conditionality.\"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires conditionals_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.AutoSeqLSTM.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = 1  # dummy value for the predict dataloader\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_hidden = nn.Linear(self.labels_size, flat_size_encode)\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.AutoSeqLSTM.decode","title":"<code>decode(z, labels, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def decode(\n    self, z: None, labels: Tensor, target: Optional[Tensor] = None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    h = self.fc_hidden(labels)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.AutoSeqLSTM.encode","title":"<code>encode(input)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def encode(self, input: Tensor):\n    return None\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.AutoSeqLSTM.forward","title":"<code>forward(x, labels=None, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    labels: Optional[Tensor] = None,\n    target: Optional[Tensor] = None,\n    **kwargs,\n) -&gt; List[Tensor]:\n\n    log_probs = self.decode(z=x, labels=labels, target=target)\n    return [log_probs, Tensor([]), Tensor([]), Tensor([])]\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.AutoSeqLSTM.loss_function","title":"<code>loss_function(log_probs, target, weights, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def loss_function(\n    self,\n    log_probs: Tensor,\n    target: Tensor,\n    weights: Tuple[Tensor, Tensor],\n    **kwargs,\n) -&gt; dict:\n    return self.seq_loss_no_kld(\n        log_probs=log_probs, target=target, weights=weights, **kwargs\n    )\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.AutoSeqLSTM.predict","title":"<code>predict(z, conditionals, device, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def predict(\n    self, z: Tensor, conditionals: Tensor, device: int, **kwargs\n) -&gt; Tensor:\n    z = z.to(device)\n    conditionals = conditionals.to(device)\n    return exp(self.decode(z=z, labels=conditionals, kwargs=kwargs))\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.forward","title":"<code>forward(batch_size, hidden, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def forward(self, batch_size, hidden, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.sample(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def forward_step(self, x, hidden):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/auto_sequence_lstm/#caveat.models.sequence.auto_sequence_lstm.Decoder.sample","title":"<code>sample(x)</code>","text":"Source code in <code>caveat/models/sequence/auto_sequence_lstm.py</code> <pre><code>def sample(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    act = torch.multinomial(\n        self.activity_prob_activation(acts.squeeze()), 1\n    ).unsqueeze(-2)\n    # _, topi = acts.topk(1)\n    # act = (\n    #     topi.squeeze(-1).detach().unsqueeze(-1)\n    # )  # detach from history as input\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/","title":"caveat.models.sequence.cond_sequence_lstm","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.CondSeqLSTM","title":"<code>CondSeqLSTM(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer and conditionality.</p> Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with encoder embedding layer and conditionality.\"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires conditionals_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.CondSeqLSTM.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = 1  # dummy value for the predict dataloader\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n\n    self.label_encoder = LabelEncoder(\n        label_embed_sizes=self.label_embed_sizes,\n        hidden_size=self.hidden_size,\n    )\n\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n        top_sampler=config.get(\"top_sampler\", True),\n    )\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_hidden = nn.Linear(self.hidden_size, flat_size_encode)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.CondSeqLSTM.decode","title":"<code>decode(z, labels, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def decode(\n    self, z: None, labels: Tensor, target: Optional[Tensor] = None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    batch_size = labels.shape[0]\n    embeds = self.label_encoder(labels)\n    h = self.fc_hidden(embeds)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size,\n            hidden=hidden,\n            target=target,\n            conditionals=embeds,\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size,\n            hidden=hidden,\n            target=None,\n            conditionals=embeds,\n        )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.CondSeqLSTM.encode","title":"<code>encode(input)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def encode(self, input: Tensor):\n    return None\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.CondSeqLSTM.forward","title":"<code>forward(x, labels=None, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    labels: Optional[Tensor] = None,\n    target: Optional[Tensor] = None,\n    **kwargs,\n) -&gt; List[Tensor]:\n\n    log_probs = self.decode(z=x, labels=labels, target=target)\n    return [log_probs, Tensor([]), Tensor([]), Tensor([])]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.CondSeqLSTM.loss_function","title":"<code>loss_function(log_probs, target, weights, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def loss_function(\n    self,\n    log_probs: Tensor,\n    target: Tensor,\n    weights: Tuple[Tensor, Tensor],\n    **kwargs,\n) -&gt; dict:\n    return self.seq_loss_no_kld(\n        log_probs=log_probs, target=target, weights=weights, **kwargs\n    )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.CondSeqLSTM.predict","title":"<code>predict(z, labels, device, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def predict(\n    self, z: Tensor, labels: Tensor, device: int, **kwargs\n) -&gt; Tensor:\n    z = z.to(device)\n    labels = labels.to(device)\n    return exp(self.decode(z=z, labels=labels, kwargs=kwargs))\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0, top_sampler=True)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n    top_sampler: bool = True,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc_out = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n\n    if top_sampler:\n        print(\"Decoder using topk sampling\")\n        self.sample = self.sample_topk\n    else:\n        print(\"Decoder using multinomial sampling\")\n        self.sample = self.sample_multinomial\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.fc_out","title":"<code>fc_out = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.sample","title":"<code>sample = self.sample_topk</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.forward","title":"<code>forward(hidden, conditionals, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def forward(self, hidden, conditionals, target=None, **kwargs):\n    hidden, cell = hidden\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n\n    batch_size = hidden[0].shape[0]\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos\n\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden, conditionals\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.forward_step","title":"<code>forward_step(x, hidden, conditionals)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def forward_step(self, x, hidden, conditionals):\n    embedded = self.embedding(x)\n    embedded = embedded + conditionals.unsqueeze(1)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc_out(output)\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    act = self.sample(acts).detach()\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.sample_multinomial","title":"<code>sample_multinomial(x)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def sample_multinomial(self, x):\n    # [N, 1, encodings]\n    act = torch.multinomial(\n        self.activity_prob_activation(x.squeeze()), 1\n    ).unsqueeze(-1)\n    return act\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.Decoder.sample_topk","title":"<code>sample_topk(x)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def sample_topk(self, x):\n    _, topi = x.topk(1)\n    act = topi.detach()\n    return act\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.LabelEncoder","title":"<code>LabelEncoder(label_embed_sizes, hidden_size)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Label Encoder using token embedding. Embedding outputs are the same size but use different weights so that they can be different sizes. Each embedding is then stacked and summed to give single encoding.</p> Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def __init__(self, label_embed_sizes, hidden_size):\n    \"\"\"Label Encoder using token embedding.\n    Embedding outputs are the same size but use different weights so that they can be different sizes.\n    Each embedding is then stacked and summed to give single encoding.\"\"\"\n    super(LabelEncoder, self).__init__()\n    self.embeds = nn.ModuleList(\n        [nn.Embedding(s, hidden_size) for s in label_embed_sizes]\n    )\n    self.fc = nn.Linear(hidden_size, hidden_size)\n    self.activation = nn.ReLU()\n</code></pre>"},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.LabelEncoder.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.LabelEncoder.embeds","title":"<code>embeds = nn.ModuleList([nn.Embedding(s, hidden_size) for s in label_embed_sizes])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.LabelEncoder.fc","title":"<code>fc = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cond_sequence_lstm/#caveat.models.sequence.cond_sequence_lstm.LabelEncoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/cond_sequence_lstm.py</code> <pre><code>def forward(self, x):\n    x = torch.stack(\n        [embed(x[:, i]) for i, embed in enumerate(self.embeds)], dim=-1\n    ).sum(dim=-1)\n    x = self.fc(x)\n    x = self.activation(x)\n    return x\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/","title":"caveat.models.sequence.cvae_sequence_lstm","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.AddLatent","title":"<code>AddLatent(labels_size, latent_dim, flat_size_encode, hidden_n, hidden_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    labels_size: int,\n    latent_dim: int,\n    flat_size_encode: int,\n    hidden_n: int,\n    hidden_size: int,\n):\n    super(AddLatent, self).__init__()\n    self.hidden_n = hidden_n\n    self.hidden_size = hidden_size\n    self.labels_fc = nn.Linear(labels_size, latent_dim)\n    self.latent_fc = nn.Linear(latent_dim, flat_size_encode)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.AddLatent.hidden_n","title":"<code>hidden_n = hidden_n</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.AddLatent.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.AddLatent.labels_fc","title":"<code>labels_fc = nn.Linear(labels_size, latent_dim)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.AddLatent.latent_fc","title":"<code>latent_fc = nn.Linear(latent_dim, flat_size_encode)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.AddLatent.forward","title":"<code>forward(z, labels)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, z: Tensor, labels: Tensor) -&gt; Tuple[Tensor, Tensor]:\n\n    # add conditionlity to z\n    labels_z = self.labels_fc(labels)\n    z = z + labels_z\n    # initialize hidden state as inputs\n    h = self.latent_fc(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.CVAESeqLSTM","title":"<code>CVAESeqLSTM(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoders with optional conditionalities at encoder, latent and decoder.</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoders with optional conditionalities at encoder, latent and decoder.\"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires labels_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n    if self.label_embed_sizes is None:\n        raise UserWarning(\"ConditionalLSTM requires label_embed_sizes\")\n    if not isinstance(self.label_embed_sizes, list):\n        raise UserWarning(\n            \"ConditionalLSTM requires label_embed_sizes to be a list of label embedding sizes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.CVAESeqLSTM.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.labels_hidden_size = config.get(\n        \"labels_hidden_size\", self.hidden_size\n    )\n    print(f\"Found label encoder hidden size = {self.labels_hidden_size}\")\n\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n\n    # label encoder\n    self.label_encoder = LabelEncoder(\n        label_embed_sizes=self.label_embed_sizes,\n        hidden_size=self.labels_hidden_size,\n    )\n\n    # encoder\n    encoder_conditionality = config.get(\"encoder_conditionality\", \"none\")\n    if encoder_conditionality == \"none\":\n        print(\"No encoder conditionality\")\n        self.encoder = Encoder(\n            input_size=self.encodings,\n            hidden_size=self.hidden_size,\n            hidden_layers=self.hidden_n,\n            dropout=self.dropout,\n        )\n    elif encoder_conditionality == \"hidden\":\n        print(\"Using hidden state encoder conditionality\")\n        self.encoder = HiddenConditionalEncoder(\n            input_size=self.encodings,\n            hidden_size=self.hidden_size,\n            hidden_layers=self.hidden_n,\n            labels_size=self.labels_hidden_size,\n            dropout=self.dropout,\n        )\n    elif encoder_conditionality == \"inputs_add\":\n        print(\"Using inputs addition encoder conditionality\")\n        self.encoder = InputsAddConditionalEncoder(\n            input_size=self.encodings,\n            hidden_size=self.hidden_size,\n            hidden_layers=self.hidden_n,\n            labels_size=self.labels_hidden_size,\n            max_length=length,\n            dropout=self.dropout,\n        )\n    elif encoder_conditionality == \"inputs_concat\":\n        print(\"Using inputs concat encoder conditionality\")\n        self.encoder = InputsConcatConditionalEncoder(\n            input_size=self.encodings,\n            hidden_size=self.hidden_size,\n            hidden_layers=self.hidden_n,\n            labels_size=self.labels_hidden_size,\n            max_length=length,\n            dropout=self.dropout,\n        )\n    elif encoder_conditionality == \"both_add\":\n        print(\"Using hidden and inputs add encoder conditionality\")\n        self.encoder = HiddenInputsAddConditionalEncoder(\n            input_size=self.encodings,\n            hidden_size=self.hidden_size,\n            hidden_layers=self.hidden_n,\n            labels_size=self.labels_hidden_size,\n            max_length=length,\n            dropout=self.dropout,\n        )\n    elif encoder_conditionality == \"both_concat\":\n        print(\"Using hidden and inputs concat encoder conditionality\")\n        self.encoder = HiddenInputsConcatConditionalEncoder(\n            input_size=self.encodings,\n            hidden_size=self.hidden_size,\n            hidden_layers=self.hidden_n,\n            labels_size=self.labels_hidden_size,\n            max_length=length,\n            dropout=self.dropout,\n        )\n    else:\n        raise ValueError(\n            f\"encoder_conditionality ({encoder_conditionality}) must be either 'none', 'hidden', 'inputs_add/concat', or 'hidden_and_inputs'\"\n        )\n\n    # encoder to latent\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n\n    # latent block (add or concat)\n    latent_conditionality = config.get(\"latent_conditionality\", \"concat\")\n    if latent_conditionality == \"concat\":\n        print(\"Label conditionality is concat\")\n        self.latent_block = ConcatLatent(\n            latent_dim=self.latent_dim,\n            labels_size=self.labels_hidden_size,\n            flat_size_encode=flat_size_encode,\n            hidden_layers=self.hidden_n,\n            hidden_size=self.hidden_size,\n        )\n    elif latent_conditionality == \"add\":\n        print(\"Label conditionality is add\")\n        self.latent_block = AddLatent(\n            labels_size=self.labels_hidden_size,\n            latent_dim=self.latent_dim,\n            flat_size_encode=flat_size_encode,\n            hidden_n=self.hidden_n,\n            hidden_size=self.hidden_size,\n        )\n    else:\n        raise ValueError(\n            \"label_conditionality must be either 'concat' or 'add'\"\n        )\n\n    # decoder conditionality\n    decoder_conditionality = config.get(\"decoder_conditionality\", \"none\")\n    if decoder_conditionality == \"none\":\n        print(\"Decoder conditionality is 'none'\")\n        self.decoder = Decoder(\n            input_size=self.encodings,\n            hidden_size=self.hidden_size,\n            output_size=self.encodings + 1,\n            num_layers=self.hidden_n,\n            max_length=length,\n            dropout=self.dropout,\n            sos=self.sos,\n        )\n    elif decoder_conditionality == \"inputs_add\":\n        print(\"Decoder conditionality is 'inputs'\")\n        self.decoder = InputsAddConditionalDecoder(\n            input_size=self.encodings,\n            hidden_size=self.hidden_size,\n            output_size=self.encodings + 1,\n            num_layers=self.hidden_n,\n            max_length=length,\n            labels_size=self.labels_hidden_size,\n            dropout=self.dropout,\n            sos=self.sos,\n        )\n    elif decoder_conditionality == \"inputs_concat\":\n        print(\"Decoder conditionality is 'inputs_concat'\")\n        self.decoder = InputsConcatConditionalDecoder(\n            input_size=self.encodings,\n            hidden_size=self.hidden_size,\n            output_size=self.encodings + 1,\n            num_layers=self.hidden_n,\n            max_length=length,\n            labels_size=self.labels_hidden_size,\n            dropout=self.dropout,\n            sos=self.sos,\n        )\n    else:\n        raise ValueError(\n            \"Decoder conditionality must be 'none'. 'inputs_add' or 'inputs_concat'\"\n        )\n\n    # share embedding\n    if config.get(\"share_embed\", False):\n        print(\"Decoder and Encoder Embedding is shared\")\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.CVAESeqLSTM.decode","title":"<code>decode(z, labels, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>hidden</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>labels_size</code> <p>Conditional labels [N, labels_size_size].</p> <p> TYPE: <code>tensor</code> </p> <code>target</code> <p>Target sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def decode(\n    self, z: Tensor, labels: Tensor, target=None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        hidden (tensor): Latent space batch [N, latent_dims].\n        labels_size (tensor): Conditional labels [N, labels_size_size].\n        target (tensor): Target sequence batch [N, steps, acts].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    batch_size = labels.shape[0]\n\n    labels_hidden = self.label_encoder(labels)\n    conditioned_z = self.latent_block(z, labels_hidden)\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size,\n            hidden=conditioned_z,\n            target=target,\n            labels=labels_hidden,\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size,\n            hidden=conditioned_z,\n            target=None,\n            labels=labels_hidden,\n        )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.CVAESeqLSTM.encode","title":"<code>encode(input, labels)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>list[tensor]: Latent layer input (means and variances) [N, latent_dims].</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def encode(self, input: Tensor, labels: Tensor) -&gt; list[Tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): Input sequence batch [N, steps, acts].\n\n    Returns:\n        list[tensor]: Latent layer input (means and variances) [N, latent_dims].\n    \"\"\"\n    labels_hidden = self.label_encoder(labels)\n    hidden = self.encoder(input, labels_hidden)\n    mu = self.fc_mu(hidden)\n    log_var = self.fc_var(hidden)\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.CVAESeqLSTM.forward","title":"<code>forward(x, labels=None, target=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>List[Tensor]</code> <p>list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(\n    self, x: Tensor, labels: Optional[Tensor] = None, target=None, **kwargs\n) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n\n    Returns:\n        list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].\n    \"\"\"\n    mu, log_var = self.encode(x, labels)\n    z = self.reparameterize(mu, log_var)\n\n    log_prob_y = self.decode(z, labels=labels, target=target)\n    return [log_prob_y, mu, log_var, z]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.CVAESeqLSTM.predict","title":"<code>predict(z, labels, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def predict(\n    self, z: Tensor, labels: Tensor, device: int, **kwargs\n) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(device)\n    labels = labels.to(device)\n    prob_samples = exp(self.decode(z=z, labels=labels, **kwargs))\n    return prob_samples\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.ConcatLatent","title":"<code>ConcatLatent(latent_dim, labels_size, flat_size_encode, hidden_layers, hidden_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    latent_dim: int,\n    labels_size: int,\n    flat_size_encode: int,\n    hidden_layers: int,\n    hidden_size: int,\n):\n    super(ConcatLatent, self).__init__()\n    self.hidden_layers = hidden_layers\n    self.hidden_size = hidden_size\n    self.latent_fc = nn.Linear(latent_dim + labels_size, flat_size_encode)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.ConcatLatent.hidden_layers","title":"<code>hidden_layers = hidden_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.ConcatLatent.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.ConcatLatent.latent_fc","title":"<code>latent_fc = nn.Linear(latent_dim + labels_size, flat_size_encode)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.ConcatLatent.forward","title":"<code>forward(z, labels)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, z: Tensor, labels: Tensor) -&gt; Tuple[Tensor, Tensor]:\n\n    # add conditionlity to z\n    z = torch.cat((z, labels), dim=-1)\n    # initialize hidden state as inputs\n    h = self.latent_fc(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(\n        1, (2 * self.hidden_layers, self.hidden_size)\n    ).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_layers\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.forward","title":"<code>forward(batch_size, hidden, labels, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, batch_size, hidden, labels, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward_step(self, x, hidden):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Decoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    _, topi = acts.topk(1)\n    act = (\n        topi.squeeze(-1).detach().unsqueeze(-1)\n    )  # detach from history as input\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Encoder","title":"<code>Encoder(input_size, hidden_size, hidden_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder without conditionality.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    hidden_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder without conditionality.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        hidden_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        hidden_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Encoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Encoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, hidden_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Encoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.Encoder.forward","title":"<code>forward(x, labels)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, x, labels):\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenConditionalEncoder","title":"<code>HiddenConditionalEncoder(input_size, hidden_size, hidden_layers, labels_size, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder with label conditionality added at RNN hidden state.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>labels</code> <p>size of labels.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    hidden_layers: int,\n    labels_size: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder with label conditionality added at RNN hidden state.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        hidden_layers (int): number of lstm layers.\n        labels (int): size of labels.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(HiddenConditionalEncoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.hidden_layers = hidden_layers\n    flat_size = 2 * hidden_layers * hidden_size\n\n    self.labels_ff = nn.Sequential(\n        nn.Linear(labels_size, flat_size),\n        # nn.LeakyReLU(),\n        nn.Dropout(dropout),\n    )\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        hidden_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenConditionalEncoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenConditionalEncoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenConditionalEncoder.hidden_layers","title":"<code>hidden_layers = hidden_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenConditionalEncoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenConditionalEncoder.labels_ff","title":"<code>labels_ff = nn.Sequential(nn.Linear(labels_size, flat_size), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenConditionalEncoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, hidden_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenConditionalEncoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenConditionalEncoder.forward","title":"<code>forward(x, labels)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, x, labels):\n    # label conditionality\n    h1, h2 = (\n        self.labels_ff(labels)\n        .unflatten(1, (2 * self.hidden_layers, self.hidden_size))\n        .permute(1, 0, 2)\n        .split(self.hidden_layers)\n    )\n    h1 = h1.contiguous()\n    h2 = h2.contiguous()\n\n    # input encoding\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded, (h1, h2))\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsAddConditionalEncoder","title":"<code>HiddenInputsAddConditionalEncoder(input_size, hidden_size, hidden_layers, labels_size, max_length, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Conditional Encoder. Labels are introduced at the hidden state and input.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>labels_size</code> <p>size of labels.</p> <p> TYPE: <code>int</code> </p> <code>flat_size_encode</code> <p>flattened hidden size.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    hidden_layers: int,\n    labels_size: int,\n    max_length: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Conditional Encoder. Labels are introduced at the hidden state and input.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        hidden_layers (int): number of lstm layers.\n        labels_size (int): size of labels.\n        flat_size_encode (int): flattened hidden size.\n        max_length (int): max length of sequences.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(HiddenInputsAddConditionalEncoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.hidden_layers = hidden_layers\n    self.max_length = max_length\n    flat_size = 2 * hidden_layers * hidden_size\n\n    self.inputs_ff = nn.Sequential(\n        nn.Linear(labels_size, hidden_size),\n        # nn.LeakyReLU(),\n        nn.Dropout(dropout),\n    )\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.labels_ff = nn.Sequential(\n        nn.Linear(labels_size, flat_size),\n        # nn.LeakyReLU(),\n        nn.Dropout(dropout),\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        hidden_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsAddConditionalEncoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsAddConditionalEncoder.hidden_layers","title":"<code>hidden_layers = hidden_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsAddConditionalEncoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsAddConditionalEncoder.inputs_ff","title":"<code>inputs_ff = nn.Sequential(nn.Linear(labels_size, hidden_size), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsAddConditionalEncoder.labels_ff","title":"<code>labels_ff = nn.Sequential(nn.Linear(labels_size, flat_size), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsAddConditionalEncoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, hidden_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsAddConditionalEncoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsAddConditionalEncoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsAddConditionalEncoder.forward","title":"<code>forward(x, labels)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, x, labels):\n    h1, h2 = (\n        self.labels_ff(labels)\n        .unflatten(1, (2 * self.hidden_layers, self.hidden_size))\n        .permute(1, 0, 2)\n        .split(self.hidden_layers)\n    )\n    h1 = h1.contiguous()\n    h2 = h2.contiguous()\n\n    inputs_labels = (\n        self.inputs_ff(labels).unsqueeze(1).repeat(1, self.max_length, 1)\n    )\n    embedded = self.embedding(x)\n    embedded = embedded + inputs_labels\n    _, (h1, h2) = self.lstm(embedded, (h1, h2))\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsConcatConditionalEncoder","title":"<code>HiddenInputsConcatConditionalEncoder(input_size, hidden_size, hidden_layers, labels_size, max_length, dropout=0.1, conditional_hidden_size=None)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    hidden_layers: int,\n    labels_size: int,\n    max_length: int,\n    dropout: float = 0.1,\n    conditional_hidden_size: Optional[int] = None,\n):\n    super().__init__()\n    self.hidden_layers = hidden_layers\n    self.hidden_size = hidden_size\n    self.max_length = max_length\n    if conditional_hidden_size is None:\n        conditional_hidden_size = int(hidden_size / 2)\n    else:\n        conditional_hidden_size = conditional_hidden_size\n    encoding_size = hidden_size - conditional_hidden_size\n    if encoding_size &lt; 0:\n        raise ValueError(\n            \"conditional_hidden_size must be less than or equal to hidden_size\"\n        )\n\n    flat_size = 2 * hidden_layers * hidden_size\n\n    self.inputs_ff = nn.Sequential(\n        nn.Linear(labels_size, conditional_hidden_size),\n        # nn.LeakyReLU(),\n        nn.Dropout(dropout),\n    )\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, encoding_size, dropout=dropout\n    )\n    self.labels_ff = nn.Sequential(\n        nn.Linear(labels_size, flat_size),\n        # nn.LeakyReLU(),\n        nn.Dropout(dropout),\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        hidden_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsConcatConditionalEncoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, encoding_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsConcatConditionalEncoder.hidden_layers","title":"<code>hidden_layers = hidden_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsConcatConditionalEncoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsConcatConditionalEncoder.inputs_ff","title":"<code>inputs_ff = nn.Sequential(nn.Linear(labels_size, conditional_hidden_size), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsConcatConditionalEncoder.labels_ff","title":"<code>labels_ff = nn.Sequential(nn.Linear(labels_size, flat_size), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsConcatConditionalEncoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, hidden_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsConcatConditionalEncoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsConcatConditionalEncoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.HiddenInputsConcatConditionalEncoder.forward","title":"<code>forward(x, labels)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, x, labels):\n    h1, h2 = (\n        self.labels_ff(labels)\n        .unflatten(1, (2 * self.hidden_layers, self.hidden_size))\n        .permute(1, 0, 2)\n        .split(self.hidden_layers)\n    )\n    h1 = h1.contiguous()\n    h2 = h2.contiguous()\n\n    inputs_labels = (\n        self.inputs_ff(labels).unsqueeze(1).repeat(1, self.max_length, 1)\n    )\n    embedded = self.embedding(x)\n    embedded = torch.concat((embedded, inputs_labels), dim=-1)\n    _, (h1, h2) = self.lstm(embedded, (h1, h2))\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalDecoder","title":"<code>InputsAddConditionalDecoder(input_size, hidden_size, output_size, num_layers, max_length, labels_size, dropout=0, sos=0)</code>","text":"<p>               Bases: <code>Decoder</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    labels_size,\n    dropout=0,\n    sos=0,\n):\n    super().__init__(\n        input_size,\n        hidden_size,\n        output_size,\n        num_layers,\n        max_length,\n        dropout,\n        sos,\n    )\n    self.inputs_ff = nn.Sequential(\n        nn.Linear(labels_size, hidden_size),\n        nn.LeakyReLU(),\n        nn.Dropout(dropout),\n    )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalDecoder.inputs_ff","title":"<code>inputs_ff = nn.Sequential(nn.Linear(labels_size, hidden_size), nn.LeakyReLU(), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalDecoder.forward","title":"<code>forward(batch_size, hidden, labels, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, batch_size, hidden, labels, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    inputs_labels = self.inputs_ff(labels).unsqueeze(1)\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden, inputs_labels\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalDecoder.forward_step","title":"<code>forward_step(x, hidden, labels)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward_step(self, x, hidden, labels):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    embedded = embedded + labels\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalEncoder","title":"<code>InputsAddConditionalEncoder(input_size, hidden_size, hidden_layers, labels_size, max_length, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Conditional Encoder. Labels are introduced at the input by addition.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>labels_size</code> <p>size of labels.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    hidden_layers: int,\n    labels_size: int,\n    max_length: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Conditional Encoder. Labels are introduced at the input by addition.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        hidden_layers (int): number of lstm layers.\n        labels_size (int): size of labels.\n        max_length (int): max length of sequences.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(InputsAddConditionalEncoder, self).__init__()\n    self.max_length = max_length\n\n    self.inputs_ff = nn.Sequential(\n        nn.Linear(labels_size, hidden_size),\n        # nn.LeakyReLU(),\n        nn.Dropout(dropout),\n    )\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        hidden_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalEncoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalEncoder.inputs_ff","title":"<code>inputs_ff = nn.Sequential(nn.Linear(labels_size, hidden_size), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalEncoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, hidden_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalEncoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalEncoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsAddConditionalEncoder.forward","title":"<code>forward(x, labels)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, x, labels):\n    labels = (\n        self.inputs_ff(labels).unsqueeze(1).repeat(1, self.max_length, 1)\n    )\n    embedded = self.embedding(x)\n    embedded = embedded + labels\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder","title":"<code>InputsConcatConditionalDecoder(input_size, hidden_size, output_size, num_layers, max_length, labels_size, dropout=0, sos=0, conditional_hidden_size=None)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing and label injection at step input via concatenation. Args:     input_size (int): lstm input size.     hidden_size (int): lstm hidden size.     num_layers (int): number of lstm layers.     max_length (int): max length of sequences.     dropout (float): dropout probability. Defaults to 0.</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    labels_size,\n    dropout=0,\n    sos=0,\n    conditional_hidden_size: Optional[int] = None,\n):\n    \"\"\"LSTM Decoder with teacher forcing and label injection at step input via concatenation.\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super().__init__()\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    if conditional_hidden_size is None:\n        conditional_hidden_size = int(hidden_size / 2)\n    else:\n        conditional_hidden_size = conditional_hidden_size\n    encoding_size = hidden_size - conditional_hidden_size\n    if encoding_size &lt; 0:\n        raise ValueError(\n            \"conditional_hidden_size must be less than or equal to hidden_size\"\n        )\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, encoding_size, dropout=dropout\n    )\n    self.inputs_ff = nn.Sequential(\n        nn.Linear(labels_size, conditional_hidden_size),\n        # nn.LeakyReLU(),\n        nn.Dropout(dropout),\n    )\n\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, encoding_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.inputs_ff","title":"<code>inputs_ff = nn.Sequential(nn.Linear(labels_size, conditional_hidden_size), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.forward","title":"<code>forward(batch_size, hidden, labels, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, batch_size, hidden, labels, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    inputs_labels = self.inputs_ff(labels).unsqueeze(1)\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden, inputs_labels\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.forward_step","title":"<code>forward_step(x, hidden, labels)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward_step(self, x, hidden, labels):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    embedded = torch.cat((embedded, labels), dim=-1)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalDecoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    _, topi = acts.topk(1)\n    act = (\n        topi.squeeze(-1).detach().unsqueeze(-1)\n    )  # detach from history as input\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalEncoder","title":"<code>InputsConcatConditionalEncoder(input_size, hidden_size, hidden_layers, labels_size, max_length, dropout=0.1, conditional_hidden_size=None)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Conditional Encoder. Labels are introduced at the input by concatenation.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>labels_size</code> <p>size of labels.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    hidden_layers: int,\n    labels_size: int,\n    max_length: int,\n    dropout: float = 0.1,\n    conditional_hidden_size: Optional[int] = None,\n):\n    \"\"\"LSTM Conditional Encoder. Labels are introduced at the input by concatenation.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        hidden_layers (int): number of lstm layers.\n        labels_size (int): size of labels.\n        max_length (int): max length of sequences.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super().__init__()\n    self.max_length = max_length\n\n    if conditional_hidden_size is None:\n        conditional_hidden_size = int(hidden_size / 2)\n    else:\n        conditional_hidden_size = conditional_hidden_size\n    encoding_size = hidden_size - conditional_hidden_size\n    if encoding_size &lt; 0:\n        raise ValueError(\n            \"conditional_hidden_size must be less than or equal to hidden_size\"\n        )\n\n    self.inputs_ff = nn.Sequential(\n        nn.Linear(labels_size, conditional_hidden_size),\n        # nn.LeakyReLU(),\n        nn.Dropout(dropout),\n    )\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, encoding_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        hidden_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalEncoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, encoding_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalEncoder.inputs_ff","title":"<code>inputs_ff = nn.Sequential(nn.Linear(labels_size, conditional_hidden_size), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalEncoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, hidden_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalEncoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalEncoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.InputsConcatConditionalEncoder.forward","title":"<code>forward(x, labels)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, x, labels):\n    labels = (\n        self.inputs_ff(labels).unsqueeze(1).repeat(1, self.max_length, 1)\n    )\n    embedded = self.embedding(x)\n    embedded = torch.cat((embedded, labels), dim=-1)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.LabelEncoder","title":"<code>LabelEncoder(label_embed_sizes, hidden_size)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Label Encoder using token embedding. Embedding outputs are the same size but use different weights so that they can be different sizes. Each embedding is then stacked and summed to give single encoding.</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def __init__(self, label_embed_sizes, hidden_size):\n    \"\"\"Label Encoder using token embedding.\n    Embedding outputs are the same size but use different weights so that they can be different sizes.\n    Each embedding is then stacked and summed to give single encoding.\"\"\"\n    super(LabelEncoder, self).__init__()\n    self.embeds = nn.ModuleList(\n        [nn.Embedding(s, hidden_size) for s in label_embed_sizes]\n    )\n    self.fc = nn.Linear(hidden_size, hidden_size)\n    self.activation = nn.ReLU()\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.LabelEncoder.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.LabelEncoder.embeds","title":"<code>embeds = nn.ModuleList([nn.Embedding(s, hidden_size) for s in label_embed_sizes])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.LabelEncoder.fc","title":"<code>fc = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm/#caveat.models.sequence.cvae_sequence_lstm.LabelEncoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm.py</code> <pre><code>def forward(self, x):\n    x = torch.stack(\n        [embed(x[:, i]) for i, embed in enumerate(self.embeds)], dim=-1\n    ).sum(dim=-1)\n    x = self.fc(x)\n    x = self.activation(x)\n    return x\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/","title":"caveat.models.sequence.cvae_sequence_lstm_double_nudger","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.CVAESeqLSTMDoubleNudger","title":"<code>CVAESeqLSTMDoubleNudger(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer and conditionality. Normalises attributes size at decoder to match latent size. Adds latent layer to decoder instead of concatenating.</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    RNN based encoder and decoder with encoder embedding layer and conditionality.\n    Normalises attributes size at decoder to match latent size.\n    Adds latent layer to decoder instead of concatenating.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires conditionals_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.CVAESeqLSTMDoubleNudger.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n    self.encoder = Encoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n    self.label_network = LabelNetwork(\n        input_size=self.labels_size,\n        hidden_size=self.hidden_size,\n        output_size=self.latent_dim,\n    )\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_conditionals = nn.Linear(self.labels_size, flat_size_encode)\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_attributes = nn.Linear(self.labels_size, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.CVAESeqLSTMDoubleNudger.decode","title":"<code>decode(z, conditionals, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def decode(\n    self, z: Tensor, conditionals: Tensor, target=None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # encode labels\n    label_mu, label_var = self.label_network(conditionals)\n    # manipulate z using label encoding\n    z = (z / label_var) - label_mu\n    # z = z - label_mu\n\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    return log_probs  # modified z removed to simplify refactor\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.CVAESeqLSTMDoubleNudger.encode","title":"<code>encode(input, conditionals)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>list[tensor]: Latent layer input (means and variances) [N, latent_dims].</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def encode(self, input: Tensor, conditionals: Tensor) -&gt; list[Tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): Input sequence batch [N, steps, acts].\n\n    Returns:\n        list[tensor]: Latent layer input (means and variances) [N, latent_dims].\n    \"\"\"\n    # encode labels\n    label_mu, label_var = self.label_network(conditionals)\n\n    hidden = self.encoder(input)\n    conditionals = self.fc_conditionals(conditionals)\n    hidden = hidden + conditionals\n\n    # Split the result into mu and var components\n    mu = self.fc_mu(hidden) + label_mu\n    log_var = self.fc_var(hidden) * label_var\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.CVAESeqLSTMDoubleNudger.forward","title":"<code>forward(x, conditionals=None, target=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>List[Tensor]</code> <p>list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    conditionals: Optional[Tensor] = None,\n    target=None,\n    **kwargs,\n) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n\n    Returns:\n        list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].\n    \"\"\"\n    mu, log_var = self.encode(x, conditionals)\n    z = self.reparameterize(mu, log_var)\n    log_prob_y = self.decode(z, conditionals=conditionals, target=target)\n    return [log_prob_y, mu, log_var, z]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.CVAESeqLSTMDoubleNudger.predict","title":"<code>predict(z, conditionals, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def predict(\n    self, z: Tensor, conditionals: Tensor, device: int, **kwargs\n) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(device)\n    conditionals = conditionals.to(device)\n    prob_samples = exp(\n        self.decode(z=z, conditionals=conditionals, **kwargs)\n    )\n    return prob_samples\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0, top_sampler=True)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n    top_sampler: bool = True,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n    if top_sampler:\n        print(\"Decoder using topk sampling\")\n        self.sample = self.topk\n    else:\n        print(\"Decoder using multinomial sampling\")\n        self.sample = self.multinomial\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.sample","title":"<code>sample = self.topk</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.forward","title":"<code>forward(batch_size, hidden, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def forward(self, batch_size, hidden, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def forward_step(self, x, hidden):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.multinomial","title":"<code>multinomial(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def multinomial(self, x):\n    # [N, 1, encodings]\n    acts = torch.multinomial(self.activity_prob_activation(x.squeeze()), 1)\n    # DETACH?\n    return acts\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    act = self.sample(acts)\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Decoder.topk","title":"<code>topk(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def topk(self, x):\n    _, topi = x.topk(1)\n    act = topi.detach()  # detach from history as input\n    # DETACH?\n    return act\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Encoder","title":"<code>Encoder(input_size, hidden_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.fc_hidden = nn.Linear(hidden_size, hidden_size)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Encoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Encoder.fc_hidden","title":"<code>fc_hidden = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Encoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Encoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Encoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Encoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def forward(self, x):\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.LabelNetwork","title":"<code>LabelNetwork(input_size, hidden_size, output_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def __init__(self, input_size, hidden_size, output_size):\n    super(LabelNetwork, self).__init__()\n    self.fc = nn.Linear(input_size, hidden_size)\n    self.activation = nn.ReLU()\n    self.fc_mu = nn.Linear(hidden_size, output_size)\n    self.fc_var = nn.Linear(hidden_size, output_size)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.LabelNetwork.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.LabelNetwork.fc","title":"<code>fc = nn.Linear(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.LabelNetwork.fc_mu","title":"<code>fc_mu = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.LabelNetwork.fc_var","title":"<code>fc_var = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_double_nudger/#caveat.models.sequence.cvae_sequence_lstm_double_nudger.LabelNetwork.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_double_nudger.py</code> <pre><code>def forward(self, x):\n    x = self.fc(x)\n    x = self.activation(x)\n    mu = self.fc_mu(x)\n    log_var = self.fc_var(x)\n    return mu, log_var\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/","title":"caveat.models.sequence.cvae_sequence_lstm_nudge_feed","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.CVAESeqLSTMNudgeFeed","title":"<code>CVAESeqLSTMNudgeFeed(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer and conditionality. Normalises attributes size at decoder to match latent size. Adds latent layer to decoder instead of concatenating.</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    RNN based encoder and decoder with encoder embedding layer and conditionality.\n    Normalises attributes size at decoder to match latent size.\n    Adds latent layer to decoder instead of concatenating.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires conditionals_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.CVAESeqLSTMNudgeFeed.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n    self.label_network = LabelNetwork(\n        input_size=self.labels_size,\n        hidden_size=self.hidden_size,\n        output_size=self.latent_dim,\n    )\n    self.encoder = Encoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_conditionals = nn.Linear(self.labels_size, flat_size_encode)\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n    self.fc_x = nn.Linear(self.labels_size, self.hidden_size)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.CVAESeqLSTMNudgeFeed.decode","title":"<code>decode(z, conditionals, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def decode(\n    self, z: Tensor, conditionals: Tensor, target=None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # un-nudge z using label encoding\n    mu_nudge, var_nudge = self.nudge(conditionals)\n    std_nudge = torch.exp(0.5 * var_nudge)\n    z = (z - mu_nudge) / std_nudge\n\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n    # initialize step inputs\n    x = self.fc_x(conditionals).unsqueeze(-2)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n\n    log_probs = self.decoder(hidden=hidden, x=x, target=None)\n\n    # TODO: add forcing back?\n    # if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n    #     # use teacher forcing\n    #     log_probs, probs = self.decoder(\n    #         batch_size=batch_size, hidden=hidden, target=target\n    #     )\n    # else:\n    #     log_probs, probs = self.decoder(\n    #         batch_size=batch_size, hidden=hidden, target=None\n    #     )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.CVAESeqLSTMNudgeFeed.encode","title":"<code>encode(input, conditionals)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>list[tensor]: Latent layer input (means and variances) [N, latent_dims].</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def encode(self, input: Tensor, conditionals: Tensor) -&gt; list[Tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): Input sequence batch [N, steps, acts].\n\n    Returns:\n        list[tensor]: Latent layer input (means and variances) [N, latent_dims].\n    \"\"\"\n    # encode labels for hidden state\n    h1, h2 = (\n        self.fc_conditionals(conditionals)\n        .unflatten(1, (2 * self.hidden_n, self.hidden_size))\n        .permute(1, 0, 2)\n        .split(self.hidden_n)  # ([hidden, N, layers, [hidden, N, layers]])\n    )\n    h1 = h1.contiguous()\n    h2 = h2.contiguous()\n    # [N, L, C]\n    hidden = self.encoder(input, (h1, h2))\n    # [N, flatsize]\n\n    mu = self.fc_mu(hidden)\n    log_var = self.fc_var(hidden)\n\n    # nudge z using label encoding\n    mu_nudge, var_nudge = self.nudge(conditionals)\n    mu = mu + mu_nudge\n    log_var = log_var + var_nudge\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.CVAESeqLSTMNudgeFeed.forward","title":"<code>forward(x, conditionals=None, target=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>List[Tensor]</code> <p>list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def forward(\n    self,\n    x: Tensor,\n    conditionals: Optional[Tensor] = None,\n    target=None,\n    **kwargs,\n) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n\n    Returns:\n        list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].\n    \"\"\"\n    mu, log_var = self.encode(x, conditionals)\n\n    z = self.reparameterize(mu, log_var)\n\n    log_prob_y = self.decode(z, conditionals=conditionals, target=target)\n    return [log_prob_y, mu, log_var, z]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.CVAESeqLSTMNudgeFeed.nudge","title":"<code>nudge(conditionals=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def nudge(\n    self, conditionals: Optional[Tensor] = None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    # encode labels\n    return self.label_network(conditionals)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.CVAESeqLSTMNudgeFeedPre","title":"<code>CVAESeqLSTMNudgeFeedPre(*args, **kwargs)</code>","text":"<p>               Bases: <code>CVAESeqLSTMNudgeFeed</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    RNN based encoder and decoder with encoder embedding layer and conditionality.\n    Normalises attributes size at decoder to match latent size.\n    Adds latent layer to decoder instead of concatenating.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires conditionals_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.CVAESeqLSTMNudgeFeedPre.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_layers = config[\"hidden_layers\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n    self.encoder = ConditionalEncoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_layers,\n        conditionals_size=self.labels_size,\n        max_length=length,\n        dropout=self.dropout,\n    )\n    self.label_network = LabelNetwork(\n        input_size=self.labels_size,\n        hidden_size=self.hidden_size,\n        output_size=self.latent_dim,\n    )\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_layers,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n    self.unflattened_shape = (2 * self.hidden_layers, self.hidden_size)\n    flat_size_encode = self.hidden_layers * self.hidden_size * 2\n    self.fc_conditionals = nn.Linear(self.labels_size, flat_size_encode)\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n    self.fc_x = nn.Linear(self.labels_size, self.hidden_size)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.CVAESeqLSTMNudgeFeedPre.encode","title":"<code>encode(input, conditionals)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def encode(\n    self, input: Tensor, conditionals: Optional[Tensor]\n) -&gt; list[Tensor]:\n    h1, h2 = (\n        self.fc_conditionals(conditionals)\n        .unflatten(1, (2 * self.hidden_layers, self.hidden_size))\n        .permute(1, 0, 2)\n        .split(self.hidden_layers)\n    )\n    h1 = h1.contiguous()\n    h2 = h2.contiguous()\n    hidden = self.encoder(input, (h1, h2), conditionals)\n    mu = self.fc_mu(hidden)\n    log_var = self.fc_var(hidden)\n\n    # nudge z using label encoding\n    mu_nudge, var_nudge = self.nudge(conditionals)\n    mu = mu + mu_nudge\n    log_var = log_var + var_nudge\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.CVAESeqLSTMNudgeFeedPre.predict","title":"<code>predict(z, conditionals, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def predict(\n    self, z: Tensor, conditionals: Tensor, device: int, **kwargs\n) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(device)\n    conditionals = conditionals.to(device)\n    prob_samples = exp(\n        self.decode(z=z, conditionals=conditionals, **kwargs)\n    )\n    return prob_samples\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder","title":"<code>ConditionalEncoder(input_size, hidden_size, num_layers, conditionals_size, max_length, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    num_layers: int,\n    conditionals_size: int,\n    max_length: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(ConditionalEncoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.max_length = max_length\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.fc_hidden = nn.Linear(hidden_size, hidden_size)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n    self.fc = nn.Linear(conditionals_size, hidden_size)\n    self.nl = nn.LeakyReLU()\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.fc","title":"<code>fc = nn.Linear(conditionals_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.fc_hidden","title":"<code>fc_hidden = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.nl","title":"<code>nl = nn.LeakyReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.ConditionalEncoder.forward","title":"<code>forward(x, hidden, conditionals)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def forward(self, x, hidden, conditionals):\n    conditionals = (\n        self.nl(self.fc(conditionals))\n        .unsqueeze(1)\n        .repeat(1, self.max_length, 1)\n    )\n    embedded = self.embedding(x)\n    embedded = embedded + conditionals\n    _, (h1, h2) = self.lstm(embedded, hidden)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0, top_sampler=True)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n    top_sampler: bool = True,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.forward","title":"<code>forward(hidden, x, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def forward(self, hidden, x, **kwargs):\n    hidden, cell = hidden\n    # decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    # decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for _ in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            x, decoder_hidden\n        )\n        outputs.append(decoder_output.squeeze())\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def forward_step(self, x, hidden):\n    # [N, 1, 2]\n    # embedded = self.embedding(x)\n    output, hidden = self.lstm(x, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Encoder","title":"<code>Encoder(input_size, hidden_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.fc_hidden = nn.Linear(hidden_size, hidden_size)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Encoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Encoder.fc_hidden","title":"<code>fc_hidden = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Encoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Encoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Encoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Encoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.Encoder.forward","title":"<code>forward(x, hidden)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def forward(self, x, hidden):\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded, hidden)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.LabelNetwork","title":"<code>LabelNetwork(input_size, hidden_size, output_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def __init__(self, input_size, hidden_size, output_size):\n    super(LabelNetwork, self).__init__()\n    self.fc = nn.Linear(input_size, hidden_size)\n    self.activation = nn.ReLU()\n    self.fc_mu = nn.Linear(hidden_size, output_size)\n    self.fc_var = nn.Linear(hidden_size, output_size)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.LabelNetwork.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.LabelNetwork.fc","title":"<code>fc = nn.Linear(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.LabelNetwork.fc_mu","title":"<code>fc_mu = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.LabelNetwork.fc_var","title":"<code>fc_var = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudge_feed/#caveat.models.sequence.cvae_sequence_lstm_nudge_feed.LabelNetwork.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudge_feed.py</code> <pre><code>def forward(self, x):\n    x = self.fc(x)\n    x = self.activation(x)\n    mu = self.fc_mu(x)\n    log_var = self.fc_var(x)\n    return mu, log_var\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/","title":"caveat.models.sequence.cvae_sequence_lstm_nudger","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.CVAESeqLSTMNudger","title":"<code>CVAESeqLSTMNudger(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer and conditionality. Normalises attributes size at decoder to match latent size. Adds latent layer to decoder instead of concatenating.</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    RNN based encoder and decoder with encoder embedding layer and conditionality.\n    Normalises attributes size at decoder to match latent size.\n    Adds latent layer to decoder instead of concatenating.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires labels_size, please check you have configures a compatible encoder and condition attributes\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.CVAESeqLSTMNudger.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n    self.encoder = Encoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n    self.label_network = LabelNetwork(\n        input_size=self.labels_size,\n        hidden_size=self.hidden_size,\n        output_size=self.latent_dim,\n    )\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_labels = nn.Linear(self.labels_size, flat_size_encode)\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_attributes = nn.Linear(self.labels_size, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.CVAESeqLSTMNudger.decode","title":"<code>decode(z, labels, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def decode(\n    self, z: Tensor, labels: Tensor, target=None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # encode labels\n    label_mu, label_var = self.label_network(labels)\n    # manipulate z using label encoding\n    z = (z * label_var) + label_mu\n\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    return log_probs  # modified z removed fro refactor\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.CVAESeqLSTMNudger.encode","title":"<code>encode(input, labels)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>list[tensor]: Latent layer input (means and variances) [N, latent_dims].</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def encode(self, input: Tensor, labels: Tensor) -&gt; list[Tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): Input sequence batch [N, steps, acts].\n\n    Returns:\n        list[tensor]: Latent layer input (means and variances) [N, latent_dims].\n    \"\"\"\n    hidden = self.encoder(input)\n    labels = self.fc_labels(labels)\n    hidden = hidden + labels\n\n    # Split the result into mu and var components\n    mu = self.fc_mu(hidden)\n    log_var = self.fc_var(hidden)\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.CVAESeqLSTMNudger.forward","title":"<code>forward(x, labels=None, target=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>List[Tensor]</code> <p>list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def forward(\n    self, x: Tensor, labels: Optional[Tensor] = None, target=None, **kwargs\n) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n\n    Returns:\n        list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].\n    \"\"\"\n    mu, log_var = self.encode(x, labels)\n    z = self.reparameterize(mu, log_var)\n    log_prob_y = self.decode(z, labels=labels, target=target)\n    return [log_prob_y, mu, log_var, z]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.CVAESeqLSTMNudger.predict","title":"<code>predict(z, labels, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def predict(\n    self, z: Tensor, labels: Tensor, device: int, **kwargs\n) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(device)\n    labels = labels.to(device)\n    prob_samples = exp(self.decode(z=z, labels=labels, **kwargs))\n    return prob_samples\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0, top_sampler=True)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n    top_sampler: bool = True,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n    if top_sampler:\n        print(\"Decoder using topk sampling\")\n        self.sample = self.topk\n    else:\n        print(\"Decoder using multinomial sampling\")\n        self.sample = self.multinomial\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.sample","title":"<code>sample = self.topk</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.forward","title":"<code>forward(batch_size, hidden, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def forward(self, batch_size, hidden, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def forward_step(self, x, hidden):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.multinomial","title":"<code>multinomial(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def multinomial(self, x):\n    # [N, 1, encodings]\n    acts = torch.multinomial(self.activity_prob_activation(x.squeeze()), 1)\n    # DETACH?\n    return acts\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    act = self.sample(acts)\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Decoder.topk","title":"<code>topk(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def topk(self, x):\n    _, topi = x.topk(1)\n    act = topi.detach()  # detach from history as input\n    # DETACH?\n    return act\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Encoder","title":"<code>Encoder(input_size, hidden_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.fc_hidden = nn.Linear(hidden_size, hidden_size)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Encoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Encoder.fc_hidden","title":"<code>fc_hidden = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Encoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Encoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Encoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Encoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def forward(self, x):\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.LabelNetwork","title":"<code>LabelNetwork(input_size, hidden_size, output_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def __init__(self, input_size, hidden_size, output_size):\n    super(LabelNetwork, self).__init__()\n    self.fc = nn.Linear(input_size, hidden_size)\n    self.activation = nn.ReLU()\n    self.fc_mu = nn.Linear(hidden_size, output_size)\n    self.fc_var = nn.Linear(hidden_size, output_size)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.LabelNetwork.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.LabelNetwork.fc","title":"<code>fc = nn.Linear(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.LabelNetwork.fc_mu","title":"<code>fc_mu = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.LabelNetwork.fc_var","title":"<code>fc_var = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger/#caveat.models.sequence.cvae_sequence_lstm_nudger.LabelNetwork.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger.py</code> <pre><code>def forward(self, x):\n    x = self.fc(x)\n    x = self.activation(x)\n    mu = self.fc_mu(x)\n    log_var = self.fc_var(x)\n    return mu, log_var\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/","title":"caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudger","title":"<code>CVAESeqLSTMNudger(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer and conditionality. Normalises attributes size at decoder to match latent size. Adds latent layer to decoder instead of concatenating.</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"\n    RNN based encoder and decoder with encoder embedding layer and conditionality.\n    Normalises attributes size at decoder to match latent size.\n    Adds latent layer to decoder instead of concatenating.\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    if self.labels_size is None:\n        raise UserWarning(\n            \"ConditionalLSTM requires labels_size, please check you have configures a compatible encoder and labels\"\n        )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudger.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n    self.encoder = Encoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n    self.label_network = LabelNetwork(\n        input_size=self.labels_size,\n        hidden_size=self.hidden_size,\n        output_size=self.latent_dim,\n    )\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_labels = nn.Linear(self.labels_size, flat_size_encode)\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_attributes = nn.Linear(self.labels_size, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudger.decode","title":"<code>decode(z, labels, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def decode(\n    self, z: Tensor, labels: Tensor, target=None, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # encode labels\n    label_mu, label_var = self.label_network(labels)\n    # manipulate z using label encoding\n    z = (z * label_var) + label_mu\n\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudger.encode","title":"<code>encode(input, labels)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>list[tensor]: Latent layer input (means and variances) [N, latent_dims].</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def encode(self, input: Tensor, labels: Tensor) -&gt; list[Tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): Input sequence batch [N, steps, acts].\n\n    Returns:\n        list[tensor]: Latent layer input (means and variances) [N, latent_dims].\n    \"\"\"\n    hidden = self.encoder(input)\n    labels = self.fc_labels(labels)\n    hidden = hidden + labels\n\n    # Split the result into mu and var components\n    mu = self.fc_mu(hidden)\n    log_var = self.fc_var(hidden)\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudger.forward","title":"<code>forward(x, labels=None, target=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>List[Tensor]</code> <p>list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def forward(\n    self, x: Tensor, labels: Optional[Tensor] = None, target=None, **kwargs\n) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n\n    Returns:\n        list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].\n    \"\"\"\n    mu, log_var = self.encode(x, labels)\n    z = self.reparameterize(mu, log_var)\n    log_prob_y = self.decode(z, labels=labels, target=target)\n    return [log_prob_y, mu, log_var, z]\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudger.predict","title":"<code>predict(z, labels, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def predict(\n    self, z: Tensor, labels: Tensor, device: int, **kwargs\n) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(device)\n    labels = labels.to(device)\n    prob_samples = exp(self.decode(z=z, labels=labels, **kwargs))\n    return prob_samples\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial","title":"<code>CVAESeqLSTMNudgerAdversarial(in_shape, encodings, encoding_weights=None, labels_size=None, sos=0, **kwargs)</code>","text":"<p>               Bases: <code>LightningModule</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def __init__(\n    self,\n    in_shape: tuple,\n    encodings: int,\n    encoding_weights: Optional[Tensor] = None,\n    labels_size: Optional[tuple] = None,\n    sos: int = 0,\n    **kwargs,\n):\n    super().__init__()\n    self.save_hyperparameters()\n    self.automatic_optimization = False\n    latent_dim = kwargs.get(\"latent_dim\", 6)\n    hidden_size = kwargs.get(\"hidden_size\", 256)\n    self.LR = kwargs.get(\"LR\", 0.001)\n    self.weight_decay = kwargs.get(\"weight_decay\", 0.0)\n    self.kld_weight = kwargs.get(\"kld_weight\", 0.0001)\n    self.duration_weight = kwargs.get(\"duration_weight\", 1.0)\n    self.adv_weight = kwargs.get(\"adv_weight\", 1.0)\n    print(f\"KLD weight: {self.kld_weight}\")\n    print(f\"duration weight: {self.duration_weight}\")\n    print(f\"adversarial weight: {self.adv_weight}\")\n\n    self.generator = CVAESeqLSTMNudger(\n        in_shape, encodings, encoding_weights, labels_size, sos, **kwargs\n    )\n    self.discriminator = Discriminator(\n        latent_dim=latent_dim,\n        hidden_size=hidden_size,\n        output_size=labels_size,\n    )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.LR","title":"<code>LR = kwargs.get('LR', 0.001)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.adv_weight","title":"<code>adv_weight = kwargs.get('adv_weight', 1.0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.automatic_optimization","title":"<code>automatic_optimization = False</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.discriminator","title":"<code>discriminator = Discriminator(latent_dim=latent_dim, hidden_size=hidden_size, output_size=labels_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.duration_weight","title":"<code>duration_weight = kwargs.get('duration_weight', 1.0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.generator","title":"<code>generator = CVAESeqLSTMNudger(in_shape, encodings, encoding_weights, labels_size, sos, **kwargs)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.kld_weight","title":"<code>kld_weight = kwargs.get('kld_weight', 0.0001)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.weight_decay","title":"<code>weight_decay = kwargs.get('weight_decay', 0.0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.adversarial_loss","title":"<code>adversarial_loss(y_hat, y)</code>","text":"<p>Adversarial loss for nudging the latent space.</p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def adversarial_loss(self, y_hat: Tensor, y: Tensor) -&gt; Tensor:\n    \"\"\"Adversarial loss for nudging the latent space.\"\"\"\n    return nn.functional.mse_loss(y_hat, y)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def configure_optimizers(self):\n    opt_g = torch.optim.Adam(\n        self.generator.parameters(), self.LR, weight_decay=self.weight_decay\n    )\n    opt_d = torch.optim.Adam(\n        self.discriminator.parameters(),\n        self.LR,\n        weight_decay=self.weight_decay,\n    )\n    return [opt_g, opt_d], []\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.predict_step","title":"<code>predict_step(batch)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def predict_step(self, batch):\n    return self.generator.predict_step(batch)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def training_step(self, batch, batch_idx):\n    (x, _), (y, y_mask), (labels, _) = batch\n    optimizer_g, optimizer_d = self.optimizers()\n\n    self.curr_device = x.device\n\n    # train generator\n    self.toggle_optimizer(optimizer_g)\n    log_probs, mu, log_var, z = self.generator.forward(\n        x, labels=labels, target=y\n    )\n    losses = self.generator.loss_function(\n        log_probs=log_probs,\n        mu=mu,\n        log_var=log_var,\n        target=y,\n        weights=y_mask,\n        kld_weight=self.kld_weight,\n        duration_weight=self.duration_weight,\n        batch_idx=batch_idx,\n    )\n\n    # generator loss\n    labels_hat = self.discriminator(z)\n\n    adversarial_loss = self.adversarial_loss(labels_hat, labels).detach()\n    losses[\"adversarial_loss\"] = adversarial_loss\n    losses[\"adversarial_weight\"] = torch.Tensor([self.adv_weight]).float()\n    weighted_adversarial_loss = adversarial_loss * self.adv_weight\n    losses[\"adversarial_loss_weighted\"] = weighted_adversarial_loss\n    losses[\"loss\"] /= weighted_adversarial_loss\n\n    self.manual_backward(losses[\"loss\"])\n    optimizer_g.step()\n    optimizer_g.zero_grad()\n    self.untoggle_optimizer(optimizer_g)\n\n    # train discriminator\n    self.toggle_optimizer(optimizer_d)\n    labels_hat = self.discriminator(z.detach())\n    d_loss = self.adversarial_loss(labels_hat, labels)\n    losses[\"discriminator_loss\"] = d_loss\n\n    self.manual_backward(d_loss)\n    optimizer_d.step()\n    optimizer_d.zero_grad()\n    self.untoggle_optimizer(optimizer_d)\n\n    self.log_dict(\n        {key: val.item() for key, val in losses.items()}, sync_dist=True\n    )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.CVAESeqLSTMNudgerAdversarial.validation_step","title":"<code>validation_step(batch, batch_idx, optimizer_idx=0)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def validation_step(self, batch, batch_idx, optimizer_idx=0):\n    (x, _), (y, y_mask), (labels, _) = batch\n    self.curr_device = x.device\n\n    log_probs, mu, log_var, z = self.generator.forward(x, labels=labels)\n    val_loss = self.generator.loss_function(\n        log_probs=log_probs,\n        mu=mu,\n        log_var=log_var,\n        target=y,\n        weights=y_mask,\n        kld_weight=self.kld_weight,\n        duration_weight=self.duration_weight,\n        optimizer_idx=optimizer_idx,\n        batch_idx=batch_idx,\n    )\n\n    self.log_dict(\n        {f\"val_{key}\": val.item() for key, val in val_loss.items()},\n        sync_dist=True,\n        on_step=False,\n        on_epoch=True,\n        prog_bar=True,\n    )\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0, top_sampler=True)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n    top_sampler: bool = True,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n    if top_sampler:\n        print(\"Decoder using topk sampling\")\n        self.sample = self.topk\n    else:\n        print(\"Decoder using multinomial sampling\")\n        self.sample = self.multinomial\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.sample","title":"<code>sample = self.topk</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.forward","title":"<code>forward(batch_size, hidden, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def forward(self, batch_size, hidden, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = torch.log(self.duration_activation(durations))\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def forward_step(self, x, hidden):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.multinomial","title":"<code>multinomial(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def multinomial(self, x):\n    # [N, 1, encodings]\n    acts = torch.multinomial(self.activity_prob_activation(x.squeeze()), 1)\n    # DETACH?\n    return acts\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    act = self.sample(acts)\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Decoder.topk","title":"<code>topk(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def topk(self, x):\n    _, topi = x.topk(1)\n    act = topi.detach()  # detach from history as input\n    # DETACH?\n    return act\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Discriminator","title":"<code>Discriminator(latent_dim, hidden_size, output_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def __init__(self, latent_dim: int, hidden_size: int, output_size: int):\n    super().__init__()\n    self.block = nn.Sequential(\n        nn.Linear(latent_dim, hidden_size),\n        nn.LeakyReLU(),\n        nn.Linear(hidden_size, hidden_size),\n        nn.LeakyReLU(),\n        nn.Linear(hidden_size, output_size),\n    )\n    self.activation = nn.Softmax(dim=-1)  # TODO!!\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Discriminator.activation","title":"<code>activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Discriminator.block","title":"<code>block = nn.Sequential(nn.Linear(latent_dim, hidden_size), nn.LeakyReLU(), nn.Linear(hidden_size, hidden_size), nn.LeakyReLU(), nn.Linear(hidden_size, output_size))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Discriminator.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def forward(self, x):\n    x = self.block(x)\n    x = self.activation(x)\n    return x\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Encoder","title":"<code>Encoder(input_size, hidden_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.fc_hidden = nn.Linear(hidden_size, hidden_size)\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Encoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Encoder.fc_hidden","title":"<code>fc_hidden = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Encoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Encoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Encoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Encoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def forward(self, x):\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.LabelNetwork","title":"<code>LabelNetwork(input_size, hidden_size, output_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def __init__(self, input_size, hidden_size, output_size):\n    super(LabelNetwork, self).__init__()\n    self.fc = nn.Linear(input_size, hidden_size)\n    self.activation = nn.ReLU()\n    self.fc_mu = nn.Linear(hidden_size, output_size)\n    self.fc_var = nn.Linear(hidden_size, output_size)\n</code></pre>"},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.LabelNetwork.activation","title":"<code>activation = nn.ReLU()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.LabelNetwork.fc","title":"<code>fc = nn.Linear(input_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.LabelNetwork.fc_mu","title":"<code>fc_mu = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.LabelNetwork.fc_var","title":"<code>fc_var = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial/#caveat.models.sequence.cvae_sequence_lstm_nudger_adversarial.LabelNetwork.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/cvae_sequence_lstm_nudger_adversarial.py</code> <pre><code>def forward(self, x):\n    x = self.fc(x)\n    x = self.activation(x)\n    mu = self.fc_mu(x)\n    log_var = self.fc_var(x)\n    return mu, log_var\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/","title":"caveat.models.sequence.vae_sequence_attention","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder","title":"<code>AttentionDecoder(input_size, output_size, hidden_size, ffwd_size, num_heads, num_layers, length, dropout=0.0, embedding='concat', position_embedding='learnt', time_embedding='none', latent_context='xattention', sos=0)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    output_size,\n    hidden_size,\n    ffwd_size,\n    num_heads,\n    num_layers,\n    length,\n    dropout: float = 0.0,\n    embedding: str = \"concat\",\n    position_embedding: str = \"learnt\",\n    time_embedding: str = \"none\",\n    latent_context: str = \"xattention\",\n    sos: int = 0,\n) -&gt; None:\n    super().__init__()\n    self.output_size = output_size\n    self.max_length = length\n    self.sos = sos\n\n    if embedding.lower() == \"concat\":\n        self.embedding = CustomDurationEmbeddingConcat(\n            input_size, hidden_size, dropout=dropout\n        )\n    elif embedding.lower() == \"add\":\n        self.embedding = CustomDurationEmbeddingAddNorm(\n            input_size, hidden_size, dropout=dropout\n        )\n    else:\n        raise ValueError(\n            f\"Embedding must be either 'concat' or 'add', got {embedding}\"\n        )\n\n    if position_embedding.lower() == \"none\":\n        self.position_embedding = None\n    elif position_embedding.lower() == \"learnt\":\n        self.position_embedding = LearntPositionalEncoding(\n            d_model=hidden_size, dropout=dropout, length=length\n        )\n    elif position_embedding.lower() == \"fixed\":\n        self.position_embedding = FixedPositionalEncoding(\n            d_model=hidden_size, dropout=dropout, length=length\n        )\n    else:\n        raise ValueError(\n            f\"Positional embedding must be either 'none', 'learnt' or 'fixed', got {position_embedding}\"\n        )\n\n    if time_embedding.lower() == \"none\":\n        self.time_embedding = None\n    elif time_embedding.lower() == \"start\":\n        self.time_embedding = StartTimePositionEncoding(dropout=0.0)\n    elif time_embedding.lower() == \"remaining\":\n        self.time_embedding = RemainingTimePositionEncoding(dropout=0.0)\n    else:\n        raise ValueError(\n            f\"Time embedding must be either 'none', 'start' or 'remaining', got {time_embedding}\"\n        )\n\n    if (\n        latent_context.lower() == \"xattention\"\n        or latent_context.lower() == \"xatt\"\n        or latent_context.lower() == \"cross_attention\"\n        or latent_context.lower() == \"cross_att\"\n    ):\n        print(\"Using cross attention for latent context\")\n        self.blocks = nn.ModuleList(\n            [\n                DecoderBlockXAttention(\n                    hidden_size,\n                    n_head=num_heads,\n                    dropout=dropout,\n                    block_size=length,\n                    ffwd_size=ffwd_size,\n                )\n                for _ in range(num_layers)\n            ]\n        )\n    elif latent_context.lower() == \"add\":\n        print(\"Using addition for latent context\")\n        self.blocks = nn.ModuleList(\n            [\n                DecoderBlockAddAttention(\n                    hidden_size,\n                    n_head=num_heads,\n                    dropout=dropout,\n                    block_size=length,\n                    ffwd_size=ffwd_size,\n                )\n                for _ in range(num_layers)\n            ]\n        )\n    else:\n        raise ValueError(\n            f\"Latent context must be either 'xattention' or 'addattention', got {latent_context}\"\n        )\n\n    self.lm_head = nn.Linear(hidden_size, output_size)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n    self.apply(self._init_weights)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.blocks","title":"<code>blocks = nn.ModuleList([DecoderBlockXAttention(hidden_size, n_head=num_heads, dropout=dropout, block_size=length, ffwd_size=ffwd_size) for _ in range(num_layers)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.lm_head","title":"<code>lm_head = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.max_length","title":"<code>max_length = length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.position_embedding","title":"<code>position_embedding = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.time_embedding","title":"<code>time_embedding = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionDecoder.forward","title":"<code>forward(hidden, target, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, hidden, target, mask=None):\n    # idx and targets are both (B,T) tensor of integers\n    outputs = self.embedding(target)  # (B,T,C)\n    if self.position_embedding is not None:\n        outputs = self.position_embedding(outputs)  # (B,T,C)\n    if self.time_embedding is not None:\n        outputs = self.time_embedding(outputs)\n    for layer in self.blocks:\n        outputs = layer(hidden, outputs, mask)\n    outputs = self.lm_head(outputs)\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = self.duration_activation(durations)\n    durations = torch.log(durations)\n\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionEncoder","title":"<code>AttentionEncoder(input_size, hidden_size, ffwd_size, length, n_head, n_layer, dropout=0.0, embedding='concat', position_embedding='learnt', time_embedding='none')</code>","text":"<p>               Bases: <code>Module</code></p> <p>Encoder with self-attention layers.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>Number of input features.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>Number of hidden units.</p> <p> TYPE: <code>int</code> </p> <code>ffwd_size</code> <p>Number of hidden units in the feedforward layer.</p> <p> TYPE: <code>int</code> </p> <code>length</code> <p>Length of the sequence.</p> <p> TYPE: <code>int</code> </p> <code>n_head</code> <p>Number of heads in the multi-head attention.</p> <p> TYPE: <code>int</code> </p> <code>n_layer</code> <p>Number of layers in the encoder.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>Dropout rate. Defaults to 0.0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> <code>embedding</code> <p>Type of embedding. Defaults to \"concat\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'concat'</code> </p> <code>position_embedding</code> <p>Type of positional embedding. Defaults to \"learnt\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'learnt'</code> </p> <code>time_embedding</code> <p>Type of time embedding. Defaults to \"none\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'none'</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    ffwd_size,\n    length,\n    n_head,\n    n_layer,\n    dropout: float = 0.0,\n    embedding: str = \"concat\",\n    position_embedding: str = \"learnt\",\n    time_embedding: str = \"none\",\n):\n    \"\"\"Encoder with self-attention layers.\n\n    Args:\n        input_size (int): Number of input features.\n        hidden_size (int): Number of hidden units.\n        ffwd_size (int): Number of hidden units in the feedforward layer.\n        length (int): Length of the sequence.\n        n_head (int): Number of heads in the multi-head attention.\n        n_layer (int): Number of layers in the encoder.\n        dropout (float, optional): Dropout rate. Defaults to 0.0.\n        embedding (str, optional): Type of embedding. Defaults to \"concat\".\n        position_embedding (str, optional): Type of positional embedding. Defaults to \"learnt\".\n        time_embedding (str, optional): Type of time embedding. Defaults to \"none\".\n    \"\"\"\n    super(AttentionEncoder, self).__init__()\n\n    self.hidden_size = hidden_size\n    self.num_layers = n_layer\n\n    if embedding.lower() == \"concat\":\n        self.embedding = CustomDurationEmbeddingConcat(\n            input_size, hidden_size, dropout=dropout\n        )\n    elif embedding.lower() == \"add\":\n        self.embedding = CustomDurationEmbeddingAddNorm(\n            input_size, hidden_size, dropout=dropout\n        )\n    else:\n        raise ValueError(\n            f\"Embedding must be either 'concat' or 'add', got {embedding}\"\n        )\n\n    if position_embedding.lower() == \"none\":\n        self.position_embedding = None\n    elif position_embedding.lower() == \"learnt\":\n        self.position_embedding = LearntPositionalEncoding(\n            d_model=hidden_size, dropout=0.0, length=length\n        )\n    elif position_embedding.lower() == \"fixed\":\n        self.position_embedding = FixedPositionalEncoding(\n            d_model=hidden_size, dropout=0.0, length=length\n        )\n    else:\n        raise ValueError(\n            f\"Positional embedding must be either 'none', 'learnt' or 'fixed', got {position_embedding}\"\n        )\n\n    if time_embedding.lower() == \"none\":\n        self.time_embedding = None\n    elif time_embedding.lower() == \"start\":\n        self.time_embedding = StartTimePositionEncoding(dropout=0.0)\n    elif time_embedding.lower() == \"remaining\":\n        self.time_embedding = RemainingTimePositionEncoding(dropout=0.0)\n    else:\n        raise ValueError(\n            f\"Time embedding must be either 'none', 'start' or 'remaining', got {time_embedding}\"\n        )\n\n    self.blocks = nn.ModuleList(\n        [\n            EncoderBlock(\n                hidden_size,\n                n_head=n_head,\n                dropout=dropout,\n                ffwd_size=ffwd_size,\n            )\n            for _ in range(n_layer)\n        ]\n    )\n    # better init?\n    self.apply(self._init_weights)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionEncoder.blocks","title":"<code>blocks = nn.ModuleList([EncoderBlock(hidden_size, n_head=n_head, dropout=dropout, ffwd_size=ffwd_size) for _ in range(n_layer)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionEncoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionEncoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionEncoder.num_layers","title":"<code>num_layers = n_layer</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionEncoder.position_embedding","title":"<code>position_embedding = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionEncoder.time_embedding","title":"<code>time_embedding = None</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionEncoder.forward","title":"<code>forward(x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x, mask=None):\n    # idx and targets are both (B,T) tensor of integers\n    x = self.embedding(x)  # (B,T,C)\n    if self.position_embedding is not None:\n        x = self.position_embedding(x)  # (B,T,C)\n    if self.time_embedding is not None:\n        x = self.time_embedding(x)\n    for block in self.blocks:\n        x = block(x, mask=mask)  # (B,T,C)\n    x = x.flatten(1)\n\n    return x\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionHead","title":"<code>AttentionHead(head_size, n_embd=10, block_size=128, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>one head of self-attention</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, head_size, n_embd=10, block_size=128, dropout=0.0):\n    super().__init__()\n    self.key = nn.Linear(n_embd, head_size, bias=False)\n    self.query = nn.Linear(n_embd, head_size, bias=False)\n    self.value = nn.Linear(n_embd, head_size, bias=False)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionHead.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionHead.key","title":"<code>key = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionHead.query","title":"<code>query = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionHead.value","title":"<code>value = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.AttentionHead.forward","title":"<code>forward(x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x, mask=None):\n    # input of size (batch, time-step, channels)\n    # output of size (batch, time-step, head size)\n    k = self.key(x)  # (B,T,hs)\n    q = self.query(x)  # (B,T,hs)\n    # compute attention scores (\"affinities\")\n    wei = (\n        q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n    )  # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)\n    if mask is not None:\n        wei = wei.masked_fill(mask == 0, float(\"-inf\"))  # (B, T, T)\n    wei = F.softmax(wei, dim=-1)  # (B, T, T)\n    wei = self.dropout(wei)\n    # perform the weighted aggregation of the values\n    v = self.value(x)  # (B,T,hs)\n    out = wei @ v  # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.CrossAttentionHead","title":"<code>CrossAttentionHead(head_size, n_embd=10, block_size=128, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>one head of x-attention</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, head_size, n_embd=10, block_size=128, dropout=0.0):\n    super().__init__()\n    self.key = nn.Linear(n_embd, head_size, bias=False)\n    self.query = nn.Linear(n_embd, head_size, bias=False)\n    self.value = nn.Linear(n_embd, head_size, bias=False)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.CrossAttentionHead.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.CrossAttentionHead.key","title":"<code>key = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.CrossAttentionHead.query","title":"<code>query = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.CrossAttentionHead.value","title":"<code>value = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.CrossAttentionHead.forward","title":"<code>forward(x_encode, x_decode, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x_encode, x_decode, mask=None):\n    # input of size (batch, time-step, channels)\n    # output of size (batch, time-step, head size)\n    k = self.key(x_encode)  # (B,T,hs)\n    q = self.query(x_decode)  # (B,T,hs)\n    # compute attention scores (\"affinities\")\n    wei = (\n        q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n    )  # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)\n    if mask is not None:\n        wei = wei.masked_fill(mask == 0, float(\"-inf\"))  # (B, T, T)\n    wei = F.softmax(wei, dim=-1)  # (B, T, T)\n    wei = self.dropout(wei)\n    # perform the weighted aggregation of the values\n    v = self.value(x_encode)  # (B,T,hs)\n    out = wei @ v  # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockAddAttention","title":"<code>DecoderBlockAddAttention(n_embd, n_head, block_size, dropout, ffwd_size=None)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(\n    self, n_embd, n_head, block_size, dropout, ffwd_size: int = None\n):\n    # n_embd: embedding dimension, n_head: the number of heads we'd like\n    super().__init__()\n    head_size = n_embd // n_head\n    self.self_attention = MultiHeadMaskedAttention(\n        num_heads=n_head,\n        head_size=head_size,\n        n_embd=n_embd,\n        block_size=block_size,\n        dropout=dropout,\n    )\n    self.ffwd = FeedFoward(n_embd=n_embd, ffwd_size=ffwd_size)\n    self.ln1 = nn.RMSNorm(n_embd)\n    self.ln2 = nn.RMSNorm(n_embd)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockAddAttention.ffwd","title":"<code>ffwd = FeedFoward(n_embd=n_embd, ffwd_size=ffwd_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockAddAttention.ln1","title":"<code>ln1 = nn.RMSNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockAddAttention.ln2","title":"<code>ln2 = nn.RMSNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockAddAttention.self_attention","title":"<code>self_attention = MultiHeadMaskedAttention(num_heads=n_head, head_size=head_size, n_embd=n_embd, block_size=block_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockAddAttention.forward","title":"<code>forward(hidden, target, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, hidden, target, mask=None):\n    target = target + self.self_attention(self.ln1(target), mask)\n    target = target + hidden\n    target = target + self.ffwd(self.ln2(target))\n    return target\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockXAttention","title":"<code>DecoderBlockXAttention(n_embd, n_head, block_size, dropout, ffwd_size=None)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(\n    self, n_embd, n_head, block_size, dropout, ffwd_size: int = None\n):\n    # n_embd: embedding dimension, n_head: the number of heads we'd like\n    super().__init__()\n    head_size = n_embd // n_head\n    self.self_attention = MultiHeadMaskedAttention(\n        num_heads=n_head,\n        head_size=head_size,\n        n_embd=n_embd,\n        block_size=block_size,\n        dropout=dropout,\n    )\n    self.cross_attention = MultiHeadCrossAttention(\n        num_heads=n_head,\n        head_size=head_size,\n        n_embd=n_embd,\n        dropout=dropout,\n    )\n    self.ffwd = FeedFoward(n_embd=n_embd, ffwd_size=ffwd_size)\n    self.ln1 = nn.RMSNorm(n_embd)\n    self.ln2 = nn.RMSNorm(n_embd)\n    self.ln3 = nn.RMSNorm(n_embd)\n    self.ln4 = nn.RMSNorm(n_embd)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockXAttention.cross_attention","title":"<code>cross_attention = MultiHeadCrossAttention(num_heads=n_head, head_size=head_size, n_embd=n_embd, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockXAttention.ffwd","title":"<code>ffwd = FeedFoward(n_embd=n_embd, ffwd_size=ffwd_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockXAttention.ln1","title":"<code>ln1 = nn.RMSNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockXAttention.ln2","title":"<code>ln2 = nn.RMSNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockXAttention.ln3","title":"<code>ln3 = nn.RMSNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockXAttention.ln4","title":"<code>ln4 = nn.RMSNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockXAttention.self_attention","title":"<code>self_attention = MultiHeadMaskedAttention(num_heads=n_head, head_size=head_size, n_embd=n_embd, block_size=block_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.DecoderBlockXAttention.forward","title":"<code>forward(hidden, target, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, hidden, target, mask=None):\n    target = target + self.self_attention(self.ln1(target), mask)\n    target = target + self.cross_attention(\n        self.ln2(hidden), self.ln3(target), mask\n    )\n    target = target + self.ffwd(self.ln4(target))\n    return target\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.EncoderBlock","title":"<code>EncoderBlock(n_embd, n_head, dropout, ffwd_size=None)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Transformer block: communication followed by computation</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, n_embd, n_head, dropout, ffwd_size: int = None):\n    # n_embd: embedding dimension, n_head: the number of heads we'd like\n    super().__init__()\n    head_size = n_embd // n_head\n    self.sa = MultiHeadAttention(\n        num_heads=n_head,\n        head_size=head_size,\n        n_embd=n_embd,\n        dropout=dropout,\n    )\n    self.ffwd = FeedFoward(n_embd=n_embd, ffwd_size=ffwd_size)\n    self.ln1 = nn.RMSNorm(n_embd)\n    self.ln2 = nn.RMSNorm(n_embd)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.EncoderBlock.ffwd","title":"<code>ffwd = FeedFoward(n_embd=n_embd, ffwd_size=ffwd_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.EncoderBlock.ln1","title":"<code>ln1 = nn.RMSNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.EncoderBlock.ln2","title":"<code>ln2 = nn.RMSNorm(n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.EncoderBlock.sa","title":"<code>sa = MultiHeadAttention(num_heads=n_head, head_size=head_size, n_embd=n_embd, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.EncoderBlock.forward","title":"<code>forward(x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x, mask=None):\n    x = x + self.sa(self.ln1(x), mask)\n    x = x + self.ffwd(self.ln2(x))\n    return x\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.FeedFoward","title":"<code>FeedFoward(n_embd, dropout=0.0, ffwd_size=None)</code>","text":"<p>               Bases: <code>Module</code></p> <p>a simple linear layer followed by a non-linearity</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, n_embd, dropout=0.0, ffwd_size=None):\n    super().__init__()\n    if ffwd_size is None:\n        ffwd_size = n_embd * 2\n    self.net = nn.Sequential(\n        nn.Linear(n_embd, ffwd_size),\n        nn.GELU(),\n        nn.Linear(ffwd_size, n_embd),\n        nn.Dropout(dropout),\n    )\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.FeedFoward.net","title":"<code>net = nn.Sequential(nn.Linear(n_embd, ffwd_size), nn.GELU(), nn.Linear(ffwd_size, n_embd), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.FeedFoward.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x):\n    return self.net(x)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.FixedPositionalEncoding","title":"<code>FixedPositionalEncoding(d_model, dropout=0.0, length=144)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, d_model: int, dropout: float = 0.0, length: int = 144):\n    super().__init__()\n    self.dropout = nn.Dropout(p=dropout)\n\n    position = torch.arange(length).unsqueeze(1)\n    div_term = torch.exp(\n        torch.arange(0, d_model, 2) * (-math.log(length) / d_model)\n    )\n    pe = torch.zeros(length, d_model)\n    pe[:, 0::2] = torch.sin(position * div_term)\n    pe[:, 1::2] = torch.cos(position * div_term)\n    self.register_buffer(\"pe\", pe)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.FixedPositionalEncoding.dropout","title":"<code>dropout = nn.Dropout(p=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.FixedPositionalEncoding.forward","title":"<code>forward(x)</code>","text":"PARAMETER DESCRIPTION <code>x</code> <p>Tensor, shape <code>[seq_len, batch_size, embedding_dim]</code></p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x: Tensor) -&gt; Tensor:\n    \"\"\"\n    Arguments:\n        x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n    \"\"\"\n    _, T, _ = x.shape\n    x = x + self.pe[:T, :]\n    return self.dropout(x)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.LearntPositionalEncoding","title":"<code>LearntPositionalEncoding(d_model, dropout=0.0, length=144)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, d_model: int, dropout: float = 0.0, length: int = 144):\n    super().__init__()\n    self.dropout = nn.Dropout(p=dropout)\n    pe = torch.arange(0, length, dtype=torch.long)  # (T)\n    self.register_buffer(\"pe\", pe)\n    self.embedding = nn.Embedding(length, d_model)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.LearntPositionalEncoding.dropout","title":"<code>dropout = nn.Dropout(p=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.LearntPositionalEncoding.embedding","title":"<code>embedding = nn.Embedding(length, d_model)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.LearntPositionalEncoding.forward","title":"<code>forward(x)</code>","text":"PARAMETER DESCRIPTION <code>x</code> <p>Tensor, shape <code>[seq_len, batch_size, embedding_dim]</code></p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x: Tensor) -&gt; Tensor:\n    \"\"\"\n    Arguments:\n        x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n    \"\"\"\n    _, L, _ = x.shape  # (B,T,C)\n\n    pos_emb = self.embedding(self.pe[:L]).unsqueeze(0)  # (1,L,C)\n    x = x + pos_emb  # (B,L,C)\n    return self.dropout(x)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MaskedAttentionHead","title":"<code>MaskedAttentionHead(head_size, n_embd, block_size, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>one head of self-attention</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, head_size, n_embd, block_size, dropout=0.0):\n    super().__init__()\n    self.key = nn.Linear(n_embd, head_size, bias=False)\n    self.query = nn.Linear(n_embd, head_size, bias=False)\n    self.value = nn.Linear(n_embd, head_size, bias=False)\n    self.register_buffer(\n        \"tril\", torch.tril(torch.ones(block_size, block_size), diagonal=0)\n    )\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MaskedAttentionHead.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MaskedAttentionHead.key","title":"<code>key = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MaskedAttentionHead.query","title":"<code>query = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MaskedAttentionHead.value","title":"<code>value = nn.Linear(n_embd, head_size, bias=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MaskedAttentionHead.forward","title":"<code>forward(x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x, mask=None):\n    B, T, C = x.shape\n    # input of size (batch, time-step, channels)\n    # output of size (batch, time-step, head size)\n    k = self.key(x)  # (B,T,hs)\n    q = self.query(x)  # (B,T,hs)\n    # compute attention scores (\"affinities\")\n    wei = (\n        q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n    )  # (B, T, hs) @ (B, hs, T) -&gt; (B, T, T)\n    wei = wei.masked_fill(\n        self.tril[:T, :T] == 0, float(\"-inf\")\n    )  # (B, T, T)\n    if mask is not None:\n        wei = wei.masked_fill(mask == 0, float(\"-inf\"))  # (B, T, T)\n    wei = F.softmax(wei, dim=-1)  # (B, T, T)\n    wei = self.dropout(wei)\n    # perform the weighted aggregation of the values\n    v = self.value(x)  # (B,T,hs)\n    out = wei @ v  # (B, T, T) @ (B, T, hs) -&gt; (B, T, hs)\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadAttention","title":"<code>MultiHeadAttention(num_heads, head_size, n_embd=10, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>multiple heads of self-attention in parallel</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, num_heads, head_size, n_embd=10, dropout=0.0):\n    super().__init__()\n    self.heads = nn.ModuleList(\n        [\n            AttentionHead(head_size=head_size, n_embd=n_embd)\n            for _ in range(num_heads)\n        ]\n    )\n    self.proj = nn.Linear(head_size * num_heads, n_embd)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadAttention.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadAttention.heads","title":"<code>heads = nn.ModuleList([AttentionHead(head_size=head_size, n_embd=n_embd) for _ in range(num_heads)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadAttention.proj","title":"<code>proj = nn.Linear(head_size * num_heads, n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadAttention.forward","title":"<code>forward(x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x, mask=None):\n    out = torch.cat([h(x, mask) for h in self.heads], dim=-1)\n    out = self.dropout(self.proj(out))\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadCrossAttention","title":"<code>MultiHeadCrossAttention(num_heads, head_size, n_embd=10, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>multiple heads of masked x-attention in parallel</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, num_heads, head_size, n_embd=10, dropout=0.0):\n    super().__init__()\n    self.heads = nn.ModuleList(\n        [\n            CrossAttentionHead(head_size=head_size, n_embd=n_embd)\n            for _ in range(num_heads)\n        ]\n    )\n    self.proj = nn.Linear(head_size * num_heads, n_embd)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadCrossAttention.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadCrossAttention.heads","title":"<code>heads = nn.ModuleList([CrossAttentionHead(head_size=head_size, n_embd=n_embd) for _ in range(num_heads)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadCrossAttention.proj","title":"<code>proj = nn.Linear(head_size * num_heads, n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadCrossAttention.forward","title":"<code>forward(x_encode, x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x_encode, x, mask=None):\n    out = torch.cat([h(x_encode, x, mask) for h in self.heads], dim=-1)\n    out = self.dropout(self.proj(out))\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadMaskedAttention","title":"<code>MultiHeadMaskedAttention(num_heads, head_size, block_size, n_embd, dropout=0.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Multiple heads of masked self-attention in parallel</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, num_heads, head_size, block_size, n_embd, dropout=0.0):\n    super().__init__()\n    self.masked_heads = nn.ModuleList(\n        [\n            MaskedAttentionHead(\n                head_size=head_size, n_embd=n_embd, block_size=block_size\n            )\n            for _ in range(num_heads)\n        ]\n    )\n    self.proj = nn.Linear(head_size * num_heads, n_embd)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadMaskedAttention.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadMaskedAttention.masked_heads","title":"<code>masked_heads = nn.ModuleList([MaskedAttentionHead(head_size=head_size, n_embd=n_embd, block_size=block_size) for _ in range(num_heads)])</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadMaskedAttention.proj","title":"<code>proj = nn.Linear(head_size * num_heads, n_embd)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.MultiHeadMaskedAttention.forward","title":"<code>forward(x, mask=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x, mask=None):\n    out = torch.cat([h(x, mask) for h in self.masked_heads], dim=-1)\n    out = self.dropout(self.proj(out))\n    return out\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.RemainingTimePositionEncoding","title":"<code>RemainingTimePositionEncoding(dropout=0.0, *args, **kwargs)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Positional encoding for remaining duration, replaces dim [:, :, -2]. Assumes durations are at [:, :, -1]</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, dropout: float = 0.0, *args, **kwargs):\n    \"\"\"Positional encoding for remaining duration, replaces dim [:, :, -2].\n    Assumes durations are at [:, :, -1]\"\"\"\n    super().__init__()\n    self.dropout = nn.Dropout(p=dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.RemainingTimePositionEncoding.dropout","title":"<code>dropout = nn.Dropout(p=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.RemainingTimePositionEncoding.forward","title":"<code>forward(x)</code>","text":"PARAMETER DESCRIPTION <code>x</code> <p>Tensor, shape <code>[seq_len, batch_size, embedding_dim]</code></p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x: Tensor) -&gt; Tensor:\n    \"\"\"\n    Arguments:\n        x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n    \"\"\"\n    durations = x[:, :, -1]\n    remaining = torch.ones_like(durations) - (\n        torch.cumsum(durations, dim=-1) - durations\n    )\n    # remaining = remaining - remaining.mean(dim=-1)[:, None]  # normalize\n    x[:, :, -1] = remaining\n    return self.dropout(x)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.StartTimePositionEncoding","title":"<code>StartTimePositionEncoding(dropout=0.0, *args, **kwargs)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Positional encoding of start times, replaces dim [:, :, -2]. Assumes durations are at [:, :, -1]</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, dropout: float = 0.0, *args, **kwargs):\n    \"\"\"Positional encoding of start times, replaces dim [:, :, -2].\n    Assumes durations are at [:, :, -1]\"\"\"\n    super().__init__()\n    self.dropout = nn.Dropout(p=dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.StartTimePositionEncoding.dropout","title":"<code>dropout = nn.Dropout(p=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.StartTimePositionEncoding.forward","title":"<code>forward(x)</code>","text":"PARAMETER DESCRIPTION <code>x</code> <p>Tensor, shape <code>[seq_len, batch_size, embedding_dim]</code></p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(self, x: Tensor) -&gt; Tensor:\n    \"\"\"\n    Arguments:\n        x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n    \"\"\"\n    durations = x[:, :, -1]\n    start_times = torch.cumsum(durations, dim=-1) - durations\n    # start_times = (\n    #     start_times - start_times.mean(dim=-1)[:, None]\n    # )  # normalize\n    x[:, :, -1] = start_times\n    return self.dropout(x)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.VAESeqXAtt","title":"<code>VAESeqXAtt(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer.</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.VAESeqXAtt.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.ffwd_size = config.get(\"ffwd_size\", self.hidden_size)\n    self.heads = config[\"heads\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config.get(\"dropout\", 0.0)\n    self.length, _ = self.in_shape\n    self.sampling = config.get(\"sampling\", \"top\")\n    self.embedding = config.get(\"embedding\", \"concat\")\n    print(f\"Embedding: {self.embedding}\")\n    self.position_embedding = config.get(\"position_embedding\", \"learnt\")\n    print(f\"Positional embedding: {self.position_embedding}\")\n    self.time_embedding = config.get(\"time_embedding\", \"none\")\n    print(f\"Time embedding: {self.time_embedding}\")\n    self.latent_context = config.get(\"latent_context\", \"xattention\")\n    print(f\"Latent context: {self.latent_context}\")\n\n    self.encoder = AttentionEncoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        ffwd_size=self.ffwd_size,\n        length=self.length,\n        n_head=self.heads,\n        n_layer=self.hidden_n,\n        dropout=self.dropout,\n        embedding=self.embedding,\n        position_embedding=self.position_embedding,\n        time_embedding=self.time_embedding,\n    )\n    self.decoder = AttentionDecoder(\n        input_size=self.encodings,\n        output_size=self.encodings + 1,\n        hidden_size=self.hidden_size,\n        ffwd_size=self.ffwd_size,\n        num_heads=self.heads,\n        num_layers=self.hidden_n,\n        length=self.length,\n        dropout=self.dropout,\n        embedding=self.embedding,\n        position_embedding=self.position_embedding,\n        time_embedding=self.time_embedding,\n        latent_context=self.latent_context,\n    )\n    self.unflattened_shape = (self.length, self.hidden_size)\n    flat_size_encode = self.length * self.hidden_size\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n\n    if config.get(\"share_embed\", False):\n        print(\"Sharing embeddings\")\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.VAESeqXAtt.decode","title":"<code>decode(z, context, mask, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def decode(\n    self, z: Tensor, context: Tensor, mask: Optional[Tensor], **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    hidden = self.fc_hidden(z)\n    hidden = hidden.unflatten(1, self.unflattened_shape)\n    log_probs = self.decoder(hidden, context, mask)\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.VAESeqXAtt.encode","title":"<code>encode(input, conditionals, mask)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>list[tensor]: Latent layer input (means and variances) [N, latent_dims].</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def encode(\n    self,\n    input: Tensor,\n    conditionals: Optional[Tensor],\n    mask: Optional[Tensor],\n) -&gt; list[Tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): Input sequence batch [N, steps, acts].\n\n    Returns:\n        list[tensor]: Latent layer input (means and variances) [N, latent_dims].\n    \"\"\"\n    # [N, L, C]\n    hidden = self.encoder(input, mask)\n    # [N, flatsize]\n\n    # Split the result into mu and var components\n    mu = self.fc_mu(hidden)\n    log_var = self.fc_var(hidden)\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.VAESeqXAtt.forward","title":"<code>forward(x, target=None, input_mask=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, L, Cin].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>List[Tensor]</code> <p>list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def forward(\n    self, x: Tensor, target=None, input_mask=None, **kwargs\n) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, L, Cin].\n\n    Returns:\n        list[tensor]: [Log probs, Probs [N, L, Cout], Input [N, L, Cin], mu [N, latent], var [N, latent]].\n    \"\"\"\n    # if input_mask is not None:\n    #     mask = torch.zeros_like(input_mask)\n    #     mask[input_mask &gt; 0] = 1.0\n    #     mask = mask[:, None, :]\n    # else:\n    #     mask = None\n    mask = None\n\n    mu, log_var = self.encode(x, conditionals=None, mask=mask)\n    z = self.reparameterize(mu, log_var)\n\n    if target is not None:  # training\n        log_prob_y = self.decode(z, context=x, mask=mask)\n        return [log_prob_y, mu, log_var, z]\n\n    # no target so assume generating\n    log_prob = self.predict_sequences(z, current_device=z.device)\n    return [log_prob, mu, log_var, z]\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.VAESeqXAtt.infer","title":"<code>infer(x, device, input_mask=None, **kwargs)</code>","text":"<p>Given an encoder input, return reconstructed output and z samples.</p> PARAMETER DESCRIPTION <code>x</code> <p>[N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>Tensor</code> <p>(tensor: [N, steps, acts], tensor: [N, latent_dims]).</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def infer(\n    self,\n    x: Tensor,\n    device: int,\n    input_mask: Optional[Tensor] = None,\n    **kwargs,\n) -&gt; Tensor:\n    \"\"\"Given an encoder input, return reconstructed output and z samples.\n\n    Args:\n        x (tensor): [N, steps, acts].\n\n    Returns:\n        (tensor: [N, steps, acts], tensor: [N, latent_dims]).\n    \"\"\"\n    log_probs_x, _, _, z = self.forward(x, input_mask=input_mask, **kwargs)\n    prob_samples = exp(log_probs_x)\n    prob_samples = prob_samples.to(device)\n    z = z.to(device)\n    return prob_samples, z\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.VAESeqXAtt.predict","title":"<code>predict(z, device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>z</code> <p>[N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def predict(self, z: Tensor, device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        z (tensor): [N, latent_dims].\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    log_prob_samples = self.predict_sequences(z, device)\n    return exp(log_prob_samples)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.VAESeqXAtt.predict_sequences","title":"<code>predict_sequences(z, current_device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>z</code> <p>[N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def predict_sequences(\n    self, z: Tensor, current_device: int, **kwargs\n) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        z (tensor): [N, latent_dims].\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(current_device)\n    B = z.shape[0]\n    log_outputs = []\n    sequence = torch.zeros(B, self.length, 2, device=z.device)\n    sequence[:, :, 0] = self.sos  # all sos with duration 0\n    for i in range(self.length):\n        # get the predictions\n        logits = self.decode(z, context=sequence, mask=None)\n        # focus only on the last time step\n        logits = logits[:, i, :]  # becomes (B, C)\n        log_outputs.append(logits.unsqueeze(1))\n        prediction = self.sample(logits)\n        # append sampled index to the running sequence\n        sequence[:, i, :] = prediction\n\n    log_probs = torch.cat(log_outputs, dim=1)\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.VAESeqXAtt.sample","title":"<code>sample(logits)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def sample(self, logits):\n    acts, duration = torch.split(logits, [self.encodings, 1], dim=-1)\n    if self.sampling == \"sample\":\n        # sample from the distribution\n        act = torch.multinomial(torch.exp(logits), num_samples=1)  # (B, 1)\n    elif self.sampling == \"top\":\n        _, topi = logits.topk(1)\n        act = (\n            topi.squeeze(-1).detach().unsqueeze(-1)\n        )  # detach from history as input?\n    else:\n        raise ValueError(\n            f\"Sampling method {self.sampling} not recognized, use 'sample' or 'top'\"\n        )\n    # [N, 1, encodings+1]\n\n    _, topi = acts.topk(1)\n    act = (\n        topi.squeeze(-1).detach().unsqueeze(-1)\n    )  # detach from history as input\n    duration = self.decoder.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_attention/#caveat.models.sequence.vae_sequence_attention.VAESeqXAtt.validation_step","title":"<code>validation_step(batch, batch_idx, optimizer_idx=0)</code>","text":"<p>Override the validation step to include the target during validation. This is required for self attention.</p> Source code in <code>caveat/models/sequence/vae_sequence_attention.py</code> <pre><code>def validation_step(self, batch, batch_idx, optimizer_idx=0):\n    \"\"\"Override the validation step to include the target during validation.\n    This is required for self attention.\n    \"\"\"\n\n    (x, _), (y, y_weights), (labels, _) = batch\n    self.curr_device = x.device\n\n    log_probs, mu, log_var, z = self.forward(\n        x, conditionals=labels, target=y\n    )\n    val_loss = self.loss_function(\n        log_probs=log_probs,\n        mu=mu,\n        log_var=log_var,\n        target=y,\n        weights=y_weights,\n        kld_weight=self.kld_loss_weight,\n        duration_weight=self.duration_loss_weight,\n        optimizer_idx=optimizer_idx,\n        batch_idx=batch_idx,\n    )\n\n    self.log_dict(\n        {f\"val_{key}\": val.item() for key, val in val_loss.items()},\n        sync_dist=True,\n        on_step=False,\n        on_epoch=True,\n        prog_bar=True,\n    )\n    self.log(\"hp_metric\", val_loss[\"loss\"])\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/","title":"caveat.models.sequence.vae_sequence_cnn","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Decoder","title":"<code>Decoder(encoded_size, target_shapes, hidden_layers, kernel_size=3, stride=2, padding=1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d Conv Decoder.</p> PARAMETER DESCRIPTION <code>target_shapes</code> <p>list of target shapes from encoder.</p> <p> TYPE: <code>list</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>kernel_size</code> <p>description. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>description. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>description. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_cnn.py</code> <pre><code>def __init__(\n    self,\n    encoded_size: int,\n    target_shapes: list,\n    hidden_layers: list,\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n):\n    \"\"\"2d Conv Decoder.\n\n    Args:\n        target_shapes (list): list of target shapes from encoder.\n        hidden_layers (list, optional): _description_. Defaults to None.\n        kernel_size (Union[tuple[int, int], int], optional): _description_. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): _description_. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): _description_. Defaults to 1.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.hidden_size = encoded_size\n    modules = []\n    target_shapes.reverse()\n\n    for i in range(len(hidden_layers) - 1):\n        modules.append(\n            nn.Sequential(\n                nn.ConvTranspose2d(\n                    in_channels=target_shapes[i][0],\n                    out_channels=target_shapes[i + 1][0],\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    output_padding=calc_output_padding_2d(\n                        target_shapes[i + 1]\n                    ),\n                    # bias=False,\n                ),\n                nn.BatchNorm2d(target_shapes[i + 1][0]),\n                nn.LeakyReLU(),\n            )\n        )\n\n    # Final layer with Tanh activation\n    modules.append(\n        nn.Sequential(\n            nn.ConvTranspose2d(\n                in_channels=target_shapes[-2][0],\n                out_channels=target_shapes[-1][0],\n                kernel_size=kernel_size,\n                stride=stride,\n                padding=padding,\n                output_padding=calc_output_padding_2d(target_shapes[-1]),\n            ),\n            nn.BatchNorm2d(target_shapes[-1][0]),\n        )\n    )\n\n    self.decoder = nn.Sequential(*modules)\n    self.logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Decoder.decoder","title":"<code>decoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Decoder.hidden_size","title":"<code>hidden_size = encoded_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Decoder.logprob_activation","title":"<code>logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Decoder.forward","title":"<code>forward(hidden, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_cnn.py</code> <pre><code>def forward(self, hidden, **kwargs):\n    y = self.decoder(hidden)\n    y = y.squeeze(1)  # remove conv channel dim\n    acts_logits, durations = torch.split(\n        y, [self.hidden_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.logprob_activation(acts_logits)\n    durations = self.duration_activation(durations)\n    durations = torch.log(durations)\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Encoder","title":"<code>Encoder(encoded_size, in_shape, hidden_layers, dropout=0.1, kernel_size=3, stride=2, padding=1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d Convolutions Encoder.</p> PARAMETER DESCRIPTION <code>encoded_size</code> <p>number of encoding classes and hidden size.</p> <p> TYPE: <code>int</code> </p> <code>in_shape</code> <p>[C, time_step, activity_encoding].</p> <p> TYPE: <code>tuple[int, int, int]</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> <code>kernel_size</code> <p>description. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>description. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>description. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_cnn.py</code> <pre><code>def __init__(\n    self,\n    encoded_size: int,\n    in_shape: tuple,\n    hidden_layers: list,\n    dropout: float = 0.1,\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n):\n    \"\"\"2d Convolutions Encoder.\n\n    Args:\n        encoded_size (int): number of encoding classes and hidden size.\n        in_shape (tuple[int, int, int]): [C, time_step, activity_encoding].\n        hidden_layers (list, optional): _description_. Defaults to None.\n        dropout (float): dropout. Defaults to 0.1.\n        kernel_size (Union[tuple[int, int], int], optional): _description_. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): _description_. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): _description_. Defaults to 1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    h = in_shape[0]\n    self.embedding = CustomDurationEmbeddingConcat(\n        encoded_size, encoded_size, dropout=dropout\n    )\n    w = encoded_size\n    channels = 1\n\n    modules = []\n    self.target_shapes = [(channels, h, w)]\n\n    for hidden_channels in hidden_layers:\n        modules.append(\n            nn.Sequential(\n                nn.Conv2d(\n                    in_channels=channels,\n                    out_channels=hidden_channels,\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    # bias=False,\n                ),\n                nn.BatchNorm2d(hidden_channels),\n                nn.LeakyReLU(),\n            )\n        )\n        h, w = conv2d_size(\n            (h, w), kernel_size=kernel_size, padding=padding, stride=stride\n        )\n        self.target_shapes.append((hidden_channels, h, w))\n        channels = hidden_channels\n\n    self.dropout = nn.Dropout(dropout)\n\n    self.shape_before_flattening = (-1, channels, h, w)\n    self.encoder = nn.Sequential(*modules)\n    self.flat_size = int(channels * h * w)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Encoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(encoded_size, encoded_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Encoder.encoder","title":"<code>encoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Encoder.flat_size","title":"<code>flat_size = int(channels * h * w)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Encoder.shape_before_flattening","title":"<code>shape_before_flattening = (-1, channels, h, w)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Encoder.target_shapes","title":"<code>target_shapes = [(channels, h, w)]</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_cnn.py</code> <pre><code>def forward(self, x):\n    y = self.dropout(self.embedding(x.int()))\n    y = y.unsqueeze(1)  # add channel dim for Conv\n    y = self.encoder(y)\n    y = y.flatten(start_dim=1)\n    return y\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.VAESeqCNN2D","title":"<code>VAESeqCNN2D(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>CNN based encoder and decoder with encoder embedding layer.</p> Source code in <code>caveat/models/sequence/vae_sequence_cnn.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"CNN based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.VAESeqCNN2D.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_cnn.py</code> <pre><code>def build(self, **config):\n    hidden_layers = list\n    latent_dim = int\n    dropout = Optional[float]\n    kernel_size = Optional[Union[tuple[int, int], int]]\n    stride = Optional[Union[tuple[int, int], int]]\n    padding = Optional[Union[tuple[int, int], int]]\n\n    encoded_size = self.encodings + 1\n    hidden_layers = utils.build_hidden_layers(config)\n    latent_dim = config[\"latent_dim\"]\n    dropout = config.get(\"dropout\", 0)\n    kernel_size = config.get(\"kernel_size\", 3)\n    stride = config.get(\"stride\", 2)\n    padding = config.get(\"padding\", 1)\n\n    self.latent_dim = latent_dim\n    # length, _ = self.in_shape\n\n    self.encoder = Encoder(\n        encoded_size=encoded_size,\n        in_shape=self.in_shape,\n        hidden_layers=hidden_layers,\n        dropout=dropout,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n    )\n    # TODO add drop out to CNNs???\n    self.decoder = Decoder(\n        encoded_size=encoded_size,\n        target_shapes=self.encoder.target_shapes,\n        hidden_layers=hidden_layers,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n    )\n    self.fc_mu = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_var = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_hidden = nn.Linear(latent_dim, self.encoder.flat_size)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn/#caveat.models.sequence.vae_sequence_cnn.VAESeqCNN2D.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_cnn.py</code> <pre><code>def decode(self, z: Tensor, target=None, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    hidden = self.fc_hidden(z)\n    hidden = hidden.view(self.encoder.shape_before_flattening)\n    log_probs = self.decoder(hidden)\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/","title":"caveat.models.sequence.vae_sequence_cnn1d","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Decoder","title":"<code>Decoder(encoded_size, target_shapes, dropout=0.1, kernel_size=3, stride=2, padding=0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>1d Conv Decoder.</p> PARAMETER DESCRIPTION <code>encoded_size</code> <p>number of encoding classes and hidden size.</p> <p> TYPE: <code>int</code> </p> <code>target_shapes</code> <p>list of target shapes.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> <code>kernel_size</code> <p>kernel size. Defaults to 3.</p> <p> TYPE: <code>int</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>stride. Defaults to 2.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>padding. Defaults to 0.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_cnn1d.py</code> <pre><code>def __init__(\n    self,\n    encoded_size: int,\n    target_shapes: list,\n    dropout: float = 0.1,\n    kernel_size: int = 3,\n    stride: int = 2,\n    padding: int = 0,\n):\n    \"\"\"1d Conv Decoder.\n\n    Args:\n        encoded_size (int): number of encoding classes and hidden size.\n        target_shapes (list): list of target shapes.\n        dropout (float): dropout. Defaults to 0.1.\n        kernel_size (int): kernel size. Defaults to 3.\n        stride (int): stride. Defaults to 2.\n        padding (int): padding. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.hidden_size = encoded_size\n    modules = []\n    target_shapes.reverse()\n\n    for i in range(len(target_shapes) - 1):\n        c_in, l_in = target_shapes[i]\n        c_out, l_out = target_shapes[i + 1]\n        if c_in == c_out and l_in == l_out:\n            print(\n                \"Skipping transpose convolution:\", c_in, l_in, c_out, l_out\n            )\n            continue\n        in_padding, out_padding = calc_output_padding_1d(\n            length=l_in,\n            target=l_out,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n        )\n        block = [\n            nn.ConvTranspose1d(\n                in_channels=c_in,\n                out_channels=c_out,\n                kernel_size=kernel_size,\n                stride=stride,\n                padding=in_padding,\n                output_padding=out_padding,\n                bias=False,\n            ),\n            nn.BatchNorm1d(c_out),\n        ]\n        if i &lt; len(target_shapes) - 2:\n            block.append(nn.LeakyReLU())\n            block.append(nn.Dropout(dropout))\n        modules.append(nn.Sequential(*block))\n\n    self.decoder = nn.Sequential(*modules)\n    self.logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Decoder.decoder","title":"<code>decoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Decoder.hidden_size","title":"<code>hidden_size = encoded_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Decoder.logprob_activation","title":"<code>logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Decoder.forward","title":"<code>forward(hidden, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_cnn1d.py</code> <pre><code>def forward(self, hidden, **kwargs):\n    y = self.decoder(hidden)\n    y = y.permute(0, 2, 1)\n    acts_logits, durations = torch.split(\n        y, [self.hidden_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.logprob_activation(acts_logits)\n    durations = self.duration_activation(durations)\n    durations = torch.log(durations)\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Encoder","title":"<code>Encoder(input_encoding, encoded_size, in_shape, hidden_layers, dropout=0.1, kernel_size=2, stride=2, padding=1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d Convolutions Encoder.</p> PARAMETER DESCRIPTION <code>encoded_size</code> <p>number of encoding classes and hidden size.</p> <p> TYPE: <code>int</code> </p> <code>in_shape</code> <p>[C, time_step, activity_encoding].</p> <p> TYPE: <code>tuple[int, int, int]</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> <code>kernel_size</code> <p>kernel size. Defaults to 2.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>stride</code> <p>stride. Defaults to 2.</p> <p> TYPE: <code>int</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>padding. Defaults to 1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_cnn1d.py</code> <pre><code>def __init__(\n    self,\n    input_encoding: int,\n    encoded_size: int,\n    in_shape: tuple,\n    hidden_layers: list,\n    dropout: float = 0.1,\n    kernel_size: int = 2,\n    stride: int = 2,\n    padding: int = 1,\n):\n    \"\"\"2d Convolutions Encoder.\n\n    Args:\n        encoded_size (int): number of encoding classes and hidden size.\n        in_shape (tuple[int, int, int]): [C, time_step, activity_encoding].\n        hidden_layers (list, optional): _description_. Defaults to None.\n        dropout (float): dropout. Defaults to 0.1.\n        kernel_size (int): kernel size. Defaults to 2.\n        stride (int): stride. Defaults to 2.\n        padding (int): padding. Defaults to 1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    print(in_shape)\n    length = in_shape[0]\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_encoding, encoded_size, dropout=dropout\n    )\n\n    channels = encoded_size\n    self.shapes = []\n    modules = []\n\n    for hidden_channels in hidden_layers:\n        self.shapes.append((channels, length))\n        if length + padding &lt; kernel_size:\n            print(\"Skipping convolution:\", length, kernel_size)\n            break\n        modules.append(\n            nn.Sequential(\n                nn.Conv1d(\n                    in_channels=channels,\n                    out_channels=hidden_channels,\n                    kernel_size=kernel_size,\n                    stride=stride,\n                    padding=padding,\n                    bias=False,\n                ),\n                nn.BatchNorm1d(hidden_channels),\n                nn.LeakyReLU(),\n                nn.Dropout(dropout),\n            )\n        )\n        length = conv1d_size(\n            length=length,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n        )\n        channels = hidden_channels\n    self.shapes.append((channels, length))\n\n    self.encoder = nn.Sequential(*modules)\n    self.shape_before_flattening = (-1, channels, length)\n    self.flat_size = int(channels * length)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Encoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_encoding, encoded_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Encoder.encoder","title":"<code>encoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Encoder.flat_size","title":"<code>flat_size = int(channels * length)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Encoder.shape_before_flattening","title":"<code>shape_before_flattening = (-1, channels, length)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Encoder.shapes","title":"<code>shapes = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_cnn1d.py</code> <pre><code>def forward(self, x):\n    y = self.embedding(x.int())\n    y = y.permute(0, 2, 1)\n    y = self.encoder(y)\n    y = y.flatten(start_dim=1)\n    return y\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.VAESeqCNN1D","title":"<code>VAESeqCNN1D(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>CNN based encoder and decoder with encoder embedding layer.</p> Source code in <code>caveat/models/sequence/vae_sequence_cnn1d.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"CNN based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.VAESeqCNN1D.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_cnn1d.py</code> <pre><code>def build(self, **config):\n    hidden_layers = list\n    latent_dim = int\n    dropout = Optional[float]\n    kernel_size = Optional[int]\n    stride = Optional[int]\n    padding = Optional[int]\n\n    encoded_size = config.get(\"embed_size\", self.encodings + 1)\n    hidden_layers = utils.build_hidden_layers(config)\n    latent_dim = config[\"latent_dim\"]\n    dropout = config.get(\"dropout\", 0)\n    kernel_size = config.get(\"kernel_size\", 2)\n    stride = config.get(\"stride\", 2)\n    padding = config.get(\"padding\", 1)\n\n    self.latent_dim = latent_dim\n\n    self.encoder = Encoder(\n        input_encoding=self.encodings,\n        encoded_size=encoded_size,\n        in_shape=self.in_shape,\n        hidden_layers=hidden_layers,\n        dropout=dropout,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n    )\n    self.decoder = Decoder(\n        encoded_size=encoded_size,\n        target_shapes=self.encoder.shapes,\n        dropout=dropout,\n        kernel_size=kernel_size,\n        stride=stride,\n        padding=padding,\n    )\n    self.fc_mu = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_var = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_hidden = nn.Linear(latent_dim, self.encoder.flat_size)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_cnn1d/#caveat.models.sequence.vae_sequence_cnn1d.VAESeqCNN1D.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_cnn1d.py</code> <pre><code>def decode(self, z: Tensor, target=None, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    hidden = self.fc_hidden(z)\n    hidden = hidden.view(self.encoder.shape_before_flattening)\n    log_probs = self.decoder(hidden)\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_fc/","title":"caveat.models.sequence.vae_sequence_fc","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Decoder","title":"<code>Decoder(length, in_size, encoded_size, hidden_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d flatten to 1d then fully connected.</p> PARAMETER DESCRIPTION <code>length</code> <p>number of time steps.</p> <p> TYPE: <code>int</code> </p> <code>in_size</code> <p>input size.</p> <p> TYPE: <code>int</code> </p> <code>encoded_size</code> <p>list of target shapes from encoder.</p> <p> TYPE: <code>list</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_fc.py</code> <pre><code>def __init__(\n    self,\n    length: int,\n    in_size: int,\n    encoded_size: int,\n    hidden_layers: list,\n    dropout: float = 0.1,\n):\n    \"\"\"2d flatten to 1d then fully connected.\n\n    Args:\n        length (int): number of time steps.\n        in_size (int): input size.\n        encoded_size (list): list of target shapes from encoder.\n        hidden_layers (list, optional): _description_. Defaults to None.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.length = length\n    self.hidden_size = encoded_size\n    hidden_layers.reverse()\n    modules = []\n\n    input_size = in_size\n    for i in range(len(hidden_layers)):\n        hidden_channels = hidden_layers[i]\n        size = length * hidden_channels\n        block = [nn.Linear(input_size, size), nn.BatchNorm1d(size)]\n        if i &lt; len(hidden_layers) - 1:\n            block.append(nn.LeakyReLU())\n            block.append(nn.Dropout(dropout))\n        modules.append(nn.Sequential(*block))\n        input_size = size\n\n    # Final layer\n    modules.append(nn.Linear(input_size, length * encoded_size))\n\n    self.dropout = nn.Dropout(dropout)\n    self.decoder = nn.Sequential(*modules)\n    self.logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Decoder.decoder","title":"<code>decoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Decoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Decoder.hidden_size","title":"<code>hidden_size = encoded_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Decoder.length","title":"<code>length = length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Decoder.logprob_activation","title":"<code>logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Decoder.forward","title":"<code>forward(hidden, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_fc.py</code> <pre><code>def forward(self, hidden, **kwargs):\n    y = self.decoder(hidden)\n    y = y.view(-1, self.length, self.hidden_size)\n    acts_logits, durations = torch.split(\n        y, [self.hidden_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.logprob_activation(acts_logits)\n    durations = self.duration_activation(durations)\n    durations = torch.log(durations)\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Encoder","title":"<code>Encoder(length, encoded_size, hidden_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>2d flatten to 1d then fully connected.</p> PARAMETER DESCRIPTION <code>length</code> <p>number of time steps.</p> <p> TYPE: <code>int</code> </p> <code>encoded_size</code> <p>number of encoding classes and hidden size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_layers</code> <p>description. Defaults to None.</p> <p> TYPE: <code>list</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_fc.py</code> <pre><code>def __init__(\n    self,\n    length: int,\n    encoded_size: int,\n    hidden_layers: list,\n    dropout: float = 0.1,\n):\n    \"\"\"2d flatten to 1d then fully connected.\n\n    Args:\n        length (int): number of time steps.\n        encoded_size (int): number of encoding classes and hidden size.\n        hidden_layers (list, optional): _description_. Defaults to None.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.embedding = CustomDurationEmbeddingConcat(\n        encoded_size, encoded_size, dropout=dropout\n    )\n    modules = []\n\n    input_size = length * encoded_size\n    self.flat_embed_size = input_size\n    for hidden_channels in hidden_layers:\n        size = length * hidden_channels\n        modules.append(\n            nn.Sequential(\n                nn.Linear(input_size, size),\n                nn.BatchNorm1d(size),\n                nn.LeakyReLU(),\n                nn.Dropout(dropout),\n            )\n        )\n        input_size = size\n    self.flat_size = size\n    self.dropout = nn.Dropout(dropout)\n    self.encoder = nn.Sequential(*modules)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Encoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(encoded_size, encoded_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Encoder.encoder","title":"<code>encoder = nn.Sequential(*modules)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Encoder.flat_embed_size","title":"<code>flat_embed_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Encoder.flat_size","title":"<code>flat_size = size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_fc.py</code> <pre><code>def forward(self, x):\n    y = self.dropout(self.embedding(x.int()))\n    y = y.flatten(1)\n    y = self.encoder(y)\n    return y\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.VAESeqFC","title":"<code>VAESeqFC(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>Fully connected encoder and decoder with embedding layer.</p> Source code in <code>caveat/models/sequence/vae_sequence_fc.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"Fully connected encoder and decoder with embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.VAESeqFC.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_fc.py</code> <pre><code>def build(self, **config):\n    hidden_layers = list\n    latent_dim = int\n    dropout = Optional[float]\n\n    encoded_size = self.encodings + 1\n    hidden_layers = utils.build_hidden_layers(config)\n    latent_dim = config[\"latent_dim\"]\n    dropout = config.get(\"dropout\", 0)\n    self.latent_dim = latent_dim\n\n    self.encoder = Encoder(\n        length=self.in_shape[0],\n        encoded_size=encoded_size,\n        hidden_layers=hidden_layers,\n        dropout=dropout,\n    )\n    self.decoder = Decoder(\n        length=self.in_shape[0],\n        in_size=self.encoder.flat_size,\n        encoded_size=encoded_size,\n        hidden_layers=hidden_layers,\n        dropout=dropout,\n    )\n    self.fc_mu = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_var = nn.Linear(self.encoder.flat_size, latent_dim)\n    self.fc_hidden = nn.Linear(latent_dim, self.encoder.flat_size)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_fc/#caveat.models.sequence.vae_sequence_fc.VAESeqFC.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_fc.py</code> <pre><code>def decode(self, z: Tensor, target=None, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    hidden = self.fc_hidden(z)\n    log_probs = self.decoder(hidden)\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/","title":"caveat.models.sequence.vae_sequence_lstm","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder","title":"<code>Decoder(input_size, hidden_size, output_size, num_layers, max_length, dropout=0.0, sos=0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Decoder with teacher forcing.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>max length of sequences.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout probability. Defaults to 0.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.0</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size,\n    hidden_size,\n    output_size,\n    num_layers,\n    max_length,\n    dropout: float = 0.0,\n    sos: int = 0,\n):\n    \"\"\"LSTM Decoder with teacher forcing.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        max_length (int): max length of sequences.\n        dropout (float): dropout probability. Defaults to 0.\n    \"\"\"\n    super(Decoder, self).__init__()\n    self.current_device = current_device()\n    self.input_size = input_size\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.max_length = max_length\n    self.sos = sos\n\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.fc = nn.Linear(hidden_size, output_size)\n    self.activity_prob_activation = nn.Softmax(dim=-1)\n    self.activity_logprob_activation = nn.LogSoftmax(dim=-1)\n    self.duration_activation = nn.Sigmoid()\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.activity_logprob_activation","title":"<code>activity_logprob_activation = nn.LogSoftmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.activity_prob_activation","title":"<code>activity_prob_activation = nn.Softmax(dim=-1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.current_device","title":"<code>current_device = current_device()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.duration_activation","title":"<code>duration_activation = nn.Sigmoid()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.fc","title":"<code>fc = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.input_size","title":"<code>input_size = input_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.output_size","title":"<code>output_size = output_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.forward","title":"<code>forward(batch_size, hidden, target=None, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def forward(self, batch_size, hidden, target=None, **kwargs):\n    hidden, cell = hidden\n    decoder_input = torch.zeros(batch_size, 1, 2, device=hidden.device)\n    decoder_input[:, :, 0] = self.sos  # set as SOS\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    outputs = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden = self.forward_step(\n            decoder_input, decoder_hidden\n        )\n        outputs.append(decoder_output.squeeze(-2))\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    outputs = torch.stack(outputs).permute(1, 0, 2)  # [N, steps, acts]\n\n    acts_logits, durations = torch.split(\n        outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = self.duration_activation(durations)\n    durations = torch.log(durations)\n\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    return log_prob_outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.forward_step","title":"<code>forward_step(x, hidden)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def forward_step(self, x, hidden):\n    # [N, 1, 2]\n    embedded = self.embedding(x)\n    output, hidden = self.lstm(embedded, hidden)\n    prediction = self.fc(output)\n    # [N, 1, encodings+1]\n    return prediction, hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Decoder.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    _, topi = acts.topk(1)\n    act = (\n        topi.squeeze(-1).detach().unsqueeze(-1)\n    )  # detach from history as input\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Encoder","title":"<code>Encoder(input_size, hidden_size, num_layers, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> <p>LSTM Encoder.</p> PARAMETER DESCRIPTION <code>input_size</code> <p>lstm input size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>lstm hidden size.</p> <p> TYPE: <code>int</code> </p> <code>num_layers</code> <p>number of lstm layers.</p> <p> TYPE: <code>int</code> </p> <code>dropout</code> <p>dropout. Defaults to 0.1.</p> <p> TYPE: <code>float</code> DEFAULT: <code>0.1</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    num_layers: int,\n    dropout: float = 0.1,\n):\n    \"\"\"LSTM Encoder.\n\n    Args:\n        input_size (int): lstm input size.\n        hidden_size (int): lstm hidden size.\n        num_layers (int): number of lstm layers.\n        dropout (float): dropout. Defaults to 0.1.\n    \"\"\"\n    super(Encoder, self).__init__()\n    self.hidden_size = hidden_size\n    self.num_layers = num_layers\n    self.embedding = CustomDurationEmbeddingConcat(\n        input_size, hidden_size, dropout=dropout\n    )\n    self.lstm = nn.LSTM(\n        hidden_size,\n        hidden_size,\n        num_layers,\n        batch_first=True,\n        bidirectional=False,\n    )\n    self.norm = nn.LayerNorm(hidden_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Encoder.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Encoder.embedding","title":"<code>embedding = CustomDurationEmbeddingConcat(input_size, hidden_size, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Encoder.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Encoder.lstm","title":"<code>lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Encoder.norm","title":"<code>norm = nn.LayerNorm(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Encoder.num_layers","title":"<code>num_layers = num_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.Encoder.forward","title":"<code>forward(x)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def forward(self, x):\n    embedded = self.embedding(x)\n    _, (h1, h2) = self.lstm(embedded)\n    # ([layers, N, C (output_size)], [layers, N, C (output_size)])\n    h1 = self.norm(h1)\n    h2 = self.norm(h2)\n    hidden = torch.cat((h1, h2)).permute(1, 0, 2).flatten(start_dim=1)\n    # [N, flatsize]\n    return hidden\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.VAESeqLSTM","title":"<code>VAESeqLSTM(*args, **kwargs)</code>","text":"<p>               Bases: <code>Base</code></p> <p>RNN based encoder and decoder with encoder embedding layer.</p> Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.VAESeqLSTM.build","title":"<code>build(**config)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def build(self, **config):\n    self.latent_dim = config[\"latent_dim\"]\n    self.hidden_size = config[\"hidden_size\"]\n    self.hidden_n = config[\"hidden_n\"]\n    self.dropout = config[\"dropout\"]\n    length, _ = self.in_shape\n\n    self.encoder = Encoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        num_layers=self.hidden_n,\n        dropout=self.dropout,\n    )\n    self.decoder = Decoder(\n        input_size=self.encodings,\n        hidden_size=self.hidden_size,\n        output_size=self.encodings + 1,\n        num_layers=self.hidden_n,\n        max_length=length,\n        dropout=self.dropout,\n        sos=self.sos,\n    )\n    self.unflattened_shape = (2 * self.hidden_n, self.hidden_size)\n    flat_size_encode = self.hidden_n * self.hidden_size * 2\n    self.fc_mu = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, self.latent_dim)\n    self.fc_hidden = nn.Linear(self.latent_dim, flat_size_encode)\n\n    if config.get(\"share_embed\", False):\n        self.decoder.embedding.weight = self.encoder.embedding.weight\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.VAESeqLSTM.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def decode(self, z: Tensor, target=None, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(1, (2 * self.hidden_n, self.hidden_size)).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_n\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.VAE_LSTM_Unweighted","title":"<code>VAE_LSTM_Unweighted(*args, **kwargs)</code>","text":"<p>               Bases: <code>VAESeqLSTM</code></p> Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"RNN based encoder and decoder with encoder embedding layer.\"\"\"\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_lstm/#caveat.models.sequence.vae_sequence_lstm.VAE_LSTM_Unweighted.loss_function","title":"<code>loss_function(log_probs, input, mu, log_var, mask, **kwargs)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_lstm.py</code> <pre><code>def loss_function(\n    self,\n    log_probs: Tensor,\n    input: Tensor,\n    mu: Tensor,\n    log_var: Tensor,\n    mask: Tensor,\n    **kwargs,\n) -&gt; dict:\n    return self.unweighted_seq_loss(\n        log_probs, input, mu, log_var, mask, **kwargs\n    )\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/","title":"caveat.models.sequence.vae_sequence_transformer","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN","title":"<code>AttnDecoderRNN(input_size, hidden_size, output_size, max_length, sos, dropout=0.1)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def __init__(\n    self,\n    input_size: int,\n    hidden_size: int,\n    output_size: int,\n    max_length: int,\n    sos: int,\n    dropout: float = 0.1,\n):\n    super(AttnDecoderRNN, self).__init__()\n    self.max_length = max_length\n    self.sos = sos\n    self.embedding = nn.Embedding(input_size, hidden_size - 1)\n    self.attention = BahdanauAttention(hidden_size)\n    self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n    self.out = nn.Linear(hidden_size, output_size)\n    self.dropout = nn.Dropout(dropout)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN.attention","title":"<code>attention = BahdanauAttention(hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN.dropout","title":"<code>dropout = nn.Dropout(dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN.embedding","title":"<code>embedding = nn.Embedding(input_size, hidden_size - 1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN.gru","title":"<code>gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN.max_length","title":"<code>max_length = max_length</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN.out","title":"<code>out = nn.Linear(hidden_size, output_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN.sos","title":"<code>sos = sos</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN.forward","title":"<code>forward(batch_size, encoder_outputs, encoder_hidden, target=None)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def forward(self, batch_size, encoder_outputs, encoder_hidden, target=None):\n    decoder_input = torch.zeros(\n        batch_size, 1, 2, dtype=torch.long, device=self.current_device\n    )\n    decoder_input[:, :, 0] = self.sos\n    hidden, cell = encoder_hidden\n    hidden = hidden.contiguous()\n    cell = cell.contiguous()\n    decoder_hidden = (hidden, cell)\n    decoder_outputs = []\n    attentions = []\n\n    for i in range(self.max_length):\n        decoder_output, decoder_hidden, attn_weights = self.forward_step(\n            decoder_input, decoder_hidden, encoder_outputs\n        )\n        decoder_outputs.append(decoder_output.squeeze())\n        attentions.append(attn_weights.squeeze())\n\n        if target is not None:\n            # teacher forcing for next step\n            decoder_input = target[:, i : i + 1, :]  # (slice maintains dim)\n        else:\n            # no teacher forcing use decoder output\n            decoder_input = self.pack(decoder_output)\n\n    decoder_outputs = torch.stack(decoder_outputs).permute(\n        1, 0, 2\n    )  # [N, steps, acts]\n    attentions = torch.stack(attentions).permute(\n        1, 0, 2\n    )  # [N, steps, encodings]\n\n    acts_logits, durations = torch.split(\n        decoder_outputs, [self.output_size - 1, 1], dim=-1\n    )\n    acts_log_probs = self.activity_logprob_activation(acts_logits)\n    durations = self.duration_activation(durations)\n    log_prob_outputs = torch.cat((acts_log_probs, durations), dim=-1)\n\n    decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n\n    return log_prob_outputs, decoder_hidden, attentions\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN.forward_step","title":"<code>forward_step(input, hidden, encoder_outputs)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def forward_step(self, input, hidden, encoder_outputs):\n    # input: [N, 1, 2]\n    embedded, durations = torch.split(input, [1, 1], dim=-1)\n    embedded = self.dropout(self.embedding(embedded.int())).squeeze(-2)\n    embedded = torch.cat((embedded, durations), dim=-1)\n\n    query = hidden.permute(1, 0, 2)\n    context, attn_weights = self.attention(query, encoder_outputs)\n    input_gru = torch.cat((embedded, context), dim=2)\n\n    output, hidden = self.gru(input_gru, hidden)\n    output = self.out(output)\n\n    return output, hidden, attn_weights\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.AttnDecoderRNN.pack","title":"<code>pack(x)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def pack(self, x):\n    # [N, 1, encodings+1]\n    acts, duration = torch.split(x, [self.output_size - 1, 1], dim=-1)\n    _, topi = acts.topk(1)\n    act = (\n        topi.squeeze(-1).detach().unsqueeze(-1)\n    )  # detach from history as input\n    duration = self.duration_activation(duration)\n    outputs = torch.cat((act, duration), dim=-1)\n    # [N, 1, 2]\n    return outputs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.BahdanauAttention","title":"<code>BahdanauAttention(hidden_size)</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def __init__(self, hidden_size):\n    super(BahdanauAttention, self).__init__()\n    self.Wa = nn.Linear(hidden_size, hidden_size)\n    self.Ua = nn.Linear(hidden_size, hidden_size)\n    self.Va = nn.Linear(hidden_size, 1)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.BahdanauAttention.Ua","title":"<code>Ua = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.BahdanauAttention.Va","title":"<code>Va = nn.Linear(hidden_size, 1)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.BahdanauAttention.Wa","title":"<code>Wa = nn.Linear(hidden_size, hidden_size)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.BahdanauAttention.forward","title":"<code>forward(query, keys)</code>","text":"Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def forward(self, query, keys):\n    scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n    scores = scores.squeeze(2).unsqueeze(1)\n\n    weights = F.softmax(scores, dim=-1)\n    context = torch.bmm(weights, keys)\n\n    return context, weights\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer","title":"<code>Transformer(in_shape, latent_dim, hidden_layers, hidden_size, teacher_forcing_ratio, encodings, encoding_weights, dropout=0.1, **kwargs)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Seq to seq via VAE model.</p> PARAMETER DESCRIPTION <code>in_shape</code> <p>[time_step, activity one-hot encoding].</p> <p> TYPE: <code>tuple[int, int]</code> </p> <code>latent_dim</code> <p>Latent space size.</p> <p> TYPE: <code>int</code> </p> <code>hidden_layers</code> <p>Lstm  layers in encoder and decoder.</p> <p> TYPE: <code>int</code> </p> <code>hidden_size</code> <p>Size of lstm layers.</p> <p> TYPE: <code>int</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def __init__(\n    self,\n    in_shape: tuple[int, int],\n    latent_dim: int,\n    hidden_layers: int,\n    hidden_size: int,\n    teacher_forcing_ratio: float,\n    encodings: int,\n    encoding_weights: Optional[Tensor],\n    dropout: float = 0.1,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Seq to seq via VAE model.\n\n    Args:\n        in_shape (tuple[int, int]): [time_step, activity one-hot encoding].\n        latent_dim (int): Latent space size.\n        hidden_layers (int): Lstm  layers in encoder and decoder.\n        hidden_size (int): Size of lstm layers.\n    \"\"\"\n    super(Transformer, self).__init__()\n    self.steps, self.width = in_shape\n    self.hidden_layers = hidden_layers\n    self.hidden_size = hidden_size\n    self.latent_dim = latent_dim\n    self.teacher_forcing_ratio = teacher_forcing_ratio\n    self.encodings = encodings\n    self.encoding_weights = encoding_weights\n\n    if (\n        kwargs.get(\"weighted_loss\") is not False\n    ):  # default to use weightings\n        if encoding_weights is None:\n            raise ValueError(\n                \"weighted_loss is True but encoding_weights is None\"\n            )\n        self.NLLL = nn.NLLLoss(weight=encoding_weights)\n    else:\n        self.NLLL = nn.NLLLoss(weight=None)\n    self.MSE = nn.MSELoss()\n    self.hamming = MulticlassHammingDistance(\n        num_classes=encodings, average=\"micro\"\n    )\n\n    self.use_mask = kwargs.get(\"use_mask\", True)  # deafult to use mask\n\n    self.encoder = Encoder(\n        input_size=encodings,\n        hidden_size=self.hidden_size,\n        num_layers=hidden_layers,\n        dropout=dropout,\n    )\n    self.decoder = AttnDecoderRNN(\n        input_size=encodings,\n        hidden_size=self.hidden_size,\n        output_size=encodings + 1,  # act encoding plus one for duration\n        max_length=self.steps,\n        sos=0,\n    )\n    flat_size_encode = self.hidden_layers * self.hidden_size * 2\n    self.fc_mu = nn.Linear(flat_size_encode, latent_dim)\n    self.fc_var = nn.Linear(flat_size_encode, latent_dim)\n    self.fc_hidden = nn.Linear(latent_dim, flat_size_encode)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.MSE","title":"<code>MSE = nn.MSELoss()</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.NLLL","title":"<code>NLLL = nn.NLLLoss(weight=encoding_weights)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.decoder","title":"<code>decoder = AttnDecoderRNN(input_size=encodings, hidden_size=self.hidden_size, output_size=encodings + 1, max_length=self.steps, sos=0)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.encoder","title":"<code>encoder = Encoder(input_size=encodings, hidden_size=self.hidden_size, num_layers=hidden_layers, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.encoding_weights","title":"<code>encoding_weights = encoding_weights</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.encodings","title":"<code>encodings = encodings</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.fc_hidden","title":"<code>fc_hidden = nn.Linear(latent_dim, flat_size_encode)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.fc_mu","title":"<code>fc_mu = nn.Linear(flat_size_encode, latent_dim)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.fc_var","title":"<code>fc_var = nn.Linear(flat_size_encode, latent_dim)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.hamming","title":"<code>hamming = MulticlassHammingDistance(num_classes=encodings, average='micro')</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.hidden_layers","title":"<code>hidden_layers = hidden_layers</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.hidden_size","title":"<code>hidden_size = hidden_size</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.latent_dim","title":"<code>latent_dim = latent_dim</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.teacher_forcing_ratio","title":"<code>teacher_forcing_ratio = teacher_forcing_ratio</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.use_mask","title":"<code>use_mask = kwargs.get('use_mask', True)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.decode","title":"<code>decode(z, target=None, **kwargs)</code>","text":"<p>Decode latent sample to batch of output sequences.</p> PARAMETER DESCRIPTION <code>z</code> <p>Latent space batch [N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Output sequence batch [N, steps, acts].</p> <p> TYPE: <code>Tuple[Tensor, Tensor]</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def decode(self, z: Tensor, target=None, **kwargs) -&gt; Tuple[Tensor, Tensor]:\n    \"\"\"Decode latent sample to batch of output sequences.\n\n    Args:\n        z (tensor): Latent space batch [N, latent_dims].\n\n    Returns:\n        tensor: Output sequence batch [N, steps, acts].\n    \"\"\"\n    # initialize hidden state as inputs\n    h = self.fc_hidden(z)\n\n    # initialize hidden state\n    hidden = h.unflatten(\n        1, (2 * self.hidden_layers, self.hidden_size)\n    ).permute(\n        1, 0, 2\n    )  # ([2xhidden, N, layers])\n    hidden = hidden.split(\n        self.hidden_layers\n    )  # ([hidden, N, layers, [hidden, N, layers]])\n    batch_size = z.shape[0]\n\n    if target is not None and torch.rand(1) &lt; self.teacher_forcing_ratio:\n        # use teacher forcing\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=target\n        )\n    else:\n        log_probs = self.decoder(\n            batch_size=batch_size, hidden=hidden, target=None\n        )\n\n    return log_probs\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.encode","title":"<code>encode(input)</code>","text":"<p>Encodes the input by passing through the encoder network.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequence batch [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>list[Tensor]</code> <p>list[tensor]: Latent layer input (means and variances) [N, latent_dims].</p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def encode(self, input: Tensor) -&gt; list[Tensor]:\n    \"\"\"Encodes the input by passing through the encoder network.\n\n    Args:\n        input (tensor): Input sequence batch [N, steps, acts].\n\n    Returns:\n        list[tensor]: Latent layer input (means and variances) [N, latent_dims].\n    \"\"\"\n    # batch_size, seq_len, feature_dim = x.shape\n    hidden = self.encoder(input)\n    # flatten last hidden cell layer\n    flat = torch.cat(hidden).permute(1, 0, 2).flatten(start_dim=1)\n\n    # Split the result into mu and var components\n    # of the latent Gaussian distribution\n    mu = self.fc_mu(flat)\n    log_var = self.fc_var(flat)\n\n    return [mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.forward","title":"<code>forward(x, target=None, **kwargs)</code>","text":"<p>Forward pass, also return latent parameterization.</p> PARAMETER DESCRIPTION <code>x</code> <p>Input sequences [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>List[Tensor]</code> <p>list[tensor]: [Output [N, steps, acts], Input [N, steps, acts], mu [N, latent_dims], var [N, latent_dims]].</p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def forward(self, x: Tensor, target=None, **kwargs) -&gt; List[Tensor]:\n    \"\"\"Forward pass, also return latent parameterization.\n\n    Args:\n        x (tensor): Input sequences [N, steps, acts].\n\n    Returns:\n        list[tensor]: [Output [N, steps, acts], Input [N, steps, acts], mu [N, latent_dims], var [N, latent_dims]].\n    \"\"\"\n    mu, log_var = self.encode(x)\n    z = self.reparameterize(mu, log_var)\n    log_prob_y, prob_y = self.decode(z, target=target)\n    return [log_prob_y, prob_y, x, mu, log_var]\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.generate","title":"<code>generate(x, current_device, **kwargs)</code>","text":"<p>Given an encoder input, return reconstructed output.</p> PARAMETER DESCRIPTION <code>x</code> <p>[N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def generate(self, x: Tensor, current_device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given an encoder input, return reconstructed output.\n\n    Args:\n        x (tensor): [N, steps, acts].\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    prob_samples = self.forward(x)[1]\n    prob_samples = prob_samples.to(current_device)\n    return prob_samples\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.loss_function","title":"<code>loss_function(log_probs, _, input, mu, log_var, mask, **kwargs)</code>","text":"<p>Computes the VAE loss function.</p> <p>Splits the input into activity and duration, and the recons into activity and duration.</p> RETURNS DESCRIPTION <code>dict</code> <p>Losses.</p> <p> TYPE: <code>dict</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def loss_function(\n    self, log_probs, _, input, mu, log_var, mask, **kwargs\n) -&gt; dict:\n    r\"\"\"Computes the VAE loss function.\n\n    Splits the input into activity and duration, and the recons into activity and duration.\n\n    Returns:\n        dict: Losses.\n    \"\"\"\n\n    kld_weight = kwargs[\"kld_weight\"]\n    duration_weight = kwargs[\"duration_weight\"]\n\n    # unpack act probs and durations\n    target_acts, target_durations = self.unpack_encoding(input)\n    pred_acts, pred_durations = self.unpack_encoding(log_probs)\n\n    if self.use_mask:  # default is to use masking\n        flat_mask = mask.view(-1).bool()\n    else:\n        flat_mask = torch.ones_like(target_acts).view(-1).bool()\n\n    # activity encodng\n    recon_acts_nlll = self.NLLL(\n        pred_acts.view(-1, self.encodings)[flat_mask],\n        target_acts.view(-1).long()[flat_mask],\n    )\n\n    # duration encodng\n    recon_dur_mse = duration_weight * self.MSE(\n        pred_durations.view(-1)[flat_mask],\n        target_durations.view(-1)[flat_mask],\n    )\n\n    # combined\n    recons_loss = recon_acts_nlll + recon_dur_mse\n\n    recon_argmax = torch.argmax(pred_acts, dim=-1)\n    recons_ham_loss = self.hamming(\n        recon_argmax, target_acts.squeeze().long()\n    )\n\n    kld_loss = kld_weight * torch.mean(\n        -0.5 * torch.sum(1 + log_var - mu**2 - log_var.exp(), dim=1), dim=0\n    )\n\n    loss = recons_loss + kld_loss\n    return {\n        \"loss\": loss,\n        \"recon_loss\": recons_loss.detach(),\n        \"recon_act_loss\": recon_acts_nlll.detach(),\n        \"recon_dur_loss\": recon_dur_mse.detach(),\n        \"recons_ham_loss\": recons_ham_loss.detach(),\n        \"KLD\": kld_loss.detach(),\n    }\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.pack_encoding","title":"<code>pack_encoding(acts, durations)</code>","text":"<p>Pack the activity and duration into input.</p> PARAMETER DESCRIPTION <code>acts</code> <p>Activity [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> <code>durations</code> <p>Duration [N, steps, 1].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>Input sequences [N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def pack_encoding(self, acts: Tensor, durations: Tensor) -&gt; Tensor:\n    \"\"\"Pack the activity and duration into input.\n\n    Args:\n        acts (tensor): Activity [N, steps, acts].\n        durations (tensor): Duration [N, steps, 1].\n\n    Returns:\n        tensor: Input sequences [N, steps, acts].\n    \"\"\"\n    return torch.cat((acts, durations), dim=-1)\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.predict","title":"<code>predict(z, current_device, **kwargs)</code>","text":"<p>Given samples from the latent space, return the corresponding decoder space map.</p> PARAMETER DESCRIPTION <code>z</code> <p>[N, latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>current_device</code> <p>Device to run the model.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N, steps, acts].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def predict(self, z: Tensor, current_device: int, **kwargs) -&gt; Tensor:\n    \"\"\"Given samples from the latent space, return the corresponding decoder space map.\n\n    Args:\n        z (tensor): [N, latent_dims].\n        current_device (int): Device to run the model.\n\n    Returns:\n        tensor: [N, steps, acts].\n    \"\"\"\n    z = z.to(current_device)\n    prob_samples = self.decode(z)[1]\n    return prob_samples\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.reparameterize","title":"<code>reparameterize(mu, logvar)</code>","text":"<p>Reparameterization trick to sample from N(mu, var) from N(0,1).</p> PARAMETER DESCRIPTION <code>mu</code> <p>Mean of the latent Gaussian [N x latent_dims].</p> <p> TYPE: <code>tensor</code> </p> <code>logvar</code> <p>Standard deviation of the latent Gaussian [N x latent_dims].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>[N x latent_dims].</p> <p> TYPE: <code>Tensor</code> </p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def reparameterize(self, mu: Tensor, logvar: Tensor) -&gt; Tensor:\n    \"\"\"Reparameterization trick to sample from N(mu, var) from N(0,1).\n\n    Args:\n        mu (tensor): Mean of the latent Gaussian [N x latent_dims].\n        logvar (tensor): Standard deviation of the latent Gaussian [N x latent_dims].\n\n    Returns:\n        tensor: [N x latent_dims].\n    \"\"\"\n    std = torch.exp(0.5 * logvar)\n    eps = torch.randn_like(std)\n    return eps * std + mu\n</code></pre>"},{"location":"reference/caveat/models/sequence/vae_sequence_transformer/#caveat.models.sequence.vae_sequence_transformer.Transformer.unpack_encoding","title":"<code>unpack_encoding(input)</code>","text":"<p>Split the input into activity and duration.</p> PARAMETER DESCRIPTION <code>input</code> <p>Input sequences [N, steps, acts].</p> <p> TYPE: <code>tensor</code> </p> RETURNS DESCRIPTION <code>tuple[Tensor, Tensor]</code> <p>tuple[tensor, tensor]: [activity [N, steps, acts], duration [N, steps, 1]].</p> Source code in <code>caveat/models/sequence/vae_sequence_transformer.py</code> <pre><code>def unpack_encoding(self, input: Tensor) -&gt; tuple[Tensor, Tensor]:\n    \"\"\"Split the input into activity and duration.\n\n    Args:\n        input (tensor): Input sequences [N, steps, acts].\n\n    Returns:\n        tuple[tensor, tensor]: [activity [N, steps, acts], duration [N, steps, 1]].\n    \"\"\"\n    acts = input[:, :, :-1].contiguous()\n    durations = input[:, :, -1:].contiguous()\n    return acts, durations\n</code></pre>"},{"location":"reference/caveat/models/utils/","title":"caveat.models.utils","text":""},{"location":"reference/caveat/models/utils/#caveat.models.utils.ScheduledOptim","title":"<code>ScheduledOptim(optimizer, lr_mul, d_model, n_warmup_steps)</code>","text":"<p>               Bases: <code>_LRScheduler</code></p> <p>A simple wrapper class for learning rate scheduling</p> Source code in <code>caveat/models/utils.py</code> <pre><code>def __init__(self, optimizer, lr_mul, d_model, n_warmup_steps):\n    self.optimizer = optimizer\n    self.lr_mul = lr_mul\n    self.d_model = d_model\n    self.n_warmup_steps = n_warmup_steps\n    self.n_steps = 0\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.ScheduledOptim.d_model","title":"<code>d_model = d_model</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/utils/#caveat.models.utils.ScheduledOptim.lr_mul","title":"<code>lr_mul = lr_mul</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/utils/#caveat.models.utils.ScheduledOptim.n_steps","title":"<code>n_steps = 0</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/utils/#caveat.models.utils.ScheduledOptim.n_warmup_steps","title":"<code>n_warmup_steps = n_warmup_steps</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/utils/#caveat.models.utils.ScheduledOptim.optimizer","title":"<code>optimizer = optimizer</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/models/utils/#caveat.models.utils.ScheduledOptim.step","title":"<code>step()</code>","text":"<p>Step with the inner optimizer</p> Source code in <code>caveat/models/utils.py</code> <pre><code>def step(self):\n    \"Step with the inner optimizer\"\n    self._update_learning_rate()\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.build_hidden_layers","title":"<code>build_hidden_layers(config)</code>","text":"<p>Build hidden layer sizes from config.</p> PARAMETER DESCRIPTION <code>config</code> <p>Configuration dictionary containing hidden layer parameters.</p> <p> TYPE: <code>dict</code> </p> RAISES DESCRIPTION <code>ValueError</code> <p>If both hidden_layers and hidden_n/hidden_size are specified.</p> <code>ValueError</code> <p>If hidden_layers is not a list.</p> <code>ValueError</code> <p>If hidden_layers contains non-integer values.</p> <code>ValueError</code> <p>If neither hidden_layers nor hidden_n/hidden_size are specified.</p> RETURNS DESCRIPTION <code>list</code> <p>List of hidden layer sizes.</p> <p> TYPE: <code>list</code> </p> Source code in <code>caveat/models/utils.py</code> <pre><code>def build_hidden_layers(config: dict) -&gt; list:\n    \"\"\"\n    Build hidden layer sizes from config.\n\n    Args:\n        config (dict): Configuration dictionary containing hidden layer parameters.\n\n    Raises:\n        ValueError: If both hidden_layers and hidden_n/hidden_size are specified.\n        ValueError: If hidden_layers is not a list.\n        ValueError: If hidden_layers contains non-integer values.\n        ValueError: If neither hidden_layers nor hidden_n/hidden_size are specified.\n\n    Returns:\n        list: List of hidden layer sizes.\n    \"\"\"\n    hidden_layers = config.get(\"hidden_layers\", None)\n    hidden_n = config.get(\"hidden_n\", None)\n    hidden_size = config.get(\"hidden_size\", None)\n    if hidden_layers is not None:\n        if hidden_n is not None or hidden_size is not None:\n            raise ValueError(\n                \"Cannot specify hidden_layers and layer_n or layer_size\"\n            )\n        if not isinstance(hidden_layers, list):\n            raise ValueError(\"hidden_layers must be a list\")\n        for layer in hidden_layers:\n            if not isinstance(layer, int):\n                raise ValueError(\"hidden_layers must be a list of integers\")\n        return hidden_layers\n    if hidden_n is not None and hidden_size is not None:\n        return [int(hidden_size)] * int(hidden_n)\n    raise ValueError(\"Must specify hidden_layers or layer_n and layer_size\")\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.calc_output_padding_1d","title":"<code>calc_output_padding_1d(length, target, kernel_size, stride, padding, patience=20)</code>","text":"<p>Calculate the output padding required for a 1D transposed convolution to achieve a target length. This function iterates over possible padding values and output padding values to find a combination that results in the desired target length after a 1D transposed convolution. Args:     length (int): The length of the input.     target (int): The desired length of the output.     kernel_size (int): The size of the convolution kernel.     stride (int): The stride of the convolution.     padding (int): The initial padding value.     patience (int, optional): The maximum number of iterations to try for padding and output padding. Default is 20. Returns:     tuple: A tuple containing the padding and output padding values that achieve the target length. Raises:     ValueError: If no combination of padding and output padding can achieve the target length within the given patience.</p> Source code in <code>caveat/models/utils.py</code> <pre><code>def calc_output_padding_1d(\n    length: int,\n    target: int,\n    kernel_size: int,\n    stride: int,\n    padding: int,\n    patience: int = 20,\n) -&gt; int:\n    \"\"\"\n    Calculate the output padding required for a 1D transposed convolution to achieve a target length.\n    This function iterates over possible padding values and output padding values to find a combination\n    that results in the desired target length after a 1D transposed convolution.\n    Args:\n        length (int): The length of the input.\n        target (int): The desired length of the output.\n        kernel_size (int): The size of the convolution kernel.\n        stride (int): The stride of the convolution.\n        padding (int): The initial padding value.\n        patience (int, optional): The maximum number of iterations to try for padding and output padding. Default is 20.\n    Returns:\n        tuple: A tuple containing the padding and output padding values that achieve the target length.\n    Raises:\n        ValueError: If no combination of padding and output padding can achieve the target length within the given patience.\n    \"\"\"\n\n    for pad in range(padding, padding + patience):\n        for i in range(patience):\n            if transconv_size_1d(length, kernel_size, stride, pad, i) == target:\n                if pad != padding:\n                    print(\n                        f\"Changed padding from {padding} to {pad} for target {target}.\"\n                    )\n                return pad, i\n    raise ValueError(\n        f\"\"\"Could not find input and output padding combination for target {target},\n        length {length}, kernel_size {kernel_size}, stride {stride}, padding {padding}.\n    \"\"\"\n    )\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.calc_output_padding_2d","title":"<code>calc_output_padding_2d(size)</code>","text":"<p>Calculate output padding for a transposed convolution such that output dims will match dimensions of inputs to a convolution of given size. For each dimension, padding is set to 1 if even size, otherwise 0.</p> PARAMETER DESCRIPTION <code>size</code> <p>input size (h, w)</p> <p> TYPE: <code>Union[tuple[int, int, int], int]</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: required padding</p> Source code in <code>caveat/models/utils.py</code> <pre><code>def calc_output_padding_2d(size: Union[tuple[int, int, int], int]) -&gt; np.array:\n    \"\"\"Calculate output padding for a transposed convolution such that output dims will\n    match dimensions of inputs to a convolution of given size.\n    For each dimension, padding is set to 1 if even size, otherwise 0.\n\n    Args:\n        size (Union[tuple[int, int, int], int]): input size (h, w)\n\n    Returns:\n        np.array: required padding\n    \"\"\"\n    if isinstance(size, int):\n        size = (0, size, size)\n    _, h, w = size\n    return (int(h % 2 == 0), int(w % 2 == 0))\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.conv1d_size","title":"<code>conv1d_size(length, kernel_size, stride, padding=0)</code>","text":"<p>Calculate output dimensions for 1d convolution.</p> PARAMETER DESCRIPTION <code>length</code> <p>Input size.</p> <p> TYPE: <code>int</code> </p> <code>kernel_size</code> <p>Kernel_size.</p> <p> TYPE: <code>int</code> </p> <code>stride</code> <p>Stride.</p> <p> TYPE: <code>int</code> </p> <code>padding</code> <p>Input padding.</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <p>Returns:     int: Output size.</p> Source code in <code>caveat/models/utils.py</code> <pre><code>def conv1d_size(\n    length: int, kernel_size: int, stride: int, padding: int = 0\n) -&gt; int:\n    \"\"\"Calculate output dimensions for 1d convolution.\n\n    Args:\n        length (int): Input size.\n        kernel_size (int): Kernel_size.\n        stride (int): Stride.\n        padding (int): Input padding.\n    Returns:\n        int: Output size.\n    \"\"\"\n    return int((length - (kernel_size - 1) + (2 * padding) - 1) / stride) + 1\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.conv2d_size","title":"<code>conv2d_size(size, kernel_size=3, stride=2, padding=1, dilation=1)</code>","text":"<p>Calculate output dimensions for 2d convolution.</p> PARAMETER DESCRIPTION <code>size</code> <p>Input size, may be integer if symetric.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> </p> <code>kernel_size</code> <p>Kernel_size. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>Stride. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>Input padding. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> <code>dilation</code> <p>Dilation. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: Output size.</p> Source code in <code>caveat/models/utils.py</code> <pre><code>def conv2d_size(\n    size: Union[tuple[int, int], int],\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n    dilation: Union[tuple[int, int], int] = 1,\n) -&gt; np.array:\n    \"\"\"Calculate output dimensions for 2d convolution.\n\n    Args:\n        size (Union[tuple[int, int], int]): Input size, may be integer if symetric.\n        kernel_size (Union[tuple[int, int], int], optional): Kernel_size. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): Stride. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): Input padding. Defaults to 1.\n        dilation (Union[tuple[int, int], int], optional): Dilation. Defaults to 1.\n\n    Returns:\n        np.array: Output size.\n    \"\"\"\n    if isinstance(size, int):\n        size = (size, size)\n    if isinstance(kernel_size, int):\n        kernel_size = (kernel_size, kernel_size)\n    if isinstance(stride, int):\n        stride = (stride, stride)\n    if isinstance(padding, int):\n        padding = (padding, padding)\n    if isinstance(dilation, int):\n        dilation = (dilation, dilation)\n    return (\n        np.array(size)\n        + 2 * np.array(padding)\n        - np.array(dilation) * (np.array(kernel_size) - 1)\n        - 1\n    ) // np.array(stride) + 1\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.duration_mask","title":"<code>duration_mask(mask)</code>","text":"Source code in <code>caveat/models/utils.py</code> <pre><code>def duration_mask(mask: Tensor) -&gt; Tensor:\n    duration_mask = mask.clone()\n    duration_mask[:, 0] = 0.0\n    idxs = torch.arange(duration_mask.shape[0])\n    duration_mask[idxs, (mask != 0).cumsum(-1).argmax(1)] = 0.0\n    return duration_mask\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.hot_argmax","title":"<code>hot_argmax(batch, axis=-1)</code>","text":"<p>Encoded given axis as one-hot based on argmax for that axis.</p> PARAMETER DESCRIPTION <code>batch</code> <p>Input tensor.</p> <p> TYPE: <code>tensor</code> </p> <code>axis</code> <p>Axis index to encode. Defaults to -1.</p> <p> TYPE: <code>int</code> DEFAULT: <code>-1</code> </p> RETURNS DESCRIPTION <code>tensor</code> <p>One hot encoded tensor.</p> <p> TYPE: <code>tensor</code> </p> Source code in <code>caveat/models/utils.py</code> <pre><code>def hot_argmax(batch: tensor, axis: int = -1) -&gt; tensor:\n    \"\"\"Encoded given axis as one-hot based on argmax for that axis.\n\n    Args:\n        batch (tensor): Input tensor.\n        axis (int, optional): Axis index to encode. Defaults to -1.\n\n    Returns:\n        tensor: One hot encoded tensor.\n    \"\"\"\n    batch = batch.swapaxes(axis, -1)\n    argmax = batch.argmax(axis=-1)\n    eye = torch.eye(batch.shape[-1])\n    eye = eye.to(current_device())\n    batch = eye[argmax]\n    return batch.swapaxes(axis, -1)\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.transconv_size_1d","title":"<code>transconv_size_1d(length, kernel_size, stride, padding, output_padding, dilation=1)</code>","text":"Source code in <code>caveat/models/utils.py</code> <pre><code>def transconv_size_1d(\n    length, kernel_size, stride, padding, output_padding, dilation=1\n):\n    return (\n        (length - 1) * stride\n        - 2 * padding\n        + dilation * (kernel_size - 1)\n        + output_padding\n        + 1\n    )\n</code></pre>"},{"location":"reference/caveat/models/utils/#caveat.models.utils.transconv_size_2d","title":"<code>transconv_size_2d(size, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)</code>","text":"<p>Calculate output dimension for 2d transpose convolution.</p> PARAMETER DESCRIPTION <code>size</code> <p>Input size, may be integer if symetric.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> </p> <code>kernel_size</code> <p>Kernel size. Defaults to 3.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>3</code> </p> <code>stride</code> <p>Stride. Defaults to 2.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>2</code> </p> <code>padding</code> <p>Input padding. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> <code>dilation</code> <p>Dilation. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> <code>output_padding</code> <p>Output padding. Defaults to 1.</p> <p> TYPE: <code>Union[tuple[int, int], int]</code> DEFAULT: <code>1</code> </p> RETURNS DESCRIPTION <code>array</code> <p>np.array: Output size.</p> Source code in <code>caveat/models/utils.py</code> <pre><code>def transconv_size_2d(\n    size: Union[tuple[int, int], int],\n    kernel_size: Union[tuple[int, int], int] = 3,\n    stride: Union[tuple[int, int], int] = 2,\n    padding: Union[tuple[int, int], int] = 1,\n    dilation: Union[tuple[int, int], int] = 1,\n    output_padding: Union[tuple[int, int], int] = 1,\n) -&gt; np.array:\n    \"\"\"Calculate output dimension for 2d transpose convolution.\n\n    Args:\n        size (Union[tuple[int, int], int]): Input size, may be integer if symetric.\n        kernel_size (Union[tuple[int, int], int], optional): Kernel size. Defaults to 3.\n        stride (Union[tuple[int, int], int], optional): Stride. Defaults to 2.\n        padding (Union[tuple[int, int], int], optional): Input padding. Defaults to 1.\n        dilation (Union[tuple[int, int], int], optional): Dilation. Defaults to 1.\n        output_padding (Union[tuple[int, int], int], optional): Output padding. Defaults to 1.\n\n    Returns:\n        np.array: Output size.\n    \"\"\"\n    if isinstance(size, int):\n        size = (size, size)\n    if isinstance(kernel_size, int):\n        kernel_size = (kernel_size, kernel_size)\n    if isinstance(stride, int):\n        stride = (stride, stride)\n    if isinstance(padding, int):\n        padding = (padding, padding)\n    if isinstance(dilation, int):\n        dilation = (dilation, dilation)\n    if isinstance(output_padding, int):\n        output_padding = (output_padding, output_padding)\n    return (\n        (np.array(size) - 1) * np.array(stride)\n        - 2 * np.array(padding)\n        + np.array(dilation) * (np.array(kernel_size) - 1)\n        + np.array(output_padding)\n        + 1\n    )\n</code></pre>"},{"location":"reference/caveat/runners/","title":"caveat.runners","text":""},{"location":"reference/caveat/runners/#caveat.runners.batch_command","title":"<code>batch_command(batch_config, stats=True, verbose=False, test=False, infer=True, gen=True)</code>","text":"<p>Runs a batch of training and reporting runs based on the provided configuration.</p> PARAMETER DESCRIPTION <code>batch_config</code> <p>A dictionary containing the configuration for each training job.</p> <p> TYPE: <code>dict[dict]</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>caveat/runners.py</code> <pre><code>def batch_command(\n    batch_config: dict,\n    stats: bool = True,\n    verbose: bool = False,\n    test: bool = False,\n    infer: bool = True,\n    gen: bool = True,\n) -&gt; None:\n    \"\"\"\n    Runs a batch of training and reporting runs based on the provided configuration.\n\n    Args:\n        batch_config (dict[dict]): A dictionary containing the configuration for each training job.\n\n    Returns:\n        None\n    \"\"\"\n    global_config = batch_config.pop(\"global\")\n    logger_params = global_config.get(\"logging_params\", {})\n    name = str(\n        logger_params.get(\n            \"name\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        )\n    )\n    log_dir = Path(logger_params.get(\"log_dir\", \"logs\"), name)\n\n    synthetic_schedules = {}\n    synthetic_attributes_all = {}\n\n    for name, config in batch_config.items():\n        name = str(name)\n        logger = initiate_logger(log_dir, name)\n\n        # build config for this run\n        combined_config = global_config.copy()\n        combined_config.update(config)\n        seed = combined_config.pop(\"seed\", seeder())\n\n        # load data\n        input_schedules, input_attributes, synthetic_attributes = load_data(\n            combined_config\n        )\n\n        # encode data\n        attribute_encoder, encoded_labels, label_weights = encode_input_labels(\n            logger.log_dir, input_attributes, combined_config\n        )\n\n        schedule_encoder, encoded_schedules, data_loader = encode_schedules(\n            logger.log_dir,\n            input_schedules,\n            encoded_labels,\n            label_weights,\n            combined_config,\n        )\n\n        # train\n        trainer = train(\n            name=name,\n            data_loader=data_loader,\n            encoded_schedules=encoded_schedules,\n            label_encoder=attribute_encoder,\n            config=combined_config,\n            test=test,\n            gen=gen,\n            logger=logger,\n            seed=seed,\n        )\n        if test:\n            # test the model\n            run_test(\n                trainer=trainer,\n                schedule_encoder=schedule_encoder,\n                write_dir=Path(logger.log_dir),\n                seed=seed,\n            )\n        if infer:\n            test_infer_path = Path(f\"{logger.log_dir}/test_inference\")\n            test_infer_path.mkdir(exist_ok=True, parents=True)\n\n            test_inference(\n                trainer=trainer,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=attribute_encoder,\n                write_dir=test_infer_path,\n                seed=seed,\n            )\n        if gen:\n            # prepare synthetic attributes\n            if synthetic_attributes is not None:\n                synthetic_population, _ = attribute_encoder.encode(\n                    synthetic_attributes\n                )\n            else:\n                synthetic_population = input_schedules.pid.nunique()\n\n            # record synthetic attributes for evaluation\n            synthetic_attributes_all[name] = synthetic_attributes\n\n            # generate synthetic schedules\n            synthetic_schedules[name] = generate(\n                trainer=trainer,\n                population=synthetic_population,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=attribute_encoder,\n                config=combined_config,\n                write_dir=Path(logger.log_dir),\n                seed=seed,\n            )[0]\n    if gen:\n        # evaluate synthetic schedules\n        evaluate_synthetics(\n            synthetic_schedules=synthetic_schedules,\n            synthetic_attributes=synthetic_attributes_all,\n            default_eval_schedules=input_schedules,\n            default_eval_attributes=input_attributes,\n            write_path=logger.log_dir,\n            eval_params=global_config.get(\"evaluation_params\", {}),\n            stats=stats,\n            verbose=verbose,\n        )\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.batch_eval_command","title":"<code>batch_eval_command(batch_config, schedules_name='synthetic_schedules.csv', labels_name=None, stats=True, verbose=False)</code>","text":"<p>Runs a batch of evaluation based on the provided configuration.</p> PARAMETER DESCRIPTION <code>batch_config</code> <p>A dictionary containing the configuration for each training job.</p> <p> TYPE: <code>dict[dict]</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>caveat/runners.py</code> <pre><code>def batch_eval_command(\n    batch_config: dict,\n    schedules_name: str = \"synthetic_schedules.csv\",\n    labels_name: Optional[str] = None,\n    stats: bool = True,\n    verbose: bool = False,\n) -&gt; None:\n    \"\"\"\n    Runs a batch of evaluation based on the provided configuration.\n\n    Args:\n        batch_config (dict[dict]): A dictionary containing the configuration for each training job.\n\n    Returns:\n        None\n    \"\"\"\n    global_config = batch_config.pop(\"global\")\n    logger_params = global_config.get(\"logging_params\")\n    name = str(logger_params.get(\"name\"))\n    batch_dir = Path(logger_params.get(\"log_dir\"), name)\n\n    synthetic_schedules_all = {}\n    synthetic_labels_all = {}\n\n    for name, config in batch_config.items():\n        name = str(name)\n        print(f\"\\n======= Loading {name} =======\")\n        log_dir = batch_dir / name\n\n        # build config for this run\n        combined_config = global_config.copy()\n        combined_config.update(config)\n\n        # load data\n        input_schedules, input_attributes, synthetic_labels = load_data(\n            combined_config, verbose=verbose\n        )\n        print(\n            f\"&gt; Loaded {input_schedules.pid.nunique()} target schedules for evaluation\"\n        )\n        print(\n            f\"&gt; Loaded {input_attributes.pid.nunique()} target attributes for evaluation\"\n        )\n\n        # get most recent version\n        version = sorted([d for d in log_dir.iterdir() if d.is_dir()])[-1]\n        outputs_dir = log_dir / version.name\n        schedules_path = outputs_dir / schedules_name\n        synthetic_schedules_all[log_dir.name] = (\n            data.load_and_validate_schedules(schedules_path)\n        )\n        print(\n            f\"&gt; Loaded {synthetic_schedules_all[log_dir.name].pid.nunique()} synthetic schedules from {schedules_path}\"\n        )\n\n        synthetic_labels_path = (\n            outputs_dir / \"synthetic_labels.csv\"\n        )  # todo: make this consistent across all models\n        synthetic_attributes_path = outputs_dir / \"synthetic_attributes.csv\"\n        if labels_name is not None:\n            synthetic_labels_path = outputs_dir / labels_name\n            synthetic_labels = load_labels(synthetic_labels_path)\n\n        elif synthetic_labels_path.exists():\n            synthetic_labels = load_labels(synthetic_labels_path)\n\n        elif synthetic_attributes_path.exists():\n            synthetic_labels = load_labels(synthetic_attributes_path)\n\n        synthetic_labels_all[log_dir.name] = synthetic_labels\n\n    # evaluate synthetic schedules\n    evaluate_synthetics(\n        synthetic_schedules=synthetic_schedules_all,\n        synthetic_attributes=synthetic_labels_all,\n        default_eval_schedules=input_schedules,\n        default_eval_attributes=input_attributes,\n        write_path=batch_dir,\n        eval_params=global_config.get(\"evaluation_params\", {}),\n        stats=stats,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.build_dataloader","title":"<code>build_dataloader(config, dataset)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def build_dataloader(\n    config: dict, dataset: encoding.BaseDataset\n) -&gt; data.DataModule:\n    data_loader_params = config.get(\"loader_params\", {})\n    datamodule = data.DataModule(data=dataset, **data_loader_params)\n    datamodule.setup()\n    return datamodule\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.build_encoder","title":"<code>build_encoder(config)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def build_encoder(config: dict) -&gt; encoding.BaseEncoder:\n    encoder_name = config[\"encoder_params\"][\"name\"]\n    data_encoder = encoding.library[encoder_name](**config[\"encoder_params\"])\n    return data_encoder\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.build_model","title":"<code>build_model(dataset, config, test, gen, label_kwargs)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def build_model(\n    dataset: encoding.BaseDataset,\n    config: dict,\n    test: bool,\n    gen: bool,\n    label_kwargs: dict,\n) -&gt; LightningModule:\n    model_name = config[\"model_params\"][\"name\"]\n    model = models.library[model_name]\n    model = model(\n        in_shape=dataset.shape(),\n        encodings=dataset.activity_encodings,\n        encoding_weights=dataset.encoding_weights,\n        labels_size=dataset.labels_shape,\n        **config[\"model_params\"],\n        test=test,\n        gen=gen,\n        **config.get(\"experiment_params\", {}),\n        **label_kwargs,\n    )\n    return model\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.build_trainer","title":"<code>build_trainer(logger, config)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def build_trainer(logger: TensorBoardLogger, config: dict) -&gt; Trainer:\n    trainer_config = config.get(\"trainer_params\", {})\n    patience = trainer_config.pop(\"patience\", 5)\n    checkpoint_callback = ModelCheckpoint(\n        dirpath=Path(logger.log_dir, \"checkpoints\"),\n        monitor=\"val_loss\",\n        save_top_k=2,\n        save_weights_only=False,\n    )\n    loss_scheduling = trainer_config.pop(\"loss_scheduling\", {})\n    custom_loss_scheduler = LinearLossScheduler(loss_scheduling)\n    return Trainer(\n        logger=logger,\n        callbacks=[\n            EarlyStopping(\n                monitor=\"val_loss\", patience=patience, stopping_threshold=0.0\n            ),\n            LearningRateMonitor(),\n            checkpoint_callback,\n            custom_loss_scheduler,\n        ],\n        **trainer_config,\n    )\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.conditional_sample","title":"<code>conditional_sample(trainer, population_size, data_encoder, config, write_dir, seed)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def conditional_sample(\n    trainer: Trainer,\n    population_size: int,\n    data_encoder: encoding.BaseEncoder,\n    config: dict,\n    write_dir: Path,\n    seed: int,\n) -&gt; DataFrame:\n    torch.manual_seed(seed)\n    print(\"\\n======= Sampling =======\")\n    predict_loader = data.build_latent_dataloader(\n        population_size, config[\"model_params\"][\"latent_dim\"], 256\n    )\n    predictions = trainer.predict(ckpt_path=\"best\", dataloaders=predict_loader)\n    predictions = torch.concat(predictions)  # type: ignore\n    synthetic = data_encoder.decode(schedules=predictions)\n    data.validate_schedules(synthetic)\n    synthesis_path = write_dir / \"synthetic.csv\"\n    synthetic.to_csv(synthesis_path)\n    return synthetic\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.encode_input_labels","title":"<code>encode_input_labels(log_dir, input_labels, config)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def encode_input_labels(\n    log_dir: Path, input_labels: Optional[DataFrame], config: dict\n) -&gt; Tuple[BaseEncoder, BaseDataset, DataModule, Tensor]:\n    attribute_encoder = None\n    # optionally encode attributes\n    encoded_attributes = None\n    weights = None\n    if input_labels is not None:\n        encoder_config = config.get(\"labels_encoder\", {})\n        encoder_name = encoder_config.get(\"name\", \"onehot\")\n        labels_config = encoder_config.get(\"labels\", None)\n        if labels_config is None:\n            raise UserWarning(\n                \"You have specified input labels, config must contain label encoder configuration with labels defined.\"\n            )\n        attribute_encoder = label_encoding.library[encoder_name](\n            config=labels_config, **encoder_config\n        )\n        encoded_attributes, weights = attribute_encoder.encode(input_labels)\n\n    pickle.dump(\n        attribute_encoder, open(f\"{log_dir}/attribute_encoder.pkl\", \"wb\")\n    )\n\n    return (attribute_encoder, encoded_attributes, weights)\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.encode_schedules","title":"<code>encode_schedules(log_dir, schedules, attributes, label_weights, config)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def encode_schedules(\n    log_dir: Path,\n    schedules: DataFrame,\n    attributes: Optional[Tensor],\n    label_weights: Optional[Tuple[Tensor, Tensor]],\n    config: dict,\n) -&gt; Tuple[BaseEncoder, BaseDataset, DataModule]:\n\n    # encode schedules\n    schedule_encoder = build_encoder(config)\n    encoded_schedules = schedule_encoder.encode(\n        schedules=schedules, labels=attributes, label_weights=label_weights\n    )\n    data_loader = build_dataloader(config, encoded_schedules)\n\n    pickle.dump(schedule_encoder, open(f\"{log_dir}/schedule_encoder.pkl\", \"wb\"))\n\n    return (schedule_encoder, encoded_schedules, data_loader)\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.eval_command","title":"<code>eval_command(config, schedules_name='synthetic_schedules.csv', labels_name=None, stats=True, verbose=False)</code>","text":"<p>Runs the evaluation process using the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing the configuration parameters.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>caveat/runners.py</code> <pre><code>def eval_command(\n    config: dict,\n    schedules_name: str = \"synthetic_schedules.csv\",\n    labels_name: Optional[str] = None,\n    stats: bool = True,\n    verbose: bool = False,\n) -&gt; None:\n    \"\"\"\n    Runs the evaluation process using the provided configuration.\n\n    Args:\n        config (dict): A dictionary containing the configuration parameters.\n\n    Returns:\n        None\n    \"\"\"\n    logger_params = config.get(\"logging_params\")\n    log_dir = Path(logger_params.get(\"log_dir\"))\n    schedules_name = str(logger_params.get(\"name\"))\n\n    # load data\n    input_schedules, input_attributes, synthetic_labels = load_data(\n        config, verbose=False\n    )\n\n    # get most recent version\n    version = sorted([d for d in log_dir.iterdir() if d.is_dir()])[-1]\n    outputs_dir = log_dir / version.name\n    schedules_path = outputs_dir / schedules_name\n    synthetic_schedules = {\n        log_dir.name: data.load_and_validate_schedules(schedules_path)\n    }\n    print(\n        f\"&gt; Loaded {synthetic_schedules[log_dir.name].pid.nunique()} synthetic schedules from {schedules_path}\"\n    )\n\n    if labels_name is not None:\n        synthetic_labels_path = outputs_dir / labels_name\n        synthetic_labels = load_labels(synthetic_labels_path)\n\n    elif \"synthetic_labels\" in outputs_dir.iterdir():\n        synthetic_labels_path = outputs_dir / \"synthetic_labels.csv\"\n        synthetic_labels = load_labels(synthetic_labels_path)\n\n    elif \"synthetic_attributes\" in outputs_dir.iterdir():\n        synthetic_labels_path = outputs_dir / \"synthetic_attributes.csv\"\n        synthetic_labels = load_labels(synthetic_labels_path)\n\n    synthetic_labels = {log_dir.name: synthetic_labels}\n\n    # evaluate synthetic schedules\n    evaluate_synthetics(\n        synthetic_schedules=synthetic_schedules,\n        synthetic_attributes=synthetic_labels,\n        default_eval_schedules=input_schedules,\n        default_eval_attributes=input_attributes,\n        write_path=log_dir,\n        eval_params=config.get(\"evaluation_params\", {}),\n        stats=stats,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.evaluate_synthetics","title":"<code>evaluate_synthetics(synthetic_schedules, synthetic_attributes, default_eval_schedules, default_eval_attributes, write_path, eval_params, stats=True, verbose=False)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def evaluate_synthetics(\n    synthetic_schedules: dict[str, DataFrame],\n    synthetic_attributes: dict[str, DataFrame],\n    default_eval_schedules: DataFrame,\n    default_eval_attributes: DataFrame,\n    write_path: Path,\n    eval_params: dict,\n    stats: bool = True,\n    verbose: bool = False,\n) -&gt; None:\n    print(\"\\n======= Evaluating synthetic schedules =======\")\n    head = eval_params.get(\"head\", 10)\n\n    eval_schedules_path = eval_params.get(\"schedules_path\", None)\n    if eval_schedules_path:\n        eval_schedules = data.load_and_validate_schedules(eval_schedules_path)\n        print(\n            f\"&lt;!&gt; Loaded {len(eval_schedules)} schedules for evaluation from {eval_schedules_path}\"\n        )\n    else:\n        eval_schedules = default_eval_schedules\n        print(\"Evaluating synthetic schedules against target schedules\")\n\n    split_on = eval_params.get(\"split_on\", [])\n    if split_on:\n        print(f\"Conditional Evaluation using: {split_on}\")\n        eval_attributes_path = eval_params.get(\"attributes_path\", None)\n        if eval_attributes_path:\n            eval_attributes = data.load_and_validate_attributes(\n                eval_params, eval_schedules\n            )\n            print(\n                f\"&lt;!&gt; Loaded {len(eval_attributes)} attributes for evaluation from {eval_attributes_path}\"\n            )\n        else:\n            eval_attributes = default_eval_attributes\n\n        sub_reports = evaluate.evaluate_subsampled(\n            synthetic_schedules=synthetic_schedules,\n            synthetic_attributes=synthetic_attributes,\n            target_schedules=eval_schedules,\n            target_attributes=eval_attributes,\n            split_on=split_on,\n            report_stats=stats,\n        )\n        evaluate.report_splits(\n            sub_reports,\n            log_dir=write_path,\n            head=head,\n            verbose=verbose,\n            suffix=\"_subs\",\n            ranking=len(synthetic_schedules) &gt; 1,\n        )\n    print(\"Evaluating schedules\")\n    reports = evaluate.evaluate(\n        target_schedules=eval_schedules,\n        synthetic_schedules=synthetic_schedules,\n        report_stats=stats,\n    )\n    evaluate.report(\n        reports,\n        log_dir=write_path,\n        head=head,\n        verbose=verbose,\n        ranking=len(synthetic_schedules) &gt; 1,\n    )\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.generate","title":"<code>generate(trainer, population, schedule_encoder, attribute_encoder, config, write_dir, seed, ckpt_path=None)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def generate(\n    trainer: Trainer,\n    population: Union[int, Tensor],\n    schedule_encoder: encoding.BaseEncoder,\n    attribute_encoder: label_encoding.BaseLabelEncoder,\n    config: dict,\n    write_dir: Path,\n    seed: int,\n    ckpt_path: Optional[str] = None,\n) -&gt; DataFrame:\n    torch.manual_seed(seed)\n    if ckpt_path is None:\n        ckpt_path = \"best\"\n    latent_dims = config.get(\"model_params\", {}).get(\"latent_dim\")\n    if latent_dims is None:\n        latent_dims = config.get(\"experiment_params\", {}).get(\"latent_dims\", 2)\n        # default of 2\n    batch_size = config.get(\"generator_params\", {}).get(\"batch_size\", 256)\n\n    if isinstance(population, int):\n        print(f\"\\n======= Sampling {population} new schedules =======\")\n        synthetic_schedules, zs = generate_n(\n            trainer,\n            n=population,\n            batch_size=batch_size,\n            latent_dims=latent_dims,\n            seed=seed,\n            ckpt_path=ckpt_path,\n        )\n        synthetic_attributes = None\n    elif isinstance(population, Tensor):\n        print(\n            f\"\\n======= Sampling {len(population)} new schedules from synthetic attributes =======\"\n        )\n        synthetic_attributes, synthetic_schedules, zs = (\n            generate_from_attributes(\n                trainer,\n                attributes=population,\n                batch_size=batch_size,\n                latent_dims=latent_dims,\n                seed=seed,\n                ckpt_path=ckpt_path,\n            )\n        )\n        synthetic_attributes = attribute_encoder.decode(synthetic_attributes)\n        synthetic_attributes.to_csv(write_dir / \"synthetic_attributes.csv\")\n\n    synthetic_schedules = schedule_encoder.decode(schedules=synthetic_schedules)\n    data.validate_schedules(synthetic_schedules)\n    synthetic_schedules.to_csv(write_dir / \"synthetic_schedules.csv\")\n    DataFrame(zs.cpu().numpy()).to_csv(\n        Path(write_dir, \"synthetic_zs.csv\"), index=False, header=False\n    )\n    return synthetic_schedules, synthetic_attributes, zs\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.generate_from_attributes","title":"<code>generate_from_attributes(trainer, attributes, batch_size, latent_dims, seed, ckpt_path)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def generate_from_attributes(\n    trainer: Trainer,\n    attributes: Tensor,\n    batch_size: int,\n    latent_dims: int,\n    seed: int,\n    ckpt_path: str,\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    torch.manual_seed(seed)\n    dataloaders = data.build_latent_conditional_dataloader(\n        attributes, latent_dims, batch_size\n    )\n    synth = trainer.predict(ckpt_path=ckpt_path, dataloaders=dataloaders)\n    synthetic_attributes, synthetic_schedules, zs = zip(*synth)\n    synthetic_attributes = torch.concat(synthetic_attributes)\n    synthetic_schedules = torch.concat(synthetic_schedules)\n    zs = torch.concat(zs)\n    return synthetic_attributes, synthetic_schedules, zs\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.generate_n","title":"<code>generate_n(trainer, n, batch_size, latent_dims, seed, ckpt_path)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def generate_n(\n    trainer: Trainer,\n    n: int,\n    batch_size: int,\n    latent_dims: int,\n    seed: int,\n    ckpt_path: str,\n) -&gt; torch.Tensor:\n    torch.manual_seed(seed)\n    dataloaders = data.build_latent_dataloader(n, latent_dims, batch_size)\n    synth = trainer.predict(ckpt_path=ckpt_path, dataloaders=dataloaders)\n    _, synthetic_schedules, zs = zip(*synth)\n    synthetic_schedules = torch.concat(synthetic_schedules)\n    zs = torch.concat(zs)\n    return synthetic_schedules, zs\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.initiate_logger","title":"<code>initiate_logger(save_dir, name)</code>","text":"<p>Initializes a TensorBoardLogger object for logging training progress.</p> PARAMETER DESCRIPTION <code>save_dir</code> <p>The directory where the logs will be saved.</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>The name of the logger.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>TensorBoardLogger</code> <p>The initialized TensorBoardLogger object.</p> <p> TYPE: <code>TensorBoardLogger</code> </p> Source code in <code>caveat/runners.py</code> <pre><code>def initiate_logger(save_dir: Union[Path, str], name: str) -&gt; TensorBoardLogger:\n    \"\"\"\n    Initializes a TensorBoardLogger object for logging training progress.\n\n    Args:\n        save_dir (str): The directory where the logs will be saved.\n        name (str): The name of the logger.\n\n    Returns:\n        TensorBoardLogger: The initialized TensorBoardLogger object.\n    \"\"\"\n    tb_logger = TensorBoardLogger(save_dir=save_dir, name=name)\n    Path(f\"{tb_logger.log_dir}/samples\").mkdir(exist_ok=True, parents=True)\n    Path(f\"{tb_logger.log_dir}/reconstructions\").mkdir(\n        exist_ok=True, parents=True\n    )\n    Path(f\"{tb_logger.log_dir}/val_z\").mkdir(exist_ok=True, parents=True)\n    return tb_logger\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.load_data","title":"<code>load_data(config, verbose=False)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def load_data(\n    config: dict, verbose: bool = False\n) -&gt; Tuple[DataFrame, DataFrame, DataFrame]:\n    # load schedules data\n    schedules_path = Path(config[\"schedules_path\"])\n    schedules = data.load_and_validate_schedules(schedules_path)\n    if verbose:\n        print(\n            f\"Loaded {schedules.pid.nunique()} schedules from {schedules_path}\"\n        )\n\n    # load attributes data (conditional case)\n    attributes, synthetic_attributes = data.load_and_validate_attributes(\n        config, schedules, verbose=verbose\n    )\n    return schedules, attributes, synthetic_attributes\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.load_labels","title":"<code>load_labels(path)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def load_labels(path):\n    synthetic_attributes = pd.read_csv(path)\n    print(f\"&gt; Loaded {len(synthetic_attributes)} synthetic labels from {path}\")\n    if synthetic_attributes.empty:\n        raise UserWarning(f\"No labels found in {path}.\")\n    return synthetic_attributes\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.load_model","title":"<code>load_model(ckpt_path, config)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def load_model(ckpt_path: Path, config: dict) -&gt; LightningModule:\n    model_name = config[\"model_params\"][\"name\"]\n    model = models.library[model_name]\n    return model.load_from_checkpoint(ckpt_path)\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.ngen_command","title":"<code>ngen_command(config, n=5, infer=True, stats=False, verbose=False)</code>","text":"<p>Repeat a single run with multiple samples varying the seed.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing the configuration parameters.</p> <p> TYPE: <code>dict</code> </p> <code>n</code> <p>The number of times to repeat the run. Defaults to 5.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> Source code in <code>caveat/runners.py</code> <pre><code>def ngen_command(\n    config: dict,\n    n: int = 5,\n    infer: bool = True,\n    stats: bool = False,\n    verbose: bool = False,\n) -&gt; None:\n    \"\"\"\n    Repeat a single run with multiple samples varying the seed.\n\n    Args:\n        config (dict): A dictionary containing the configuration parameters.\n        n (int, optional): The number of times to repeat the run. Defaults to 5.\n    \"\"\"\n    logger_params = config.get(\"logging_params\", {})\n    name = str(\n        logger_params.get(\n            \"name\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        )\n    )\n    log_dir = Path(logger_params.get(\"log_dir\", \"logs\"))\n    training_logger = initiate_logger(log_dir, name)\n\n    # load data\n    input_schedules, input_attributes, synthetic_attributes = load_data(config)\n\n    # encode data\n    attribute_encoder, encoded_labels, label_weights = encode_input_labels(\n        log_dir, input_attributes, config\n    )\n\n    schedule_encoder, encoded_schedules, data_loader = encode_schedules(\n        log_dir, input_schedules, encoded_labels, label_weights, config\n    )\n\n    seed = config.pop(\"seed\", seeder())\n\n    # train\n    trainer = train(\n        name=name,\n        data_loader=data_loader,\n        encoded_schedules=encoded_schedules,\n        label_encoder=attribute_encoder,\n        config=config,\n        test=False,\n        gen=True,\n        logger=training_logger,\n        seed=seed,\n    )\n\n    synthetic_schedules = {}\n    all_synthetic_attributes = {}\n\n    # prepare synthetic attributes\n    if synthetic_attributes is not None:\n        synthetic_population = attribute_encoder.encode(synthetic_attributes)\n    else:\n        synthetic_population = input_schedules.pid.nunique()\n\n    for i in range(n):\n        logger = initiate_logger(training_logger.log_dir, f\"nsample{i}\")\n        seed = seeder()\n        if infer:\n            test_infer_path = Path(f\"{logger.log_dir}/test_inference\")\n            test_infer_path.mkdir(exist_ok=True, parents=True)\n\n            test_inference(\n                trainer=trainer,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=attribute_encoder,\n                write_dir=test_infer_path,\n                seed=seed,\n            )\n\n        synthetic_schedules[f\"nsample{i}\"] = generate(\n            trainer=trainer,\n            population=synthetic_population,\n            schedule_encoder=schedule_encoder,\n            attribute_encoder=attribute_encoder,\n            config=config,\n            write_dir=Path(logger.log_dir),\n            seed=seed,\n        )[0]\n        all_synthetic_attributes[f\"nsample{i}\"] = synthetic_attributes\n\n    evaluate_synthetics(\n        synthetic_schedules=synthetic_schedules,\n        synthetic_attributes=all_synthetic_attributes,\n        default_eval_schedules=input_schedules,\n        default_eval_attributes=input_attributes,\n        write_path=log_dir,\n        eval_params=config.get(\"evaluation_params\", {}),\n        stats=stats,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.nrun_command","title":"<code>nrun_command(config, n=5, stats=True, verbose=False, test=False, infer=True, gen=True)</code>","text":"<p>Repeat a single model training while varying the seed.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing the configuration parameters.</p> <p> TYPE: <code>dict</code> </p> <code>n</code> <p>The number of times to repeat the run. Defaults to 5.</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> Source code in <code>caveat/runners.py</code> <pre><code>def nrun_command(\n    config: dict,\n    n: int = 5,\n    stats: bool = True,\n    verbose: bool = False,\n    test: bool = False,\n    infer: bool = True,\n    gen: bool = True,\n) -&gt; None:\n    \"\"\"\n    Repeat a single model training while varying the seed.\n\n    Args:\n        config (dict): A dictionary containing the configuration parameters.\n        n (int, optional): The number of times to repeat the run. Defaults to 5.\n    \"\"\"\n    logger_params = config.get(\"logging_params\", {})\n\n    name = str(\n        logger_params.get(\n            \"name\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        )\n    )\n    log_dir = Path(logger_params.get(\"log_dir\", \"logs\")) / name\n    log_dir.mkdir(exist_ok=True, parents=True)\n\n    # load data\n    input_schedules, input_attributes, synthetic_attributes = load_data(config)\n\n    # encode data\n    attribute_encoder, encoded_labels, label_weights = encode_input_labels(\n        log_dir, input_attributes, config\n    )\n\n    schedule_encoder, encoded_schedules, data_loader = encode_schedules(\n        log_dir, input_schedules, encoded_labels, label_weights, config\n    )\n\n    synthetic_schedules = {}\n    all_synthetic_attributes = {}\n\n    for i in range(n):\n        run_name = f\"{name}_nrun{i}\"\n        logger = initiate_logger(log_dir, run_name)\n        seed = seeder()\n        trainer = train(\n            name=run_name,\n            data_loader=data_loader,\n            encoded_schedules=encoded_schedules,\n            label_encoder=attribute_encoder,\n            config=config,\n            test=test,\n            gen=gen,\n            logger=logger,\n            seed=seed,\n        )\n        if test:\n            run_test(\n                trainer=trainer,\n                schedule_encoder=schedule_encoder,\n                write_dir=Path(logger.log_dir),\n                seed=seed,\n            )\n        if infer:\n            test_infer_path = Path(f\"{logger.log_dir}/test_inference\")\n            test_infer_path.mkdir(exist_ok=True, parents=True)\n\n            test_inference(\n                trainer=trainer,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=attribute_encoder,\n                write_dir=test_infer_path,\n                seed=seed,\n            )\n        if gen:\n            # prepare synthetic attributes\n            if synthetic_attributes is not None:\n                synthetic_population, _ = attribute_encoder.encode(\n                    synthetic_attributes\n                )\n            else:\n                synthetic_population = input_schedules.pid.nunique()\n\n            all_synthetic_attributes[run_name] = synthetic_attributes\n\n            synthetic_schedules[run_name] = generate(\n                trainer=trainer,\n                population=synthetic_population,\n                schedule_encoder=schedule_encoder,\n                attribute_encoder=attribute_encoder,\n                config=config,\n                write_dir=Path(logger.log_dir),\n                seed=seed,\n            )[0]\n\n    if gen:\n        evaluate_synthetics(\n            synthetic_schedules=synthetic_schedules,\n            synthetic_attributes=all_synthetic_attributes,\n            default_eval_schedules=input_schedules,\n            default_eval_attributes=input_attributes,\n            write_path=log_dir,\n            eval_params=config.get(\"evaluation_params\", {}),\n            stats=stats,\n            verbose=verbose,\n        )\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.report_command","title":"<code>report_command(observed_path, log_dir, name='synthetic_schedules.csv', verbose=False, head=10, batch=False, stats=True)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def report_command(\n    observed_path: Path,\n    log_dir: Path,\n    name: str = \"synthetic_schedules.csv\",\n    verbose: bool = False,\n    head: int = 10,\n    batch: bool = False,\n    stats: bool = True,\n):\n    observed_path = Path(observed_path)\n    log_dir = Path(log_dir)\n    observed = data.load_and_validate_schedules(observed_path)\n    synthetic_schedules = {}\n    if batch:\n        paths = [p for p in log_dir.iterdir() if p.is_dir()]\n    else:\n        paths = [log_dir]\n\n    for experiment in paths:\n        # get most recent version\n        version = sorted([d for d in experiment.iterdir() if d.is_dir()])[-1]\n        path = experiment / version.name / name\n        synthetic_schedules[experiment.name] = data.load_and_validate_schedules(\n            path\n        )\n\n    reports = evaluate.evaluate(\n        target_schedules=observed,\n        synthetic_schedules=synthetic_schedules,\n        report_stats=stats,\n    )\n    evaluate.report(reports, log_dir=log_dir, head=head, verbose=verbose)\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.run_command","title":"<code>run_command(config, verbose=False, gen=True, test=False, infer=True)</code>","text":"<p>Runs the training and reporting process using the provided configuration.</p> PARAMETER DESCRIPTION <code>config</code> <p>A dictionary containing the configuration parameters.</p> <p> TYPE: <code>dict</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>caveat/runners.py</code> <pre><code>def run_command(\n    config: dict,\n    verbose: bool = False,\n    gen: bool = True,\n    test: bool = False,\n    infer=True,\n) -&gt; None:\n    \"\"\"\n    Runs the training and reporting process using the provided configuration.\n\n    Args:\n        config (dict): A dictionary containing the configuration parameters.\n\n    Returns:\n        None\n    \"\"\"\n    logger_params = config.get(\"logging_params\", {})\n    log_dir = Path(logger_params.get(\"log_dir\", \"logs\"))\n    name = str(\n        logger_params.get(\n            \"name\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        )\n    )\n    logger = initiate_logger(log_dir, name)\n    seed = config.pop(\"seed\", seeder())\n\n    # load data\n    input_schedules, input_attributes, synthetic_attributes = load_data(config)\n\n    # encode data\n    attribute_encoder, encoded_labels, label_weights = encode_input_labels(\n        logger.log_dir, input_attributes, config\n    )\n\n    schedule_encoder, encoded_schedules, data_loader = encode_schedules(\n        logger.log_dir, input_schedules, encoded_labels, label_weights, config\n    )\n\n    # train\n    trainer = train(\n        name=name,\n        data_loader=data_loader,\n        encoded_schedules=encoded_schedules,\n        label_encoder=attribute_encoder,\n        config=config,\n        test=test,\n        gen=gen,\n        logger=logger,\n        seed=seed,\n    )\n\n    if test:\n        # test the model\n        run_test(\n            trainer=trainer,\n            schedule_encoder=schedule_encoder,\n            write_dir=Path(logger.log_dir),\n            seed=seed,\n        )\n\n    if infer:\n        test_infer_path = Path(f\"{logger.log_dir}/test_inference\")\n        test_infer_path.mkdir(exist_ok=True, parents=True)\n\n        test_inference(\n            trainer=trainer,\n            schedule_encoder=schedule_encoder,\n            attribute_encoder=attribute_encoder,\n            write_dir=test_infer_path,\n            seed=seed,\n        )\n\n    if gen:\n        # prepare synthetic attributes\n        if synthetic_attributes is not None:\n            synthetic_population, _ = attribute_encoder.encode(\n                synthetic_attributes\n            )\n        else:\n            synthetic_population = input_schedules.pid.nunique()\n\n        # generate synthetic schedules\n        synthetic_schedules, _, _ = generate(\n            trainer=trainer,\n            population=synthetic_population,\n            schedule_encoder=schedule_encoder,\n            attribute_encoder=attribute_encoder,\n            config=config,\n            write_dir=Path(logger.log_dir),\n            seed=seed,\n        )\n\n        # evaluate synthetic schedules\n        evaluate_synthetics(\n            synthetic_schedules={name: synthetic_schedules},\n            synthetic_attributes={name: synthetic_attributes},\n            default_eval_schedules=input_schedules,\n            default_eval_attributes=input_attributes,\n            write_path=Path(logger.log_dir),\n            eval_params=config.get(\"evaluation_params\", {}),\n            stats=False,\n            verbose=verbose,\n        )\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.run_test","title":"<code>run_test(trainer, schedule_encoder, write_dir, seed, ckpt_path=None)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def run_test(\n    trainer: Trainer,\n    schedule_encoder: encoding.BaseEncoder,\n    write_dir: Path,\n    seed: int,\n    ckpt_path: Optional[str] = None,\n):\n    torch.manual_seed(seed)\n    print(\"\\n======= Testing =======\")\n    if ckpt_path is None:\n        ckpt_path = \"best\"\n    trainer.test(ckpt_path=ckpt_path, datamodule=trainer.datamodule)\n    (test_in, test_target, conditionals, predictions) = zip(\n        *list(\n            trainer.predict(\n                ckpt_path=\"best\",\n                dataloaders=trainer.datamodule.test_dataloader(),\n            )\n        )\n    )\n    test_in = torch.concat(test_in)\n    test_target = torch.concat(test_target)\n    conditionals = torch.concat(conditionals)\n    predictions = torch.concat(predictions)\n\n    test_in = schedule_encoder.decode_input(schedules=test_in)\n    data.validate_schedules(test_in)\n    test_in.to_csv(write_dir / \"test_input.csv\")\n\n    test_target = schedule_encoder.decode_target(schedules=test_target)\n    test_target.to_csv(write_dir / \"test_target.csv\")\n\n    predictions = schedule_encoder.decode_output(schedules=predictions)\n    predictions.to_csv(write_dir / \"pred.csv\")\n\n    return test_in, test_target, predictions\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.test_inference","title":"<code>test_inference(trainer, schedule_encoder, attribute_encoder, write_dir, seed, ckpt_path=None)</code>","text":"Source code in <code>caveat/runners.py</code> <pre><code>def test_inference(\n    trainer: Trainer,\n    schedule_encoder: encoding.BaseEncoder,\n    attribute_encoder: label_encoding.BaseLabelEncoder,\n    write_dir: Path,\n    seed: int,\n    ckpt_path: Optional[str] = None,\n):\n    torch.manual_seed(seed)\n    if ckpt_path is None:\n        ckpt_path = \"best\"\n\n    print(\"\\n======= Testing Inference =======\")\n    inference = trainer.predict(\n        ckpt_path=ckpt_path, dataloaders=trainer.datamodule.test_dataloader()\n    )\n    input_schedules, inferred_schedules, zs, conditionals = zip(*inference)\n\n    input_schedules = torch.concat(input_schedules)\n    inferred_schedules = torch.concat(inferred_schedules)\n    zs = torch.concat(zs)\n    conditionals = torch.concat(conditionals)\n\n    input_schedules = schedule_encoder.decode(input_schedules, argmax=False)\n    data.validate_schedules(input_schedules)\n    input_schedules.to_csv(write_dir / \"input_schedules.csv\")\n\n    inferred_schedules = schedule_encoder.decode(inferred_schedules)\n    data.validate_schedules(inferred_schedules)\n    inferred_schedules.to_csv(write_dir / \"inferred_schedules.csv\")\n\n    DataFrame(zs.cpu().numpy()).to_csv(\n        Path(write_dir, \"zs.csv\"), index=False, header=False\n    )\n\n    if attribute_encoder is not None:\n        attributes = attribute_encoder.decode(conditionals)\n        attributes.to_csv(write_dir / \"input_attributes.csv\")\n</code></pre>"},{"location":"reference/caveat/runners/#caveat.runners.train","title":"<code>train(name, data_loader, encoded_schedules, config, test, gen, logger, seed=None, ckpt_path=None, label_encoder=None)</code>","text":"<p>Trains a model on the observed data. Return model trainer (which includes model) and encoder.</p> PARAMETER DESCRIPTION <code>name</code> <p>The name of the experiment.</p> <p> TYPE: <code>str</code> </p> <code>schedules</code> <p>The \"observed\" population data to train the model on.</p> <p> TYPE: <code>DataFrame</code> </p> <code>conditionals</code> <p>The \"conditionals\" data to train the model on.</p> <p> TYPE: <code>DataFrame</code> </p> <code>config</code> <p>A dictionary containing the configuration parameters for the experiment.</p> <p> TYPE: <code>dict</code> </p> <code>logger</code> <p>Logger.</p> <p> TYPE: <code>TensorBoardLogger</code> </p> RETURNS DESCRIPTION <code>Tuple[Trainer, BaseEncoder]</code> <p>Tuple(pytorch.Trainer, BaseEncoder).</p> Source code in <code>caveat/runners.py</code> <pre><code>def train(\n    name: str,\n    data_loader: DataModule,\n    encoded_schedules: BaseDataset,\n    config: dict,\n    test: bool,\n    gen: bool,\n    logger: TensorBoardLogger,\n    seed: Optional[int] = None,\n    ckpt_path: Optional[Path] = None,\n    label_encoder: Optional[BaseLabelEncoder] = None,\n) -&gt; Tuple[Trainer, encoding.BaseEncoder]:\n    \"\"\"\n    Trains a model on the observed data. Return model trainer (which includes model) and encoder.\n\n    Args:\n        name (str): The name of the experiment.\n        schedules (pandas.DataFrame): The \"observed\" population data to train the model on.\n        conditionals (pandas.DataFrame): The \"conditionals\" data to train the model on.\n        config (dict): A dictionary containing the configuration parameters for the experiment.\n        logger (TensorBoardLogger): Logger.\n\n    Returns:\n        Tuple(pytorch.Trainer, BaseEncoder).\n    \"\"\"\n    print(f\"\\n======= Training {name} =======\")\n\n    torch.manual_seed(seed)\n\n    if cuda_available():\n        torch.set_float32_matmul_precision(\"medium\")\n\n    torch.cuda.empty_cache()\n    if ckpt_path is not None:\n        experiment = load_model(ckpt_path, config)\n    else:\n        label_kwargs = label_encoder.label_kwargs if label_encoder else {}\n        experiment = build_model(\n            encoded_schedules, config, test, gen, label_kwargs\n        )\n    trainer = build_trainer(logger, config)\n    trainer.fit(experiment, datamodule=data_loader)\n    return trainer\n</code></pre>"},{"location":"reference/caveat/samplers/","title":"caveat.samplers","text":""},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler","title":"<code>TargetLabelSampler(target_labels, target_columns)</code>","text":"Source code in <code>caveat/samplers.py</code> <pre><code>def __init__(self, target_labels: pd.DataFrame, target_columns: list):\n\n    assert \"pid\" in target_labels.columns\n    assert all(column in target_labels.columns for column in target_columns)\n\n    self.target_columns = target_columns\n    # self.label_dtypes = target_labels.dtypes.to_dict()\n    # self.target_labels = target_labels[target_columns].copy()\n\n    self.target_labels_dict = {\n        k: v for k, v in target_labels.groupby(target_columns)\n    }\n    self.target_sizes = {\n        k: len(v) for k, v in self.target_labels_dict.items()\n    }\n    self.found_sizes = {k: 0 for k in self.target_labels_dict.keys()}\n\n    self.n = len(target_labels)\n    self.sampled_schedules = []\n    self.sampled_labels = []\n\n    self.sample_n = 0\n    self.i = 0\n</code></pre>"},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.found_sizes","title":"<code>found_sizes = {k: 0for k in self.target_labels_dict.keys()}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.i","title":"<code>i = 0</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.n","title":"<code>n = len(target_labels)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.sample_n","title":"<code>sample_n = 0</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.sampled_labels","title":"<code>sampled_labels = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.sampled_schedules","title":"<code>sampled_schedules = []</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.target_columns","title":"<code>target_columns = target_columns</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.target_labels_dict","title":"<code>target_labels_dict = {k: vfor (k, v) in target_labels.groupby(target_columns)}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.target_sizes","title":"<code>target_sizes = {k: len(v)for (k, v) in self.target_labels_dict.items()}</code>  <code>instance-attribute</code>","text":""},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.finish","title":"<code>finish()</code>","text":"Source code in <code>caveat/samplers.py</code> <pre><code>def finish(self):\n\n    if len(self.sampled_labels) == 0:\n        return pd.DataFrame(), pd.DataFrame()\n\n    sampled_labels = pd.concat(\n        self.sampled_labels, axis=0, ignore_index=True\n    )\n\n    sampled_schedules = pd.concat(\n        self.sampled_schedules, axis=0, ignore_index=True\n    )\n    sampled_schedules = sampled_schedules.set_index(\n        pd.Series(range(len(sampled_schedules)))\n    )\n    return (sampled_labels, sampled_schedules)\n</code></pre>"},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.is_done","title":"<code>is_done()</code>","text":"Source code in <code>caveat/samplers.py</code> <pre><code>def is_done(self):\n    if self.nfound() == self.n:\n        return True\n    return False\n</code></pre>"},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.nfound","title":"<code>nfound()</code>","text":"Source code in <code>caveat/samplers.py</code> <pre><code>def nfound(self):\n    return sum(self.found_sizes.values())\n</code></pre>"},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.print","title":"<code>print(verbose=False)</code>","text":"Source code in <code>caveat/samplers.py</code> <pre><code>def print(self, verbose=False):\n    perc = self.nfound() / self.n\n    print(\n        f\"Sampled {perc:.2%} of target labels in {self.sample_n} sampling iterations.)\"\n    )\n    if verbose:\n        print(\"Unsampled_labels:\")\n        for i, n in self.target_sizes.items():\n            found = self.found_sizes[i]\n            if found &lt; n:\n                print(f\"&lt;!&gt;{i}: {found/n:.2%} of {n} found.\")\n</code></pre>"},{"location":"reference/caveat/samplers/#caveat.samplers.TargetLabelSampler.sample","title":"<code>sample(labels, schedules)</code>","text":"Source code in <code>caveat/samplers.py</code> <pre><code>def sample(self, labels, schedules):\n\n    assert \"pid\" in labels.columns\n    assert \"pid\" in schedules.columns\n    assert all(column in labels.columns for column in self.target_columns)\n\n    self.sample_n += 1\n    print(\"Sampling iteration \", self.sample_n)\n\n    labels_dict = {k: v for k, v in labels.groupby(self.target_columns)}\n\n    for target_label, target_data in self.target_labels_dict.items():\n\n        if target_data is None or len(target_data) == 0:\n            continue\n\n        found_data = labels_dict.get(target_label)\n        if found_data is None or len(found_data) == 0:\n            continue\n\n        n_extract = min(len(target_data), len(found_data))\n        self.found_sizes[target_label] += n_extract\n        found_idx = target_data.index[:n_extract]\n\n        # labels\n        sampled_labels = target_data.iloc[:n_extract].copy()\n        sampled_pids = sampled_labels[\"pid\"]\n\n        sampled_labels[\"pid\"] = range(self.i, self.i + n_extract)\n        self.sampled_labels.append(sampled_labels)\n\n        # schedules\n        sampled_schedules = schedules[\n            schedules[\"pid\"].isin(sampled_pids)\n        ].copy()\n        sampled_schedules[\"pid\"] = sampled_schedules.groupby(\"pid\").ngroup()\n        sampled_schedules[\"pid\"] += self.i\n        self.sampled_schedules.append(sampled_schedules)\n\n        # update\n        target_data.drop(found_idx, inplace=True, axis=0)  # is this ok?\n        self.i += n_extract\n\n    print()  # not a mistake\n</code></pre>"},{"location":"reference/caveat/tune/","title":"caveat.tune","text":""},{"location":"reference/caveat/tune/#caveat.tune.best_callback","title":"<code>best_callback(study, trial)</code>","text":"Source code in <code>caveat/tune.py</code> <pre><code>def best_callback(study, trial):\n    if study.best_trial.number == trial.number:\n        study.set_user_attr(\"config\", trial.user_attrs[\"config\"])\n</code></pre>"},{"location":"reference/caveat/tune/#caveat.tune.build_config","title":"<code>build_config(trial, config)</code>","text":"<p>Iterate through the config leaves and parse the values</p> Source code in <code>caveat/tune.py</code> <pre><code>def build_config(trial: optuna.Trial, config: dict) -&gt; dict:\n    \"\"\"Iterate through the config leaves and parse the values\"\"\"\n    new_config = copy.deepcopy(config)\n    new_config = build_suggestions(trial, new_config)\n    return new_config\n</code></pre>"},{"location":"reference/caveat/tune/#caveat.tune.build_suggestions","title":"<code>build_suggestions(trial, config)</code>","text":"Source code in <code>caveat/tune.py</code> <pre><code>def build_suggestions(trial: optuna.Trial, config: dict):\n    for k, v in config.copy().items():\n        if isinstance(v, dict):\n            config[k] = build_suggestions(trial, v)\n        else:\n            found, suggestion = parse_suggestion(trial, v)\n            if found:\n                config.pop(k)\n                config[k] = suggestion\n    return config\n</code></pre>"},{"location":"reference/caveat/tune/#caveat.tune.build_trail_trainer","title":"<code>build_trail_trainer(trial, logger, config)</code>","text":"Source code in <code>caveat/tune.py</code> <pre><code>def build_trail_trainer(\n    trial: optuna.Trial, logger: TensorBoardLogger, config: dict\n) -&gt; Trainer:\n    trainer_config = config.get(\"trainer_params\", {})\n    patience = trainer_config.pop(\"patience\", 5)\n    checkpoint_callback = ModelCheckpoint(\n        dirpath=Path(logger.log_dir, \"checkpoints\"),\n        monitor=\"val_loss\",\n        save_top_k=2,\n        save_weights_only=False,\n    )\n    loss_scheduling = trainer_config.pop(\"loss_scheduling\", {})\n    custom_loss_scheduler = LinearLossScheduler(loss_scheduling)\n    return Trainer(\n        logger=logger,\n        callbacks=[\n            PyTorchLightningPruningCallback(\n                trial, monitor=\"val_loss\", mode=\"min\"\n            ),\n            EarlyStopping(\n                monitor=\"val_loss\", patience=patience, stopping_threshold=0.0\n            ),\n            LearningRateMonitor(),\n            checkpoint_callback,\n            custom_loss_scheduler,\n        ],\n        **trainer_config,\n    )\n</code></pre>"},{"location":"reference/caveat/tune/#caveat.tune.build_trial_name","title":"<code>build_trial_name(number)</code>","text":"Source code in <code>caveat/tune.py</code> <pre><code>def build_trial_name(number: int) -&gt; str:\n    return str(number).zfill(4)\n</code></pre>"},{"location":"reference/caveat/tune/#caveat.tune.parse_suggestion","title":"<code>parse_suggestion(trial, value)</code>","text":"<p>Execute the value and return the suggested value. Or return Nones if not a suggestion.</p> Source code in <code>caveat/tune.py</code> <pre><code>def parse_suggestion(trial, value: str):\n    \"\"\"Execute the value and return the suggested value.\n    Or return Nones if not a suggestion.\n    \"\"\"\n    if isinstance(value, str) and value.startswith(\"trial.suggest\"):\n        return True, eval(value)\n    else:\n        return False, None\n</code></pre>"},{"location":"reference/caveat/tune/#caveat.tune.skey","title":"<code>skey(key)</code>","text":"Source code in <code>caveat/tune.py</code> <pre><code>def skey(key: str) -&gt; str:\n    ks = key.split(\"_\")\n    if len(ks) &gt; 1:\n        return \"\".join([k[0].upper() for k in ks])\n    length = len(key)\n    if length &gt; 3:\n        return key[:4]\n    return key\n</code></pre>"},{"location":"reference/caveat/tune/#caveat.tune.svalue","title":"<code>svalue(value)</code>","text":"Source code in <code>caveat/tune.py</code> <pre><code>def svalue(value) -&gt; str:\n    if isinstance(value, float):\n        return f\"{value:.2e}\"\n    return str(value)\n</code></pre>"},{"location":"reference/caveat/tune/#caveat.tune.tune_command","title":"<code>tune_command(config, verbose=False, gen=True, test=False, infer=True)</code>","text":"<p>Tune the hyperparameters of the model using optuna.</p> PARAMETER DESCRIPTION <code>config</code> <p>The configuration dictionary.</p> <p> TYPE: <code>dict</code> </p> <code>verbose</code> <p>Whether to print verbose output. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>gen</code> <p>Whether to generate synthetic data. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>test</code> <p>Whether to test the model. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>infer</code> <p>Whether to infer the model. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>None</code> <p>None</p> Source code in <code>caveat/tune.py</code> <pre><code>def tune_command(\n    config: dict,\n    verbose: bool = False,\n    gen: bool = True,\n    test: bool = False,\n    infer=True,\n) -&gt; None:\n    \"\"\"\n    Tune the hyperparameters of the model using optuna.\n\n    Args:\n        config (dict): The configuration dictionary.\n        verbose (bool, optional): Whether to print verbose output. Defaults to False.\n        gen (bool, optional): Whether to generate synthetic data. Defaults to True.\n        test (bool, optional): Whether to test the model. Defaults to False.\n        infer (bool, optional): Whether to infer the model. Defaults to True.\n\n    Returns:\n        None\n\n    \"\"\"\n    logger_params = config.get(\"logging_params\", {})\n    log_dir = Path(logger_params.get(\"log_dir\", \"logs\"))\n    name = str(\n        logger_params.get(\n            \"name\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        )\n    )\n    base_logger = runners.initiate_logger(log_dir, name)\n    base_dir = base_logger.log_dir\n    seed = config.pop(\"seed\", seeder())\n\n    # load data\n    input_schedules, input_attributes, synthetic_attributes = runners.load_data(\n        config\n    )\n\n    trials = config.get(\"tune\", {}).get(\"trials\", 20)\n    prune = config.get(\"tune\", {}).get(\"prune\", True)\n    timeout = config.get(\"tune\", {}).get(\"timeout\", 600)\n\n    def objective(trial: optuna.Trial) -&gt; float:\n\n        torch.manual_seed(seed)\n        if cuda_available():\n            torch.set_float32_matmul_precision(\"medium\")\n        torch.cuda.empty_cache()\n\n        trial_config = build_config(trial, config)\n\n        trial_name = build_trial_name(trial.number)\n        logger = runners.initiate_logger(base_dir, trial_name)\n\n        # encode data\n        label_encoder, encoded_labels, label_weights = (\n            runners.encode_input_labels(\n                logger.log_dir, input_attributes, trial_config\n            )\n        )\n\n        _, encoded_schedules, data_loader = runners.encode_schedules(\n            logger.log_dir,\n            input_schedules,\n            encoded_labels,\n            label_weights,\n            trial_config,\n        )\n\n        # build model\n        ckpt_path = trial_config.get(\"ckpt_path\", None)\n        if ckpt_path is not None:\n            model = runners.load_model(ckpt_path, trial_config)\n        else:\n            label_kwargs = label_encoder.label_kwargs if label_encoder else {}\n            model = runners.build_model(\n                encoded_schedules, trial_config, test, gen, label_kwargs\n            )\n\n        trainer = runners.build_trainer(logger, trial_config)\n        trainer.logger.log_hyperparams(trial.params)\n\n        trial.set_user_attr(\"config\", trial_config)\n\n        trainer.fit(model, datamodule=data_loader)\n\n        return trainer.callback_metrics[\"val_loss\"].item()\n\n    if prune:\n        pruner = optuna.pruners.MedianPruner()\n    else:\n        pruner = optuna.pruners.NopPruner()\n\n    db_name = f\"sqlite:///{base_dir}/optuna.db\"\n    print(f\"Study logging to {db_name}\")\n    study = optuna.create_study(\n        storage=db_name,\n        study_name=name,\n        direction=\"minimize\",\n        sampler=optuna.samplers.TPESampler(seed=seed),\n        pruner=pruner,\n    )\n    study.optimize(\n        objective, n_trials=trials, timeout=timeout, callbacks=[best_callback]\n    )\n\n    config = study.user_attrs[\"config\"]\n    config[\"logging_params\"][\"log_dir\"] = base_dir\n    config[\"logging_params\"][\"name\"] = \"best_trial\"\n\n    best_trial = study.best_trial\n    print(\"Best params:\", best_trial.params)\n    print(\"=============================================\")\n\n    runners.run_command(\n        config, verbose=verbose, gen=gen, test=test, infer=infer\n    )\n    print(\"=============================================\")\n    print(f\"Best ({best_trial.value}) params: {best_trial.params}\")\n</code></pre>"}]}